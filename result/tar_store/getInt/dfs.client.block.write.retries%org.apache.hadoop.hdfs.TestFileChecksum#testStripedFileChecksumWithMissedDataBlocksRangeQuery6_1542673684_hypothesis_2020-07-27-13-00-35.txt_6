reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589842360-172.17.0.14-1595854930420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-1b968d27-2cc0-4855-97e6-805141eb0c55,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-b799abb6-d96a-4cdd-b850-edef62febaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-003976fa-470e-459b-8ad6-b774702583b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-8adcaf27-14c4-49e4-b14f-b6d2a14ea691,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-f15afb0f-7532-4899-a0cd-1f12f7f7ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-b29606a9-5262-41e8-9ca3-969b9e48a616,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-1c3d2838-cd30-4438-bee9-9e0c19dadefc,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-e0a6dce8-9959-48d6-bd2e-82dc0fbb02ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589842360-172.17.0.14-1595854930420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-1b968d27-2cc0-4855-97e6-805141eb0c55,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-b799abb6-d96a-4cdd-b850-edef62febaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-003976fa-470e-459b-8ad6-b774702583b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-8adcaf27-14c4-49e4-b14f-b6d2a14ea691,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-f15afb0f-7532-4899-a0cd-1f12f7f7ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-b29606a9-5262-41e8-9ca3-969b9e48a616,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-1c3d2838-cd30-4438-bee9-9e0c19dadefc,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-e0a6dce8-9959-48d6-bd2e-82dc0fbb02ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148062253-172.17.0.14-1595855024680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-a0aeedd4-6bf4-4674-907d-d8796249d20d,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-980231f9-616a-4577-b318-e1158ce97ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-5fad62d4-bdc2-4ee0-9c1f-6f6e30b116f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-0bd33b1a-0359-4ad0-9aa1-125a3fe8c646,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-fa09992d-4a40-48f6-89a4-fed677981ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-d2f325c6-3655-4283-bc11-d398caf55bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-a287e332-74c2-4feb-a4ae-97631d02cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-db697f7b-1e04-4ec9-89f6-6fff7c6c07a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148062253-172.17.0.14-1595855024680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-a0aeedd4-6bf4-4674-907d-d8796249d20d,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-980231f9-616a-4577-b318-e1158ce97ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-5fad62d4-bdc2-4ee0-9c1f-6f6e30b116f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-0bd33b1a-0359-4ad0-9aa1-125a3fe8c646,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-fa09992d-4a40-48f6-89a4-fed677981ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-d2f325c6-3655-4283-bc11-d398caf55bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-a287e332-74c2-4feb-a4ae-97631d02cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-db697f7b-1e04-4ec9-89f6-6fff7c6c07a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183450110-172.17.0.14-1595855477507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-c801c23a-11ad-4e6f-a44b-aefd81e39f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8a762746-de06-4ea9-8cfe-d53b9f517534,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-eb58b227-1536-4efe-87f4-9421b95440b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-c67017cf-0d15-4ef1-937f-49d9a572ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-fba21d6f-290f-4b92-843d-3b5b796c4e18,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-e12f060b-d052-41c7-acda-501426d91b94,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-98f6f8a4-5c7a-46b9-adf1-43da78003206,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-77cb8389-1bed-4bf7-aba2-c6338f92c987,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183450110-172.17.0.14-1595855477507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-c801c23a-11ad-4e6f-a44b-aefd81e39f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8a762746-de06-4ea9-8cfe-d53b9f517534,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-eb58b227-1536-4efe-87f4-9421b95440b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-c67017cf-0d15-4ef1-937f-49d9a572ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-fba21d6f-290f-4b92-843d-3b5b796c4e18,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-e12f060b-d052-41c7-acda-501426d91b94,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-98f6f8a4-5c7a-46b9-adf1-43da78003206,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-77cb8389-1bed-4bf7-aba2-c6338f92c987,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975382123-172.17.0.14-1595855586402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-151d8b65-2a3c-433d-b782-9b02e57ca889,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-4cb5250e-3b1c-4dee-9882-289c772fcb18,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-e1bd7b80-5543-47fb-87cb-0d493dd4be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-8333ebc2-0e0d-4dea-9f48-729e07fe4f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-3f9914c5-bae4-49da-af78-e142647da14b,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-829d5e93-b530-4a8c-8964-9a28857cc864,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-fa6bfcfc-364a-467d-87e2-144cfe0afa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-7e2aa343-a879-4487-80cd-38f330ce30ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975382123-172.17.0.14-1595855586402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-151d8b65-2a3c-433d-b782-9b02e57ca889,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-4cb5250e-3b1c-4dee-9882-289c772fcb18,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-e1bd7b80-5543-47fb-87cb-0d493dd4be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-8333ebc2-0e0d-4dea-9f48-729e07fe4f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-3f9914c5-bae4-49da-af78-e142647da14b,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-829d5e93-b530-4a8c-8964-9a28857cc864,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-fa6bfcfc-364a-467d-87e2-144cfe0afa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-7e2aa343-a879-4487-80cd-38f330ce30ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003826261-172.17.0.14-1595855950918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-e9bf4d3c-0a6e-4df9-b423-b985ed0dc07b,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-bd7247f2-9619-41d8-a31e-c95e9900f1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-117279e9-f02d-44df-a887-8b2941ad7a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-0388846e-cb0f-4ee6-9f48-7dc9ddf92642,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-29df7358-1cc1-4c5e-9971-75d606405d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-76cb6ac4-db47-451d-94eb-49a36c59b9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-541d8d15-e634-498a-9683-ead111679254,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-0977c0ca-8e41-403e-8319-119e2c8abb71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003826261-172.17.0.14-1595855950918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-e9bf4d3c-0a6e-4df9-b423-b985ed0dc07b,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-bd7247f2-9619-41d8-a31e-c95e9900f1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-117279e9-f02d-44df-a887-8b2941ad7a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-0388846e-cb0f-4ee6-9f48-7dc9ddf92642,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-29df7358-1cc1-4c5e-9971-75d606405d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-76cb6ac4-db47-451d-94eb-49a36c59b9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-541d8d15-e634-498a-9683-ead111679254,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-0977c0ca-8e41-403e-8319-119e2c8abb71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418049353-172.17.0.14-1595855986989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-5a4050b5-03b6-4a36-953f-1eac1ff2d326,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-f5ecb7b4-2956-4d04-aa40-404c85d0f9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-0f2f575c-401b-4510-94cf-8f5f6fea9f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-a9643d0b-80c7-43c8-acb5-6b839b39f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-1c3c39a6-7d5b-42a7-87b6-e57c1de841d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-f367eab8-93de-4cb3-a5d3-e65984fcd893,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-51bdb86c-6bb4-4d49-a2ae-f5f64145d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-16e45d50-2684-4b03-a4f3-ae45ab3a8615,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418049353-172.17.0.14-1595855986989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-5a4050b5-03b6-4a36-953f-1eac1ff2d326,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-f5ecb7b4-2956-4d04-aa40-404c85d0f9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-0f2f575c-401b-4510-94cf-8f5f6fea9f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-a9643d0b-80c7-43c8-acb5-6b839b39f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-1c3c39a6-7d5b-42a7-87b6-e57c1de841d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-f367eab8-93de-4cb3-a5d3-e65984fcd893,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-51bdb86c-6bb4-4d49-a2ae-f5f64145d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-16e45d50-2684-4b03-a4f3-ae45ab3a8615,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793946179-172.17.0.14-1595856214029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46084,DS-4c5979b4-a2dd-4093-9f02-126a47995c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-700d8f92-9c44-4d08-861f-f33fff124b25,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-997bff9a-c394-48fc-8a52-7a9907d647e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-743ae368-2db4-4e23-81ce-d877ee1cb8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-9a766188-1061-463b-a1be-e98a194a6f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-7ddf1f0e-3ff4-4e43-834d-98e7555d4b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-51f64ab7-6289-498a-92c9-e5d984677cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-08d894fa-eb56-4b1a-8ed9-b70cf9bed738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793946179-172.17.0.14-1595856214029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46084,DS-4c5979b4-a2dd-4093-9f02-126a47995c04,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-700d8f92-9c44-4d08-861f-f33fff124b25,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-997bff9a-c394-48fc-8a52-7a9907d647e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-743ae368-2db4-4e23-81ce-d877ee1cb8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-9a766188-1061-463b-a1be-e98a194a6f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-7ddf1f0e-3ff4-4e43-834d-98e7555d4b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-51f64ab7-6289-498a-92c9-e5d984677cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-08d894fa-eb56-4b1a-8ed9-b70cf9bed738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052079895-172.17.0.14-1595856323842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33171,DS-813a65af-1092-4fe5-a55d-5ee292081452,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-e8f034ff-4d5c-4afc-a16b-7f9414757fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-2316ce75-ab5f-4d37-95f5-5546211319b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-123e2a8d-3325-4003-aea6-cb1237046d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-3d886de2-6730-49b9-96fa-4a6cd88afd15,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-e777860b-88ed-4d8e-abee-b61dc2671495,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-c0124805-83e4-4f2a-8f39-e3dc15f5d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-3a9c676d-17d0-4e85-a684-a657c2787b20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052079895-172.17.0.14-1595856323842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33171,DS-813a65af-1092-4fe5-a55d-5ee292081452,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-e8f034ff-4d5c-4afc-a16b-7f9414757fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-2316ce75-ab5f-4d37-95f5-5546211319b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-123e2a8d-3325-4003-aea6-cb1237046d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-3d886de2-6730-49b9-96fa-4a6cd88afd15,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-e777860b-88ed-4d8e-abee-b61dc2671495,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-c0124805-83e4-4f2a-8f39-e3dc15f5d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-3a9c676d-17d0-4e85-a684-a657c2787b20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457382291-172.17.0.14-1595856499414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-b03bdb2c-731f-4f1d-a6ac-05f16e6f5a82,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-bea4bd57-6659-4f3a-a3f6-a29497fcc1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-731b4209-f231-428a-9bf5-6507aec98ede,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-5a1626f0-305d-4c15-ae94-2563cac5c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-8b78a442-b93c-4d41-ade4-eef5c12fba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-54141331-e478-4392-aa29-47a53e7a3068,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-30849788-9eaa-4e51-be12-31967e10e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-f628711d-79d8-4ce9-b4f5-4597d4541815,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457382291-172.17.0.14-1595856499414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-b03bdb2c-731f-4f1d-a6ac-05f16e6f5a82,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-bea4bd57-6659-4f3a-a3f6-a29497fcc1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-731b4209-f231-428a-9bf5-6507aec98ede,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-5a1626f0-305d-4c15-ae94-2563cac5c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-8b78a442-b93c-4d41-ade4-eef5c12fba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-54141331-e478-4392-aa29-47a53e7a3068,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-30849788-9eaa-4e51-be12-31967e10e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-f628711d-79d8-4ce9-b4f5-4597d4541815,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315280949-172.17.0.14-1595856635498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-ab26cd4b-d712-40df-b646-a1b72d7bc9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-b5da6aa3-b9da-4a85-9d74-b46c6ebc8494,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-a43fd8bc-100a-45f1-9345-3794b51776cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-e0167904-4a35-45ad-9e6d-166a60854be5,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-26fef723-0a92-4210-b922-6dc0df05d720,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-c21ed43e-eadd-4a5d-bee6-76da00357ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-0203317f-72c7-47d7-979f-36763382b1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-a466054f-e9a8-4fcf-a42a-d1d55e1ed464,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315280949-172.17.0.14-1595856635498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-ab26cd4b-d712-40df-b646-a1b72d7bc9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-b5da6aa3-b9da-4a85-9d74-b46c6ebc8494,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-a43fd8bc-100a-45f1-9345-3794b51776cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-e0167904-4a35-45ad-9e6d-166a60854be5,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-26fef723-0a92-4210-b922-6dc0df05d720,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-c21ed43e-eadd-4a5d-bee6-76da00357ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-0203317f-72c7-47d7-979f-36763382b1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-a466054f-e9a8-4fcf-a42a-d1d55e1ed464,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035717968-172.17.0.14-1595856671494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-0f2a2df9-e740-459d-8ffc-8b7ffb522c83,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-87fc8152-c4ac-4ed4-aa5e-e7864cd64c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-c5a4a132-b2f6-4da1-a761-0dbcd07be117,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-dd89fbe4-bbfe-4d43-b18f-2caf02cd9bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-899c3c57-013d-47a1-a99f-d2e2ea2a0f58,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-e65e476b-edc3-4dc4-8093-33ff37a81abc,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-5ef10c17-137a-4168-bad4-66925ed18da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-a5840efe-9ae8-45c8-83e3-ae5030331ded,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035717968-172.17.0.14-1595856671494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-0f2a2df9-e740-459d-8ffc-8b7ffb522c83,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-87fc8152-c4ac-4ed4-aa5e-e7864cd64c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-c5a4a132-b2f6-4da1-a761-0dbcd07be117,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-dd89fbe4-bbfe-4d43-b18f-2caf02cd9bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-899c3c57-013d-47a1-a99f-d2e2ea2a0f58,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-e65e476b-edc3-4dc4-8093-33ff37a81abc,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-5ef10c17-137a-4168-bad4-66925ed18da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-a5840efe-9ae8-45c8-83e3-ae5030331ded,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112508842-172.17.0.14-1595856745525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-fb3b836a-551b-4c78-8969-be8777611430,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-5ed886f2-a52f-4ea0-969f-032269666b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-e7e51940-349d-4306-afba-b1b499942ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-530089b1-a977-431c-a39d-7114990a8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-be3f6638-b9b4-4db4-a97e-6ec02b08d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-383c1794-4a9b-4bd7-a8d9-0ccebbd50bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-202a4f3c-2b1c-4689-acd2-c4ae2c290b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-360ac73a-edae-4f68-a8f5-a9285de07fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112508842-172.17.0.14-1595856745525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-fb3b836a-551b-4c78-8969-be8777611430,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-5ed886f2-a52f-4ea0-969f-032269666b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-e7e51940-349d-4306-afba-b1b499942ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-530089b1-a977-431c-a39d-7114990a8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-be3f6638-b9b4-4db4-a97e-6ec02b08d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-383c1794-4a9b-4bd7-a8d9-0ccebbd50bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-202a4f3c-2b1c-4689-acd2-c4ae2c290b73,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-360ac73a-edae-4f68-a8f5-a9285de07fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483962851-172.17.0.14-1595856781832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32876,DS-0ba151f8-2537-4f5b-9f16-90ca8e23b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-0f16c7ab-c8c5-4775-9bdf-e80f156cefa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-9fe434a7-0c69-4145-a499-243c325bda29,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-8c778b62-5f02-4c95-8a3e-2599540d81cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-ea5e8892-1c8d-4689-825f-c3c0a81e8325,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-d9077f6e-802c-449b-9d93-a5ba6a6245e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-329be33a-f77f-478e-a30f-527da8b4499e,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-fa074cf9-6617-4d7a-ae23-8db07a981a1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483962851-172.17.0.14-1595856781832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32876,DS-0ba151f8-2537-4f5b-9f16-90ca8e23b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-0f16c7ab-c8c5-4775-9bdf-e80f156cefa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-9fe434a7-0c69-4145-a499-243c325bda29,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-8c778b62-5f02-4c95-8a3e-2599540d81cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-ea5e8892-1c8d-4689-825f-c3c0a81e8325,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-d9077f6e-802c-449b-9d93-a5ba6a6245e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-329be33a-f77f-478e-a30f-527da8b4499e,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-fa074cf9-6617-4d7a-ae23-8db07a981a1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143850830-172.17.0.14-1595857180336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44606,DS-5d26a18e-2507-4392-b74a-b0ff82b557d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-f6ff7037-7653-4177-97ca-dea6e33a9eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-15cb3e43-14a2-4a47-9c78-393bf01627bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-7b3a36e8-af7a-4b8a-801e-709714cc280f,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-ad49527d-8a8c-4e53-8002-f1efd99b1100,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-2dea65e7-d860-460c-9ff9-ba8198b9b524,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-82bc30c8-c90c-4c42-98ad-6acba305b5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-c7402c81-8039-4baa-879c-de8a30c4fb2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143850830-172.17.0.14-1595857180336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44606,DS-5d26a18e-2507-4392-b74a-b0ff82b557d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-f6ff7037-7653-4177-97ca-dea6e33a9eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-15cb3e43-14a2-4a47-9c78-393bf01627bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-7b3a36e8-af7a-4b8a-801e-709714cc280f,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-ad49527d-8a8c-4e53-8002-f1efd99b1100,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-2dea65e7-d860-460c-9ff9-ba8198b9b524,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-82bc30c8-c90c-4c42-98ad-6acba305b5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-c7402c81-8039-4baa-879c-de8a30c4fb2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487634875-172.17.0.14-1595857447437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-4969d215-c1de-4932-8cc5-eb49cb325bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-32ecb04a-2059-4308-a4e7-3a530d315a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-7e58afb0-37c8-4b03-b259-72650338408a,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-1f39d97e-49fe-4bb6-ae44-64cb2b0a2b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-28220921-a213-4af3-8162-19e638e3eed0,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-bab50dfc-1df2-4450-b8cb-711f57b53525,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-7f434037-16c5-4a78-9549-b38e3dd7e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-27b383e5-03bb-4b94-9152-1f3a7c9068c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487634875-172.17.0.14-1595857447437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-4969d215-c1de-4932-8cc5-eb49cb325bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-32ecb04a-2059-4308-a4e7-3a530d315a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-7e58afb0-37c8-4b03-b259-72650338408a,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-1f39d97e-49fe-4bb6-ae44-64cb2b0a2b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-28220921-a213-4af3-8162-19e638e3eed0,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-bab50dfc-1df2-4450-b8cb-711f57b53525,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-7f434037-16c5-4a78-9549-b38e3dd7e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-27b383e5-03bb-4b94-9152-1f3a7c9068c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39140715-172.17.0.14-1595857911730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46833,DS-dc889735-729c-47ef-afde-e07a18787f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-b3d7ced4-aa2f-42a4-af07-ebd804f5ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-a9b0023f-9aea-4c0a-9352-e6331513844a,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-bc695a1b-7292-42b9-b7b9-4ff89163ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-73133e17-b4dd-48c7-bd03-03869f1b79b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-90131191-4761-4aff-900b-27fe2cabbd23,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-84be7e98-5a27-4385-a2e4-bc817b9e5deb,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-82dde13a-fcfb-4e6b-af2e-e7f689f04f09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39140715-172.17.0.14-1595857911730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46833,DS-dc889735-729c-47ef-afde-e07a18787f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-b3d7ced4-aa2f-42a4-af07-ebd804f5ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-a9b0023f-9aea-4c0a-9352-e6331513844a,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-bc695a1b-7292-42b9-b7b9-4ff89163ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-73133e17-b4dd-48c7-bd03-03869f1b79b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-90131191-4761-4aff-900b-27fe2cabbd23,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-84be7e98-5a27-4385-a2e4-bc817b9e5deb,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-82dde13a-fcfb-4e6b-af2e-e7f689f04f09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684721823-172.17.0.14-1595858391771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-2a992fef-d393-4810-8d7f-ff51e397e275,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-1f40afe7-4b9f-4436-8790-eb8248b6eee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-5e25ce99-d3d4-4b63-b92e-d0e835562dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-660af37e-047e-4d77-9d9a-c3cf659d7714,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-f5a64606-1e44-421d-a5df-6da785116362,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-309f6c0f-021c-43a1-a8ab-c360f8fe67f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-0aca0904-6050-4da8-805d-daf7ba4599ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-c62566f2-9eca-4f2f-88cf-cd81c7523b9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684721823-172.17.0.14-1595858391771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-2a992fef-d393-4810-8d7f-ff51e397e275,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-1f40afe7-4b9f-4436-8790-eb8248b6eee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-5e25ce99-d3d4-4b63-b92e-d0e835562dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-660af37e-047e-4d77-9d9a-c3cf659d7714,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-f5a64606-1e44-421d-a5df-6da785116362,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-309f6c0f-021c-43a1-a8ab-c360f8fe67f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-0aca0904-6050-4da8-805d-daf7ba4599ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-c62566f2-9eca-4f2f-88cf-cd81c7523b9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909476867-172.17.0.14-1595858423977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39674,DS-ed7fb4e2-1ff6-4db7-a188-2988bff4da96,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-68ca8d24-24a0-4cb9-b4db-109fc9be4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-05a871fc-acff-427f-b941-ac137e605180,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-eb21c4de-721d-4b7a-be4c-8f717f834f66,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-b9c333c5-ee64-4d61-b688-7f27df931db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-b8208c2a-4581-4e2d-895d-0d975cc844ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-ed211743-44b6-48bb-a015-3613894ce0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-c53b8814-88c7-49aa-8757-dc0c04f66eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909476867-172.17.0.14-1595858423977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39674,DS-ed7fb4e2-1ff6-4db7-a188-2988bff4da96,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-68ca8d24-24a0-4cb9-b4db-109fc9be4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-05a871fc-acff-427f-b941-ac137e605180,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-eb21c4de-721d-4b7a-be4c-8f717f834f66,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-b9c333c5-ee64-4d61-b688-7f27df931db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-b8208c2a-4581-4e2d-895d-0d975cc844ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-ed211743-44b6-48bb-a015-3613894ce0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-c53b8814-88c7-49aa-8757-dc0c04f66eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954917154-172.17.0.14-1595858535515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-e503e0c6-9b03-40d6-b13e-89968ebf6b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-0ac31b2e-fe98-486e-bf8f-10ae5f4046ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-0bd41feb-f795-4826-9c2f-f9861e54b7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-017bee6f-ac43-4eee-ab9a-fc0077caf76a,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-1060ec29-bb13-4e71-8a94-73a7e16f9e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-a8408860-46af-49db-95ec-8db96ffa914f,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-0996407f-5e3b-46f9-ba5a-0916d67eb212,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-8e81814c-c226-4b63-ad21-ece1c019a82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954917154-172.17.0.14-1595858535515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-e503e0c6-9b03-40d6-b13e-89968ebf6b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-0ac31b2e-fe98-486e-bf8f-10ae5f4046ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-0bd41feb-f795-4826-9c2f-f9861e54b7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-017bee6f-ac43-4eee-ab9a-fc0077caf76a,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-1060ec29-bb13-4e71-8a94-73a7e16f9e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-a8408860-46af-49db-95ec-8db96ffa914f,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-0996407f-5e3b-46f9-ba5a-0916d67eb212,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-8e81814c-c226-4b63-ad21-ece1c019a82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112687708-172.17.0.14-1595858751028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44330,DS-b5b240d5-4d10-4672-9807-7215e8dd58f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-9016db5f-f533-4135-bbef-061636e90b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-96f02587-cf52-4249-8a87-249abaec5f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-6768ea4c-1fd4-46e2-b683-8471738d7b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-74d9f6ee-8ba0-4fcf-a720-82d4ac2998b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-1634de44-f3a7-419b-955a-52384d13d454,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-2d6aaa8e-4c85-42c8-820a-abeda4ba39e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-2f7c8dd4-c5c1-431e-9d08-a00b648c16e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112687708-172.17.0.14-1595858751028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44330,DS-b5b240d5-4d10-4672-9807-7215e8dd58f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-9016db5f-f533-4135-bbef-061636e90b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-96f02587-cf52-4249-8a87-249abaec5f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-6768ea4c-1fd4-46e2-b683-8471738d7b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-74d9f6ee-8ba0-4fcf-a720-82d4ac2998b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-1634de44-f3a7-419b-955a-52384d13d454,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-2d6aaa8e-4c85-42c8-820a-abeda4ba39e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-2f7c8dd4-c5c1-431e-9d08-a00b648c16e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598944947-172.17.0.14-1595858828281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-8a53af58-357f-4105-b177-921938447f85,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-8f610dab-a035-4cc7-a836-e8ce35ef43aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-ba7fcdc4-2b1a-4aac-91ad-f73ca410cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-ad4bce0f-5ce8-4521-a98e-6a2c38882ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-7c3c9542-50e9-44ed-a0a7-51cd3226bf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-c0facb3d-b8d7-47f0-8e2f-33ea5c45f987,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-29e281ee-f29b-4487-aae7-6b006a717154,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-0f9c5c61-d711-40a7-b9f9-5c4fc0afc7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598944947-172.17.0.14-1595858828281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-8a53af58-357f-4105-b177-921938447f85,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-8f610dab-a035-4cc7-a836-e8ce35ef43aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-ba7fcdc4-2b1a-4aac-91ad-f73ca410cddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-ad4bce0f-5ce8-4521-a98e-6a2c38882ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-7c3c9542-50e9-44ed-a0a7-51cd3226bf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-c0facb3d-b8d7-47f0-8e2f-33ea5c45f987,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-29e281ee-f29b-4487-aae7-6b006a717154,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-0f9c5c61-d711-40a7-b9f9-5c4fc0afc7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181117385-172.17.0.14-1595859299475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33691,DS-e39e03b0-f5e8-4db2-bf46-0a900ca8d814,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-8a1226da-41b0-4d3f-9124-51fe05e12318,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-33accaee-499b-474f-814f-e2535e50c77a,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-06078cee-af25-4261-807d-52955f0a0a18,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-b1438452-1db9-4eb1-8553-a18ef5c34528,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-7c7bea06-83a3-4359-a548-104d215330c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-393de03b-f341-4e76-8fe4-087b01e1080c,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-900f73ea-65f1-4b57-aa9f-1c4921f65c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181117385-172.17.0.14-1595859299475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33691,DS-e39e03b0-f5e8-4db2-bf46-0a900ca8d814,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-8a1226da-41b0-4d3f-9124-51fe05e12318,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-33accaee-499b-474f-814f-e2535e50c77a,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-06078cee-af25-4261-807d-52955f0a0a18,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-b1438452-1db9-4eb1-8553-a18ef5c34528,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-7c7bea06-83a3-4359-a548-104d215330c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-393de03b-f341-4e76-8fe4-087b01e1080c,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-900f73ea-65f1-4b57-aa9f-1c4921f65c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436951484-172.17.0.14-1595859406493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33053,DS-b0063a75-6985-4c04-aee3-31dc82652dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-400d9801-4223-4f24-ac13-9cf6a8b3f0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f053266b-8dfa-415e-aabf-5d40b1e75598,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-42eec29c-5913-4c79-a855-0305f4526350,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-cee682c9-f097-4c72-9eb4-9016f2daadcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-fa3ae04e-df72-4344-a2e5-d10e90f116d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-b180b787-7e51-4e1e-9a61-f1131c300342,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-cbe3a618-5716-4f1d-82e8-b8182f678ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436951484-172.17.0.14-1595859406493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33053,DS-b0063a75-6985-4c04-aee3-31dc82652dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-400d9801-4223-4f24-ac13-9cf6a8b3f0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f053266b-8dfa-415e-aabf-5d40b1e75598,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-42eec29c-5913-4c79-a855-0305f4526350,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-cee682c9-f097-4c72-9eb4-9016f2daadcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-fa3ae04e-df72-4344-a2e5-d10e90f116d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-b180b787-7e51-4e1e-9a61-f1131c300342,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-cbe3a618-5716-4f1d-82e8-b8182f678ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343482314-172.17.0.14-1595859713770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-a8bb4780-082b-4bec-a10d-5a35d8ee2217,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-42b96fd3-e2d1-455d-b43b-11f9c9dbc288,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-d99968d0-238a-4af8-ad68-4334eb0040a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-7322f047-f2c2-4a6e-b7e9-4b69406a1195,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-4b7baa3a-3adc-411a-84fe-abe5180c2600,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-65c533d9-5d41-44a6-8381-a0504b0af1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-ed8a094a-84cf-4de8-8e58-73527b0482db,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-4c16661c-e7fa-4757-b0cc-92cf144f83ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343482314-172.17.0.14-1595859713770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-a8bb4780-082b-4bec-a10d-5a35d8ee2217,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-42b96fd3-e2d1-455d-b43b-11f9c9dbc288,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-d99968d0-238a-4af8-ad68-4334eb0040a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-7322f047-f2c2-4a6e-b7e9-4b69406a1195,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-4b7baa3a-3adc-411a-84fe-abe5180c2600,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-65c533d9-5d41-44a6-8381-a0504b0af1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-ed8a094a-84cf-4de8-8e58-73527b0482db,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-4c16661c-e7fa-4757-b0cc-92cf144f83ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173941545-172.17.0.14-1595859753984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45605,DS-527463a2-68fc-4b97-b341-cff4f29213fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-528a9447-cf46-4c58-bea5-e39fcdd925ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-ed917ed6-9a46-4a25-bc25-79b2062c7afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-27049ae9-b0f2-4b6b-b4f0-0d8d3de0b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-a297fe0e-2da5-4fc8-8a2f-5cbfb926dfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-cc79113c-d3b5-4670-9be1-2981747fa0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-33516254-ec21-44ad-9c29-50850baa5bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-30ffed03-a1bb-4a41-a839-c5a06d5706d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173941545-172.17.0.14-1595859753984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45605,DS-527463a2-68fc-4b97-b341-cff4f29213fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-528a9447-cf46-4c58-bea5-e39fcdd925ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-ed917ed6-9a46-4a25-bc25-79b2062c7afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-27049ae9-b0f2-4b6b-b4f0-0d8d3de0b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-a297fe0e-2da5-4fc8-8a2f-5cbfb926dfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-cc79113c-d3b5-4670-9be1-2981747fa0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-33516254-ec21-44ad-9c29-50850baa5bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-30ffed03-a1bb-4a41-a839-c5a06d5706d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073581697-172.17.0.14-1595859990025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41098,DS-02df1d8c-a3a2-4900-8ca1-b2cc810db46a,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-e5cc942e-dd5b-49ac-8683-e91ee290202b,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-c734f69a-9688-4c81-a3aa-4cac42dbc1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-c16b407b-3e38-4c07-9fae-bf4cc6cee00b,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-6156e85c-77e7-4307-83eb-40a0f2b98b28,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-62564a10-4e34-4143-b4ed-902cb4521547,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-0e7d06f8-105d-4a09-b3f7-7d9fd19b2a11,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-b09bde82-14cb-41e1-b886-31d9cb7a530b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073581697-172.17.0.14-1595859990025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41098,DS-02df1d8c-a3a2-4900-8ca1-b2cc810db46a,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-e5cc942e-dd5b-49ac-8683-e91ee290202b,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-c734f69a-9688-4c81-a3aa-4cac42dbc1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-c16b407b-3e38-4c07-9fae-bf4cc6cee00b,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-6156e85c-77e7-4307-83eb-40a0f2b98b28,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-62564a10-4e34-4143-b4ed-902cb4521547,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-0e7d06f8-105d-4a09-b3f7-7d9fd19b2a11,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-b09bde82-14cb-41e1-b886-31d9cb7a530b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412855027-172.17.0.14-1595860063425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41353,DS-b994c2e1-232c-4219-a401-2619ef893dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-540af36f-e4eb-485a-abd5-8bae12d12fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-8a7c2ab9-4d8b-49bd-a92f-b91507ce47c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-b53c6376-975a-4190-8775-7f2546e5d503,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-57c1d036-0f95-4a12-890d-684a5a5aad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-7969ce63-4c9f-4775-997a-7b75aa4fa465,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-9205dcf7-d5bd-4d90-96ff-bcf8a9db858b,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-c8ce15ef-b295-4f9e-9f96-731ebd321bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412855027-172.17.0.14-1595860063425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41353,DS-b994c2e1-232c-4219-a401-2619ef893dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-540af36f-e4eb-485a-abd5-8bae12d12fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-8a7c2ab9-4d8b-49bd-a92f-b91507ce47c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-b53c6376-975a-4190-8775-7f2546e5d503,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-57c1d036-0f95-4a12-890d-684a5a5aad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-7969ce63-4c9f-4775-997a-7b75aa4fa465,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-9205dcf7-d5bd-4d90-96ff-bcf8a9db858b,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-c8ce15ef-b295-4f9e-9f96-731ebd321bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044310675-172.17.0.14-1595860216612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33631,DS-1245a319-58db-4231-8457-069d55e1cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-18de8cda-f9f1-4698-96ca-0a1927b82204,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-c17118ef-6565-4e35-bfec-504480502387,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-1e1bd64f-9554-4f11-9578-9545aa1426b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-f150d64b-970e-4880-9ad1-3ee7a75b69d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-00a57064-4499-4ceb-87a4-bf1e78368541,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-7972260c-9296-4b77-a906-02b4c9f0bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-5963de00-a15e-4b0c-b095-0ec455f9be74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044310675-172.17.0.14-1595860216612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33631,DS-1245a319-58db-4231-8457-069d55e1cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-18de8cda-f9f1-4698-96ca-0a1927b82204,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-c17118ef-6565-4e35-bfec-504480502387,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-1e1bd64f-9554-4f11-9578-9545aa1426b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-f150d64b-970e-4880-9ad1-3ee7a75b69d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-00a57064-4499-4ceb-87a4-bf1e78368541,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-7972260c-9296-4b77-a906-02b4c9f0bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-5963de00-a15e-4b0c-b095-0ec455f9be74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184682249-172.17.0.14-1595860332827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-d720bf98-8ca6-44cf-81cc-bccb872a09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-96dabefe-54da-4608-a8ee-01b641c74bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-9ceb94b1-b0da-4202-a5f6-3f6d3f1fc017,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-a92f2e08-c6c1-4598-b717-89b00d01eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-8e886d8c-da42-404e-b720-5e8ed2448658,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-1df524eb-26e7-4c17-9cf0-2ebb59bf8e07,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-01b6612a-b1d6-4ede-9838-58ec2e7f0f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-e403c275-e671-4c3b-b531-540d0d75d577,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184682249-172.17.0.14-1595860332827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-d720bf98-8ca6-44cf-81cc-bccb872a09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-96dabefe-54da-4608-a8ee-01b641c74bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-9ceb94b1-b0da-4202-a5f6-3f6d3f1fc017,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-a92f2e08-c6c1-4598-b717-89b00d01eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-8e886d8c-da42-404e-b720-5e8ed2448658,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-1df524eb-26e7-4c17-9cf0-2ebb59bf8e07,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-01b6612a-b1d6-4ede-9838-58ec2e7f0f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-e403c275-e671-4c3b-b531-540d0d75d577,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5561
