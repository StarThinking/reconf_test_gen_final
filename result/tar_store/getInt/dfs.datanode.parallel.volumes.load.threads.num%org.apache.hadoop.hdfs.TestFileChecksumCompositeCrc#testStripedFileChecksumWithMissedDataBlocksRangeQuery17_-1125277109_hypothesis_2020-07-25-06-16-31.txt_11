reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344189944-172.17.0.11-1595657912091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43470,DS-20def38a-6dd0-483d-a39f-a2b77b8f95f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-49a27993-0390-4209-b42b-0a633173af42,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-a402f587-a2b7-4b4e-8ea0-7e315063b6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-a78685c2-0a8f-432e-9432-9863c5f2fda9,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-e4ab94c6-d837-48b1-9e39-f4e90eec305c,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-8d701fdc-6e0c-431a-ad66-a75813403ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-ccfafc99-0fcf-42ee-951a-943ddae2c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-018f21f3-3dc5-435c-9a53-06564684b1c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344189944-172.17.0.11-1595657912091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43470,DS-20def38a-6dd0-483d-a39f-a2b77b8f95f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-49a27993-0390-4209-b42b-0a633173af42,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-a402f587-a2b7-4b4e-8ea0-7e315063b6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-a78685c2-0a8f-432e-9432-9863c5f2fda9,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-e4ab94c6-d837-48b1-9e39-f4e90eec305c,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-8d701fdc-6e0c-431a-ad66-a75813403ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-ccfafc99-0fcf-42ee-951a-943ddae2c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-018f21f3-3dc5-435c-9a53-06564684b1c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2008583946-172.17.0.11-1595658007864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34553,DS-98e26824-9b3a-4852-bda6-beced3cb46b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-657c984f-d372-4b5f-bc28-ecc56498e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-d9f35099-84fd-4906-81f9-743aa1269549,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-8c8872ca-ca5f-495c-bff7-1aef665749b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-7a9124ce-2a42-40d8-ad1a-4942da1c1105,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-98de61e1-073c-4189-8084-71c64e5cda4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-0262566c-2cbe-4721-af5a-ed8bb8135baf,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-93675386-22dd-40d4-96b7-d174e7f2b5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2008583946-172.17.0.11-1595658007864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34553,DS-98e26824-9b3a-4852-bda6-beced3cb46b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-657c984f-d372-4b5f-bc28-ecc56498e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-d9f35099-84fd-4906-81f9-743aa1269549,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-8c8872ca-ca5f-495c-bff7-1aef665749b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-7a9124ce-2a42-40d8-ad1a-4942da1c1105,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-98de61e1-073c-4189-8084-71c64e5cda4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-0262566c-2cbe-4721-af5a-ed8bb8135baf,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-93675386-22dd-40d4-96b7-d174e7f2b5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988455820-172.17.0.11-1595658411870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33428,DS-1939e384-14ef-4123-b9aa-ec15ccd9f9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-f510e929-b2c6-426c-8e8a-a0c4f302b892,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-35820003-0056-4135-b016-3913485ab157,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-eea67d6d-b3f8-485c-ab32-92ffa544b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-2b07c0f8-43b7-49a6-adaa-bd8155b9a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-40d9888d-945b-4319-b970-a69aa9909bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-c1236c90-1043-4fa0-a04e-f284803dc800,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-013d0071-019b-46cb-ac3c-a6df22dc4f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988455820-172.17.0.11-1595658411870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33428,DS-1939e384-14ef-4123-b9aa-ec15ccd9f9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-f510e929-b2c6-426c-8e8a-a0c4f302b892,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-35820003-0056-4135-b016-3913485ab157,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-eea67d6d-b3f8-485c-ab32-92ffa544b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-2b07c0f8-43b7-49a6-adaa-bd8155b9a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-40d9888d-945b-4319-b970-a69aa9909bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-c1236c90-1043-4fa0-a04e-f284803dc800,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-013d0071-019b-46cb-ac3c-a6df22dc4f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723665824-172.17.0.11-1595659039378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-50011b5f-c5d2-43b0-acc4-8f8f6661b07b,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-40eea582-441b-4cc9-90df-53575b57a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-e00d4818-bee8-4b7e-8000-82f18922240b,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-d2bad678-f046-4cbb-bb10-3d003f2190b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-9ccf7cae-814d-4da9-b68d-8392ddc9f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-3a90daab-46d2-4bf7-be56-abfc39923f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-63c14294-3d13-4a3e-9c8a-10e9e6b0556f,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-fc3fd9a9-128c-4f1a-8067-af2e70993c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723665824-172.17.0.11-1595659039378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-50011b5f-c5d2-43b0-acc4-8f8f6661b07b,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-40eea582-441b-4cc9-90df-53575b57a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-e00d4818-bee8-4b7e-8000-82f18922240b,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-d2bad678-f046-4cbb-bb10-3d003f2190b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-9ccf7cae-814d-4da9-b68d-8392ddc9f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-3a90daab-46d2-4bf7-be56-abfc39923f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-63c14294-3d13-4a3e-9c8a-10e9e6b0556f,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-fc3fd9a9-128c-4f1a-8067-af2e70993c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701071163-172.17.0.11-1595659072308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42850,DS-58fda703-610a-4277-b95c-d6cfdf2404c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-69d9f902-e892-4d1f-9a8f-d2763aee4e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-53a3b06e-c036-4a6e-afc6-95dbe472e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-7121d0ab-40f2-49de-95c8-faa448aee739,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-363173f3-b96a-4a7b-9ba2-3a12e71d7a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-b475816f-7064-4f62-a4ab-db24fa7c2043,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-2d9931f8-a71a-498e-bab5-bfac871a0576,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-a1c02857-6680-477f-b412-8d2949a63855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701071163-172.17.0.11-1595659072308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42850,DS-58fda703-610a-4277-b95c-d6cfdf2404c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-69d9f902-e892-4d1f-9a8f-d2763aee4e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-53a3b06e-c036-4a6e-afc6-95dbe472e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-7121d0ab-40f2-49de-95c8-faa448aee739,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-363173f3-b96a-4a7b-9ba2-3a12e71d7a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-b475816f-7064-4f62-a4ab-db24fa7c2043,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-2d9931f8-a71a-498e-bab5-bfac871a0576,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-a1c02857-6680-477f-b412-8d2949a63855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306229028-172.17.0.11-1595659109945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-b3a55f1d-6df9-4ab3-9870-c21d1be3df30,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-bce653f1-6ae7-4ed7-9b6a-43ff0d173d75,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-31babfc2-6270-4bc0-bb4c-411586e79714,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-1bad17de-ee0b-4bbc-a5a5-f35c36be4e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-cf68169f-ffac-443e-ad99-624c485bc672,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-ddfdad6a-5efc-4b27-8594-50d8de72e684,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-681cefd4-d45b-466e-b6b6-2d032756f635,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-dc2b7642-9b03-4d2a-b153-5263b84cfb4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306229028-172.17.0.11-1595659109945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-b3a55f1d-6df9-4ab3-9870-c21d1be3df30,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-bce653f1-6ae7-4ed7-9b6a-43ff0d173d75,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-31babfc2-6270-4bc0-bb4c-411586e79714,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-1bad17de-ee0b-4bbc-a5a5-f35c36be4e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-cf68169f-ffac-443e-ad99-624c485bc672,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-ddfdad6a-5efc-4b27-8594-50d8de72e684,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-681cefd4-d45b-466e-b6b6-2d032756f635,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-dc2b7642-9b03-4d2a-b153-5263b84cfb4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239423352-172.17.0.11-1595659144210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46700,DS-60de799b-d676-4ed6-aaa2-7a7f9cbf0470,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-5c273efe-7f09-4a74-875d-545522fcd349,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-30f6414f-2748-418b-bd79-b7fd9c4da47e,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-0a5d9e7f-1968-4d59-864e-d883e821064e,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-ff7ce976-31e4-4bb5-900b-0b6378a33996,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-fd83d985-ff6c-4c2e-a7a4-bf693d95bb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-b2a861f2-67f7-4644-8a0d-d0808efb0be9,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-1814c194-c39a-4de3-9a93-ddbd65127287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239423352-172.17.0.11-1595659144210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46700,DS-60de799b-d676-4ed6-aaa2-7a7f9cbf0470,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-5c273efe-7f09-4a74-875d-545522fcd349,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-30f6414f-2748-418b-bd79-b7fd9c4da47e,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-0a5d9e7f-1968-4d59-864e-d883e821064e,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-ff7ce976-31e4-4bb5-900b-0b6378a33996,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-fd83d985-ff6c-4c2e-a7a4-bf693d95bb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-b2a861f2-67f7-4644-8a0d-d0808efb0be9,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-1814c194-c39a-4de3-9a93-ddbd65127287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393767603-172.17.0.11-1595659418135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-dd776da7-a93b-405f-bd24-eda463a56a98,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-0c53ed60-0380-472b-82f3-e5d41ae0a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-2cb01486-63da-4e97-ba6a-439b2b78489c,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-52d38df0-66b4-4ee0-ac64-4c375f08d6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-5cd422a2-258a-4c32-94c5-14fa2337cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-a7a6ebd9-8b20-4a6e-b870-a68b4da43400,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-3a620311-2772-4e63-9c87-9f8318513d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-67d481ee-12d0-4044-bac6-bfd77f914176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393767603-172.17.0.11-1595659418135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-dd776da7-a93b-405f-bd24-eda463a56a98,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-0c53ed60-0380-472b-82f3-e5d41ae0a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-2cb01486-63da-4e97-ba6a-439b2b78489c,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-52d38df0-66b4-4ee0-ac64-4c375f08d6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-5cd422a2-258a-4c32-94c5-14fa2337cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-a7a6ebd9-8b20-4a6e-b870-a68b4da43400,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-3a620311-2772-4e63-9c87-9f8318513d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-67d481ee-12d0-4044-bac6-bfd77f914176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361314706-172.17.0.11-1595660167973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-8b0cf9c6-fda0-47fc-9134-5205a288079d,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-1a54191e-418d-4ae9-b6ff-6a0dcd6557e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-3c77d80d-dbe5-4cba-82dc-cec4d5ca2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-762f5ccf-9596-4d27-bfee-08f231c637c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-754eee61-0a52-4d9e-8bcf-4490de6801b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-66f9d3ae-4bd7-4dbb-aec2-ccab292b847d,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-a5e959ee-3827-4838-8c4f-33f1eaaec50d,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-2d23b01a-0233-4191-b1cf-f9d962cd171b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361314706-172.17.0.11-1595660167973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-8b0cf9c6-fda0-47fc-9134-5205a288079d,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-1a54191e-418d-4ae9-b6ff-6a0dcd6557e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-3c77d80d-dbe5-4cba-82dc-cec4d5ca2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-762f5ccf-9596-4d27-bfee-08f231c637c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-754eee61-0a52-4d9e-8bcf-4490de6801b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-66f9d3ae-4bd7-4dbb-aec2-ccab292b847d,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-a5e959ee-3827-4838-8c4f-33f1eaaec50d,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-2d23b01a-0233-4191-b1cf-f9d962cd171b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360428364-172.17.0.11-1595660422291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39586,DS-05ddcf15-7b49-4940-9185-840e3ed9aeab,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d4b17a23-d3d8-4122-b1b5-a383700a2ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-e86f972e-0deb-4aed-95d6-7406e3eade05,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-9d41fbad-a9d5-4401-a33f-7de0bf4e9271,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-6aed4b8d-6b6c-442f-bc03-836b28285a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-0633bcc8-2891-4db9-8346-1fda9b946d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-838c4b7e-5931-4c0b-ae36-e8c41e1055d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-6f81e2d4-f71b-42a9-9fb5-f3e472e6cf40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360428364-172.17.0.11-1595660422291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39586,DS-05ddcf15-7b49-4940-9185-840e3ed9aeab,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d4b17a23-d3d8-4122-b1b5-a383700a2ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-e86f972e-0deb-4aed-95d6-7406e3eade05,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-9d41fbad-a9d5-4401-a33f-7de0bf4e9271,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-6aed4b8d-6b6c-442f-bc03-836b28285a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-0633bcc8-2891-4db9-8346-1fda9b946d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-838c4b7e-5931-4c0b-ae36-e8c41e1055d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-6f81e2d4-f71b-42a9-9fb5-f3e472e6cf40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805720186-172.17.0.11-1595660533008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-9b882a1b-9f1f-4b7f-bfbe-f0a6831b54a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-b31448cf-a27f-4d4a-907d-91a8880a8165,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-1947250e-1533-425b-b153-f3017f2c9d20,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-ad7c9a4c-a6cd-4d68-9b3b-d6b66f7a06e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-cbcb59aa-dd4f-47a7-b62d-15dd213ccb47,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-01d77d14-a56b-4cd3-8ad4-85f4927fff97,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-2872b6e5-fe56-49e2-8282-dadfd178f0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-2c892b90-05b5-4608-8d38-6b9f9fb6839c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805720186-172.17.0.11-1595660533008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-9b882a1b-9f1f-4b7f-bfbe-f0a6831b54a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-b31448cf-a27f-4d4a-907d-91a8880a8165,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-1947250e-1533-425b-b153-f3017f2c9d20,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-ad7c9a4c-a6cd-4d68-9b3b-d6b66f7a06e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-cbcb59aa-dd4f-47a7-b62d-15dd213ccb47,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-01d77d14-a56b-4cd3-8ad4-85f4927fff97,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-2872b6e5-fe56-49e2-8282-dadfd178f0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-2c892b90-05b5-4608-8d38-6b9f9fb6839c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907148600-172.17.0.11-1595661255967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-2361c427-e959-459b-9614-4dd9b0d012d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-548404cb-24da-4ce8-af34-95eace40e55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-3fa7977e-5e1b-4130-8b46-86df7fd8f4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-01775b3e-b892-4d57-8d40-3b2a5499ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-668763f8-b949-4b86-8e1c-e27b17af8667,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-aebe2b9a-4c6e-4b0e-bcf2-868334424d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-80d61b5a-b69c-4762-a742-8f1351b2348e,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-86120c52-d94f-407f-9d75-f379f3fd5781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907148600-172.17.0.11-1595661255967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-2361c427-e959-459b-9614-4dd9b0d012d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-548404cb-24da-4ce8-af34-95eace40e55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-3fa7977e-5e1b-4130-8b46-86df7fd8f4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-01775b3e-b892-4d57-8d40-3b2a5499ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-668763f8-b949-4b86-8e1c-e27b17af8667,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-aebe2b9a-4c6e-4b0e-bcf2-868334424d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-80d61b5a-b69c-4762-a742-8f1351b2348e,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-86120c52-d94f-407f-9d75-f379f3fd5781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819923118-172.17.0.11-1595662033815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34858,DS-e9429c0e-fec8-49c4-9adb-cefecc14c434,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-b7006b87-1d1a-40b6-a189-078716c1f431,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-c3d5b12e-b1af-4c4b-8644-8b16a708cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-356021f8-da30-430d-a50a-894e8ba12095,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-343d5f4a-14cb-427d-b6bc-6868fc803e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-46cfe7f8-2046-4959-9c8c-a5729e0e42bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-644d1663-9c66-45e3-a2a5-733ef04ba931,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-e75cd6c6-2780-41e4-b497-ba9860a8cb0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819923118-172.17.0.11-1595662033815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34858,DS-e9429c0e-fec8-49c4-9adb-cefecc14c434,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-b7006b87-1d1a-40b6-a189-078716c1f431,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-c3d5b12e-b1af-4c4b-8644-8b16a708cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-356021f8-da30-430d-a50a-894e8ba12095,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-343d5f4a-14cb-427d-b6bc-6868fc803e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-46cfe7f8-2046-4959-9c8c-a5729e0e42bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-644d1663-9c66-45e3-a2a5-733ef04ba931,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-e75cd6c6-2780-41e4-b497-ba9860a8cb0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308981494-172.17.0.11-1595662364110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-2acd628f-fc77-47d0-b1e8-62f81a1a77e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-cfdc8df5-dc51-423b-ad2f-1c71ac443d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-6b1f40ea-eb4c-48e3-ae96-da50b17c5324,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-5946346a-9989-4fcc-a956-997f18145eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-2c4d8aac-b40f-47c4-94bf-d1eb5085ae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-b338e851-edf6-4f89-9202-0c561c652c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-cb7a4f05-8117-4141-bbf0-22d293a8e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-f6791987-532c-4538-997b-989df8a24714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308981494-172.17.0.11-1595662364110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-2acd628f-fc77-47d0-b1e8-62f81a1a77e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-cfdc8df5-dc51-423b-ad2f-1c71ac443d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-6b1f40ea-eb4c-48e3-ae96-da50b17c5324,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-5946346a-9989-4fcc-a956-997f18145eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-2c4d8aac-b40f-47c4-94bf-d1eb5085ae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-b338e851-edf6-4f89-9202-0c561c652c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-cb7a4f05-8117-4141-bbf0-22d293a8e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-f6791987-532c-4538-997b-989df8a24714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360354405-172.17.0.11-1595662554327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36054,DS-81336e35-616b-46de-bd9e-6841b37fec95,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-59b53217-b94c-46c0-b400-1e7c9d3195f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-1961a367-a48c-4817-814a-a4888dcf77ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-46a40781-d4ee-4658-9a85-1e3bfc8d5ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-c0e5bd4a-9de2-4d14-a4c5-0bf7edfce68d,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-bddd8074-94dd-43d1-a15d-fe4006e0f60a,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-ea69f9b0-b1c4-48df-95b7-f1e6a9350924,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-17c742a8-cdc6-43c1-9ee7-630353ec1f7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360354405-172.17.0.11-1595662554327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36054,DS-81336e35-616b-46de-bd9e-6841b37fec95,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-59b53217-b94c-46c0-b400-1e7c9d3195f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-1961a367-a48c-4817-814a-a4888dcf77ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-46a40781-d4ee-4658-9a85-1e3bfc8d5ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-c0e5bd4a-9de2-4d14-a4c5-0bf7edfce68d,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-bddd8074-94dd-43d1-a15d-fe4006e0f60a,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-ea69f9b0-b1c4-48df-95b7-f1e6a9350924,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-17c742a8-cdc6-43c1-9ee7-630353ec1f7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283013316-172.17.0.11-1595662592118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34998,DS-e8a85643-c4d6-42b5-bf42-c68eea47ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-522a38b4-98f5-4d33-b16a-09a37c2721bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-c89fab82-cf01-427b-84b8-6290904c38cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-095d16f5-6b32-464f-b6ae-690c5957ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-222c9639-5745-4d88-9161-e787d2fc59e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-36952929-e4fd-409f-acc4-3e55c90eac83,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-9ff98f8e-acb0-4463-a39c-1d3ecbaab5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-dfd33cd9-0cde-4c6a-86cd-1d408fafa039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283013316-172.17.0.11-1595662592118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34998,DS-e8a85643-c4d6-42b5-bf42-c68eea47ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-522a38b4-98f5-4d33-b16a-09a37c2721bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-c89fab82-cf01-427b-84b8-6290904c38cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-095d16f5-6b32-464f-b6ae-690c5957ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-222c9639-5745-4d88-9161-e787d2fc59e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-36952929-e4fd-409f-acc4-3e55c90eac83,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-9ff98f8e-acb0-4463-a39c-1d3ecbaab5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-dfd33cd9-0cde-4c6a-86cd-1d408fafa039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619146007-172.17.0.11-1595662882456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40529,DS-6d48e3f4-29bd-4129-90c3-9b3eafbdce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-3518b454-91f0-4a6d-9e9a-688e0373cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-73a423a7-73bd-40f4-bae5-b7d427f97036,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-04d2b51b-2340-405a-859b-0af3d203d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-d718bf45-3d49-4a2f-a3c3-1457de6a6c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-45dee38d-dadb-44ef-bcac-271f3c4df78c,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-1a448481-edfa-4609-ba69-bcb00daf192e,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-6a7d51bf-3bae-485d-b5bd-e0b7fadfb405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619146007-172.17.0.11-1595662882456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40529,DS-6d48e3f4-29bd-4129-90c3-9b3eafbdce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-3518b454-91f0-4a6d-9e9a-688e0373cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-73a423a7-73bd-40f4-bae5-b7d427f97036,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-04d2b51b-2340-405a-859b-0af3d203d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-d718bf45-3d49-4a2f-a3c3-1457de6a6c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-45dee38d-dadb-44ef-bcac-271f3c4df78c,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-1a448481-edfa-4609-ba69-bcb00daf192e,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-6a7d51bf-3bae-485d-b5bd-e0b7fadfb405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438043108-172.17.0.11-1595663031973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40570,DS-2d394b5d-2589-40ac-85c9-71cbcdb762ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-4e8de2c1-ecd1-4234-b284-0c091c8d3f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-e29e8122-ab40-4a5e-998d-77a726b19be1,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-f278cf8f-850e-4a78-990e-dc1ca942dd78,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-65d39d27-5639-4897-8273-dceb68491bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-7d4d54ab-5e7c-4c2e-b9f3-f55c52e0b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-bc70259b-f400-4b8e-a122-5ec80253d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-8fc5c1ac-df8a-4d09-82bb-eca4b24483c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438043108-172.17.0.11-1595663031973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40570,DS-2d394b5d-2589-40ac-85c9-71cbcdb762ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-4e8de2c1-ecd1-4234-b284-0c091c8d3f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-e29e8122-ab40-4a5e-998d-77a726b19be1,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-f278cf8f-850e-4a78-990e-dc1ca942dd78,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-65d39d27-5639-4897-8273-dceb68491bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-7d4d54ab-5e7c-4c2e-b9f3-f55c52e0b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-bc70259b-f400-4b8e-a122-5ec80253d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-8fc5c1ac-df8a-4d09-82bb-eca4b24483c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5256
