reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56887304-172.17.0.14-1596027382277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40695,DS-67360343-ad7a-41bf-a80f-b6c699e46ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-f7169627-e77f-4adf-ab0a-f6e845516e55,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-b129dcc3-287c-4b7d-8b73-c057afc4e2da,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-0e00ce5b-72e0-418b-888d-462e6514c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-c0af14a4-b28b-4ba7-a471-ddd1594687f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-cac95b2f-54f0-4357-8852-87c47c02ac79,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-81f01234-7d0c-4eff-9665-d982bfefc38e,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-4aaf9432-d66d-48a0-9948-277e1b54ba01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56887304-172.17.0.14-1596027382277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40695,DS-67360343-ad7a-41bf-a80f-b6c699e46ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-f7169627-e77f-4adf-ab0a-f6e845516e55,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-b129dcc3-287c-4b7d-8b73-c057afc4e2da,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-0e00ce5b-72e0-418b-888d-462e6514c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-c0af14a4-b28b-4ba7-a471-ddd1594687f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-cac95b2f-54f0-4357-8852-87c47c02ac79,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-81f01234-7d0c-4eff-9665-d982bfefc38e,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-4aaf9432-d66d-48a0-9948-277e1b54ba01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303881351-172.17.0.14-1596027852525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-c2efc613-33db-498c-abf2-5b86e125ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-b145a52e-6ea4-4649-a4f9-2a17440d9aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-e0d87975-a89f-4231-93a3-f124048e85e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-3dbbeffc-454c-4fc5-b032-a823eadd75c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-4a6f2092-81ea-4a28-a200-f38980d4b432,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-dd593b40-f372-4e13-aca7-cc8723a8efc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-ce800ffc-630a-4f44-b9a8-46607c5e3c07,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-9105b767-caf0-42f3-825f-c140297a00ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303881351-172.17.0.14-1596027852525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-c2efc613-33db-498c-abf2-5b86e125ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-b145a52e-6ea4-4649-a4f9-2a17440d9aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-e0d87975-a89f-4231-93a3-f124048e85e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-3dbbeffc-454c-4fc5-b032-a823eadd75c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-4a6f2092-81ea-4a28-a200-f38980d4b432,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-dd593b40-f372-4e13-aca7-cc8723a8efc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-ce800ffc-630a-4f44-b9a8-46607c5e3c07,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-9105b767-caf0-42f3-825f-c140297a00ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239313760-172.17.0.14-1596027958693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36172,DS-7e77e354-5d19-4976-9cad-dfd4a3d79ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-c207945d-b150-47ae-a6cb-cd3535b16529,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-7bf3b5fa-629c-402b-a06f-4e98068b3473,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-afe103d3-a2d9-477f-a9cc-acabb4eb0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-727c757f-3ab2-44df-84d9-eed9628600eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-c7cd6921-9a85-44db-b0cb-89bd613e9e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-2d631386-2ae6-41b5-b4e0-8778644ed987,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-a3dd58a3-b00f-45d1-b555-5ed799198101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239313760-172.17.0.14-1596027958693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36172,DS-7e77e354-5d19-4976-9cad-dfd4a3d79ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-c207945d-b150-47ae-a6cb-cd3535b16529,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-7bf3b5fa-629c-402b-a06f-4e98068b3473,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-afe103d3-a2d9-477f-a9cc-acabb4eb0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-727c757f-3ab2-44df-84d9-eed9628600eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-c7cd6921-9a85-44db-b0cb-89bd613e9e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-2d631386-2ae6-41b5-b4e0-8778644ed987,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-a3dd58a3-b00f-45d1-b555-5ed799198101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603894594-172.17.0.14-1596028037831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33276,DS-1f366b4b-0489-4a3b-a023-25a1cd2edd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-6ccb57d1-262b-46d0-afd8-4a586f85ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-3d87d03e-e79d-4636-98b8-f585772378d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-5c19d49c-5823-4c79-b1e5-3bdd76b5467d,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-15d5f061-bd8a-4992-816f-2a976134f204,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-3ce84927-381e-4b55-b074-5dd74adb7c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-e222782d-81a7-40c5-bfbf-37a6e8eb4004,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-70d7a506-50ba-4ae7-9b5a-3590341bc3d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603894594-172.17.0.14-1596028037831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33276,DS-1f366b4b-0489-4a3b-a023-25a1cd2edd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-6ccb57d1-262b-46d0-afd8-4a586f85ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-3d87d03e-e79d-4636-98b8-f585772378d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-5c19d49c-5823-4c79-b1e5-3bdd76b5467d,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-15d5f061-bd8a-4992-816f-2a976134f204,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-3ce84927-381e-4b55-b074-5dd74adb7c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-e222782d-81a7-40c5-bfbf-37a6e8eb4004,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-70d7a506-50ba-4ae7-9b5a-3590341bc3d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238194288-172.17.0.14-1596028164835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33711,DS-2919b475-472b-41c5-881c-c1d851b95379,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-7ee8637f-8570-4446-8f27-ce36525eb32d,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-b7dd5ff3-7deb-474d-8d4d-2547c2111963,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-55c7ec41-c4b3-431b-80f7-aaac0bb2ab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-0e8f4dfe-4121-41a0-9a14-3cc30baab804,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-47613af6-d8dc-4f86-bbb1-1115cfa35fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-fa4d0c24-fa31-4ee4-9cbd-1bb1c6702d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-a1bec05e-29e6-44ab-b08d-4f38c16d4fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238194288-172.17.0.14-1596028164835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33711,DS-2919b475-472b-41c5-881c-c1d851b95379,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-7ee8637f-8570-4446-8f27-ce36525eb32d,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-b7dd5ff3-7deb-474d-8d4d-2547c2111963,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-55c7ec41-c4b3-431b-80f7-aaac0bb2ab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-0e8f4dfe-4121-41a0-9a14-3cc30baab804,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-47613af6-d8dc-4f86-bbb1-1115cfa35fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-fa4d0c24-fa31-4ee4-9cbd-1bb1c6702d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-a1bec05e-29e6-44ab-b08d-4f38c16d4fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427583772-172.17.0.14-1596028181102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-87730bb1-f77c-4eda-8f35-2e6b3ca463d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-d4857aab-55de-42e6-a3b1-b0f80d81ce95,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-ce7af40b-db05-44d4-bee9-7d9902afe64a,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-617bc7f2-a6ad-493d-9441-5670b02d4941,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-5cc55c46-3768-4a3a-9fe3-e2e420a39153,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-f9eb7b58-5eba-459c-9ea7-e5a5721c2adf,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-d83a3031-8a9f-46e9-88a1-d633acea4de3,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-66ba66ee-a922-4a34-8c4e-963f9e2708e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427583772-172.17.0.14-1596028181102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-87730bb1-f77c-4eda-8f35-2e6b3ca463d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-d4857aab-55de-42e6-a3b1-b0f80d81ce95,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-ce7af40b-db05-44d4-bee9-7d9902afe64a,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-617bc7f2-a6ad-493d-9441-5670b02d4941,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-5cc55c46-3768-4a3a-9fe3-e2e420a39153,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-f9eb7b58-5eba-459c-9ea7-e5a5721c2adf,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-d83a3031-8a9f-46e9-88a1-d633acea4de3,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-66ba66ee-a922-4a34-8c4e-963f9e2708e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383583420-172.17.0.14-1596028197081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35638,DS-3bacf37c-a4d0-4f1e-bad3-dc8e834f2654,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-fb7785ed-eab2-4214-8fdd-10a188eefbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-659f6d5c-cd1a-4ee0-a9df-d9222c80237c,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-d2f58e6c-466c-488b-805c-ce345f77c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-b539d5fb-3254-4d70-bad3-a67059acb384,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-f5ec6d32-ce35-48c9-acee-f35033e43af3,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-3c408321-898b-4cb0-bda3-d39ac46e2681,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-cfe3b1eb-2773-4451-a5a1-c306ec669742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383583420-172.17.0.14-1596028197081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35638,DS-3bacf37c-a4d0-4f1e-bad3-dc8e834f2654,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-fb7785ed-eab2-4214-8fdd-10a188eefbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-659f6d5c-cd1a-4ee0-a9df-d9222c80237c,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-d2f58e6c-466c-488b-805c-ce345f77c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-b539d5fb-3254-4d70-bad3-a67059acb384,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-f5ec6d32-ce35-48c9-acee-f35033e43af3,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-3c408321-898b-4cb0-bda3-d39ac46e2681,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-cfe3b1eb-2773-4451-a5a1-c306ec669742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431705086-172.17.0.14-1596028308036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39993,DS-5388fac8-f8a1-4db5-ab1a-f2a2599b010e,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-4bbad758-5c52-4150-aa56-d357d6ab1210,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-9be61c90-c408-4631-be63-18f83ac39d63,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-5ddb99a8-147a-4e5f-9aca-b3d65fcc0342,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-b2fb1eca-8cdd-4a20-9c5a-8fc267da733b,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-a8aa8cad-ccb2-44f5-96fa-aa899f42e0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-c813f29f-9e6e-486f-85a0-b9728079f180,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-f34667ef-ec17-4f59-a93e-483acafccbfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431705086-172.17.0.14-1596028308036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39993,DS-5388fac8-f8a1-4db5-ab1a-f2a2599b010e,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-4bbad758-5c52-4150-aa56-d357d6ab1210,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-9be61c90-c408-4631-be63-18f83ac39d63,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-5ddb99a8-147a-4e5f-9aca-b3d65fcc0342,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-b2fb1eca-8cdd-4a20-9c5a-8fc267da733b,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-a8aa8cad-ccb2-44f5-96fa-aa899f42e0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-c813f29f-9e6e-486f-85a0-b9728079f180,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-f34667ef-ec17-4f59-a93e-483acafccbfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147659196-172.17.0.14-1596028403412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-b8a7e866-2471-4f55-9f3e-92602030330c,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-0fb49917-7352-4bee-960d-175b39766ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-df25cf54-cb0b-40b2-8b28-dbf8566b51a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-f317028d-7fae-4cd0-bd91-4eeb217b02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-7ada0665-a977-430b-9e66-2d995024b281,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-84516d00-11bc-4c99-bec1-f90040386e65,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-6389ab18-a645-4d71-8e07-66905f0aaafe,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-4d7ebd85-7fab-46bd-896e-375051aba7dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147659196-172.17.0.14-1596028403412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-b8a7e866-2471-4f55-9f3e-92602030330c,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-0fb49917-7352-4bee-960d-175b39766ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-df25cf54-cb0b-40b2-8b28-dbf8566b51a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-f317028d-7fae-4cd0-bd91-4eeb217b02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-7ada0665-a977-430b-9e66-2d995024b281,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-84516d00-11bc-4c99-bec1-f90040386e65,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-6389ab18-a645-4d71-8e07-66905f0aaafe,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-4d7ebd85-7fab-46bd-896e-375051aba7dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819435154-172.17.0.14-1596028419412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-7aede288-2abc-44dd-8bcc-7478b5a7ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-e9d22bce-5080-4ea6-b04c-82cb06a9f397,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-f38b8042-6bd6-4441-84fb-7e024f46ad51,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-148aaaa2-fb7d-4db2-9693-0372b31905a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-dfd8f8bc-5f79-4db5-aaf1-aa5ddbf93356,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-01ccc54b-e408-48f9-a91d-a2c7cfc587a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-10d72c02-d649-4ed6-9c1e-f25c91dc93b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-49b32f72-3b66-4c02-bb4a-c36e646a8419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819435154-172.17.0.14-1596028419412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-7aede288-2abc-44dd-8bcc-7478b5a7ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-e9d22bce-5080-4ea6-b04c-82cb06a9f397,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-f38b8042-6bd6-4441-84fb-7e024f46ad51,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-148aaaa2-fb7d-4db2-9693-0372b31905a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-dfd8f8bc-5f79-4db5-aaf1-aa5ddbf93356,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-01ccc54b-e408-48f9-a91d-a2c7cfc587a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-10d72c02-d649-4ed6-9c1e-f25c91dc93b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-49b32f72-3b66-4c02-bb4a-c36e646a8419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759507570-172.17.0.14-1596028498766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42531,DS-1bd46c70-0124-490a-ad1e-9ab80837380d,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-58b62f25-77b5-426a-ad35-b5f4453b9a79,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-d5b69224-4d4f-409a-a4c9-770eceeddb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-6c7032c9-961c-46a4-96e8-dc53e723b625,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-8880543e-f4ee-4f5a-8620-a618bf4dac8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-de4fbe78-76aa-482d-89c2-30180428752d,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-69ed301e-e696-45a6-9f4b-bca45a852949,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-aba04847-b09d-42c4-99c6-a429381f90eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759507570-172.17.0.14-1596028498766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42531,DS-1bd46c70-0124-490a-ad1e-9ab80837380d,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-58b62f25-77b5-426a-ad35-b5f4453b9a79,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-d5b69224-4d4f-409a-a4c9-770eceeddb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-6c7032c9-961c-46a4-96e8-dc53e723b625,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-8880543e-f4ee-4f5a-8620-a618bf4dac8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-de4fbe78-76aa-482d-89c2-30180428752d,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-69ed301e-e696-45a6-9f4b-bca45a852949,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-aba04847-b09d-42c4-99c6-a429381f90eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305909141-172.17.0.14-1596028989896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37316,DS-6d0a41e7-9cf5-43c1-9109-2d9d092dc179,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-839c2c06-5c61-4771-a989-68df847ad4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-d1e1b7d5-c0c5-437e-813c-30566d1dfb62,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-32de7a92-e60d-4b93-bf18-9c0e35baa3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-7a3f840c-d0f1-467d-970e-c4d16a0c735c,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-2ad8056e-514f-420f-a347-07d036336a71,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-00185985-6424-40a1-8b74-9f23c0997f21,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-b27f1f62-fe22-4958-a7c0-c817e834244a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305909141-172.17.0.14-1596028989896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37316,DS-6d0a41e7-9cf5-43c1-9109-2d9d092dc179,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-839c2c06-5c61-4771-a989-68df847ad4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-d1e1b7d5-c0c5-437e-813c-30566d1dfb62,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-32de7a92-e60d-4b93-bf18-9c0e35baa3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-7a3f840c-d0f1-467d-970e-c4d16a0c735c,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-2ad8056e-514f-420f-a347-07d036336a71,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-00185985-6424-40a1-8b74-9f23c0997f21,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-b27f1f62-fe22-4958-a7c0-c817e834244a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723537257-172.17.0.14-1596029306383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-ec9b1906-c78e-4e3c-a23d-9c1c75b5fe4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-81199e96-9fc8-4cfb-b275-e8654b3dd607,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-665e07c0-d710-41bc-9de4-de894dee4a52,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-1043d950-cc73-42fb-894d-ade6131d3968,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-4e180ac3-4c2f-478b-94f7-172bd85a062a,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-9bf38165-d30a-4923-b146-1d926dc7fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-97e7bc56-0f1a-4693-a503-c6f7d81ddfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-97e1a8ab-cbae-41c3-8586-1d311c1406ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723537257-172.17.0.14-1596029306383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-ec9b1906-c78e-4e3c-a23d-9c1c75b5fe4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-81199e96-9fc8-4cfb-b275-e8654b3dd607,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-665e07c0-d710-41bc-9de4-de894dee4a52,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-1043d950-cc73-42fb-894d-ade6131d3968,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-4e180ac3-4c2f-478b-94f7-172bd85a062a,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-9bf38165-d30a-4923-b146-1d926dc7fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-97e7bc56-0f1a-4693-a503-c6f7d81ddfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-97e1a8ab-cbae-41c3-8586-1d311c1406ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929289845-172.17.0.14-1596029544448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-43e669c0-c7a2-4692-b18e-414c1505c569,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-2a951597-0e77-4478-8807-0f0de71dcb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-45f09ebb-b8ff-4795-89d9-dacc7a6943e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-df43cbf0-42e5-42fd-bad7-55cd850645a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-9be2ff89-b134-4f6c-86cf-30f74ff79a06,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-adebf6fa-c1e3-42d3-8cfe-6780754c9432,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-62c9fc50-bae3-410c-92b1-581571b5e974,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-580730f8-255a-4b92-9950-6489f19124fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929289845-172.17.0.14-1596029544448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-43e669c0-c7a2-4692-b18e-414c1505c569,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-2a951597-0e77-4478-8807-0f0de71dcb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-45f09ebb-b8ff-4795-89d9-dacc7a6943e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-df43cbf0-42e5-42fd-bad7-55cd850645a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-9be2ff89-b134-4f6c-86cf-30f74ff79a06,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-adebf6fa-c1e3-42d3-8cfe-6780754c9432,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-62c9fc50-bae3-410c-92b1-581571b5e974,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-580730f8-255a-4b92-9950-6489f19124fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831411871-172.17.0.14-1596029591700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46437,DS-f6961115-ece2-4f76-b7f7-4d9f005fc60a,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-c8481570-e891-4c38-8604-1fab1050065b,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-2cbaa3c7-5013-4ffd-9585-7912858f496d,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-db3493e1-716a-4e3c-92bb-5ea99ada73a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-168af09e-e755-4020-9be8-59362a1d7911,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-82e2e3b9-a0e8-4659-817b-e5b7a441ddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-f4e73eb1-f282-4ac9-b0c6-c51cdb4923df,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-208b23c6-8743-45a2-b803-17b49792dad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831411871-172.17.0.14-1596029591700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46437,DS-f6961115-ece2-4f76-b7f7-4d9f005fc60a,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-c8481570-e891-4c38-8604-1fab1050065b,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-2cbaa3c7-5013-4ffd-9585-7912858f496d,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-db3493e1-716a-4e3c-92bb-5ea99ada73a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-168af09e-e755-4020-9be8-59362a1d7911,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-82e2e3b9-a0e8-4659-817b-e5b7a441ddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-f4e73eb1-f282-4ac9-b0c6-c51cdb4923df,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-208b23c6-8743-45a2-b803-17b49792dad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009720654-172.17.0.14-1596029718120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36707,DS-c4d05a64-546d-483b-bf14-4dea424ec199,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-9a01bbcd-382d-4b81-88db-cebefe71d5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-95fbeeaf-d9e9-46c7-b6f0-d01cd53d2b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-f5a9a960-d746-4426-87b6-a774844c8236,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-200d7e2f-445b-43d6-a268-c366e7101889,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-5085669c-a1ca-43d4-b222-fc1cef90af03,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-6a9709ca-c4b3-48b5-b921-33835ce58b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-91c9c215-70f4-4315-9210-76f876b7a941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009720654-172.17.0.14-1596029718120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36707,DS-c4d05a64-546d-483b-bf14-4dea424ec199,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-9a01bbcd-382d-4b81-88db-cebefe71d5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-95fbeeaf-d9e9-46c7-b6f0-d01cd53d2b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-f5a9a960-d746-4426-87b6-a774844c8236,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-200d7e2f-445b-43d6-a268-c366e7101889,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-5085669c-a1ca-43d4-b222-fc1cef90af03,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-6a9709ca-c4b3-48b5-b921-33835ce58b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-91c9c215-70f4-4315-9210-76f876b7a941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840826520-172.17.0.14-1596030003547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-6bc3f4c6-643a-41ed-b5d9-def9c78b846b,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-5bc81726-b92c-4dfc-be3c-301e6e3e88ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-8239b4c6-6a24-4637-be85-8b6ac366c350,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-a338aad5-42d8-4b07-a7e8-27fbb5d5f94f,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-b86b68c0-9a3d-493b-80b5-252594eba3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-65c8627f-3b2e-4ee0-a38c-8122eaffd22f,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-fc4f58e3-f55c-4392-9f70-92f22442ce74,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-96c70714-91c8-4909-8d46-aabf01f97a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840826520-172.17.0.14-1596030003547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-6bc3f4c6-643a-41ed-b5d9-def9c78b846b,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-5bc81726-b92c-4dfc-be3c-301e6e3e88ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-8239b4c6-6a24-4637-be85-8b6ac366c350,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-a338aad5-42d8-4b07-a7e8-27fbb5d5f94f,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-b86b68c0-9a3d-493b-80b5-252594eba3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-65c8627f-3b2e-4ee0-a38c-8122eaffd22f,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-fc4f58e3-f55c-4392-9f70-92f22442ce74,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-96c70714-91c8-4909-8d46-aabf01f97a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 2727
