reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383199416-172.17.0.2-1596043889044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37313,DS-02bed960-c0a4-44a1-b3c3-d77a26cbea77,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-786dee7b-3860-4504-bfbf-45198b4f33db,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-e2a356c6-2da4-43b7-a3e2-f8fa7d1c6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-cb2e2b91-d9fb-4395-8674-145a06f4fe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-baa91fd0-871b-417f-bf61-365211d9ed70,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-e1d8285f-9753-44fc-9c58-85e5c2fcf8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-391627d1-1cc6-48cc-9876-ac6cad5905e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-b0daec30-1c2a-4c54-a217-35d8e4727164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383199416-172.17.0.2-1596043889044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37313,DS-02bed960-c0a4-44a1-b3c3-d77a26cbea77,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-786dee7b-3860-4504-bfbf-45198b4f33db,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-e2a356c6-2da4-43b7-a3e2-f8fa7d1c6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-cb2e2b91-d9fb-4395-8674-145a06f4fe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-baa91fd0-871b-417f-bf61-365211d9ed70,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-e1d8285f-9753-44fc-9c58-85e5c2fcf8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-391627d1-1cc6-48cc-9876-ac6cad5905e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-b0daec30-1c2a-4c54-a217-35d8e4727164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854279566-172.17.0.2-1596044103065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45736,DS-6338fb3a-4406-4881-96fb-dda9c51352b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-ba807a8f-f236-4768-945b-393077bfbe62,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-5cf96afd-95d3-4de2-9282-01b9bc65197b,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-2ad40b5a-4de1-4df0-bbff-0c5b9411b779,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-e8a12277-4b8c-46cb-8572-2a012dc37125,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-8aa5e025-69c9-40da-8491-6c5bdfafc526,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7c09ed80-293c-4ed9-b8e0-11df44c1cc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-59feed8c-63f9-4ec9-95a0-ba96c9e155f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854279566-172.17.0.2-1596044103065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45736,DS-6338fb3a-4406-4881-96fb-dda9c51352b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-ba807a8f-f236-4768-945b-393077bfbe62,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-5cf96afd-95d3-4de2-9282-01b9bc65197b,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-2ad40b5a-4de1-4df0-bbff-0c5b9411b779,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-e8a12277-4b8c-46cb-8572-2a012dc37125,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-8aa5e025-69c9-40da-8491-6c5bdfafc526,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7c09ed80-293c-4ed9-b8e0-11df44c1cc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-59feed8c-63f9-4ec9-95a0-ba96c9e155f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197455589-172.17.0.2-1596044550083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-e7753e96-d745-4850-be0a-325d61515d63,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-880f034d-4ce2-4560-bd92-53db29fbe89c,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-068b6542-962d-430c-8816-9550440908ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-bba57017-d615-41b1-8456-8794eef9bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-f146166f-bd6d-4cb3-a475-1ed55abfecf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-8bbe95ed-7862-43e1-9706-beecc5f86c70,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-290781fd-dd6b-4df0-a13f-ec3b19d711c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-651bc812-62ad-444f-9a6d-f22f5d5a912e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197455589-172.17.0.2-1596044550083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-e7753e96-d745-4850-be0a-325d61515d63,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-880f034d-4ce2-4560-bd92-53db29fbe89c,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-068b6542-962d-430c-8816-9550440908ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-bba57017-d615-41b1-8456-8794eef9bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-f146166f-bd6d-4cb3-a475-1ed55abfecf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-8bbe95ed-7862-43e1-9706-beecc5f86c70,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-290781fd-dd6b-4df0-a13f-ec3b19d711c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-651bc812-62ad-444f-9a6d-f22f5d5a912e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164458387-172.17.0.2-1596044655936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-3be572e6-9a7a-456b-89b5-50645a6f2ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-63f290ef-50b6-40d6-9098-b4feeb678a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-8443be38-743e-421c-bb4e-c598c85d4fed,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-96f394ed-c981-4ecc-92c3-12604be1d548,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-8529c3c2-55c5-4e52-9816-4ec3b6869404,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-a721c5b2-e906-47ee-b1b7-e249b21a16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-d0eb7af2-8c2f-4e15-91d8-0204355f9be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-a3e43ed6-e750-4068-92be-491245d01e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164458387-172.17.0.2-1596044655936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-3be572e6-9a7a-456b-89b5-50645a6f2ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-63f290ef-50b6-40d6-9098-b4feeb678a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-8443be38-743e-421c-bb4e-c598c85d4fed,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-96f394ed-c981-4ecc-92c3-12604be1d548,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-8529c3c2-55c5-4e52-9816-4ec3b6869404,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-a721c5b2-e906-47ee-b1b7-e249b21a16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-d0eb7af2-8c2f-4e15-91d8-0204355f9be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-a3e43ed6-e750-4068-92be-491245d01e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255694980-172.17.0.2-1596044731615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34506,DS-f59fd98f-f4ee-4b33-a863-b581c951a304,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-03048b77-b915-4491-a64f-bf1fd47fd551,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-d4a1e566-7abe-4241-84c6-c087d14ae684,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-8d7b5ec9-59d3-40ee-a091-cbe10e21231b,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-84777d9c-7428-46bc-b03b-82afa9ab0f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-d6054c13-6c5f-427d-9de6-890aa33e1b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-8b204638-7027-4581-83c0-ba89afae6831,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-20ebb63f-6758-4cf6-975c-4beeab11e217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255694980-172.17.0.2-1596044731615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34506,DS-f59fd98f-f4ee-4b33-a863-b581c951a304,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-03048b77-b915-4491-a64f-bf1fd47fd551,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-d4a1e566-7abe-4241-84c6-c087d14ae684,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-8d7b5ec9-59d3-40ee-a091-cbe10e21231b,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-84777d9c-7428-46bc-b03b-82afa9ab0f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-d6054c13-6c5f-427d-9de6-890aa33e1b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-8b204638-7027-4581-83c0-ba89afae6831,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-20ebb63f-6758-4cf6-975c-4beeab11e217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169412820-172.17.0.2-1596045020722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-6a2bf7d2-83bd-4c52-b690-c062b6544d27,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-0092f656-14de-4ae5-a07e-517fb9387ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-378b9b18-6c2d-4ebd-b8cb-25bb59c73613,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-7b310959-ce48-4dbe-adb0-c619f681e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-c34f35a4-75d0-4c25-9374-dd8dacc4f839,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-d4b5a98b-7c28-4441-9863-b23aa91baf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-70552628-df82-48d8-8de1-5d0a64321246,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-b21823e0-bf08-4edf-ac18-ff402ae2ffac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169412820-172.17.0.2-1596045020722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-6a2bf7d2-83bd-4c52-b690-c062b6544d27,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-0092f656-14de-4ae5-a07e-517fb9387ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-378b9b18-6c2d-4ebd-b8cb-25bb59c73613,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-7b310959-ce48-4dbe-adb0-c619f681e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-c34f35a4-75d0-4c25-9374-dd8dacc4f839,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-d4b5a98b-7c28-4441-9863-b23aa91baf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-70552628-df82-48d8-8de1-5d0a64321246,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-b21823e0-bf08-4edf-ac18-ff402ae2ffac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430695366-172.17.0.2-1596045381977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45744,DS-6e267879-b164-485e-970c-483d2011f516,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-38a6bb24-66f4-4aae-babb-4d036aea45cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-e6df65a7-b3c2-4139-aaef-436bbef11e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-2ab191fa-2d4f-456e-815b-30854a34fc71,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-6ad66f3e-dcc6-4198-af5b-ad2597c08a42,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-a44f1d34-d37c-4e91-bf89-565b98499441,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-4c350d61-830f-476d-8f2a-69c841f12c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-07c91022-3630-4ba0-b834-6eb1ec0b7b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430695366-172.17.0.2-1596045381977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45744,DS-6e267879-b164-485e-970c-483d2011f516,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-38a6bb24-66f4-4aae-babb-4d036aea45cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-e6df65a7-b3c2-4139-aaef-436bbef11e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-2ab191fa-2d4f-456e-815b-30854a34fc71,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-6ad66f3e-dcc6-4198-af5b-ad2597c08a42,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-a44f1d34-d37c-4e91-bf89-565b98499441,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-4c350d61-830f-476d-8f2a-69c841f12c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-07c91022-3630-4ba0-b834-6eb1ec0b7b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228144833-172.17.0.2-1596045678123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45307,DS-f4fa288c-62e9-4bed-a569-8ed3c5c667a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-74b84197-5c57-457e-8fd8-f6137e4fa2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-0460a6f3-a0b4-484d-947d-cde0685630ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-e9473b16-6eb2-4605-a744-1d930f54c7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-d175b92f-1efd-405b-ab72-868a60ca9de1,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-343a00be-ad63-4e25-9a8a-4049e7657393,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-6d6a91d1-7c03-4f94-bfbf-31e3a4d2bb08,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-4d4aebdf-2acd-440d-ba33-7ac9c4a13e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228144833-172.17.0.2-1596045678123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45307,DS-f4fa288c-62e9-4bed-a569-8ed3c5c667a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-74b84197-5c57-457e-8fd8-f6137e4fa2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-0460a6f3-a0b4-484d-947d-cde0685630ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-e9473b16-6eb2-4605-a744-1d930f54c7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-d175b92f-1efd-405b-ab72-868a60ca9de1,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-343a00be-ad63-4e25-9a8a-4049e7657393,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-6d6a91d1-7c03-4f94-bfbf-31e3a4d2bb08,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-4d4aebdf-2acd-440d-ba33-7ac9c4a13e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393151613-172.17.0.2-1596045713517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-e51ace89-228b-4eae-a177-230b9d54a499,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-eb0213c9-a649-4115-ba3e-ddb2daafdbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-9f793db5-b1f2-4564-bdfc-cbb396b021bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-87509734-479b-4456-9272-1b8f2cdd41bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-749ddd51-383e-4176-9475-0b3bb5f5b9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-773a3e6d-3769-4009-9fc4-c6aaf4192178,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-539bbf83-d775-40fa-aeca-8822bc8e0295,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-1bad62b1-bbf9-4a25-a7c6-e149ca1e63f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393151613-172.17.0.2-1596045713517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-e51ace89-228b-4eae-a177-230b9d54a499,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-eb0213c9-a649-4115-ba3e-ddb2daafdbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-9f793db5-b1f2-4564-bdfc-cbb396b021bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-87509734-479b-4456-9272-1b8f2cdd41bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-749ddd51-383e-4176-9475-0b3bb5f5b9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-773a3e6d-3769-4009-9fc4-c6aaf4192178,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-539bbf83-d775-40fa-aeca-8822bc8e0295,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-1bad62b1-bbf9-4a25-a7c6-e149ca1e63f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847203257-172.17.0.2-1596046492038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35102,DS-6474fc27-3ba9-42c8-a01b-1e8517e740a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-9dc6b063-a02a-4164-b3ad-597589f1471c,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-247180bb-9ea5-4666-9a56-0d5fdb3da9af,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-0eadbc67-247f-43f4-9857-fb5e5d62a2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-828d857b-5da6-4430-b161-481ef9074f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-46364798-9c69-4334-a120-e9e039f59288,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-c86e2ffd-9976-4a66-af32-fcb2b755af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-1bb42539-d6ab-49a8-baa5-c5dafc967acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847203257-172.17.0.2-1596046492038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35102,DS-6474fc27-3ba9-42c8-a01b-1e8517e740a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-9dc6b063-a02a-4164-b3ad-597589f1471c,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-247180bb-9ea5-4666-9a56-0d5fdb3da9af,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-0eadbc67-247f-43f4-9857-fb5e5d62a2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-828d857b-5da6-4430-b161-481ef9074f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-46364798-9c69-4334-a120-e9e039f59288,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-c86e2ffd-9976-4a66-af32-fcb2b755af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-1bb42539-d6ab-49a8-baa5-c5dafc967acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554951700-172.17.0.2-1596046963090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45258,DS-3bd3dfc6-ed8a-4c84-9016-40aacd8225b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-446bee40-1c4d-4ccb-9f4b-28fae556e320,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-eaef1cbf-891d-45cd-968d-f62bc774687c,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-fe67e409-0325-466a-bc31-25c15cfe1485,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-2dedb2b9-fdcd-43d6-b5bd-4407bcbb0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-cfabd477-f3ce-4de6-b8b8-8b1d377a7be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-e8ee6bee-171a-4873-827a-7715ae75b2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-d6ca4f76-4cb0-4c8a-b010-8b316e4b3632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554951700-172.17.0.2-1596046963090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45258,DS-3bd3dfc6-ed8a-4c84-9016-40aacd8225b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-446bee40-1c4d-4ccb-9f4b-28fae556e320,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-eaef1cbf-891d-45cd-968d-f62bc774687c,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-fe67e409-0325-466a-bc31-25c15cfe1485,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-2dedb2b9-fdcd-43d6-b5bd-4407bcbb0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-cfabd477-f3ce-4de6-b8b8-8b1d377a7be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-e8ee6bee-171a-4873-827a-7715ae75b2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-d6ca4f76-4cb0-4c8a-b010-8b316e4b3632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523883849-172.17.0.2-1596047069453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40769,DS-93e5c822-f284-455b-8cfd-6ae633622d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-6847578f-356a-48ed-b84c-62c308ac33e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-edb3ce79-03c6-4813-9517-9db4261be78e,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-0327c97a-364c-47cd-8443-f0011946477d,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-145bbea9-78ff-4909-a95a-4f388881f54b,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-38623f2f-bb77-474b-bba8-6a512a3e03c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-3b08ad2c-0e8f-482d-b490-a1259d82a3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-a3576efd-374a-455d-99d9-3047347c34d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523883849-172.17.0.2-1596047069453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40769,DS-93e5c822-f284-455b-8cfd-6ae633622d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-6847578f-356a-48ed-b84c-62c308ac33e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-edb3ce79-03c6-4813-9517-9db4261be78e,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-0327c97a-364c-47cd-8443-f0011946477d,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-145bbea9-78ff-4909-a95a-4f388881f54b,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-38623f2f-bb77-474b-bba8-6a512a3e03c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-3b08ad2c-0e8f-482d-b490-a1259d82a3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-a3576efd-374a-455d-99d9-3047347c34d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470979987-172.17.0.2-1596047216985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36676,DS-9ec024fc-3538-43d4-af79-bd076f5aba02,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-88e9289c-7ed6-40c4-b3b0-430c64c9f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-eabba2b7-0ca0-4d79-a1d4-2df4f71b4a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-596e4357-23d2-4f57-b08b-f27371281c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-749f5209-43b7-454c-805d-de020ee0fa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-d8722c73-9397-4d77-adb7-d6c497104ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-97c0fea0-6328-48c6-a99d-093ee60a5620,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-3ed707ef-f132-48d7-9e7f-a405ffc4e870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470979987-172.17.0.2-1596047216985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36676,DS-9ec024fc-3538-43d4-af79-bd076f5aba02,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-88e9289c-7ed6-40c4-b3b0-430c64c9f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-eabba2b7-0ca0-4d79-a1d4-2df4f71b4a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-596e4357-23d2-4f57-b08b-f27371281c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-749f5209-43b7-454c-805d-de020ee0fa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-d8722c73-9397-4d77-adb7-d6c497104ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-97c0fea0-6328-48c6-a99d-093ee60a5620,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-3ed707ef-f132-48d7-9e7f-a405ffc4e870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577622058-172.17.0.2-1596047238094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45066,DS-8ec8f119-4e23-4a1e-b6ee-17e511d761c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-4a4ec240-a250-4d2a-9273-3c21629a1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-3c0b80c5-a5d5-4fe3-8a6b-2418ec4777c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-0dc89644-93fd-4952-9339-3eb229f1ac75,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-ca8a469e-ca5d-4f6e-8a09-dfbbbc4d25d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-d9f76b03-c4b0-4477-85ad-1021871cf9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-886c3973-335e-4e62-8b6b-4514832f8148,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-0b815dc8-3262-48c3-bd2e-a4fa3f8a0884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577622058-172.17.0.2-1596047238094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45066,DS-8ec8f119-4e23-4a1e-b6ee-17e511d761c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-4a4ec240-a250-4d2a-9273-3c21629a1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-3c0b80c5-a5d5-4fe3-8a6b-2418ec4777c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-0dc89644-93fd-4952-9339-3eb229f1ac75,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-ca8a469e-ca5d-4f6e-8a09-dfbbbc4d25d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-d9f76b03-c4b0-4477-85ad-1021871cf9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-886c3973-335e-4e62-8b6b-4514832f8148,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-0b815dc8-3262-48c3-bd2e-a4fa3f8a0884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944591173-172.17.0.2-1596047300882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46292,DS-ff58357a-91f7-49bc-9878-16b184bd2f75,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-c514309c-b929-4625-b698-f40aa6785ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-d646acad-8a26-4bcd-8ce2-98aaedf7ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-46284b9e-eea5-4ef3-937a-93b4b959b0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-f808339a-279b-4cce-b38b-27253e4d3af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-0c71ecc8-ea6b-403f-ab88-1de01ae305c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-f794964c-a981-44f1-80e3-f2ea581a7209,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-8a566e2f-ef2e-4b02-9100-a2c4b33a2eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944591173-172.17.0.2-1596047300882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46292,DS-ff58357a-91f7-49bc-9878-16b184bd2f75,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-c514309c-b929-4625-b698-f40aa6785ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-d646acad-8a26-4bcd-8ce2-98aaedf7ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-46284b9e-eea5-4ef3-937a-93b4b959b0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-f808339a-279b-4cce-b38b-27253e4d3af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-0c71ecc8-ea6b-403f-ab88-1de01ae305c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-f794964c-a981-44f1-80e3-f2ea581a7209,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-8a566e2f-ef2e-4b02-9100-a2c4b33a2eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415088030-172.17.0.2-1596047427234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-d42bfff2-5b1d-428d-903a-5d0573c1dcff,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-b4d9d749-0368-43fb-a42e-37c47e0b26d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-22fffbd3-2011-46a7-b96e-8a27a01ce374,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-94da3204-504c-4f32-b8af-0571dbccb6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-b5f3e082-dcf8-4a6e-b7f7-1bcc5b9ff185,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-fdf36423-ee6b-4efc-8a5f-c7c6a1da418a,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-7ee272b5-d4a4-4f09-b4de-17c153071acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-08bfcefb-a3b5-4f8f-b6d0-600ab8c50cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415088030-172.17.0.2-1596047427234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-d42bfff2-5b1d-428d-903a-5d0573c1dcff,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-b4d9d749-0368-43fb-a42e-37c47e0b26d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-22fffbd3-2011-46a7-b96e-8a27a01ce374,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-94da3204-504c-4f32-b8af-0571dbccb6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-b5f3e082-dcf8-4a6e-b7f7-1bcc5b9ff185,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-fdf36423-ee6b-4efc-8a5f-c7c6a1da418a,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-7ee272b5-d4a4-4f09-b4de-17c153071acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-08bfcefb-a3b5-4f8f-b6d0-600ab8c50cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829216512-172.17.0.2-1596047594173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33845,DS-abccc799-5088-4c22-882d-644010be273b,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-7cdc601e-b4f5-4b5b-8346-a39d8091f723,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-a346041d-0041-4ee4-9d7e-1b91c6d9b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-788f61ca-a595-4080-b7fa-ef2e3cdac170,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-f8697d2a-473b-41fc-a3bc-a964b96b2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-1aa6be74-0112-49fa-9a56-a032281d03ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-bf49a046-85d5-452f-9952-aa98798f2537,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-f959619a-b37c-496c-9cf6-baf73d43b313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829216512-172.17.0.2-1596047594173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33845,DS-abccc799-5088-4c22-882d-644010be273b,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-7cdc601e-b4f5-4b5b-8346-a39d8091f723,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-a346041d-0041-4ee4-9d7e-1b91c6d9b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-788f61ca-a595-4080-b7fa-ef2e3cdac170,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-f8697d2a-473b-41fc-a3bc-a964b96b2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-1aa6be74-0112-49fa-9a56-a032281d03ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-bf49a046-85d5-452f-9952-aa98798f2537,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-f959619a-b37c-496c-9cf6-baf73d43b313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567990060-172.17.0.2-1596047635755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44908,DS-d56bd7d8-2e9a-46f8-9520-a39fd5a35f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-9e0295a6-28ba-49eb-88e3-e4150556f531,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-3b408514-0048-4986-bb71-7d4f976f9ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-c5d4090c-52d7-4efe-a8d8-d3acf5e5e5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-e6f815f9-cf05-4d0a-af8c-bd3a37706bff,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-29835f77-7bc9-4293-b267-a804399990c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-15b79364-4afc-4808-ab81-7384cb94284d,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-f1c0fdc1-5b11-4afc-8457-65e72ac6aa8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567990060-172.17.0.2-1596047635755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44908,DS-d56bd7d8-2e9a-46f8-9520-a39fd5a35f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-9e0295a6-28ba-49eb-88e3-e4150556f531,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-3b408514-0048-4986-bb71-7d4f976f9ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-c5d4090c-52d7-4efe-a8d8-d3acf5e5e5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-e6f815f9-cf05-4d0a-af8c-bd3a37706bff,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-29835f77-7bc9-4293-b267-a804399990c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-15b79364-4afc-4808-ab81-7384cb94284d,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-f1c0fdc1-5b11-4afc-8457-65e72ac6aa8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4392
