reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767427964-172.17.0.2-1595874618893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43320,DS-ec6a858d-0fbc-44d5-b672-9b1c6bd907a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-f42a967f-54c7-4354-ae57-aee82903096e,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-bd3fa7b9-8d96-4118-a4b4-fa7776bf4442,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-aa3c6bda-8075-47a2-9672-a2c0e30390f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-f95ffa99-27ce-46d6-a96b-f02e8ae9983e,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-c68b585c-924f-4e6a-af28-39f2a36d5b59,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-099647fd-dcc4-4f92-9213-f4adcdb48d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-823826ce-b85a-46b9-8114-02cd218c9336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767427964-172.17.0.2-1595874618893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43320,DS-ec6a858d-0fbc-44d5-b672-9b1c6bd907a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-f42a967f-54c7-4354-ae57-aee82903096e,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-bd3fa7b9-8d96-4118-a4b4-fa7776bf4442,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-aa3c6bda-8075-47a2-9672-a2c0e30390f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-f95ffa99-27ce-46d6-a96b-f02e8ae9983e,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-c68b585c-924f-4e6a-af28-39f2a36d5b59,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-099647fd-dcc4-4f92-9213-f4adcdb48d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-823826ce-b85a-46b9-8114-02cd218c9336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548944991-172.17.0.2-1595874972527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36812,DS-127bf804-d819-4c62-abc3-9e0703715436,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-144f97fc-120f-44ea-8094-9176cd6eec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-e1771115-66a4-4cee-bf88-074cd0afa057,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-046e1039-1e34-4e74-9677-f6a3d8636b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-a5b62a86-3c4e-43e0-a742-49710d77c450,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-8498c6a5-abee-414b-a926-026f70ecf569,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-9374b488-4bfd-4f99-bebd-8efc76a6ed75,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-5dfff449-3cfa-4d91-bc78-5f471845a248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548944991-172.17.0.2-1595874972527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36812,DS-127bf804-d819-4c62-abc3-9e0703715436,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-144f97fc-120f-44ea-8094-9176cd6eec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-e1771115-66a4-4cee-bf88-074cd0afa057,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-046e1039-1e34-4e74-9677-f6a3d8636b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-a5b62a86-3c4e-43e0-a742-49710d77c450,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-8498c6a5-abee-414b-a926-026f70ecf569,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-9374b488-4bfd-4f99-bebd-8efc76a6ed75,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-5dfff449-3cfa-4d91-bc78-5f471845a248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311131484-172.17.0.2-1595875005415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45397,DS-70f29932-1c1a-4a98-ad52-2901d166250e,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-e83bc881-2108-4bbf-ab90-b36cf84b0560,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-e4fcf6c9-40db-4f2c-8cd5-e38470d5872e,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-7e3b907e-feca-4165-b03f-21e0222a390e,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-c344fe72-c205-45d7-b715-c1b47d5cd558,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-7f7cf8c9-c56b-4e0b-bb34-8f548fd5401a,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-1bb392c7-2ce8-445b-8311-9c5f6e692e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-287b88ed-995c-4ffb-a51d-faaba4bfd5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311131484-172.17.0.2-1595875005415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45397,DS-70f29932-1c1a-4a98-ad52-2901d166250e,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-e83bc881-2108-4bbf-ab90-b36cf84b0560,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-e4fcf6c9-40db-4f2c-8cd5-e38470d5872e,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-7e3b907e-feca-4165-b03f-21e0222a390e,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-c344fe72-c205-45d7-b715-c1b47d5cd558,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-7f7cf8c9-c56b-4e0b-bb34-8f548fd5401a,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-1bb392c7-2ce8-445b-8311-9c5f6e692e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-287b88ed-995c-4ffb-a51d-faaba4bfd5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196435672-172.17.0.2-1595875395435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-a5f80678-dfe0-4d9c-9793-e70e2420f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-1774c201-1253-42c6-88cb-3accd9cee2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-17d17473-6729-4658-b741-1f10cd46d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-d0f4ff39-864b-4402-90ba-0eb783a55be5,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-62e30029-2395-4193-b121-ea0a5eeb7572,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-183381ed-71cb-41cf-97a4-bf720eed5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-75dc87e3-ea96-4768-951f-79b9f631c56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-aad87e46-82cd-4ff3-a25f-ac3590c62869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196435672-172.17.0.2-1595875395435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-a5f80678-dfe0-4d9c-9793-e70e2420f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-1774c201-1253-42c6-88cb-3accd9cee2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-17d17473-6729-4658-b741-1f10cd46d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-d0f4ff39-864b-4402-90ba-0eb783a55be5,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-62e30029-2395-4193-b121-ea0a5eeb7572,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-183381ed-71cb-41cf-97a4-bf720eed5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-75dc87e3-ea96-4768-951f-79b9f631c56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-aad87e46-82cd-4ff3-a25f-ac3590c62869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495115676-172.17.0.2-1595875466750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40109,DS-4b0085a6-522c-4fac-a09a-5a807c22b049,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-a6a0b1e8-d920-49b9-8458-e6a5a5ae3c45,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-cf9e4679-f80c-4e72-81db-abce0cbd24e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-8b3b2cc6-1da1-400f-9242-6766cc5954ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-6fd57fb5-d749-4cab-b6b8-febf50a832fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-70a206d1-29c8-4033-8fd9-07a9a199da4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-a0ac3072-9179-4b6e-a699-2104a4f638e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-c7e03256-a6ea-4159-a89e-455b7b7b2757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495115676-172.17.0.2-1595875466750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40109,DS-4b0085a6-522c-4fac-a09a-5a807c22b049,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-a6a0b1e8-d920-49b9-8458-e6a5a5ae3c45,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-cf9e4679-f80c-4e72-81db-abce0cbd24e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-8b3b2cc6-1da1-400f-9242-6766cc5954ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-6fd57fb5-d749-4cab-b6b8-febf50a832fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-70a206d1-29c8-4033-8fd9-07a9a199da4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-a0ac3072-9179-4b6e-a699-2104a4f638e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-c7e03256-a6ea-4159-a89e-455b7b7b2757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379510732-172.17.0.2-1595875615552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-5388bfba-4df4-431e-b7b5-ea124c0caa19,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-99017eff-8054-4790-87b8-9c1c153d1a94,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-c1515daf-1fe5-48a4-9683-b5de3a1695bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-6ba5c1f9-8ea2-4f12-8d96-76448d5060ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-d8dcee4c-cba3-4cd0-86c9-35c2af9c4b78,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-775d8a9f-8860-4775-820c-57627b7f9c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-0eb9120c-669e-4d28-8cad-fe0115466778,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-ed762a6d-ab69-4c19-8f18-927e7d75e487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379510732-172.17.0.2-1595875615552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-5388bfba-4df4-431e-b7b5-ea124c0caa19,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-99017eff-8054-4790-87b8-9c1c153d1a94,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-c1515daf-1fe5-48a4-9683-b5de3a1695bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-6ba5c1f9-8ea2-4f12-8d96-76448d5060ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-d8dcee4c-cba3-4cd0-86c9-35c2af9c4b78,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-775d8a9f-8860-4775-820c-57627b7f9c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-0eb9120c-669e-4d28-8cad-fe0115466778,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-ed762a6d-ab69-4c19-8f18-927e7d75e487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318640841-172.17.0.2-1595875693032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38461,DS-287a3d88-fc93-4686-9c1a-fbd84b0131eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-d5ba5106-a841-41d8-8758-80663f3f70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-713e5e45-a52d-44f2-a992-24a9a7698a26,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-be0b35dc-e8c0-4e89-b2a5-eee45871111d,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-16d9dd1d-5a66-4e28-9af5-6e16e1ad98e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-c07e2baf-50d1-4069-8180-cddd6006c614,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-90dddf9e-8416-4674-911a-86d3cdb13059,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-18c7617e-5d5b-4b81-bf8c-174e15ac2f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318640841-172.17.0.2-1595875693032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38461,DS-287a3d88-fc93-4686-9c1a-fbd84b0131eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-d5ba5106-a841-41d8-8758-80663f3f70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-713e5e45-a52d-44f2-a992-24a9a7698a26,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-be0b35dc-e8c0-4e89-b2a5-eee45871111d,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-16d9dd1d-5a66-4e28-9af5-6e16e1ad98e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-c07e2baf-50d1-4069-8180-cddd6006c614,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-90dddf9e-8416-4674-911a-86d3cdb13059,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-18c7617e-5d5b-4b81-bf8c-174e15ac2f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220496223-172.17.0.2-1595875915129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39792,DS-5b866116-f25c-4565-b8ef-ce2bab3a0854,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-8f2a6fa6-a7f4-42a0-901d-a99cd6cf14be,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-ecf1b8a8-2908-4504-8435-4282d070892c,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-446f32ea-9266-4edb-8980-1489ee5d07d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-982326cc-4c48-4b7c-b784-a8c6d29217aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-89191e7c-1907-444c-8379-fe6871eb7cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-66ed6b21-72c2-4bb1-bc30-cd155d902ded,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-fd8a427a-fbe7-404b-a0a9-c329c63e43f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220496223-172.17.0.2-1595875915129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39792,DS-5b866116-f25c-4565-b8ef-ce2bab3a0854,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-8f2a6fa6-a7f4-42a0-901d-a99cd6cf14be,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-ecf1b8a8-2908-4504-8435-4282d070892c,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-446f32ea-9266-4edb-8980-1489ee5d07d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-982326cc-4c48-4b7c-b784-a8c6d29217aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-89191e7c-1907-444c-8379-fe6871eb7cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-66ed6b21-72c2-4bb1-bc30-cd155d902ded,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-fd8a427a-fbe7-404b-a0a9-c329c63e43f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388564951-172.17.0.2-1595876096716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41850,DS-a1a79a3d-d1af-487f-a4f7-2746d473681a,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-6c4ebe23-5700-4ce1-9e68-15e4e93d427b,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-b1caa16b-c8e9-4912-bfae-bacc56373dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-651cacd7-5391-4de8-8985-155d2803d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-ad36eeb2-8eff-4f5c-a035-3aca8692a0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-876c10dd-323c-46d7-8759-825b7543a8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-caa953c5-617e-4f84-9fee-5b762520f015,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-e158380f-2944-462b-9fc5-9f36ab99afee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388564951-172.17.0.2-1595876096716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41850,DS-a1a79a3d-d1af-487f-a4f7-2746d473681a,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-6c4ebe23-5700-4ce1-9e68-15e4e93d427b,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-b1caa16b-c8e9-4912-bfae-bacc56373dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-651cacd7-5391-4de8-8985-155d2803d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-ad36eeb2-8eff-4f5c-a035-3aca8692a0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-876c10dd-323c-46d7-8759-825b7543a8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-caa953c5-617e-4f84-9fee-5b762520f015,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-e158380f-2944-462b-9fc5-9f36ab99afee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339815427-172.17.0.2-1595876562864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41992,DS-fec77d2f-44c7-4a2d-bc96-50ff3876d444,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-91a3963b-33eb-4343-a95a-9d949982b64e,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-52a59a2f-f703-4956-9926-d7799e6641c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-d578aaab-e02f-4c4d-a6fb-c03e51e62eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-306f8e68-7f49-41c5-810b-b57dfe4f6f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-952b4ca5-ca60-4d38-a9ab-66be3e106e50,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-a6086819-3916-40b3-b5f6-098dea45d880,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-7ae9d35f-4f66-4bd3-a531-2ef601b2dd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339815427-172.17.0.2-1595876562864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41992,DS-fec77d2f-44c7-4a2d-bc96-50ff3876d444,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-91a3963b-33eb-4343-a95a-9d949982b64e,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-52a59a2f-f703-4956-9926-d7799e6641c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-d578aaab-e02f-4c4d-a6fb-c03e51e62eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-306f8e68-7f49-41c5-810b-b57dfe4f6f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-952b4ca5-ca60-4d38-a9ab-66be3e106e50,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-a6086819-3916-40b3-b5f6-098dea45d880,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-7ae9d35f-4f66-4bd3-a531-2ef601b2dd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772519799-172.17.0.2-1595876668733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43881,DS-8be5dc4c-0d77-4e37-bb3f-e5510ae76e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-05aa6f31-41e0-481a-8c07-e18151b8a80a,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-793622a6-1d13-47c0-844e-cb89efc5c39b,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-12fffdcd-d584-4b7d-a185-219583be1ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-65178041-e5e3-4519-a8c8-4755d86458d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-d0f1b2ad-b664-4440-b778-08026da467b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-1ca449e8-8028-4edc-b83a-423ea459467c,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-7f4a4b75-45b5-464e-a267-e835a9d8eb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772519799-172.17.0.2-1595876668733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43881,DS-8be5dc4c-0d77-4e37-bb3f-e5510ae76e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-05aa6f31-41e0-481a-8c07-e18151b8a80a,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-793622a6-1d13-47c0-844e-cb89efc5c39b,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-12fffdcd-d584-4b7d-a185-219583be1ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-65178041-e5e3-4519-a8c8-4755d86458d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-d0f1b2ad-b664-4440-b778-08026da467b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-1ca449e8-8028-4edc-b83a-423ea459467c,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-7f4a4b75-45b5-464e-a267-e835a9d8eb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701382088-172.17.0.2-1595876909848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34164,DS-30af24cb-4e31-4e9f-966d-bd41c9c85db7,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-6a727e5c-b144-4364-be2d-b3872494c57b,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-26b91a91-3e8c-44e0-99b4-440396b0d246,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-14173944-1677-46d0-8967-b66c819b4a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-497dd8c3-4726-479d-8d23-a9665092b1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-ff112769-aa8e-464a-9cbd-b5f79587a5db,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-c136b182-3dce-41b3-a5c0-45a31e4f8bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-8eb1e2aa-99f2-4915-a160-866cf0ff88cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701382088-172.17.0.2-1595876909848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34164,DS-30af24cb-4e31-4e9f-966d-bd41c9c85db7,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-6a727e5c-b144-4364-be2d-b3872494c57b,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-26b91a91-3e8c-44e0-99b4-440396b0d246,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-14173944-1677-46d0-8967-b66c819b4a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-497dd8c3-4726-479d-8d23-a9665092b1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-ff112769-aa8e-464a-9cbd-b5f79587a5db,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-c136b182-3dce-41b3-a5c0-45a31e4f8bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-8eb1e2aa-99f2-4915-a160-866cf0ff88cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477364125-172.17.0.2-1595876944752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37949,DS-3af4d082-53be-4751-bb97-d176754a1904,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-8cd77cde-cbeb-4b1f-a685-1f67179f3f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-cb9ef2c0-e01f-4a41-8f4d-19f481d13c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-55cc7e8f-ac29-4720-84a3-bc990fdeabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-bae1c7fb-bf7b-4d3b-9a34-e80ea153864f,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-f614c9a7-49ba-4ecb-80d8-dad9d658c3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-2ceb2774-91eb-4dca-97f3-e8f0335817d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-4eb20c9e-89e6-478f-92b0-d7b2c5e2fa23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477364125-172.17.0.2-1595876944752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37949,DS-3af4d082-53be-4751-bb97-d176754a1904,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-8cd77cde-cbeb-4b1f-a685-1f67179f3f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-cb9ef2c0-e01f-4a41-8f4d-19f481d13c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-55cc7e8f-ac29-4720-84a3-bc990fdeabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-bae1c7fb-bf7b-4d3b-9a34-e80ea153864f,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-f614c9a7-49ba-4ecb-80d8-dad9d658c3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-2ceb2774-91eb-4dca-97f3-e8f0335817d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-4eb20c9e-89e6-478f-92b0-d7b2c5e2fa23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789337516-172.17.0.2-1595876968631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-cf1d7e66-a63a-45e6-ac76-46c7abe5c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-67742bc1-29b3-4dd4-a3a3-9c600d3006c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-8f407ba7-4192-4edd-bfc4-ce798e893931,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-ea11c6ab-609f-44c5-88d1-47479015f8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-a1c7430d-ac8e-4c7e-a7bc-63222523d399,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-e99fc6bb-1380-4659-87cb-ee36219c76ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-6c0fb535-c88e-4c46-8378-3f46e43f1164,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-9a77bd54-a9ab-4bfe-beb5-ffe5264bc13d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789337516-172.17.0.2-1595876968631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44843,DS-cf1d7e66-a63a-45e6-ac76-46c7abe5c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-67742bc1-29b3-4dd4-a3a3-9c600d3006c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-8f407ba7-4192-4edd-bfc4-ce798e893931,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-ea11c6ab-609f-44c5-88d1-47479015f8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-a1c7430d-ac8e-4c7e-a7bc-63222523d399,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-e99fc6bb-1380-4659-87cb-ee36219c76ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-6c0fb535-c88e-4c46-8378-3f46e43f1164,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-9a77bd54-a9ab-4bfe-beb5-ffe5264bc13d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160386286-172.17.0.2-1595878221346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40285,DS-08b111bd-6094-4471-9afe-66df7995e938,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-af2af0cb-5500-4e88-8240-ebf6aae2c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-a5f4454b-e999-4443-a12e-5988283dec91,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-48324507-182e-4eb9-8696-cda94830964d,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-3585f8e7-91c3-4a2b-96d1-136c78dfed44,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-c3d9a949-f934-48f9-864f-6b7216c91675,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-cba0a085-3a6a-4e4e-9077-229866711551,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-25c4860a-5a78-4f60-991f-7d9f47e0e278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160386286-172.17.0.2-1595878221346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40285,DS-08b111bd-6094-4471-9afe-66df7995e938,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-af2af0cb-5500-4e88-8240-ebf6aae2c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-a5f4454b-e999-4443-a12e-5988283dec91,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-48324507-182e-4eb9-8696-cda94830964d,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-3585f8e7-91c3-4a2b-96d1-136c78dfed44,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-c3d9a949-f934-48f9-864f-6b7216c91675,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-cba0a085-3a6a-4e4e-9077-229866711551,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-25c4860a-5a78-4f60-991f-7d9f47e0e278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324880096-172.17.0.2-1595878805681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39920,DS-956a38fa-48a2-4a32-a54b-9562de5259ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-0f3d6eff-158f-46c3-b1b4-df06cdd45bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-5fd98a5f-93d1-418a-9b87-a502725fed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-c67b48a8-176e-4d1a-b1ec-e945723e8ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-efac3642-2651-4712-b398-f91008ba28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-74761c6e-3103-4c80-a107-f9ed4b4b4d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-d468455e-92db-4111-8ce5-d8368b31a406,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-78598c4a-b4fd-4f80-afae-df7a94b7e015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324880096-172.17.0.2-1595878805681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39920,DS-956a38fa-48a2-4a32-a54b-9562de5259ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-0f3d6eff-158f-46c3-b1b4-df06cdd45bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-5fd98a5f-93d1-418a-9b87-a502725fed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-c67b48a8-176e-4d1a-b1ec-e945723e8ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-efac3642-2651-4712-b398-f91008ba28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-74761c6e-3103-4c80-a107-f9ed4b4b4d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-d468455e-92db-4111-8ce5-d8368b31a406,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-78598c4a-b4fd-4f80-afae-df7a94b7e015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738801139-172.17.0.2-1595878842896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42096,DS-13ca251f-c648-4687-ac62-ab7708af1e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-ab07016f-027c-452a-acda-73dd46a5316b,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-6d559f3b-40ee-4d8e-9e88-ab19a9eb62d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-5493573d-a4d5-438c-849d-e77f530ad20d,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-494fbc42-ef1f-4013-9480-59526ed81987,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-31596cc0-36ce-4230-b986-99fa0792108a,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-a99ae77d-d299-4e54-8296-20b8e0a421e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-45a8b75b-4976-4d97-9290-15dc92e33110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738801139-172.17.0.2-1595878842896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42096,DS-13ca251f-c648-4687-ac62-ab7708af1e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-ab07016f-027c-452a-acda-73dd46a5316b,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-6d559f3b-40ee-4d8e-9e88-ab19a9eb62d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-5493573d-a4d5-438c-849d-e77f530ad20d,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-494fbc42-ef1f-4013-9480-59526ed81987,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-31596cc0-36ce-4230-b986-99fa0792108a,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-a99ae77d-d299-4e54-8296-20b8e0a421e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-45a8b75b-4976-4d97-9290-15dc92e33110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787495029-172.17.0.2-1595878919286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-20b120fe-796b-4441-8a45-8ded277a2b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-b9b62975-35a9-49bd-8a63-64c73d68a7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-5e7d811f-9edd-43b2-ad5d-1b4783570b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-127a0fcc-acb5-493a-955e-770e451e3c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-9c29e705-54a9-4c7b-8852-d1332f485b87,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-96439d40-1aae-43df-a92a-4296614e494b,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-72b5b2ae-e69b-494b-9eeb-84ed11287456,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-f3d3923b-d99d-41bf-bc17-35be512c7768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787495029-172.17.0.2-1595878919286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34193,DS-20b120fe-796b-4441-8a45-8ded277a2b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-b9b62975-35a9-49bd-8a63-64c73d68a7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-5e7d811f-9edd-43b2-ad5d-1b4783570b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-127a0fcc-acb5-493a-955e-770e451e3c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-9c29e705-54a9-4c7b-8852-d1332f485b87,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-96439d40-1aae-43df-a92a-4296614e494b,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-72b5b2ae-e69b-494b-9eeb-84ed11287456,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-f3d3923b-d99d-41bf-bc17-35be512c7768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 1200000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561856041-172.17.0.2-1595879571946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-ca64fac0-2be3-4054-b7b2-9af2195dd21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-ddb04a99-dcfd-45d4-a2b8-8d29a85e54d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-f4e80f1d-bcff-4932-97cc-713159ca8d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-b065324a-1c46-44eb-bb57-8d4693e07a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-a3588572-afee-4bc5-b4b5-64aa0536738b,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-4ad3f354-171a-4061-847d-3f30e79ec87f,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-4ce364bd-e9fc-4941-a277-350e451dfab3,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-4d7c0715-d110-4e01-af61-9cfc0db6c771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561856041-172.17.0.2-1595879571946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-ca64fac0-2be3-4054-b7b2-9af2195dd21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-ddb04a99-dcfd-45d4-a2b8-8d29a85e54d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-f4e80f1d-bcff-4932-97cc-713159ca8d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-b065324a-1c46-44eb-bb57-8d4693e07a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-a3588572-afee-4bc5-b4b5-64aa0536738b,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-4ad3f354-171a-4061-847d-3f30e79ec87f,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-4ce364bd-e9fc-4941-a277-350e451dfab3,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-4d7c0715-d110-4e01-af61-9cfc0db6c771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5142
