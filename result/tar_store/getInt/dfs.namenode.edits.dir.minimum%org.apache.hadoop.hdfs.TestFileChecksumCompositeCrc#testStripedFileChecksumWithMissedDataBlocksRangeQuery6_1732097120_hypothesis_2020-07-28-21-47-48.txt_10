reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412915557-172.17.0.21-1595972886444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39439,DS-1b39d1c5-22b6-44ed-931f-4bbf090e98c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-3a197995-a107-41c7-a285-9136e2025e47,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-97e27925-efce-4608-91da-57234d118da3,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-8345080c-c281-420d-9608-6e328009d0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-5ef726d9-c168-4dbc-bb57-d6f1159ac793,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-600368d7-12d7-4fa9-9856-0d7749a0dcff,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-6cc36945-c6cf-4298-a4e3-c087f2407f78,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-8b1ca378-206a-4281-ac88-6bd7a86c54ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412915557-172.17.0.21-1595972886444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39439,DS-1b39d1c5-22b6-44ed-931f-4bbf090e98c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-3a197995-a107-41c7-a285-9136e2025e47,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-97e27925-efce-4608-91da-57234d118da3,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-8345080c-c281-420d-9608-6e328009d0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-5ef726d9-c168-4dbc-bb57-d6f1159ac793,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-600368d7-12d7-4fa9-9856-0d7749a0dcff,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-6cc36945-c6cf-4298-a4e3-c087f2407f78,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-8b1ca378-206a-4281-ac88-6bd7a86c54ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156199472-172.17.0.21-1595973131122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45328,DS-6b030331-d522-48f5-8e0c-a2ddaef54bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-d7e4c8a0-cdee-49e2-8193-5bc35fc16d77,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-96f71d63-2c67-4746-8382-cb868ba4c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-892f0382-3faa-44e7-82b5-bee6f501ca18,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-ed9c1d78-a860-43ff-841a-e6cf22148a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-d62caf17-a321-4589-aa2c-304a81c32c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-3a305045-e602-4903-9902-7f33d3d27de5,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-2b73461a-0828-4404-bde4-96c10138c419,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156199472-172.17.0.21-1595973131122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45328,DS-6b030331-d522-48f5-8e0c-a2ddaef54bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-d7e4c8a0-cdee-49e2-8193-5bc35fc16d77,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-96f71d63-2c67-4746-8382-cb868ba4c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-892f0382-3faa-44e7-82b5-bee6f501ca18,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-ed9c1d78-a860-43ff-841a-e6cf22148a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-d62caf17-a321-4589-aa2c-304a81c32c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-3a305045-e602-4903-9902-7f33d3d27de5,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-2b73461a-0828-4404-bde4-96c10138c419,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22380625-172.17.0.21-1595973574591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42234,DS-d0f4aeff-4d28-4b42-b4b4-8a743c859776,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-fc2ccc60-8d5a-40b5-b0bc-99fe9bdadd10,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-cf17f349-06f1-4de2-908a-0590fb79a0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-bed29870-23dd-4fae-82f9-6467804fc008,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-167e5ac9-5069-47fb-bc55-294df342e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-55b23361-9283-4aec-92dc-7ff4954af402,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-d3de393b-8bd5-4ff1-bc0d-cac87a5a22d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-26798f44-981f-4bba-b990-e9309f6dbdc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22380625-172.17.0.21-1595973574591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42234,DS-d0f4aeff-4d28-4b42-b4b4-8a743c859776,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-fc2ccc60-8d5a-40b5-b0bc-99fe9bdadd10,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-cf17f349-06f1-4de2-908a-0590fb79a0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-bed29870-23dd-4fae-82f9-6467804fc008,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-167e5ac9-5069-47fb-bc55-294df342e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-55b23361-9283-4aec-92dc-7ff4954af402,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-d3de393b-8bd5-4ff1-bc0d-cac87a5a22d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-26798f44-981f-4bba-b990-e9309f6dbdc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031422899-172.17.0.21-1595973760031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-d53aad9f-4aa4-497c-839e-e72213be0ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-5d4aa526-75dc-49d9-a6eb-3819929c732a,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-dbcc7703-0cbe-4954-9b4f-98e55b1be880,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-bf909fa3-9d6e-42b3-a9fe-05a4daa74c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-ea4eb1e8-f983-4948-a839-e7c5e8bf9cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-ce08c466-15e0-4fd4-9b5a-a83e9e8f7ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-9ef2a296-0652-4b5d-9a8e-dcf9593ea756,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-1287e0a0-64c0-4e62-b156-2886acc21892,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031422899-172.17.0.21-1595973760031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-d53aad9f-4aa4-497c-839e-e72213be0ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-5d4aa526-75dc-49d9-a6eb-3819929c732a,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-dbcc7703-0cbe-4954-9b4f-98e55b1be880,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-bf909fa3-9d6e-42b3-a9fe-05a4daa74c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-ea4eb1e8-f983-4948-a839-e7c5e8bf9cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-ce08c466-15e0-4fd4-9b5a-a83e9e8f7ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-9ef2a296-0652-4b5d-9a8e-dcf9593ea756,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-1287e0a0-64c0-4e62-b156-2886acc21892,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992291336-172.17.0.21-1595974071705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-fc5657f7-f158-450a-9ff0-33ab456ea18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-8415f1c0-466e-4962-b6fa-7ed87d46e69d,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-5199e5f3-e9a5-45eb-8b95-36e114340db1,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-cefee9a0-aded-4dda-9981-0f4fd72794ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-4f5ba52d-2a66-4cc4-b96d-f7c285db59e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-dd89eeb2-4e43-4bff-8300-472a6c89c8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-a3530326-6643-47b3-ab70-903942f9317d,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-06680468-26fb-4cd9-a3f1-3a4d6500931a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992291336-172.17.0.21-1595974071705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-fc5657f7-f158-450a-9ff0-33ab456ea18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-8415f1c0-466e-4962-b6fa-7ed87d46e69d,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-5199e5f3-e9a5-45eb-8b95-36e114340db1,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-cefee9a0-aded-4dda-9981-0f4fd72794ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-4f5ba52d-2a66-4cc4-b96d-f7c285db59e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-dd89eeb2-4e43-4bff-8300-472a6c89c8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-a3530326-6643-47b3-ab70-903942f9317d,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-06680468-26fb-4cd9-a3f1-3a4d6500931a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735972105-172.17.0.21-1595974103201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41362,DS-7262a466-9d78-47dd-875e-dec8fedd9006,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-68768d89-65a2-438b-8498-2baa0acf1788,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-11de3cec-6c14-4879-af40-27db6b402604,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-2a02eeef-d44d-42f4-a3e5-070ca1ce0e12,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-2b0b6a80-49e5-4593-aea9-0528ac96b5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-e34abefa-ad79-4d0c-930c-a16f7b7ea63c,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-afd1f12f-75b5-430e-84db-a77245606593,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-993b732f-0410-47c1-bcef-9cdb24509c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735972105-172.17.0.21-1595974103201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41362,DS-7262a466-9d78-47dd-875e-dec8fedd9006,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-68768d89-65a2-438b-8498-2baa0acf1788,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-11de3cec-6c14-4879-af40-27db6b402604,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-2a02eeef-d44d-42f4-a3e5-070ca1ce0e12,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-2b0b6a80-49e5-4593-aea9-0528ac96b5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-e34abefa-ad79-4d0c-930c-a16f7b7ea63c,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-afd1f12f-75b5-430e-84db-a77245606593,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-993b732f-0410-47c1-bcef-9cdb24509c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549471051-172.17.0.21-1595974555195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37572,DS-96ad6115-5446-42c5-967f-090c1b8b6188,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-c86d8e67-76da-4c7a-8b9d-a46aa64b9ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-d560643b-f27d-4386-ba0e-9efbb55c39d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-e131924d-256c-48b2-924b-219d55c6939b,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-9341a2cf-a817-497c-92fb-f406bb59c9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-580f22b0-f4be-40a2-9464-4c2e20037c79,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-07fbb2ca-a20f-4855-aacb-318c1f90a971,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-541fd234-413d-4fa0-9d16-fee13eac1950,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549471051-172.17.0.21-1595974555195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37572,DS-96ad6115-5446-42c5-967f-090c1b8b6188,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-c86d8e67-76da-4c7a-8b9d-a46aa64b9ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-d560643b-f27d-4386-ba0e-9efbb55c39d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-e131924d-256c-48b2-924b-219d55c6939b,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-9341a2cf-a817-497c-92fb-f406bb59c9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-580f22b0-f4be-40a2-9464-4c2e20037c79,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-07fbb2ca-a20f-4855-aacb-318c1f90a971,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-541fd234-413d-4fa0-9d16-fee13eac1950,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194966323-172.17.0.21-1595974598814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-55574dd2-a580-4394-b588-d4f744f3dfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-26c4642a-f0c7-4bd0-a065-d61761c269c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-02d5064d-ceed-4ecd-891d-7a8215e4f3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-80ce51e7-7f55-4f3f-8bdb-2781ebf629c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-cd34a9e2-8ae6-4407-8a2d-7924720e3876,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-a0d2e7f3-3ec0-4abf-9184-2f819de40e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-bce0bd81-45a3-4428-bd49-a66abdf1fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-deacf675-f342-461e-ac9d-2aa8948c3898,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194966323-172.17.0.21-1595974598814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-55574dd2-a580-4394-b588-d4f744f3dfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-26c4642a-f0c7-4bd0-a065-d61761c269c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-02d5064d-ceed-4ecd-891d-7a8215e4f3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-80ce51e7-7f55-4f3f-8bdb-2781ebf629c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-cd34a9e2-8ae6-4407-8a2d-7924720e3876,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-a0d2e7f3-3ec0-4abf-9184-2f819de40e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-bce0bd81-45a3-4428-bd49-a66abdf1fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-deacf675-f342-461e-ac9d-2aa8948c3898,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248925372-172.17.0.21-1595974631390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43442,DS-983cc9ef-8c1c-475e-93e7-9f137f300c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-de77d887-8c61-4ecf-885d-051e27da9c01,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-b932852f-9f3f-4a56-bcc8-533233b17671,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-c017ce2d-0e62-4472-bf80-3e67a0c76304,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-1c8a728c-dd30-4aa6-9185-9dc4529be5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-2e6a6aa4-a45d-4668-81eb-d8859144f4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-e71359df-3295-418c-99cf-f502bfe7f1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-8afbaa9b-4c9a-4d05-9c2d-c89f61754002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248925372-172.17.0.21-1595974631390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43442,DS-983cc9ef-8c1c-475e-93e7-9f137f300c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-de77d887-8c61-4ecf-885d-051e27da9c01,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-b932852f-9f3f-4a56-bcc8-533233b17671,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-c017ce2d-0e62-4472-bf80-3e67a0c76304,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-1c8a728c-dd30-4aa6-9185-9dc4529be5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-2e6a6aa4-a45d-4668-81eb-d8859144f4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-e71359df-3295-418c-99cf-f502bfe7f1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-8afbaa9b-4c9a-4d05-9c2d-c89f61754002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646462533-172.17.0.21-1595974706278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-b41f4c2d-cdb5-4123-b195-47819dcd29d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-df8484f6-6d6c-4674-95df-624d808ad9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-0b9d8795-8db9-4eb9-9031-e56cf2d556bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-23fde2de-af27-423b-bea6-e56cbd34d2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-96fe69ca-22bc-4721-b518-f56ec12796fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-1b155528-7af5-4cfc-9ce7-1a89dd377545,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-20296ba8-6ffd-4178-b531-e18a8b542ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-7d7248a4-ac4c-4b20-8a85-7ec5b26de149,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646462533-172.17.0.21-1595974706278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-b41f4c2d-cdb5-4123-b195-47819dcd29d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-df8484f6-6d6c-4674-95df-624d808ad9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-0b9d8795-8db9-4eb9-9031-e56cf2d556bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-23fde2de-af27-423b-bea6-e56cbd34d2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-96fe69ca-22bc-4721-b518-f56ec12796fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-1b155528-7af5-4cfc-9ce7-1a89dd377545,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-20296ba8-6ffd-4178-b531-e18a8b542ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-7d7248a4-ac4c-4b20-8a85-7ec5b26de149,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907002968-172.17.0.21-1595975278900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-c8278ec4-fd79-4da7-90ea-0b4285a580ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-cffdc74f-70cf-46ed-956e-8050cd53519c,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-93e46b62-0fd9-48b3-99cb-fbbf78fc06ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-d2c43203-e00a-4b0f-b3c9-33d7b1d2261c,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-d912a51c-c0b4-42ce-84fa-e9df4a9ffb30,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-e71215a1-7792-4b88-a910-a433db61113b,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-1587c0aa-ba8e-4cea-a64e-0c7a18e6c5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-ea87bc04-535d-4c7c-a0ef-aa8aa11dd859,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907002968-172.17.0.21-1595975278900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-c8278ec4-fd79-4da7-90ea-0b4285a580ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-cffdc74f-70cf-46ed-956e-8050cd53519c,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-93e46b62-0fd9-48b3-99cb-fbbf78fc06ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-d2c43203-e00a-4b0f-b3c9-33d7b1d2261c,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-d912a51c-c0b4-42ce-84fa-e9df4a9ffb30,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-e71215a1-7792-4b88-a910-a433db61113b,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-1587c0aa-ba8e-4cea-a64e-0c7a18e6c5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-ea87bc04-535d-4c7c-a0ef-aa8aa11dd859,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197969611-172.17.0.21-1595975424551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36437,DS-3722e490-7513-4147-b821-97e946d074fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-362611fb-3232-41fc-b6f8-b8c4d7684e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-401aceb5-ecb6-4ad3-809b-b760ae79d8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-727d1326-515b-41b5-80ec-9703b2b88a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-df30b765-1ea9-40e4-b486-652ed5483a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-523a917b-a8be-4374-b487-dd18da5e60ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-4b2b6f13-eb9e-42e3-96e5-52bbf0b2c7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-7602004d-4d0c-4098-befc-a339f8e56a8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197969611-172.17.0.21-1595975424551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36437,DS-3722e490-7513-4147-b821-97e946d074fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-362611fb-3232-41fc-b6f8-b8c4d7684e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-401aceb5-ecb6-4ad3-809b-b760ae79d8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-727d1326-515b-41b5-80ec-9703b2b88a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-df30b765-1ea9-40e4-b486-652ed5483a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-523a917b-a8be-4374-b487-dd18da5e60ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-4b2b6f13-eb9e-42e3-96e5-52bbf0b2c7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-7602004d-4d0c-4098-befc-a339f8e56a8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006674055-172.17.0.21-1595975462898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32813,DS-a9ae9377-478c-4237-aafc-36966ccb9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-9445aa18-b8a8-4b7c-8adb-b220976a65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-4d636d97-25ed-4124-9c3a-4b6799aebdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-f58976a5-367e-4ad3-8338-8f0bbc151205,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-72c9828c-aa85-4527-8e15-ff62aa49d229,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-74ede8e7-9f77-4716-952c-f4b8aa782ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-b0685b0b-9e91-4c20-9c08-b7c09eb9075f,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-92049002-7c9d-41d7-b3f8-6dfcc46a6531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006674055-172.17.0.21-1595975462898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32813,DS-a9ae9377-478c-4237-aafc-36966ccb9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-9445aa18-b8a8-4b7c-8adb-b220976a65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-4d636d97-25ed-4124-9c3a-4b6799aebdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-f58976a5-367e-4ad3-8338-8f0bbc151205,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-72c9828c-aa85-4527-8e15-ff62aa49d229,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-74ede8e7-9f77-4716-952c-f4b8aa782ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-b0685b0b-9e91-4c20-9c08-b7c09eb9075f,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-92049002-7c9d-41d7-b3f8-6dfcc46a6531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277742379-172.17.0.21-1595975541968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45447,DS-1175913b-6308-4cfe-8a84-d242237011ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-c2fb8c45-bad5-4a6c-b94a-631704255635,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-684727f6-47e5-4349-ad08-add0a22dac50,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-8ac4cf22-c123-4a09-a938-822e24d91c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-de964a17-0b97-427f-8443-57061c3dcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-b1629f9f-a903-4727-8648-6b4a3177e3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-b07b4582-3559-4321-b109-d65805d13187,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-5c7c83fc-42dc-4d46-a09a-00daf76e94b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277742379-172.17.0.21-1595975541968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45447,DS-1175913b-6308-4cfe-8a84-d242237011ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-c2fb8c45-bad5-4a6c-b94a-631704255635,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-684727f6-47e5-4349-ad08-add0a22dac50,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-8ac4cf22-c123-4a09-a938-822e24d91c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-de964a17-0b97-427f-8443-57061c3dcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-b1629f9f-a903-4727-8648-6b4a3177e3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-b07b4582-3559-4321-b109-d65805d13187,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-5c7c83fc-42dc-4d46-a09a-00daf76e94b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983294424-172.17.0.21-1595976112514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37331,DS-19fba567-2e85-482e-abc2-df8b68a28262,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-2f5be786-e818-45dc-808c-bd373767b8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-ec7e9390-6bee-452f-a207-0a4646726f35,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-bd6cf844-6c74-470e-aa62-30a5b4a2076f,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-c2fdd98a-c1dc-43e1-a379-f5755520cf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-d2ab725b-acbf-4f87-8798-f16678788ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-5bff844b-5eb1-4c04-b7e7-01f962d6d5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-f26f8d77-f56b-432c-acdf-bc1c22257cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983294424-172.17.0.21-1595976112514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37331,DS-19fba567-2e85-482e-abc2-df8b68a28262,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-2f5be786-e818-45dc-808c-bd373767b8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-ec7e9390-6bee-452f-a207-0a4646726f35,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-bd6cf844-6c74-470e-aa62-30a5b4a2076f,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-c2fdd98a-c1dc-43e1-a379-f5755520cf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-d2ab725b-acbf-4f87-8798-f16678788ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-5bff844b-5eb1-4c04-b7e7-01f962d6d5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-f26f8d77-f56b-432c-acdf-bc1c22257cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303599063-172.17.0.21-1595976372842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33921,DS-3303e758-f121-4ae3-bde8-c1c263738059,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-81011ad9-0c1d-4091-b68b-25b0dba91e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-1ffb3280-dd0f-4660-b19f-c12622c94483,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-b79569be-51f4-452c-9c44-006b1de541f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-fb62bb57-ac8a-40b1-9276-81ea4036c3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-ebd513fd-7e56-449a-8662-ba664c298ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-45d91387-7ca6-4e80-9370-a573166ff52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-41a4575f-0831-4fd3-a42c-0ed00589e48e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303599063-172.17.0.21-1595976372842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33921,DS-3303e758-f121-4ae3-bde8-c1c263738059,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-81011ad9-0c1d-4091-b68b-25b0dba91e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-1ffb3280-dd0f-4660-b19f-c12622c94483,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-b79569be-51f4-452c-9c44-006b1de541f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-fb62bb57-ac8a-40b1-9276-81ea4036c3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-ebd513fd-7e56-449a-8662-ba664c298ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-45d91387-7ca6-4e80-9370-a573166ff52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-41a4575f-0831-4fd3-a42c-0ed00589e48e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689205766-172.17.0.21-1595976477229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45079,DS-d2652cca-cd15-4c24-b15f-90700a209fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-e3f9dce3-eea5-4ecd-8a23-e6bffb1c0af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-afba9759-35db-45a9-b953-dac696a233ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-ba2f6297-e687-4f66-850d-11c2df8d2668,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-b94a026c-69b9-4814-aa89-2aff4af2d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-12def87a-8f43-4a55-98d7-1b7a6e8d25de,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-1f247f71-41b6-4117-865f-22d86a5132f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-0b44fb0d-24cc-4f2c-9ce2-7039d2bca163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689205766-172.17.0.21-1595976477229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45079,DS-d2652cca-cd15-4c24-b15f-90700a209fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-e3f9dce3-eea5-4ecd-8a23-e6bffb1c0af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-afba9759-35db-45a9-b953-dac696a233ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-ba2f6297-e687-4f66-850d-11c2df8d2668,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-b94a026c-69b9-4814-aa89-2aff4af2d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-12def87a-8f43-4a55-98d7-1b7a6e8d25de,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-1f247f71-41b6-4117-865f-22d86a5132f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-0b44fb0d-24cc-4f2c-9ce2-7039d2bca163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535803101-172.17.0.21-1595976765422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-771a485b-c1c2-48d8-80a9-5fdf9155a727,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-45ebac32-02c2-48e1-bf16-039dc98694e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-8e704783-d392-4ad8-929f-ad6096bb876e,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-9313e35a-d38c-4fbd-9781-ce9b8cdb0f92,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-532c4b55-c398-46ca-a936-882f5c160bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-6f4de006-9487-41ec-bfb4-65ac6367d88b,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-5ab50e15-04d4-4170-9853-7d245d8dc549,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-d2cb7e97-68be-4705-b1af-1ee7d8fbb913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535803101-172.17.0.21-1595976765422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-771a485b-c1c2-48d8-80a9-5fdf9155a727,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-45ebac32-02c2-48e1-bf16-039dc98694e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-8e704783-d392-4ad8-929f-ad6096bb876e,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-9313e35a-d38c-4fbd-9781-ce9b8cdb0f92,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-532c4b55-c398-46ca-a936-882f5c160bae,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-6f4de006-9487-41ec-bfb4-65ac6367d88b,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-5ab50e15-04d4-4170-9853-7d245d8dc549,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-d2cb7e97-68be-4705-b1af-1ee7d8fbb913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763658054-172.17.0.21-1595976994491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44760,DS-3d65dde4-81d9-4890-bc42-bfd96ed99118,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-d051f5cb-6249-4202-944c-5e419d1298b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-97be851d-2074-447d-a60e-a9c73af639c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-5801fa03-dc6e-4aa6-bdce-456d5aea2203,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-27fa890d-809f-4bea-bd8c-d1eedca16603,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-8f48f735-bb2f-404b-a145-d6d6a233061b,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-473c8a91-30d6-4c89-8ca3-8450ca74156a,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-4bec41e4-3e55-47be-b231-0a363cdb5861,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763658054-172.17.0.21-1595976994491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44760,DS-3d65dde4-81d9-4890-bc42-bfd96ed99118,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-d051f5cb-6249-4202-944c-5e419d1298b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-97be851d-2074-447d-a60e-a9c73af639c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-5801fa03-dc6e-4aa6-bdce-456d5aea2203,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-27fa890d-809f-4bea-bd8c-d1eedca16603,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-8f48f735-bb2f-404b-a145-d6d6a233061b,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-473c8a91-30d6-4c89-8ca3-8450ca74156a,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-4bec41e4-3e55-47be-b231-0a363cdb5861,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412573514-172.17.0.21-1595977437201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44627,DS-d5be635a-b5b9-404b-b013-38fbfe6d72c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-c4869e3d-2537-494f-99e5-7a7f48ea2905,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-68c796e6-1dfe-4381-a8ac-cfe7d973e900,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-cf674ae8-4a57-4861-9b73-94158b3d77ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-f3daeac1-eb64-4a7a-b091-f23c2c12b70a,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-7ebf0ee3-2880-40e8-8a19-500aa79f98f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-e344095b-7b83-431b-8084-6246942cf825,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-fd11d2c9-98ce-4360-8245-cbe43034457c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412573514-172.17.0.21-1595977437201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44627,DS-d5be635a-b5b9-404b-b013-38fbfe6d72c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-c4869e3d-2537-494f-99e5-7a7f48ea2905,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-68c796e6-1dfe-4381-a8ac-cfe7d973e900,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-cf674ae8-4a57-4861-9b73-94158b3d77ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-f3daeac1-eb64-4a7a-b091-f23c2c12b70a,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-7ebf0ee3-2880-40e8-8a19-500aa79f98f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-e344095b-7b83-431b-8084-6246942cf825,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-fd11d2c9-98ce-4360-8245-cbe43034457c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069639782-172.17.0.21-1595977552664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33913,DS-04bb5e0f-f2b5-4bac-b27c-02e4a54807b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-d14cbd3c-987b-430b-8a77-740a20959773,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-fc2e1c64-dbea-4062-b580-1ecdfbacf971,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-fead850e-d0e6-4734-8936-86b988c95e42,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-9ec8b611-e86d-4190-9ef4-6c7868c7b5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-883e9632-c969-4052-b47c-7e73aee1f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-935e42bb-b4cd-4b79-8b0c-0f9a0631f76e,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-092dbad5-78ce-444d-9246-a7274294f3a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069639782-172.17.0.21-1595977552664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33913,DS-04bb5e0f-f2b5-4bac-b27c-02e4a54807b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-d14cbd3c-987b-430b-8a77-740a20959773,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-fc2e1c64-dbea-4062-b580-1ecdfbacf971,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-fead850e-d0e6-4734-8936-86b988c95e42,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-9ec8b611-e86d-4190-9ef4-6c7868c7b5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-883e9632-c969-4052-b47c-7e73aee1f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-935e42bb-b4cd-4b79-8b0c-0f9a0631f76e,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-092dbad5-78ce-444d-9246-a7274294f3a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349323666-172.17.0.21-1595977821535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34145,DS-f5c458d7-87e8-4f7e-8933-c979df3366fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-c1348c80-fd4a-49d5-81ab-212e283417a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-046591c3-fb77-4d09-8211-788a69be5704,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-278fa64c-aa6f-4cf7-9855-1a89565d2d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-3707ade8-f032-476a-89be-df12b54ed298,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-951a39a2-ad1c-40a6-b74e-27a340b59b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-dedb5a29-9300-44cb-a35c-e3b58dfa3ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-a9b077a3-d833-4bc6-8a94-9c1724c1f727,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349323666-172.17.0.21-1595977821535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34145,DS-f5c458d7-87e8-4f7e-8933-c979df3366fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-c1348c80-fd4a-49d5-81ab-212e283417a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-046591c3-fb77-4d09-8211-788a69be5704,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-278fa64c-aa6f-4cf7-9855-1a89565d2d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-3707ade8-f032-476a-89be-df12b54ed298,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-951a39a2-ad1c-40a6-b74e-27a340b59b75,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-dedb5a29-9300-44cb-a35c-e3b58dfa3ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-a9b077a3-d833-4bc6-8a94-9c1724c1f727,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384556713-172.17.0.21-1595977978107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42551,DS-3cb3a71e-29a5-4fae-bf92-0ae4a71ea706,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-3eb02022-5d29-4334-b103-c457e11eb4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-7cf59762-9e1f-45cd-8b67-ed1eb62086e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-e1a5f82f-4eb5-48bb-bedb-791ad7d1c279,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-1ea19cff-987e-488b-86f2-0c8fdbe28aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-663ad12c-2e99-4634-81ef-5ee376248f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-46e31594-d7b0-44a9-87eb-cedbb983095c,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-0b663426-815c-4b32-a53b-766378fcf87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384556713-172.17.0.21-1595977978107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42551,DS-3cb3a71e-29a5-4fae-bf92-0ae4a71ea706,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-3eb02022-5d29-4334-b103-c457e11eb4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-7cf59762-9e1f-45cd-8b67-ed1eb62086e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-e1a5f82f-4eb5-48bb-bedb-791ad7d1c279,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-1ea19cff-987e-488b-86f2-0c8fdbe28aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-663ad12c-2e99-4634-81ef-5ee376248f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-46e31594-d7b0-44a9-87eb-cedbb983095c,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-0b663426-815c-4b32-a53b-766378fcf87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586450600-172.17.0.21-1595978024815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36898,DS-f1f832f0-6cd0-4786-9680-1ebcc722e5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-656c7c48-867e-4777-b31e-ef5e820b54af,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-0db3ee70-15b0-4983-ba4f-9387bdf9a141,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-977ae06b-c0e7-48c3-b24d-21cd766502dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-39f22778-7e6f-4b56-b297-4c8ccdaf0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-2194e071-a936-4e73-a8d2-5e6f4cb320bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-276a6d74-d8de-488c-938f-f8d9f916c350,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-8c5b4057-d76d-4acf-b262-b69048178803,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586450600-172.17.0.21-1595978024815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36898,DS-f1f832f0-6cd0-4786-9680-1ebcc722e5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-656c7c48-867e-4777-b31e-ef5e820b54af,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-0db3ee70-15b0-4983-ba4f-9387bdf9a141,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-977ae06b-c0e7-48c3-b24d-21cd766502dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-39f22778-7e6f-4b56-b297-4c8ccdaf0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-2194e071-a936-4e73-a8d2-5e6f4cb320bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-276a6d74-d8de-488c-938f-f8d9f916c350,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-8c5b4057-d76d-4acf-b262-b69048178803,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292555356-172.17.0.21-1595978541280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38344,DS-eee0f601-ba46-45d3-8b5e-05dfba4fd6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-285f6118-ba1d-4b48-8bbf-9f6b73567fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-1b576727-e663-461b-9acc-98d85b5b1488,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-a75f3d4b-c431-46c5-8d6f-ea7ec1afb443,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-2fdca8dc-ba39-4199-be3e-e1a3ec1ec6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-e3f589ab-d7af-4f1b-bdc6-f2dd9d9ea140,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-d1099e36-faa5-4956-9f3f-a26d2694d255,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-5eefb5ec-b291-4dce-b5c7-56602269722b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292555356-172.17.0.21-1595978541280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38344,DS-eee0f601-ba46-45d3-8b5e-05dfba4fd6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-285f6118-ba1d-4b48-8bbf-9f6b73567fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-1b576727-e663-461b-9acc-98d85b5b1488,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-a75f3d4b-c431-46c5-8d6f-ea7ec1afb443,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-2fdca8dc-ba39-4199-be3e-e1a3ec1ec6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-e3f589ab-d7af-4f1b-bdc6-f2dd9d9ea140,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-d1099e36-faa5-4956-9f3f-a26d2694d255,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-5eefb5ec-b291-4dce-b5c7-56602269722b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5728
