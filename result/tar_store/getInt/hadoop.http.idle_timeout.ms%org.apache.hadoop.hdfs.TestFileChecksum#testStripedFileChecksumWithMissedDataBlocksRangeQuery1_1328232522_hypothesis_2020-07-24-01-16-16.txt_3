reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559135890-172.17.0.18-1595553743745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44275,DS-126f806f-5420-47d0-9175-90900e10979a,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-d25b5213-d1c7-44b6-93a9-819307732f26,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-5e9b0c5a-dd12-4803-9817-63d68e2f8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-33ff615b-3cc1-46bc-bf1d-5c35a848effa,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-469f8ef0-efc3-41c8-80cb-b14b1732b3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-4cadcc9c-3578-4ca1-ae03-d1aa881925fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-8d5e2315-2692-4c19-8771-2e9810321cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-6cda4d5c-ac0e-4c48-89fe-49dcb60d9ef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559135890-172.17.0.18-1595553743745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44275,DS-126f806f-5420-47d0-9175-90900e10979a,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-d25b5213-d1c7-44b6-93a9-819307732f26,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-5e9b0c5a-dd12-4803-9817-63d68e2f8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-33ff615b-3cc1-46bc-bf1d-5c35a848effa,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-469f8ef0-efc3-41c8-80cb-b14b1732b3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-4cadcc9c-3578-4ca1-ae03-d1aa881925fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-8d5e2315-2692-4c19-8771-2e9810321cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-6cda4d5c-ac0e-4c48-89fe-49dcb60d9ef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27940975-172.17.0.18-1595553898785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45526,DS-38f96c4d-78bc-4fdb-ab9c-4f4d8891aa35,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-50e1d39e-968e-4ae2-9674-58724052e71a,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b68c523a-ebbb-4cf1-a913-f53ba91ec8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-c15655e2-2af8-44bd-b558-ee9bb8104e78,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-9f559833-5f73-4539-8e56-0e85bdcca8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-4ddfee38-6390-4190-af4c-b49b0d6a1192,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-f3209196-dd0f-4ae0-b72a-65c025971ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-d1b39a3a-375f-4e37-a91f-92dd40a5a0a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27940975-172.17.0.18-1595553898785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45526,DS-38f96c4d-78bc-4fdb-ab9c-4f4d8891aa35,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-50e1d39e-968e-4ae2-9674-58724052e71a,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b68c523a-ebbb-4cf1-a913-f53ba91ec8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-c15655e2-2af8-44bd-b558-ee9bb8104e78,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-9f559833-5f73-4539-8e56-0e85bdcca8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-4ddfee38-6390-4190-af4c-b49b0d6a1192,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-f3209196-dd0f-4ae0-b72a-65c025971ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-d1b39a3a-375f-4e37-a91f-92dd40a5a0a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322303730-172.17.0.18-1595554729283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41235,DS-d3991436-ad46-4161-9e4d-ee19a765bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-243fe977-f3eb-421d-b88c-bb7b29b2c97f,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-652c47ad-0a32-4ff9-bc70-5e117d091c62,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-3b09c402-0c45-46cc-b8c4-597a4da2eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-80d98565-de3d-4f58-b39b-e62d9d62f346,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-07c79698-f80c-490a-b3d3-e5974463a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-980680af-5572-43f5-8668-efeecb1a9d09,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-2037bf52-d92e-43c6-90a0-247e59fbb284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322303730-172.17.0.18-1595554729283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41235,DS-d3991436-ad46-4161-9e4d-ee19a765bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-243fe977-f3eb-421d-b88c-bb7b29b2c97f,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-652c47ad-0a32-4ff9-bc70-5e117d091c62,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-3b09c402-0c45-46cc-b8c4-597a4da2eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-80d98565-de3d-4f58-b39b-e62d9d62f346,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-07c79698-f80c-490a-b3d3-e5974463a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-980680af-5572-43f5-8668-efeecb1a9d09,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-2037bf52-d92e-43c6-90a0-247e59fbb284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90653237-172.17.0.18-1595555141282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35753,DS-c2d7c147-1ef9-4645-9cd3-7e50880cd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-93d13068-2a02-43fa-8e41-0266acbbab82,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-c63b2c54-043b-4868-a450-0604e18f5589,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-19b7c86d-7a23-4c01-9f99-d4136e04d3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-687da98e-3bfb-49db-ba4f-125c932f1f56,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-57f04dd8-68c6-4cc3-b461-f69516baa88d,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-806cc20c-e4ed-4b4f-b200-dfffe8371ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-a4c1cd74-bf11-4d38-bdc3-bd2e91debb95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90653237-172.17.0.18-1595555141282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35753,DS-c2d7c147-1ef9-4645-9cd3-7e50880cd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-93d13068-2a02-43fa-8e41-0266acbbab82,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-c63b2c54-043b-4868-a450-0604e18f5589,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-19b7c86d-7a23-4c01-9f99-d4136e04d3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-687da98e-3bfb-49db-ba4f-125c932f1f56,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-57f04dd8-68c6-4cc3-b461-f69516baa88d,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-806cc20c-e4ed-4b4f-b200-dfffe8371ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-a4c1cd74-bf11-4d38-bdc3-bd2e91debb95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297223473-172.17.0.18-1595555183007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35614,DS-7e9867b2-0e8d-4bf7-b163-d541a2c85ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-b6ca990b-4f92-44fd-af4f-149dc6e5feaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-51780456-e803-4c58-a83f-afe0ca9e52cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-ae909de5-9be7-4654-8a02-2f32c60a5502,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-11c4f263-bb25-4944-b665-393b63a61aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-4c2fdf8e-8941-4a4c-9f48-6bfd32ec306c,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-83d86a6d-12f6-4418-8823-9013100b82f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-53e8ed91-0d39-4528-b600-29ea6ac2a458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297223473-172.17.0.18-1595555183007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35614,DS-7e9867b2-0e8d-4bf7-b163-d541a2c85ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-b6ca990b-4f92-44fd-af4f-149dc6e5feaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-51780456-e803-4c58-a83f-afe0ca9e52cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-ae909de5-9be7-4654-8a02-2f32c60a5502,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-11c4f263-bb25-4944-b665-393b63a61aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-4c2fdf8e-8941-4a4c-9f48-6bfd32ec306c,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-83d86a6d-12f6-4418-8823-9013100b82f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-53e8ed91-0d39-4528-b600-29ea6ac2a458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246216085-172.17.0.18-1595555220286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36909,DS-127ba069-dbc9-468b-88c5-0c48a8c5fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-14ec8398-6f67-4759-98e1-825c4b29dc39,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-f1a4bead-d010-459b-8526-acd95c777451,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-2d9e6376-0330-44dc-87d1-46355cccc463,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-938c5bf5-ce37-4c91-9145-c016c4c7dc48,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-d96384b7-70d3-4a67-9b24-ed0b4eab3a11,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-d93e0ddc-40c4-4ecc-80aa-760d97448063,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-c1c827c0-bd26-4fc5-90b7-fabdf7e7e11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246216085-172.17.0.18-1595555220286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36909,DS-127ba069-dbc9-468b-88c5-0c48a8c5fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-14ec8398-6f67-4759-98e1-825c4b29dc39,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-f1a4bead-d010-459b-8526-acd95c777451,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-2d9e6376-0330-44dc-87d1-46355cccc463,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-938c5bf5-ce37-4c91-9145-c016c4c7dc48,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-d96384b7-70d3-4a67-9b24-ed0b4eab3a11,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-d93e0ddc-40c4-4ecc-80aa-760d97448063,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-c1c827c0-bd26-4fc5-90b7-fabdf7e7e11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135749545-172.17.0.18-1595556534215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-ff21bc5d-2df6-4fd6-b0f6-d4e21ebdb7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-c15585f7-057e-44b3-9abf-27ebb71a267f,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-34de921f-9e88-4a6e-8be6-eca71371d204,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-a5376e4d-5709-4652-94e0-ec83ab469927,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-8b635c36-f7a3-473c-bed5-bfa5d5e877a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-83d38d12-77dd-4ab8-9500-b6c500073629,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-76af0b95-47d1-48e5-902e-333842eef47a,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-08c361ca-ba70-4740-b79e-e107d57e9ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135749545-172.17.0.18-1595556534215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-ff21bc5d-2df6-4fd6-b0f6-d4e21ebdb7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-c15585f7-057e-44b3-9abf-27ebb71a267f,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-34de921f-9e88-4a6e-8be6-eca71371d204,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-a5376e4d-5709-4652-94e0-ec83ab469927,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-8b635c36-f7a3-473c-bed5-bfa5d5e877a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-83d38d12-77dd-4ab8-9500-b6c500073629,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-76af0b95-47d1-48e5-902e-333842eef47a,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-08c361ca-ba70-4740-b79e-e107d57e9ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424109360-172.17.0.18-1595556659731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46836,DS-f597da3b-d25a-482b-9176-8df2b146f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-f96bbcad-7e3e-4929-9726-b8b6a217614c,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-a4684adb-2b60-4004-abba-765eab61bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-cc3d4691-8be5-4fb2-9e11-f481a845c259,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-2bda2e18-7f6a-4c52-b083-2f5e4336f897,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-000af1f6-36e7-41ff-ba4a-e415ac7b74cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-d8ef2fda-666f-4fdf-a0d0-fddfe2b1961b,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-4b3ac83c-cea8-4bf2-8814-4b747dcacf1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424109360-172.17.0.18-1595556659731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46836,DS-f597da3b-d25a-482b-9176-8df2b146f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-f96bbcad-7e3e-4929-9726-b8b6a217614c,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-a4684adb-2b60-4004-abba-765eab61bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-cc3d4691-8be5-4fb2-9e11-f481a845c259,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-2bda2e18-7f6a-4c52-b083-2f5e4336f897,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-000af1f6-36e7-41ff-ba4a-e415ac7b74cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-d8ef2fda-666f-4fdf-a0d0-fddfe2b1961b,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-4b3ac83c-cea8-4bf2-8814-4b747dcacf1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909688781-172.17.0.18-1595557063830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42497,DS-8f7e8af8-fbbb-4d92-bdbd-a6252acce6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-4be8b029-cc37-4dd2-92c4-680a726e6b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-d4364a29-da30-443c-b698-65565a812fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-cd492174-f84d-416e-9952-bc2a79599203,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-7147bf94-3a82-4d70-8f2f-d952e5325e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-dd9c88a9-3de4-44ce-bdf9-e6c49ae708d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-674b29b2-b2ae-4d85-816c-409d0e281d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-abac4b0d-861c-470f-9f17-5f52e65cdd3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909688781-172.17.0.18-1595557063830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42497,DS-8f7e8af8-fbbb-4d92-bdbd-a6252acce6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-4be8b029-cc37-4dd2-92c4-680a726e6b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-d4364a29-da30-443c-b698-65565a812fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-cd492174-f84d-416e-9952-bc2a79599203,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-7147bf94-3a82-4d70-8f2f-d952e5325e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-dd9c88a9-3de4-44ce-bdf9-e6c49ae708d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-674b29b2-b2ae-4d85-816c-409d0e281d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-abac4b0d-861c-470f-9f17-5f52e65cdd3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961216139-172.17.0.18-1595557186538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42224,DS-eccf22e1-38e2-4485-8208-70f8a443b1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-3c468ea9-b899-4dfb-a9b2-0e682c73fc10,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-d30c71cd-3633-45d6-a6d0-f9f2bdf9cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-50d863b5-55be-4423-a1b9-bf865c8ba1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-0a2c177d-28b3-46ee-8de5-fceea85ce2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-7080a27f-c1e8-41ec-8650-88b2d9d73a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-f7d1536e-bbe7-4973-9b0c-c82f111ef210,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-a33bee95-834f-4b33-b8be-f0e4619c005a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961216139-172.17.0.18-1595557186538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42224,DS-eccf22e1-38e2-4485-8208-70f8a443b1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-3c468ea9-b899-4dfb-a9b2-0e682c73fc10,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-d30c71cd-3633-45d6-a6d0-f9f2bdf9cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-50d863b5-55be-4423-a1b9-bf865c8ba1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-0a2c177d-28b3-46ee-8de5-fceea85ce2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-7080a27f-c1e8-41ec-8650-88b2d9d73a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-f7d1536e-bbe7-4973-9b0c-c82f111ef210,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-a33bee95-834f-4b33-b8be-f0e4619c005a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906418850-172.17.0.18-1595557258051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43850,DS-71e0d4b4-9244-4272-a557-c5b39b9f80f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-b7dc3135-67d1-4f29-8380-4f10e88eaa22,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-ed75beb8-8c8c-4cf5-b6d5-418e0aa61c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-d4ebdd46-87e5-4e51-a8af-2e5fec7daee7,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-2b7ed0ae-7909-4285-9dc7-4742bd37cb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-42c3f151-1c0c-424e-a403-38a6110df56b,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-3dbecfde-49c0-473f-8496-c7d69d357619,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-c3b6e622-5c3c-49ff-91e2-d59467fc529e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906418850-172.17.0.18-1595557258051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43850,DS-71e0d4b4-9244-4272-a557-c5b39b9f80f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-b7dc3135-67d1-4f29-8380-4f10e88eaa22,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-ed75beb8-8c8c-4cf5-b6d5-418e0aa61c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-d4ebdd46-87e5-4e51-a8af-2e5fec7daee7,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-2b7ed0ae-7909-4285-9dc7-4742bd37cb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-42c3f151-1c0c-424e-a403-38a6110df56b,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-3dbecfde-49c0-473f-8496-c7d69d357619,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-c3b6e622-5c3c-49ff-91e2-d59467fc529e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465763470-172.17.0.18-1595557469983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-d39ecd9e-a298-41b0-a56b-530005ed2885,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-cdc01d89-6d6b-49d9-a67e-cfa929b7fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-86e948bb-434d-4ebe-9627-67958e08a907,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-355da4e3-61ac-4bb5-80f8-01cc9df7878c,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-1fa67a6a-6803-4ae4-bd11-9c6abfee4b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-08ffa928-ead4-4a78-8d6a-76ecfc880ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-8bc9319b-bc38-4cd4-97a7-3d3abec4cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-cb1174eb-5a04-4459-9eb7-d781da7eaeb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465763470-172.17.0.18-1595557469983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-d39ecd9e-a298-41b0-a56b-530005ed2885,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-cdc01d89-6d6b-49d9-a67e-cfa929b7fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-86e948bb-434d-4ebe-9627-67958e08a907,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-355da4e3-61ac-4bb5-80f8-01cc9df7878c,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-1fa67a6a-6803-4ae4-bd11-9c6abfee4b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-08ffa928-ead4-4a78-8d6a-76ecfc880ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-8bc9319b-bc38-4cd4-97a7-3d3abec4cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-cb1174eb-5a04-4459-9eb7-d781da7eaeb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147055177-172.17.0.18-1595558556618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-10e9e36a-475c-4e20-ba75-6a2dcc80b5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-641f00b0-1eb6-43c1-ad26-e75d03c9312a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-6a074bf9-04ad-4a4c-9fe5-80ab7cf7fad8,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-7de7e7c4-4b46-49cc-92bc-3226bc5377db,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-08561875-f050-4a43-8b95-0cd470e781b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-8e9c1c82-2678-4683-8c76-d17d961dbb37,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-00021758-ff38-4def-a54d-c89a201bd0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-ef5b6ec7-e2de-4489-9562-7dc7360b6d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147055177-172.17.0.18-1595558556618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-10e9e36a-475c-4e20-ba75-6a2dcc80b5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-641f00b0-1eb6-43c1-ad26-e75d03c9312a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-6a074bf9-04ad-4a4c-9fe5-80ab7cf7fad8,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-7de7e7c4-4b46-49cc-92bc-3226bc5377db,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-08561875-f050-4a43-8b95-0cd470e781b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-8e9c1c82-2678-4683-8c76-d17d961dbb37,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-00021758-ff38-4def-a54d-c89a201bd0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-ef5b6ec7-e2de-4489-9562-7dc7360b6d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5230
