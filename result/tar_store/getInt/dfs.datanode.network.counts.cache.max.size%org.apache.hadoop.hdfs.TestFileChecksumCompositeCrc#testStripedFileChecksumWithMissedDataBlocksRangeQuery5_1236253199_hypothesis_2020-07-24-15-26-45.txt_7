reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601987083-172.17.0.20-1595604897082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43143,DS-2631457b-5121-4cf9-963b-b243d349aac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-681618a3-06df-4c95-953f-83ffe60da293,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-5fc19882-a326-4d75-9abd-65ab4bb8efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-e873bdb6-1ddf-45b1-a445-da981a507f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-9058b05c-f1ac-4254-afd5-8c76b52a443a,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-d3bfb54f-c3aa-4a1d-a872-2dc99e81d29b,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-d8203314-c217-4564-bad2-941f8064020a,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-da4b1b77-3a98-43ba-8db0-9688e15727c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601987083-172.17.0.20-1595604897082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43143,DS-2631457b-5121-4cf9-963b-b243d349aac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-681618a3-06df-4c95-953f-83ffe60da293,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-5fc19882-a326-4d75-9abd-65ab4bb8efb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-e873bdb6-1ddf-45b1-a445-da981a507f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-9058b05c-f1ac-4254-afd5-8c76b52a443a,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-d3bfb54f-c3aa-4a1d-a872-2dc99e81d29b,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-d8203314-c217-4564-bad2-941f8064020a,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-da4b1b77-3a98-43ba-8db0-9688e15727c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475484507-172.17.0.20-1595605182872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46371,DS-299fc7fc-9cab-4f2b-87ed-b0d27719beae,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-1dc299ec-5412-4a38-b6f3-2fc331d8b1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-734f737a-dd4c-4763-a86d-8775ca693ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-3eaa510a-4573-4cca-b9db-d01244e394fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-bc23df8b-25dd-4f47-9de5-8037f560e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-77df5dcd-1e23-4eef-8987-a07475295f11,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-eabdd8bb-8d03-4d4f-a92a-8f1be3a83d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-f5c1c850-8fc7-4662-be5b-36f599282499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475484507-172.17.0.20-1595605182872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46371,DS-299fc7fc-9cab-4f2b-87ed-b0d27719beae,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-1dc299ec-5412-4a38-b6f3-2fc331d8b1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-734f737a-dd4c-4763-a86d-8775ca693ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-3eaa510a-4573-4cca-b9db-d01244e394fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-bc23df8b-25dd-4f47-9de5-8037f560e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-77df5dcd-1e23-4eef-8987-a07475295f11,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-eabdd8bb-8d03-4d4f-a92a-8f1be3a83d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-f5c1c850-8fc7-4662-be5b-36f599282499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091213850-172.17.0.20-1595605316017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-b696f637-1a83-4fd2-8c55-b34e242cf56c,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-8928f614-2efa-4e76-8813-8d9f495ee8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-42e39084-a838-475b-93f4-312f2d001c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-442417fb-71a9-4590-bc57-cf49f4b93f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-7309b61f-d7e6-4b01-9d36-8388f8e0207d,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-c9e9624e-27ae-4fd1-aff5-e8e9b2b003a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-951e4fd5-fae5-49c5-98f7-56a86e96829d,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-4d3a10a5-6cbf-4022-a846-ae68fe39f80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091213850-172.17.0.20-1595605316017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-b696f637-1a83-4fd2-8c55-b34e242cf56c,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-8928f614-2efa-4e76-8813-8d9f495ee8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-42e39084-a838-475b-93f4-312f2d001c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-442417fb-71a9-4590-bc57-cf49f4b93f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-7309b61f-d7e6-4b01-9d36-8388f8e0207d,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-c9e9624e-27ae-4fd1-aff5-e8e9b2b003a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-951e4fd5-fae5-49c5-98f7-56a86e96829d,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-4d3a10a5-6cbf-4022-a846-ae68fe39f80f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130484745-172.17.0.20-1595605619072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35683,DS-742a3ac0-1f33-4f95-b48f-200b6a353f64,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-8a476d94-27f9-4b71-ba87-401cbc334ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-6b03bea8-3d7b-43b2-9705-2e87fffbdeba,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-671bda10-2487-4225-887c-3556b586bc29,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-e735ed73-1414-409a-a876-aea3589fff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-27bf2afd-abb9-4af5-9f4a-592c221f73c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-2d7acbb3-7d8c-4649-8bbf-aef9e2626ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-d8309a8d-982f-4f35-baeb-5f46276ff1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130484745-172.17.0.20-1595605619072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35683,DS-742a3ac0-1f33-4f95-b48f-200b6a353f64,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-8a476d94-27f9-4b71-ba87-401cbc334ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-6b03bea8-3d7b-43b2-9705-2e87fffbdeba,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-671bda10-2487-4225-887c-3556b586bc29,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-e735ed73-1414-409a-a876-aea3589fff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-27bf2afd-abb9-4af5-9f4a-592c221f73c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-2d7acbb3-7d8c-4649-8bbf-aef9e2626ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-d8309a8d-982f-4f35-baeb-5f46276ff1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735466277-172.17.0.20-1595605761575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38778,DS-c2407973-d33a-498f-ae01-130519e5f971,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-1b3c59c0-dcb1-4c9e-845b-2e72ab9f09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-ee43cdbc-fb6c-42ef-993b-17d8069bef46,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-1909c253-812a-4e64-acc5-4492cb3c44e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-b7e382b0-ccc1-4dd8-aa73-afe048e7e214,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-3c4a9e1c-d6d4-455b-ad96-9a974ccb8af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-60df8682-a356-4bbe-8602-7580d345206c,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-415be605-4568-43d0-95f4-34bf1a53ad16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735466277-172.17.0.20-1595605761575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38778,DS-c2407973-d33a-498f-ae01-130519e5f971,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-1b3c59c0-dcb1-4c9e-845b-2e72ab9f09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-ee43cdbc-fb6c-42ef-993b-17d8069bef46,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-1909c253-812a-4e64-acc5-4492cb3c44e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-b7e382b0-ccc1-4dd8-aa73-afe048e7e214,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-3c4a9e1c-d6d4-455b-ad96-9a974ccb8af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-60df8682-a356-4bbe-8602-7580d345206c,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-415be605-4568-43d0-95f4-34bf1a53ad16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446194341-172.17.0.20-1595606405827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41757,DS-89d2d6d7-c35f-41c1-99e9-3126fb53b510,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-6eead3c0-5336-4b60-b818-d565391d7e43,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-aa9696d0-7e47-4d18-9f8d-d87a2100fe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-cb57964f-61a6-4892-9a46-cb3faf277e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-8b17b3b0-97b4-4464-a232-f24fc40a8925,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-e46f046a-14f0-43d0-bfd7-3806e22e4e66,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-8b1aa323-6053-49ac-b521-0e39d9e70748,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-9db49843-bd1e-45e9-a79f-23bc7163b77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446194341-172.17.0.20-1595606405827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41757,DS-89d2d6d7-c35f-41c1-99e9-3126fb53b510,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-6eead3c0-5336-4b60-b818-d565391d7e43,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-aa9696d0-7e47-4d18-9f8d-d87a2100fe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-cb57964f-61a6-4892-9a46-cb3faf277e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-8b17b3b0-97b4-4464-a232-f24fc40a8925,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-e46f046a-14f0-43d0-bfd7-3806e22e4e66,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-8b1aa323-6053-49ac-b521-0e39d9e70748,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-9db49843-bd1e-45e9-a79f-23bc7163b77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435093596-172.17.0.20-1595606445459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-b9c7bebc-b74e-4bf2-aecf-be96b609ad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-90f58899-4ef7-4152-a240-679a18038c15,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-5c26b03a-b6fc-4b6d-aebe-c160f9f4da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-c5a774ff-c113-4ec0-b8cf-a17446e6ce5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-811c7c26-a1d3-4ace-b963-3b75745d7938,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-1eadeaf2-c4ba-4553-a25b-922e8e614b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-fc6a2f0b-cb75-430a-84f6-6290e30a297a,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-c569a84f-05b4-47a9-9134-a6e969811714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435093596-172.17.0.20-1595606445459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-b9c7bebc-b74e-4bf2-aecf-be96b609ad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-90f58899-4ef7-4152-a240-679a18038c15,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-5c26b03a-b6fc-4b6d-aebe-c160f9f4da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-c5a774ff-c113-4ec0-b8cf-a17446e6ce5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-811c7c26-a1d3-4ace-b963-3b75745d7938,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-1eadeaf2-c4ba-4553-a25b-922e8e614b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-fc6a2f0b-cb75-430a-84f6-6290e30a297a,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-c569a84f-05b4-47a9-9134-a6e969811714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693508524-172.17.0.20-1595606850973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-410bb1be-8d38-43c0-896d-73b740fba27d,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-7ad97995-a08d-4bdd-97a2-5ee837435170,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-7fde6b9f-e02e-4711-bfa3-28d7dd2a63ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-b9b571ad-d023-426c-967f-217be2af999f,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-c6292db0-b41f-4933-a7d5-06a5be05c539,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-4c6f5aec-3399-4955-bc0e-10ade89a1bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-18e88f8b-6e04-4b9e-a127-10f1ea6620d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-2c1f49e2-3ed1-438b-b316-ba7245bff571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693508524-172.17.0.20-1595606850973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-410bb1be-8d38-43c0-896d-73b740fba27d,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-7ad97995-a08d-4bdd-97a2-5ee837435170,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-7fde6b9f-e02e-4711-bfa3-28d7dd2a63ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-b9b571ad-d023-426c-967f-217be2af999f,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-c6292db0-b41f-4933-a7d5-06a5be05c539,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-4c6f5aec-3399-4955-bc0e-10ade89a1bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-18e88f8b-6e04-4b9e-a127-10f1ea6620d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-2c1f49e2-3ed1-438b-b316-ba7245bff571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686033888-172.17.0.20-1595607270550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-78d775f3-6d24-45e0-83ca-d4cd92c382bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-38def05d-26a3-4bfb-876e-ab1431f55b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-9099f8d4-4c78-4671-bdde-aa03b0827e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-cf9a900f-130c-4b66-aed3-039e38f6c62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-6443b4de-5bbc-42ec-a62d-606dd7dfcfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-0f7bdd80-55ef-4ab8-bbcf-39f3f9cb64b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-802d182b-3d59-49ab-a6bc-c13c02670e98,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-ee800663-e1b5-45a8-beab-ad583e604cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686033888-172.17.0.20-1595607270550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-78d775f3-6d24-45e0-83ca-d4cd92c382bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-38def05d-26a3-4bfb-876e-ab1431f55b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-9099f8d4-4c78-4671-bdde-aa03b0827e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-cf9a900f-130c-4b66-aed3-039e38f6c62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-6443b4de-5bbc-42ec-a62d-606dd7dfcfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-0f7bdd80-55ef-4ab8-bbcf-39f3f9cb64b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-802d182b-3d59-49ab-a6bc-c13c02670e98,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-ee800663-e1b5-45a8-beab-ad583e604cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211782914-172.17.0.20-1595607446686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45672,DS-5a961527-69b7-42c0-8632-8d7d913b6d72,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-9e5ca899-5824-47e1-bdd3-ef69874e7bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-df4cb0e1-a02b-42d2-9aff-d55d880cf539,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-054e7397-a169-43d9-8bae-0b74808c5af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-4d98b6b6-a00c-4ba9-8208-9a168ddb65ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-d83273d9-8046-4a83-9629-ae306d3df97e,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-f9e7952c-4180-4b8c-adb8-155328d4cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-365e3622-30e4-4cd0-afb7-60e33fbb2b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211782914-172.17.0.20-1595607446686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45672,DS-5a961527-69b7-42c0-8632-8d7d913b6d72,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-9e5ca899-5824-47e1-bdd3-ef69874e7bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-df4cb0e1-a02b-42d2-9aff-d55d880cf539,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-054e7397-a169-43d9-8bae-0b74808c5af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-4d98b6b6-a00c-4ba9-8208-9a168ddb65ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-d83273d9-8046-4a83-9629-ae306d3df97e,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-f9e7952c-4180-4b8c-adb8-155328d4cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-365e3622-30e4-4cd0-afb7-60e33fbb2b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989725764-172.17.0.20-1595607520492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34323,DS-844963d7-bfc4-45d6-9f20-0ed22b743fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-c797fa03-76ec-4ef6-a319-5d945d7169f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-c1272dbe-4725-4602-b637-9a25a4449474,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-d3cc8033-f051-4a0e-8533-78ff6b598b93,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-7a435d63-f2c0-444d-b61f-005ce876ac84,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-d887e4e8-052b-426a-8375-3a66141086a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-c55306ea-b57e-49a2-aac1-8455aba69d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-a94911fa-6d13-407b-80ba-540ef53db752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989725764-172.17.0.20-1595607520492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34323,DS-844963d7-bfc4-45d6-9f20-0ed22b743fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-c797fa03-76ec-4ef6-a319-5d945d7169f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-c1272dbe-4725-4602-b637-9a25a4449474,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-d3cc8033-f051-4a0e-8533-78ff6b598b93,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-7a435d63-f2c0-444d-b61f-005ce876ac84,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-d887e4e8-052b-426a-8375-3a66141086a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-c55306ea-b57e-49a2-aac1-8455aba69d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-a94911fa-6d13-407b-80ba-540ef53db752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558285937-172.17.0.20-1595608403239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35142,DS-e51a8916-1679-4335-a7bd-69b92b5d08b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-e1d0fad4-1bfe-4fd0-a45f-30b168a01c46,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-125881db-fac3-44df-956a-5282335dd4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-d1164be0-d719-49bb-b2fa-9ee4f466ca34,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-e3588ae5-f8fa-49cd-bd7f-6a7a5be83d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-14f1b59a-bea7-4e22-983f-59ca2453c410,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-66ea6019-aba1-4497-b17b-c21769652900,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-7c14a103-f778-499c-b565-b1f5b0eaa057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558285937-172.17.0.20-1595608403239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35142,DS-e51a8916-1679-4335-a7bd-69b92b5d08b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-e1d0fad4-1bfe-4fd0-a45f-30b168a01c46,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-125881db-fac3-44df-956a-5282335dd4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-d1164be0-d719-49bb-b2fa-9ee4f466ca34,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-e3588ae5-f8fa-49cd-bd7f-6a7a5be83d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-14f1b59a-bea7-4e22-983f-59ca2453c410,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-66ea6019-aba1-4497-b17b-c21769652900,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-7c14a103-f778-499c-b565-b1f5b0eaa057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20372125-172.17.0.20-1595608496020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36311,DS-2fb1c19c-6b1b-45de-9a88-3081987a0ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-25d67a09-15a5-4ae6-9f35-cf0779a4dab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-6ed23e26-d706-405a-920a-f8118e13fdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-2d580a06-219a-47ac-8da3-19cab660b722,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-1f8ffc18-964f-4fd7-9b01-9c0924b225bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-e3304b6d-14bf-4b77-aef9-b0abc1f8aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-4a107cca-4e82-444d-8546-330006f265d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-7c15d631-7236-46dd-85f8-2796e405fd12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20372125-172.17.0.20-1595608496020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36311,DS-2fb1c19c-6b1b-45de-9a88-3081987a0ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-25d67a09-15a5-4ae6-9f35-cf0779a4dab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-6ed23e26-d706-405a-920a-f8118e13fdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-2d580a06-219a-47ac-8da3-19cab660b722,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-1f8ffc18-964f-4fd7-9b01-9c0924b225bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-e3304b6d-14bf-4b77-aef9-b0abc1f8aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-4a107cca-4e82-444d-8546-330006f265d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-7c15d631-7236-46dd-85f8-2796e405fd12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169825835-172.17.0.20-1595608863987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-227602d9-e1b3-435d-b280-57a929f607a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-4a52639e-20ff-41dd-877d-bf44a638f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-0bbc3457-c616-4a6b-918b-2b6dda2cb5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-756941af-bfe4-4e5a-bcb7-0d048f4ec555,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-0450add5-b401-4635-8632-da8032b7c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-951ef69b-d100-456f-b52f-ade2f9458d21,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-e8799a73-dab0-41de-a97c-248abfd8d766,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-0d3283f4-50ce-40a8-8b6e-03b8eef50498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169825835-172.17.0.20-1595608863987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-227602d9-e1b3-435d-b280-57a929f607a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-4a52639e-20ff-41dd-877d-bf44a638f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-0bbc3457-c616-4a6b-918b-2b6dda2cb5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-756941af-bfe4-4e5a-bcb7-0d048f4ec555,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-0450add5-b401-4635-8632-da8032b7c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-951ef69b-d100-456f-b52f-ade2f9458d21,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-e8799a73-dab0-41de-a97c-248abfd8d766,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-0d3283f4-50ce-40a8-8b6e-03b8eef50498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121872079-172.17.0.20-1595609137038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-bd0b655b-8010-4c13-be22-86f2146e43df,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-320b9888-8df7-4fe7-9fa2-0087df434cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-b1386b8b-f7d8-4d71-9d98-4c379cc630d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-e4298c08-07c1-4188-9db0-3eb42e65daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-2c710cc0-1bbe-4ada-b15a-887b1301ea3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-8d90db31-992d-4c59-aef9-d62961755784,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-85b34fe2-b243-4279-b1d4-420fe7f16998,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-185d7faf-ddb8-4b75-a360-2c596b760a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121872079-172.17.0.20-1595609137038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-bd0b655b-8010-4c13-be22-86f2146e43df,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-320b9888-8df7-4fe7-9fa2-0087df434cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-b1386b8b-f7d8-4d71-9d98-4c379cc630d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-e4298c08-07c1-4188-9db0-3eb42e65daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-2c710cc0-1bbe-4ada-b15a-887b1301ea3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-8d90db31-992d-4c59-aef9-d62961755784,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-85b34fe2-b243-4279-b1d4-420fe7f16998,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-185d7faf-ddb8-4b75-a360-2c596b760a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277939025-172.17.0.20-1595610230400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-a39d4d6f-a78a-4290-8480-c34145b96f28,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-044daa34-1744-4975-9ead-830cfbb16132,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-3c46de56-7752-4ee0-8b6f-d039109c5367,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-7a3a07b0-451e-4304-8365-87e96e52cc20,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-17fbf854-d0ab-4a8f-ab2b-8fe4d72a92e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-6381c431-58e4-4435-a718-6993efbb45da,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-5e2c05a5-104a-4e7d-bcc1-0a84909f942f,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-235d7939-bd57-443f-89c2-4772410c830d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277939025-172.17.0.20-1595610230400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-a39d4d6f-a78a-4290-8480-c34145b96f28,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-044daa34-1744-4975-9ead-830cfbb16132,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-3c46de56-7752-4ee0-8b6f-d039109c5367,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-7a3a07b0-451e-4304-8365-87e96e52cc20,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-17fbf854-d0ab-4a8f-ab2b-8fe4d72a92e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-6381c431-58e4-4435-a718-6993efbb45da,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-5e2c05a5-104a-4e7d-bcc1-0a84909f942f,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-235d7939-bd57-443f-89c2-4772410c830d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832739532-172.17.0.20-1595610779718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-8c674eda-73a4-4070-b100-c4404757765f,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-ca09550b-942c-4817-815e-87c2fe979764,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-01f067a5-b7be-4eb5-be61-37f5689b6497,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-9372f385-fe86-4c34-84d5-d6be77de360f,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-fb13813a-5ebf-4acc-bbe4-78ebbd741784,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-bef47b0b-8c95-4c30-ae06-998dd9077c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-d3b07d20-dd4a-4610-878e-eb9cce63dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-70d440b7-ebe6-4339-a09c-6fd803e90f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832739532-172.17.0.20-1595610779718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-8c674eda-73a4-4070-b100-c4404757765f,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-ca09550b-942c-4817-815e-87c2fe979764,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-01f067a5-b7be-4eb5-be61-37f5689b6497,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-9372f385-fe86-4c34-84d5-d6be77de360f,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-fb13813a-5ebf-4acc-bbe4-78ebbd741784,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-bef47b0b-8c95-4c30-ae06-998dd9077c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-d3b07d20-dd4a-4610-878e-eb9cce63dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-70d440b7-ebe6-4339-a09c-6fd803e90f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161604626-172.17.0.20-1595610948885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-7642d26b-a91a-4575-b38a-3b197ccdbdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-aa0339b3-428d-4f39-bc50-0e5771e2b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-a77ff2d8-4bb1-4856-ac04-b8da60c101d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-bbf48545-a331-4154-923e-69f94a6175f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-885d569a-56c3-4c50-a4b2-e19d7931c196,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-eceffe28-5a9c-4609-8dfe-8657df03cab7,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-65b788ea-76ec-4775-b1a2-a34a042c8410,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-e5c50bdf-bb31-489c-88b5-7ab6f238d5e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161604626-172.17.0.20-1595610948885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-7642d26b-a91a-4575-b38a-3b197ccdbdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-aa0339b3-428d-4f39-bc50-0e5771e2b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-a77ff2d8-4bb1-4856-ac04-b8da60c101d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-bbf48545-a331-4154-923e-69f94a6175f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-885d569a-56c3-4c50-a4b2-e19d7931c196,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-eceffe28-5a9c-4609-8dfe-8657df03cab7,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-65b788ea-76ec-4775-b1a2-a34a042c8410,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-e5c50bdf-bb31-489c-88b5-7ab6f238d5e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651239509-172.17.0.20-1595611235710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45353,DS-5133f636-047f-4b8b-8824-59358e08427d,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-56f0a0a7-4ab7-45fe-94da-ebcbf9c2024c,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-68a23e5e-7416-4d02-b625-c707713edf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-10efe6c7-0b63-4bc0-939c-d2a154f5a7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-a2f9bb48-e534-4490-8657-132da035e054,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-6bbc0414-1eb0-4275-89aa-28818399cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-770a0feb-ef41-464d-baa9-fb45dd95b20a,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-f020c790-acd8-424b-8e0f-b967fb0d8d42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651239509-172.17.0.20-1595611235710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45353,DS-5133f636-047f-4b8b-8824-59358e08427d,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-56f0a0a7-4ab7-45fe-94da-ebcbf9c2024c,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-68a23e5e-7416-4d02-b625-c707713edf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-10efe6c7-0b63-4bc0-939c-d2a154f5a7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-a2f9bb48-e534-4490-8657-132da035e054,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-6bbc0414-1eb0-4275-89aa-28818399cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-770a0feb-ef41-464d-baa9-fb45dd95b20a,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-f020c790-acd8-424b-8e0f-b967fb0d8d42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 6933
