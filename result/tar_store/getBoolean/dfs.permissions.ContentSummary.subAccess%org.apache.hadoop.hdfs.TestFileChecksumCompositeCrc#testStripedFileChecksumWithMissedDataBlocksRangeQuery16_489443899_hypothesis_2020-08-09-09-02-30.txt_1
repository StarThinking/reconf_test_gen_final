reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806777142-172.17.0.7-1596964142509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37660,DS-8a3001fc-0384-47f6-8d13-1cbfc38294b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-ec98a460-0cc7-4ca2-81d7-e8aebb67e5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-5958a5af-e58f-4e8a-85dd-aa453519ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e4dd1836-635b-45ca-9926-c1a14fc3c183,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-6a38e1b4-1a93-4b39-a5d4-f616c76409b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-0c3758c5-d30b-480f-a8f9-4d1b95c30eab,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-1eb08650-de39-4352-89df-7363e23a3bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-0086e4c3-9443-459d-9b2d-c94e414fd619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806777142-172.17.0.7-1596964142509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37660,DS-8a3001fc-0384-47f6-8d13-1cbfc38294b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-ec98a460-0cc7-4ca2-81d7-e8aebb67e5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-5958a5af-e58f-4e8a-85dd-aa453519ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e4dd1836-635b-45ca-9926-c1a14fc3c183,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-6a38e1b4-1a93-4b39-a5d4-f616c76409b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-0c3758c5-d30b-480f-a8f9-4d1b95c30eab,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-1eb08650-de39-4352-89df-7363e23a3bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-0086e4c3-9443-459d-9b2d-c94e414fd619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205122054-172.17.0.7-1596964696246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37382,DS-d81bc4c3-e0c2-430c-a413-b7e6ea345ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-89e33102-f69e-487b-9a41-dc45b79d27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-81dadeef-e334-45f1-9c22-a6cd84529fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-a1e1c06d-115e-44e2-a2c7-9a70ae8e5d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-568e91a1-cb4e-491f-b726-9ac0faefe6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-ee91dcdb-c525-4370-af5f-4005356c3d18,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-2157513c-f1c7-4691-9508-78a19a31cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-8044a5b3-3843-4833-ba69-11b67564fc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205122054-172.17.0.7-1596964696246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37382,DS-d81bc4c3-e0c2-430c-a413-b7e6ea345ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-89e33102-f69e-487b-9a41-dc45b79d27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-81dadeef-e334-45f1-9c22-a6cd84529fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-a1e1c06d-115e-44e2-a2c7-9a70ae8e5d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-568e91a1-cb4e-491f-b726-9ac0faefe6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-ee91dcdb-c525-4370-af5f-4005356c3d18,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-2157513c-f1c7-4691-9508-78a19a31cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-8044a5b3-3843-4833-ba69-11b67564fc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852607244-172.17.0.7-1596965023057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35257,DS-2879883e-1049-408e-8cb3-658a1f3ed313,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-0dc2c753-0a9c-4212-9809-2a27b9c9f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-d5f41e6f-23fb-4502-a4eb-c62bf946d2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-77c094cd-9a41-452f-9420-c46d4a735ded,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-79eede82-9dfe-4850-a5d8-4edfd97fbed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-e5697c29-545c-4fa9-969a-6ea5f414e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-ac569e1c-7527-45c7-add2-874bb7896bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-5ae4b439-c849-4841-83ce-b29dcab7fdf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852607244-172.17.0.7-1596965023057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35257,DS-2879883e-1049-408e-8cb3-658a1f3ed313,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-0dc2c753-0a9c-4212-9809-2a27b9c9f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-d5f41e6f-23fb-4502-a4eb-c62bf946d2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-77c094cd-9a41-452f-9420-c46d4a735ded,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-79eede82-9dfe-4850-a5d8-4edfd97fbed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-e5697c29-545c-4fa9-969a-6ea5f414e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-ac569e1c-7527-45c7-add2-874bb7896bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-5ae4b439-c849-4841-83ce-b29dcab7fdf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426221194-172.17.0.7-1596965811851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-5edcc003-73f1-469b-94ef-7118ac70393b,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-c4c44108-a71e-416a-a16b-d10f9e65709c,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-7826cafe-d86b-4074-9afc-ae26d2958320,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-014d4b77-f764-4fe8-9014-537317033c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-345ea441-9226-4e9a-b009-5a32806e3e54,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-c0e30681-e331-4f09-a1cd-5a236b293639,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-ea006c2a-ede9-447e-8c7f-f27827fa563d,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-e7f0672a-06f8-4b21-982f-2d690a704a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426221194-172.17.0.7-1596965811851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-5edcc003-73f1-469b-94ef-7118ac70393b,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-c4c44108-a71e-416a-a16b-d10f9e65709c,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-7826cafe-d86b-4074-9afc-ae26d2958320,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-014d4b77-f764-4fe8-9014-537317033c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-345ea441-9226-4e9a-b009-5a32806e3e54,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-c0e30681-e331-4f09-a1cd-5a236b293639,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-ea006c2a-ede9-447e-8c7f-f27827fa563d,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-e7f0672a-06f8-4b21-982f-2d690a704a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996823308-172.17.0.7-1596965975459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46372,DS-de5ba093-3605-4c8b-afb0-fbe3b74bd0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-7fc36ad4-e72c-45f7-b535-12255d76eeba,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-eaa8f377-2421-4273-917f-fd20b10f7aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-cb027b74-334c-4784-a2c8-b171f4d66763,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-193b7f68-08ce-4495-9170-023c1e0504e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-bfbe16c4-8902-4bdf-be9c-f5f76f446dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-7c73f45e-5c9d-4f1f-a857-e34dc3dcabb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-11ba4331-1cf1-4ed5-87b5-f7bf4abd4e72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996823308-172.17.0.7-1596965975459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46372,DS-de5ba093-3605-4c8b-afb0-fbe3b74bd0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-7fc36ad4-e72c-45f7-b535-12255d76eeba,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-eaa8f377-2421-4273-917f-fd20b10f7aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-cb027b74-334c-4784-a2c8-b171f4d66763,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-193b7f68-08ce-4495-9170-023c1e0504e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-bfbe16c4-8902-4bdf-be9c-f5f76f446dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-7c73f45e-5c9d-4f1f-a857-e34dc3dcabb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-11ba4331-1cf1-4ed5-87b5-f7bf4abd4e72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97472288-172.17.0.7-1596966073985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34074,DS-0e198b46-a67d-458a-8193-31f5bfd5c1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-3e9d956d-080b-4153-bed6-f79074bc7977,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-9747702a-3c56-4348-97b8-51163b29153c,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-c8be8fab-42d4-45bb-a3a4-b4209ea7f5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-8dbf53a4-670d-4ded-be2a-6bf302f3b469,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-4fa76448-f577-4749-8732-e4d92b021ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-b98fd18a-99fd-4555-a4a9-ce754e829ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-e834bdca-4557-4d13-b341-4a479df55e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97472288-172.17.0.7-1596966073985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34074,DS-0e198b46-a67d-458a-8193-31f5bfd5c1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-3e9d956d-080b-4153-bed6-f79074bc7977,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-9747702a-3c56-4348-97b8-51163b29153c,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-c8be8fab-42d4-45bb-a3a4-b4209ea7f5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-8dbf53a4-670d-4ded-be2a-6bf302f3b469,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-4fa76448-f577-4749-8732-e4d92b021ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-b98fd18a-99fd-4555-a4a9-ce754e829ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-e834bdca-4557-4d13-b341-4a479df55e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241855144-172.17.0.7-1596966545900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42988,DS-bfd6e6a7-b732-46af-8df6-e9d578dbbb40,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-547c9cec-b31f-4e01-aac7-e4c10180579a,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-947006e6-9a61-421b-ae10-9600e290876a,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-3b6aa78c-b393-472a-8aab-5052e4ce8902,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-338023cf-9878-4f47-afa8-0241c09ca0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-ef478766-cfba-4209-9789-5c8f6a628f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-14f4fe9c-3abb-4b45-8631-ab1fd0579236,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-231e48fb-1625-487a-9589-e81badef1118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241855144-172.17.0.7-1596966545900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42988,DS-bfd6e6a7-b732-46af-8df6-e9d578dbbb40,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-547c9cec-b31f-4e01-aac7-e4c10180579a,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-947006e6-9a61-421b-ae10-9600e290876a,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-3b6aa78c-b393-472a-8aab-5052e4ce8902,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-338023cf-9878-4f47-afa8-0241c09ca0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-ef478766-cfba-4209-9789-5c8f6a628f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-14f4fe9c-3abb-4b45-8631-ab1fd0579236,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-231e48fb-1625-487a-9589-e81badef1118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585942824-172.17.0.7-1596966696068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39673,DS-397a5e15-672b-476b-8c94-2e0ed5713066,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-d2e8447a-d442-4287-a0b0-2b47b62e5c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-e96be06a-2bc9-4e42-8dfd-580fdfc85bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-d780c88a-34b9-4631-a32d-71addbecc079,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-687eb52e-1b23-4d89-982a-5e976365818d,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-1f229618-ec4f-4092-97c1-f7621cc3cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-4dc852e5-146b-4efb-8236-24e60bcad7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-b09487a6-d0b2-4601-919f-bda49205ef8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585942824-172.17.0.7-1596966696068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39673,DS-397a5e15-672b-476b-8c94-2e0ed5713066,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-d2e8447a-d442-4287-a0b0-2b47b62e5c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-e96be06a-2bc9-4e42-8dfd-580fdfc85bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-d780c88a-34b9-4631-a32d-71addbecc079,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-687eb52e-1b23-4d89-982a-5e976365818d,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-1f229618-ec4f-4092-97c1-f7621cc3cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-4dc852e5-146b-4efb-8236-24e60bcad7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-b09487a6-d0b2-4601-919f-bda49205ef8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463995535-172.17.0.7-1596966851821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39256,DS-35c43f0d-e579-4ddd-b562-4d2e3004bf23,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-be9fc60e-7541-4854-8345-c078146cb45c,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-d2ba509c-6d75-4e97-b854-38bfa7af7781,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-a937bb37-d334-42dc-9629-2e5fb473fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-7dc73940-bfda-40ee-8951-2cf845a13cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-725129bc-8bf3-418c-a94c-9e3a002a50b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-7570bd0d-454d-4e9f-a5ea-c8da42a305ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-b6f6fb18-9213-4f05-8276-099b506ce5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463995535-172.17.0.7-1596966851821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39256,DS-35c43f0d-e579-4ddd-b562-4d2e3004bf23,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-be9fc60e-7541-4854-8345-c078146cb45c,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-d2ba509c-6d75-4e97-b854-38bfa7af7781,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-a937bb37-d334-42dc-9629-2e5fb473fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-7dc73940-bfda-40ee-8951-2cf845a13cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-725129bc-8bf3-418c-a94c-9e3a002a50b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-7570bd0d-454d-4e9f-a5ea-c8da42a305ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-b6f6fb18-9213-4f05-8276-099b506ce5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362124673-172.17.0.7-1596967101825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-0ea9e148-cf58-47da-8e94-502f24ca5478,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-b5f73be5-92c4-46a0-b88d-b42a7011154f,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-8d4c1fee-ac07-4cd7-a5b3-86a9373d48b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-46244eb2-56ad-48fe-9cf3-85577c677f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-dbee5d12-d6d8-4baa-a4ce-372937ee3f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-d20cc8bf-0bee-40eb-af5c-1564f6a202c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-b76d04b9-e92f-4488-b425-8778e73fc89a,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-e710bda8-3235-4981-8d9a-1343372457cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362124673-172.17.0.7-1596967101825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-0ea9e148-cf58-47da-8e94-502f24ca5478,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-b5f73be5-92c4-46a0-b88d-b42a7011154f,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-8d4c1fee-ac07-4cd7-a5b3-86a9373d48b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-46244eb2-56ad-48fe-9cf3-85577c677f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-dbee5d12-d6d8-4baa-a4ce-372937ee3f31,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-d20cc8bf-0bee-40eb-af5c-1564f6a202c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-b76d04b9-e92f-4488-b425-8778e73fc89a,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-e710bda8-3235-4981-8d9a-1343372457cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484401273-172.17.0.7-1596967213095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-ae815d70-fd23-423d-962b-a32174441ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-63e57d8e-4e0f-435f-9e28-432add2b11e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-cd4d157f-944d-438a-84ef-0a98c1afc751,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-5f8e5a4b-482d-40d9-ae01-28db39314544,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-a74bbbfd-6434-49ad-ad24-93317c948d31,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-51b25bb9-a1a9-4e76-80b7-1dfa915b00fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-547d5533-30c0-49e1-b0da-d0004d503733,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-a1e9eb6f-4cbf-40c1-b8aa-54ebcbfb36ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484401273-172.17.0.7-1596967213095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-ae815d70-fd23-423d-962b-a32174441ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-63e57d8e-4e0f-435f-9e28-432add2b11e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-cd4d157f-944d-438a-84ef-0a98c1afc751,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-5f8e5a4b-482d-40d9-ae01-28db39314544,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-a74bbbfd-6434-49ad-ad24-93317c948d31,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-51b25bb9-a1a9-4e76-80b7-1dfa915b00fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-547d5533-30c0-49e1-b0da-d0004d503733,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-a1e9eb6f-4cbf-40c1-b8aa-54ebcbfb36ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894889509-172.17.0.7-1596967670753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-21826b95-98d6-4b32-a564-8d4edf8225e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-a66a6aea-eaa2-4b22-9bd0-4a216b5d3f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-517558ba-0738-4752-9eb0-17fe4b854d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-66bf9233-ddcf-4cb9-be0a-501b67734a95,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-d72c4cd6-3ce9-4a06-843e-a1d88920118b,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-b0c5afde-decb-4166-937e-8651a2b0fe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-4e329016-897f-4be5-b2e6-b4ab39428d20,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-3044c802-ff20-4a7d-a78a-c303c0bcb93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894889509-172.17.0.7-1596967670753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-21826b95-98d6-4b32-a564-8d4edf8225e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-a66a6aea-eaa2-4b22-9bd0-4a216b5d3f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-517558ba-0738-4752-9eb0-17fe4b854d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-66bf9233-ddcf-4cb9-be0a-501b67734a95,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-d72c4cd6-3ce9-4a06-843e-a1d88920118b,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-b0c5afde-decb-4166-937e-8651a2b0fe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-4e329016-897f-4be5-b2e6-b4ab39428d20,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-3044c802-ff20-4a7d-a78a-c303c0bcb93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647886808-172.17.0.7-1596967824008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34747,DS-565fffd6-8607-4189-9c91-62baed4c7475,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-779943b5-3830-4fc5-a7d4-6b3fb216cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-0b7e526d-329e-4dd3-ba70-7efc6b4f903a,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-f2088e04-22e4-4859-b4c5-4d2a32010b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-f467e733-e28b-4b57-b00e-ca31d0393548,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-2245b5d5-c5f0-4bf5-b2ec-b965e6bada61,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-5009f9ef-9595-4282-99e3-2dc6bd719697,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-79774fdf-505b-4ed5-9194-fee11dba35da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647886808-172.17.0.7-1596967824008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34747,DS-565fffd6-8607-4189-9c91-62baed4c7475,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-779943b5-3830-4fc5-a7d4-6b3fb216cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-0b7e526d-329e-4dd3-ba70-7efc6b4f903a,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-f2088e04-22e4-4859-b4c5-4d2a32010b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-f467e733-e28b-4b57-b00e-ca31d0393548,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-2245b5d5-c5f0-4bf5-b2ec-b965e6bada61,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-5009f9ef-9595-4282-99e3-2dc6bd719697,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-79774fdf-505b-4ed5-9194-fee11dba35da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926572217-172.17.0.7-1596968309247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-e595f068-5e99-45ff-bdff-e1ce1fd939b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-33685fb9-5d5c-449b-8758-d993e1386c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-298c987d-374f-464e-b0a0-00793355281f,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-80121d34-0fd3-4ffb-8935-7e50c3b63ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-b624cf60-ce38-469d-9a8b-9c0e8974ed64,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-1e103476-1ac7-4267-8570-3f90ecb7c7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-c36bf7ce-850b-4707-b188-c42727c2d272,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-db3c3c0e-517c-40c5-81f2-e2853710ab3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926572217-172.17.0.7-1596968309247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-e595f068-5e99-45ff-bdff-e1ce1fd939b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-33685fb9-5d5c-449b-8758-d993e1386c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-298c987d-374f-464e-b0a0-00793355281f,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-80121d34-0fd3-4ffb-8935-7e50c3b63ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-b624cf60-ce38-469d-9a8b-9c0e8974ed64,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-1e103476-1ac7-4267-8570-3f90ecb7c7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-c36bf7ce-850b-4707-b188-c42727c2d272,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-db3c3c0e-517c-40c5-81f2-e2853710ab3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4665
