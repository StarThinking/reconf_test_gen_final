reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520748382-172.17.0.13-1596874745509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42057,DS-e54c689e-d97f-4c2b-b3c0-81b64b8dc3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-94c60d6e-4a10-43dd-a6c6-64fc38922428,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-5cb263af-928c-4162-aa04-5298db0d365e,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-3bd61726-bded-4a49-b823-188bca0d685f,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-6fbfd17f-8a12-49e5-aaa6-03ea99f87e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-dfea1b59-f7c2-480f-b477-376393b4c275,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-cf44673f-fb38-4e6a-a6d0-87b59cc42d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-c1d02fe8-2a2b-4c71-a3ea-a27652e22392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520748382-172.17.0.13-1596874745509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42057,DS-e54c689e-d97f-4c2b-b3c0-81b64b8dc3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-94c60d6e-4a10-43dd-a6c6-64fc38922428,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-5cb263af-928c-4162-aa04-5298db0d365e,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-3bd61726-bded-4a49-b823-188bca0d685f,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-6fbfd17f-8a12-49e5-aaa6-03ea99f87e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-dfea1b59-f7c2-480f-b477-376393b4c275,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-cf44673f-fb38-4e6a-a6d0-87b59cc42d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-c1d02fe8-2a2b-4c71-a3ea-a27652e22392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90241299-172.17.0.13-1596875047140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38140,DS-c85f67eb-0dd0-4c40-8e51-1df00103c8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-768d7ffb-e3cf-481b-9e14-ecea81d697e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-48119492-1aac-4b31-9ce4-14ced8293b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-bf8efa26-0d8e-4892-9f22-17ee2c4b6a13,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-af718081-24b5-4396-aae5-c96870321cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-2b4e115e-769f-4b67-a161-6bfa05f8a391,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-257ebd4b-ee25-422d-8315-8a801ce42c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-207f6ee9-69a6-4615-9539-b8866267352e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90241299-172.17.0.13-1596875047140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38140,DS-c85f67eb-0dd0-4c40-8e51-1df00103c8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-768d7ffb-e3cf-481b-9e14-ecea81d697e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-48119492-1aac-4b31-9ce4-14ced8293b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-bf8efa26-0d8e-4892-9f22-17ee2c4b6a13,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-af718081-24b5-4396-aae5-c96870321cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-2b4e115e-769f-4b67-a161-6bfa05f8a391,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-257ebd4b-ee25-422d-8315-8a801ce42c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-207f6ee9-69a6-4615-9539-b8866267352e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180144975-172.17.0.13-1596875591285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-ff754745-c1a1-4836-8d21-aed92c9fdbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-645378ef-24c0-4e33-8e4f-fbab1ffc25f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-3fdacfd3-c45d-47fe-a920-e6aac4a5da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-fcad450d-48f3-4484-8bab-dd88d97523d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-7e66a3bc-7ed7-4170-96c8-bf90dcbeff36,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-465183f2-2741-4e03-90cf-f49fbe69f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-b81e5e6d-2a91-4c6a-b595-5851e1460dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-b73aae9e-2f0b-4895-a6ad-2ad06b3aa62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180144975-172.17.0.13-1596875591285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-ff754745-c1a1-4836-8d21-aed92c9fdbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-645378ef-24c0-4e33-8e4f-fbab1ffc25f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-3fdacfd3-c45d-47fe-a920-e6aac4a5da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-fcad450d-48f3-4484-8bab-dd88d97523d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-7e66a3bc-7ed7-4170-96c8-bf90dcbeff36,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-465183f2-2741-4e03-90cf-f49fbe69f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-b81e5e6d-2a91-4c6a-b595-5851e1460dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-b73aae9e-2f0b-4895-a6ad-2ad06b3aa62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631510482-172.17.0.13-1596875930907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43747,DS-64ed237d-84c0-4f79-802a-a02561facf89,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-7d9e4ef4-b8e9-47da-a2fb-43ab1f394b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-7c7a23ee-772d-47a6-96f3-62468d948340,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-6f61d54e-4495-493e-a97c-4189e12803a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-d6aa1b44-40ab-4c39-8195-f76cd90c8311,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-666bfd95-34fc-43d7-8f24-0582496bb8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-7c1ed231-ac6e-4587-872e-2578e0809aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-4d28e2e7-c062-4477-89e6-793c2a7dc888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631510482-172.17.0.13-1596875930907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43747,DS-64ed237d-84c0-4f79-802a-a02561facf89,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-7d9e4ef4-b8e9-47da-a2fb-43ab1f394b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-7c7a23ee-772d-47a6-96f3-62468d948340,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-6f61d54e-4495-493e-a97c-4189e12803a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-d6aa1b44-40ab-4c39-8195-f76cd90c8311,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-666bfd95-34fc-43d7-8f24-0582496bb8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-7c1ed231-ac6e-4587-872e-2578e0809aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-4d28e2e7-c062-4477-89e6-793c2a7dc888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808489184-172.17.0.13-1596876376312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40256,DS-a23974cc-70b3-4336-8e8e-b224af6881bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-54f2c0b2-c259-4c88-b008-f201ad9442a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-30b12134-c255-4b27-9afe-fd7ae5310847,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-73c9abbf-5da0-4603-8051-b0b47176974a,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-0a0c2164-c193-4aa8-83cf-c07a6af6a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-746bf4e1-5cac-4efe-8371-591433525676,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-c639ee96-a72e-4930-b484-338cc68cc2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-7bce2b63-02aa-41c8-91e8-b75d5a6d386b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808489184-172.17.0.13-1596876376312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40256,DS-a23974cc-70b3-4336-8e8e-b224af6881bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-54f2c0b2-c259-4c88-b008-f201ad9442a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-30b12134-c255-4b27-9afe-fd7ae5310847,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-73c9abbf-5da0-4603-8051-b0b47176974a,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-0a0c2164-c193-4aa8-83cf-c07a6af6a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-746bf4e1-5cac-4efe-8371-591433525676,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-c639ee96-a72e-4930-b484-338cc68cc2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-7bce2b63-02aa-41c8-91e8-b75d5a6d386b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181751788-172.17.0.13-1596876749230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42281,DS-98920dac-f7ff-4d95-9139-1590413fdc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-17e73cb1-c96e-4a5d-8044-dfb6c691c978,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-b1b54165-968f-4a11-8130-c944bf273bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-f84fbc83-f47a-4066-bcfd-f083271d33bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-980ab32f-576a-41fd-9906-655a6cacbd57,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-a8d77956-1bf4-4ce6-9e53-4dd0c3db5ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-7defd63b-d94a-41ce-97c7-d256cf679ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-a7d9f2d7-2cf2-4825-8c04-478c990cc864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181751788-172.17.0.13-1596876749230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42281,DS-98920dac-f7ff-4d95-9139-1590413fdc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-17e73cb1-c96e-4a5d-8044-dfb6c691c978,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-b1b54165-968f-4a11-8130-c944bf273bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-f84fbc83-f47a-4066-bcfd-f083271d33bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-980ab32f-576a-41fd-9906-655a6cacbd57,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-a8d77956-1bf4-4ce6-9e53-4dd0c3db5ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-7defd63b-d94a-41ce-97c7-d256cf679ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-a7d9f2d7-2cf2-4825-8c04-478c990cc864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450502172-172.17.0.13-1596878016380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-e843f5b6-42ba-459e-9166-5f974fcc4031,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-89597638-d75b-4a45-806f-6f99f4c23ada,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-3f3f33c9-600c-47d1-93b4-eecfffcca601,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-53052bf2-19a7-4467-b6f1-e7a776d3c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-62372315-f81d-479d-9039-732777027b84,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-393b3c8a-8ce5-430d-8994-79540161f92f,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-207b7f16-1796-4f09-abd7-e5de5ffb594d,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-22ff7667-4ba6-42f8-8c16-147cc4db44cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450502172-172.17.0.13-1596878016380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-e843f5b6-42ba-459e-9166-5f974fcc4031,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-89597638-d75b-4a45-806f-6f99f4c23ada,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-3f3f33c9-600c-47d1-93b4-eecfffcca601,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-53052bf2-19a7-4467-b6f1-e7a776d3c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-62372315-f81d-479d-9039-732777027b84,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-393b3c8a-8ce5-430d-8994-79540161f92f,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-207b7f16-1796-4f09-abd7-e5de5ffb594d,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-22ff7667-4ba6-42f8-8c16-147cc4db44cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700122742-172.17.0.13-1596878645385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43684,DS-1d07a3ef-8286-4532-bf59-b17e94952449,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-e8c81e87-5cfe-44f6-b4dc-92a1a7a5953e,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-6aa8bfae-5a97-4d59-8778-ce5dbee7943c,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-d97a8587-5971-4fad-802f-4d2bb5a76910,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-e66cb799-1587-4e9e-92ca-1b68fca6a206,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-14ab582b-8fcc-44b6-aa81-25f2bdac750e,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-e8179abe-6f16-45f8-ab74-418f5f0ba652,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-ea3962c1-7d64-49ba-bed4-61226505af7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700122742-172.17.0.13-1596878645385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43684,DS-1d07a3ef-8286-4532-bf59-b17e94952449,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-e8c81e87-5cfe-44f6-b4dc-92a1a7a5953e,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-6aa8bfae-5a97-4d59-8778-ce5dbee7943c,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-d97a8587-5971-4fad-802f-4d2bb5a76910,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-e66cb799-1587-4e9e-92ca-1b68fca6a206,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-14ab582b-8fcc-44b6-aa81-25f2bdac750e,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-e8179abe-6f16-45f8-ab74-418f5f0ba652,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-ea3962c1-7d64-49ba-bed4-61226505af7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111305892-172.17.0.13-1596878974736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-f50ecdfc-7c61-4efa-a4f9-8b3abc33bb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-0839584a-5991-40a3-9d4e-6351170760a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-3c36adbf-2005-4d6d-a2d7-063e0b1c12d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-73ef1474-7fee-49d7-999e-3667ff6f3f32,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-4a408645-41c6-48da-9865-618eaa272950,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-d9982fd8-5206-4980-92e5-60168d861b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-bbe316e0-53f4-4d4b-93bc-f43fe06d60e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-325e7d36-c5f9-49e2-9fb8-e7e1d72b0475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111305892-172.17.0.13-1596878974736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-f50ecdfc-7c61-4efa-a4f9-8b3abc33bb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-0839584a-5991-40a3-9d4e-6351170760a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-3c36adbf-2005-4d6d-a2d7-063e0b1c12d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-73ef1474-7fee-49d7-999e-3667ff6f3f32,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-4a408645-41c6-48da-9865-618eaa272950,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-d9982fd8-5206-4980-92e5-60168d861b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-bbe316e0-53f4-4d4b-93bc-f43fe06d60e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-325e7d36-c5f9-49e2-9fb8-e7e1d72b0475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317139625-172.17.0.13-1596879103263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-9e1cc56a-afd4-4828-b4c6-4f5c1f140fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-483e8a5d-669d-4bc8-88b2-49c46c7fdbab,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-a3e1aff5-fef1-4f35-bf79-2343313920b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-4a21971c-6b69-497d-8520-90c8503cad0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-7bd3d1ae-8155-402e-89f5-ad680f4d4097,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-f9c1eb3b-818b-4200-8b9d-8d7d2c8fc89d,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-56031ad6-e3d4-459b-8687-09c66689279b,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-9365a3d3-5a40-4082-a52a-19586a30bf66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317139625-172.17.0.13-1596879103263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-9e1cc56a-afd4-4828-b4c6-4f5c1f140fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-483e8a5d-669d-4bc8-88b2-49c46c7fdbab,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-a3e1aff5-fef1-4f35-bf79-2343313920b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-4a21971c-6b69-497d-8520-90c8503cad0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-7bd3d1ae-8155-402e-89f5-ad680f4d4097,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-f9c1eb3b-818b-4200-8b9d-8d7d2c8fc89d,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-56031ad6-e3d4-459b-8687-09c66689279b,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-9365a3d3-5a40-4082-a52a-19586a30bf66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079759875-172.17.0.13-1596879560350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-ffa1b6b7-f2b8-4ec9-9ae4-f5d671bf1d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-c26c887a-80ce-484e-bfd0-682430777ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-1587fec6-e69d-4801-a7cf-a442c8b5a452,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-866233cf-8c3b-4094-9864-938f7f6a04ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-38b0c044-35ad-4ef7-b12a-971eed593c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-4f04cb34-06b5-4797-ab7d-7888d9a5e450,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-f7349530-224a-4e09-a429-0eea93445fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-742c4fd0-6bf8-4ed5-9d1e-6379dd87546e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079759875-172.17.0.13-1596879560350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-ffa1b6b7-f2b8-4ec9-9ae4-f5d671bf1d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-c26c887a-80ce-484e-bfd0-682430777ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-1587fec6-e69d-4801-a7cf-a442c8b5a452,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-866233cf-8c3b-4094-9864-938f7f6a04ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-38b0c044-35ad-4ef7-b12a-971eed593c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-4f04cb34-06b5-4797-ab7d-7888d9a5e450,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-f7349530-224a-4e09-a429-0eea93445fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-742c4fd0-6bf8-4ed5-9d1e-6379dd87546e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124963338-172.17.0.13-1596880155580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-76265660-8d89-4ba3-bee8-07c6a8341944,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-ac932763-4168-4a61-8af8-da9e27431b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-b8c4b70f-d5ac-4405-962d-aa9a3425bc70,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-a3731bdc-6a19-4287-a09b-2228d7af0de0,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-e7e00b7c-f6de-40e7-a1cc-5a9416e1fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-a81261cb-0996-405d-8bb7-b33f8f3dec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-02d64e54-f5c7-4021-aebe-ac791d4caa08,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-6ee7f572-9357-4af2-88b9-703d3a61f2ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124963338-172.17.0.13-1596880155580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-76265660-8d89-4ba3-bee8-07c6a8341944,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-ac932763-4168-4a61-8af8-da9e27431b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-b8c4b70f-d5ac-4405-962d-aa9a3425bc70,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-a3731bdc-6a19-4287-a09b-2228d7af0de0,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-e7e00b7c-f6de-40e7-a1cc-5a9416e1fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-a81261cb-0996-405d-8bb7-b33f8f3dec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-02d64e54-f5c7-4021-aebe-ac791d4caa08,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-6ee7f572-9357-4af2-88b9-703d3a61f2ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539885915-172.17.0.13-1596880397907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-67428b21-77de-499b-b2d7-e34a6bc2c487,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-c1315c9f-886e-48c9-9ed1-aba0468acfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-57894e6d-a9d3-403f-81c3-19d1ce8aec41,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-2c66bc43-d05a-49ef-9ae8-8daaf7baae92,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-28ceeea3-d7ec-45cb-aa2e-ee27c8b2de54,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-50a43862-0995-4fff-80a8-99e269556a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-9fb9bb3b-3f89-48d8-b4fe-97ee655a1dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-85982474-e6e1-4a51-a194-c070d9d69ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539885915-172.17.0.13-1596880397907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-67428b21-77de-499b-b2d7-e34a6bc2c487,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-c1315c9f-886e-48c9-9ed1-aba0468acfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-57894e6d-a9d3-403f-81c3-19d1ce8aec41,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-2c66bc43-d05a-49ef-9ae8-8daaf7baae92,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-28ceeea3-d7ec-45cb-aa2e-ee27c8b2de54,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-50a43862-0995-4fff-80a8-99e269556a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-9fb9bb3b-3f89-48d8-b4fe-97ee655a1dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-85982474-e6e1-4a51-a194-c070d9d69ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 6826
