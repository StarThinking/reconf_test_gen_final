reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006301074-172.17.0.15-1596878465067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37898,DS-48c8eea0-649e-40c2-a6d4-7feb849b7e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-fc8976d0-40b6-4a74-92cf-c04ced14c2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-adad1884-423d-47d9-b002-66a75b71e73d,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-6f084d05-8af1-4620-942a-f69c2c94c0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-71f94017-29f6-4cba-8dc9-851c93a5aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-fe68552d-deef-41f0-a554-bd1075c88c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-ae7ea87d-f25d-4d2f-bd9a-244e0ef809dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-cc1acf7a-c68c-4c44-ad49-e06bf392dbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006301074-172.17.0.15-1596878465067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37898,DS-48c8eea0-649e-40c2-a6d4-7feb849b7e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-fc8976d0-40b6-4a74-92cf-c04ced14c2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-adad1884-423d-47d9-b002-66a75b71e73d,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-6f084d05-8af1-4620-942a-f69c2c94c0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-71f94017-29f6-4cba-8dc9-851c93a5aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-fe68552d-deef-41f0-a554-bd1075c88c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-ae7ea87d-f25d-4d2f-bd9a-244e0ef809dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-cc1acf7a-c68c-4c44-ad49-e06bf392dbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163328447-172.17.0.15-1596878893431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-a47dc13f-c650-4a6c-9176-e3e29be459fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-ca629e46-cc0f-410f-a7c3-fe661f2cbc20,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-13c5d48d-148c-4185-858d-47eccef313b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-34d06857-2de5-4bde-8d84-b479d9a7099c,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-c6159225-0b31-4dca-b886-44b7b7b24666,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-2850d34f-971a-4b74-b0cc-dfb91665504d,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b27a475e-f2c5-4fc4-a52f-cd3c99c3c862,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-2e4b0adf-71f8-44c8-bbbb-1f0a1b7dfe5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163328447-172.17.0.15-1596878893431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-a47dc13f-c650-4a6c-9176-e3e29be459fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-ca629e46-cc0f-410f-a7c3-fe661f2cbc20,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-13c5d48d-148c-4185-858d-47eccef313b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-34d06857-2de5-4bde-8d84-b479d9a7099c,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-c6159225-0b31-4dca-b886-44b7b7b24666,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-2850d34f-971a-4b74-b0cc-dfb91665504d,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-b27a475e-f2c5-4fc4-a52f-cd3c99c3c862,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-2e4b0adf-71f8-44c8-bbbb-1f0a1b7dfe5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106083441-172.17.0.15-1596878922921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-4d5ec585-b5c5-498f-aa0b-615472d9daef,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-fcf247b7-d622-458b-a4f9-0f2a6bdc9d75,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-fb28c0f1-28b8-42a9-91cc-448a44caa1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-72630fa9-63fe-4b8a-954a-6957cebb242f,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-1d1610c9-59c5-4ecb-88a5-28e2c118d505,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-3d7b3e55-22a2-4e2d-b0d4-79a46543779e,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-90fb00c7-78aa-427a-8e9f-de3a3c3d18c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-ce7ae1ef-3133-4616-99c4-9791435dafd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106083441-172.17.0.15-1596878922921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-4d5ec585-b5c5-498f-aa0b-615472d9daef,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-fcf247b7-d622-458b-a4f9-0f2a6bdc9d75,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-fb28c0f1-28b8-42a9-91cc-448a44caa1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-72630fa9-63fe-4b8a-954a-6957cebb242f,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-1d1610c9-59c5-4ecb-88a5-28e2c118d505,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-3d7b3e55-22a2-4e2d-b0d4-79a46543779e,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-90fb00c7-78aa-427a-8e9f-de3a3c3d18c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-ce7ae1ef-3133-4616-99c4-9791435dafd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584891349-172.17.0.15-1596879132119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40742,DS-7ab305e0-a9b8-43d7-aa93-0679b6f0a80c,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-ea232400-539f-4683-ac41-64a1067f6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-3a3dc50b-28ac-46f4-9643-ceaed8e728b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-0bf62d87-6e06-4906-85cf-9e903717eb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-628b3c8b-ab74-4b62-9e95-c78d617dfa51,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-740f5a44-fbe2-4759-9a66-66b3cd00c07f,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-4c40ce75-bb78-4991-846d-f7f3ba575593,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-19bc6ad5-6530-4173-9959-61e78341f40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584891349-172.17.0.15-1596879132119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40742,DS-7ab305e0-a9b8-43d7-aa93-0679b6f0a80c,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-ea232400-539f-4683-ac41-64a1067f6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-3a3dc50b-28ac-46f4-9643-ceaed8e728b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-0bf62d87-6e06-4906-85cf-9e903717eb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-628b3c8b-ab74-4b62-9e95-c78d617dfa51,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-740f5a44-fbe2-4759-9a66-66b3cd00c07f,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-4c40ce75-bb78-4991-846d-f7f3ba575593,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-19bc6ad5-6530-4173-9959-61e78341f40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717773660-172.17.0.15-1596879703870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38461,DS-3ae0cf0c-fd6e-4f00-b5f6-8b3fb2f89618,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-109014df-54f7-4f37-ab33-712f762aa4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-b56df4b9-a625-401d-b739-15f4b3b66495,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-4737be92-2701-4b66-988e-855624925431,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-ed2004dd-263f-493d-8db1-670ebe67aa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-1b3c2d0a-78d7-4187-a66e-4124938df93a,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-1b9bcabb-df17-4967-9b09-c5fd3e0d5ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-3e08c30d-e9e3-4d9b-85ac-c3086d49a170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717773660-172.17.0.15-1596879703870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38461,DS-3ae0cf0c-fd6e-4f00-b5f6-8b3fb2f89618,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-109014df-54f7-4f37-ab33-712f762aa4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-b56df4b9-a625-401d-b739-15f4b3b66495,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-4737be92-2701-4b66-988e-855624925431,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-ed2004dd-263f-493d-8db1-670ebe67aa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-1b3c2d0a-78d7-4187-a66e-4124938df93a,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-1b9bcabb-df17-4967-9b09-c5fd3e0d5ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-3e08c30d-e9e3-4d9b-85ac-c3086d49a170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27527397-172.17.0.15-1596880435045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39211,DS-ef651a56-9154-49c9-8e1a-3a1b8bb6b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-d5c75db8-2664-4c05-8643-d59590a179b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-f3631b84-db63-46b5-b9d2-a07b241108be,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-106c9d2e-0fb3-4086-b354-411ad5bbc504,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-da37935f-07cc-4ccb-be09-7343c22cdfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-b6699ce6-3c29-4022-851a-a8c5f17335ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-53c4088f-1adc-4222-a657-eeabe9f961c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-9411038f-3e1e-4bb9-94b7-231b1aee5224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27527397-172.17.0.15-1596880435045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39211,DS-ef651a56-9154-49c9-8e1a-3a1b8bb6b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-d5c75db8-2664-4c05-8643-d59590a179b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-f3631b84-db63-46b5-b9d2-a07b241108be,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-106c9d2e-0fb3-4086-b354-411ad5bbc504,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-da37935f-07cc-4ccb-be09-7343c22cdfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-b6699ce6-3c29-4022-851a-a8c5f17335ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-53c4088f-1adc-4222-a657-eeabe9f961c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-9411038f-3e1e-4bb9-94b7-231b1aee5224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145358587-172.17.0.15-1596880866940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38199,DS-b5423dad-565b-4711-a745-a8cd898c54cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-17802bcd-ce2e-449f-a51d-58db6cf32b79,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-8d389f39-d262-4f0c-916b-ffe5a45e082a,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-0fde413b-d411-4e46-a609-a7785d866800,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-ac93b71d-35c5-472f-9baa-5ddcc4cf60f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-cc60cbee-8c71-48b8-bf42-fe7eaecddbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-0d1f0567-8b67-41e5-8709-df2dfe49ba32,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-990efe00-37a8-41bd-992f-95c47c624b66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145358587-172.17.0.15-1596880866940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38199,DS-b5423dad-565b-4711-a745-a8cd898c54cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-17802bcd-ce2e-449f-a51d-58db6cf32b79,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-8d389f39-d262-4f0c-916b-ffe5a45e082a,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-0fde413b-d411-4e46-a609-a7785d866800,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-ac93b71d-35c5-472f-9baa-5ddcc4cf60f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-cc60cbee-8c71-48b8-bf42-fe7eaecddbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-0d1f0567-8b67-41e5-8709-df2dfe49ba32,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-990efe00-37a8-41bd-992f-95c47c624b66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71710234-172.17.0.15-1596881084862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-c852e9eb-f075-466a-9975-613deea0d4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-dc7f41b6-9cfa-4ba0-8f52-d0d84672229f,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-75dbfce4-01b2-4d6a-9b88-211c99f716e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-68751137-0a5a-4099-9a61-f3e9a5784e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-bb893549-6e0d-4c75-b62b-aad30dd68c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-4b1e3b4d-de89-4da2-9dc4-be7ce05014d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-29bf93e2-ec52-44ef-8d36-c82b0a04f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-1c23886a-0492-44be-9c1a-989d36b6721a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71710234-172.17.0.15-1596881084862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-c852e9eb-f075-466a-9975-613deea0d4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-dc7f41b6-9cfa-4ba0-8f52-d0d84672229f,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-75dbfce4-01b2-4d6a-9b88-211c99f716e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-68751137-0a5a-4099-9a61-f3e9a5784e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-bb893549-6e0d-4c75-b62b-aad30dd68c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-4b1e3b4d-de89-4da2-9dc4-be7ce05014d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-29bf93e2-ec52-44ef-8d36-c82b0a04f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-1c23886a-0492-44be-9c1a-989d36b6721a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015838775-172.17.0.15-1596881536253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-de74d996-b4ef-4b04-8f8f-7e3e6c4aac87,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-684a9584-edd7-47f7-bb92-6571f02ff187,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-8f23cd14-b61c-42c6-b9aa-cd006ec9e054,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-c92cfad9-3815-4499-bd3c-b9d1bff1836a,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-60e0a1e7-bce7-4fa5-952c-93532b98d3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-dbb5ed5e-0392-4680-8c52-3bf22bdf00b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-c3c8d14a-f6f7-4245-b443-7ec5d8ff8d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-34b68e6d-c4d1-49e3-ba86-81507095c3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015838775-172.17.0.15-1596881536253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-de74d996-b4ef-4b04-8f8f-7e3e6c4aac87,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-684a9584-edd7-47f7-bb92-6571f02ff187,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-8f23cd14-b61c-42c6-b9aa-cd006ec9e054,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-c92cfad9-3815-4499-bd3c-b9d1bff1836a,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-60e0a1e7-bce7-4fa5-952c-93532b98d3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-dbb5ed5e-0392-4680-8c52-3bf22bdf00b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-c3c8d14a-f6f7-4245-b443-7ec5d8ff8d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-34b68e6d-c4d1-49e3-ba86-81507095c3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159536953-172.17.0.15-1596882333708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45644,DS-712bc87b-72ec-4407-8440-13884c2ed8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-5aa34716-83d9-4fca-9a2d-4ed0d97b193e,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-3014c090-3829-44b1-9066-e57bc39bf2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-d632d395-6b0b-4fc6-a010-27bc9e41ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-a1dd6d65-6f90-4c24-8a75-9f7b4ed2fb16,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-e5d76f02-60f6-4983-a3d6-1439058b7070,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-2bfb53a4-a066-4e62-83f4-7cba28e2e62c,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-a7d853a2-25d5-476e-8bbd-148e8bf2e8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159536953-172.17.0.15-1596882333708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45644,DS-712bc87b-72ec-4407-8440-13884c2ed8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-5aa34716-83d9-4fca-9a2d-4ed0d97b193e,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-3014c090-3829-44b1-9066-e57bc39bf2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-d632d395-6b0b-4fc6-a010-27bc9e41ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-a1dd6d65-6f90-4c24-8a75-9f7b4ed2fb16,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-e5d76f02-60f6-4983-a3d6-1439058b7070,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-2bfb53a4-a066-4e62-83f4-7cba28e2e62c,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-a7d853a2-25d5-476e-8bbd-148e8bf2e8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428743700-172.17.0.15-1596883772425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-5a99f50b-46bd-45b5-bf74-8319326c8bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-73582cc0-bc00-4922-8787-0cb1df5e26ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-a6782d1c-c2bb-4d58-9fbe-75f4325800ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-ec1f8f82-5e76-4441-8452-dd27ea9b698a,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-76ef9e23-8cbe-490a-b8c2-539ed623c9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-b615fc82-6a3f-4356-b499-e40e2274e4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-b887a4e2-1ec7-4b1f-a0f0-b9c0fd7304f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-83560d2b-f5e0-468b-af59-4084af46e020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428743700-172.17.0.15-1596883772425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-5a99f50b-46bd-45b5-bf74-8319326c8bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-73582cc0-bc00-4922-8787-0cb1df5e26ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-a6782d1c-c2bb-4d58-9fbe-75f4325800ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-ec1f8f82-5e76-4441-8452-dd27ea9b698a,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-76ef9e23-8cbe-490a-b8c2-539ed623c9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-b615fc82-6a3f-4356-b499-e40e2274e4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-b887a4e2-1ec7-4b1f-a0f0-b9c0fd7304f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-83560d2b-f5e0-468b-af59-4084af46e020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5516
