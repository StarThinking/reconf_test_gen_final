reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154919518-172.17.0.16-1596877218196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44739,DS-0377674c-74e4-4932-b94e-783bbbfb7c25,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-ed709f93-20f2-478e-abaa-110e14f0e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-f3af113d-974b-47b6-8fac-285e8bb8b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-bac3f732-356d-4400-9782-52786a46cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-0b2adce9-823d-4ef6-8c8f-7d987be86643,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-794080b2-8a81-4a33-9f58-54f136067158,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-c7cdbbb3-0941-4f8b-ba28-4a77e817d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-3d53f8db-3de8-4049-932d-926341c26d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154919518-172.17.0.16-1596877218196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44739,DS-0377674c-74e4-4932-b94e-783bbbfb7c25,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-ed709f93-20f2-478e-abaa-110e14f0e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-f3af113d-974b-47b6-8fac-285e8bb8b7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-bac3f732-356d-4400-9782-52786a46cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-0b2adce9-823d-4ef6-8c8f-7d987be86643,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-794080b2-8a81-4a33-9f58-54f136067158,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-c7cdbbb3-0941-4f8b-ba28-4a77e817d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-3d53f8db-3de8-4049-932d-926341c26d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388667015-172.17.0.16-1596877294736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-043ba725-4b71-4725-935b-adbc8170947a,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-29b6ba45-9a4a-41af-8146-8fc4dd8c8de3,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-20371fce-899a-4d83-8699-85b77b42da50,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-51ed4b2a-438b-4001-bd14-777078b67f64,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-9d7d399b-d94c-4072-8523-21621c0b724b,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-0ac31062-e373-4ffb-acdd-cf3a65e9894f,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-bd8fb125-6b39-4343-a9b4-7445ebcb0b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-da5eb4aa-cecb-402b-bb9a-ce79330608d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388667015-172.17.0.16-1596877294736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-043ba725-4b71-4725-935b-adbc8170947a,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-29b6ba45-9a4a-41af-8146-8fc4dd8c8de3,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-20371fce-899a-4d83-8699-85b77b42da50,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-51ed4b2a-438b-4001-bd14-777078b67f64,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-9d7d399b-d94c-4072-8523-21621c0b724b,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-0ac31062-e373-4ffb-acdd-cf3a65e9894f,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-bd8fb125-6b39-4343-a9b4-7445ebcb0b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-da5eb4aa-cecb-402b-bb9a-ce79330608d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370833183-172.17.0.16-1596877991847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-809a1431-b6f2-4710-baf0-acba44f391a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-0e37a357-5c14-4a80-976c-224046967f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-9d72efb8-fc3f-4284-ad33-4a553576473a,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-e668b1eb-92dc-4db5-8a1a-e47442eface5,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-b4422e0e-a072-4f20-ba85-f02f72873238,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-a5ac7443-c43b-4828-b4ec-97d06d1efed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-f8e314e1-da0a-4bd8-87b6-fc90f8b47e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-e001b8df-31d8-4dc9-a86d-541b278b072c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370833183-172.17.0.16-1596877991847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-809a1431-b6f2-4710-baf0-acba44f391a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-0e37a357-5c14-4a80-976c-224046967f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-9d72efb8-fc3f-4284-ad33-4a553576473a,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-e668b1eb-92dc-4db5-8a1a-e47442eface5,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-b4422e0e-a072-4f20-ba85-f02f72873238,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-a5ac7443-c43b-4828-b4ec-97d06d1efed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-f8e314e1-da0a-4bd8-87b6-fc90f8b47e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-e001b8df-31d8-4dc9-a86d-541b278b072c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405196785-172.17.0.16-1596878272636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38789,DS-98064d66-98af-4fe2-8eb6-07a26e119aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-cd13d87d-5d4b-4ac6-a651-51ddb346245d,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-073d391f-0902-4cd3-91af-9319b63aca2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-4bfc2949-5ce5-4cea-a18f-ea491d419163,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-297f3d2e-ae85-447e-917b-6f782ee68b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-717b0ffc-3196-439e-8f36-57a1eab5ab92,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-3a2d6445-a60c-4c3c-9347-d418da720475,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-f128e58c-b280-459c-a636-603db69b3728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405196785-172.17.0.16-1596878272636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38789,DS-98064d66-98af-4fe2-8eb6-07a26e119aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-cd13d87d-5d4b-4ac6-a651-51ddb346245d,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-073d391f-0902-4cd3-91af-9319b63aca2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-4bfc2949-5ce5-4cea-a18f-ea491d419163,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-297f3d2e-ae85-447e-917b-6f782ee68b04,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-717b0ffc-3196-439e-8f36-57a1eab5ab92,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-3a2d6445-a60c-4c3c-9347-d418da720475,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-f128e58c-b280-459c-a636-603db69b3728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709399063-172.17.0.16-1596878443557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46744,DS-dcacd140-0069-4eec-a6b0-cf76beb76725,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-ea15371b-467e-4b48-856d-142e2d6aaba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-a397fa49-f768-40a0-b322-4009ca800695,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-a49c91b8-198d-44bb-ad60-cd0562d0d70b,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-df2f3d36-0af1-4450-ae92-35082207cad9,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-4d295ee4-7b92-42cc-a4b8-ba4eb6b1e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-fc3f103c-419d-4351-8bc4-d921e3b6300e,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-b9c34389-07d8-4789-99e4-befde42c8a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709399063-172.17.0.16-1596878443557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46744,DS-dcacd140-0069-4eec-a6b0-cf76beb76725,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-ea15371b-467e-4b48-856d-142e2d6aaba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-a397fa49-f768-40a0-b322-4009ca800695,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-a49c91b8-198d-44bb-ad60-cd0562d0d70b,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-df2f3d36-0af1-4450-ae92-35082207cad9,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-4d295ee4-7b92-42cc-a4b8-ba4eb6b1e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-fc3f103c-419d-4351-8bc4-d921e3b6300e,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-b9c34389-07d8-4789-99e4-befde42c8a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820475261-172.17.0.16-1596878651944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38838,DS-d1666092-0bca-41ae-9d7d-ec3132077f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-260aacf2-0eeb-47db-ac9a-1e70d102e669,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-a57ce80e-2fb4-4395-8f36-600f9e3921af,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-5fdad2fc-b386-4542-900e-870e083c2d67,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-5737be4b-414f-4abe-8795-677617b28690,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-d2e64646-25cc-4040-8e50-961c65931063,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-0b708d33-b08c-4abb-81c8-d2b558149f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-24bbbc28-3e8f-455f-928f-fe282d74ef3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820475261-172.17.0.16-1596878651944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38838,DS-d1666092-0bca-41ae-9d7d-ec3132077f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-260aacf2-0eeb-47db-ac9a-1e70d102e669,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-a57ce80e-2fb4-4395-8f36-600f9e3921af,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-5fdad2fc-b386-4542-900e-870e083c2d67,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-5737be4b-414f-4abe-8795-677617b28690,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-d2e64646-25cc-4040-8e50-961c65931063,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-0b708d33-b08c-4abb-81c8-d2b558149f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-24bbbc28-3e8f-455f-928f-fe282d74ef3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844746823-172.17.0.16-1596878689948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38379,DS-02a4f8bc-f491-4235-8c11-a72c401551d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-a19d0ac9-f7da-4d84-8cde-e57e1fc9df17,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-075e4606-a20a-4a62-9044-f5f65c8bdabb,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-f2103b59-d8bc-44f8-9ec0-61f50bb6b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-0fab08c6-b126-4149-8c0e-752bf37c2b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-63e0dbc5-fe19-42cc-a601-df88eb97b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-39b0a6a3-f062-4ade-8731-3a61e5b11018,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-b02e6c3b-fc7c-4861-b87c-8d5e50ef90fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844746823-172.17.0.16-1596878689948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38379,DS-02a4f8bc-f491-4235-8c11-a72c401551d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-a19d0ac9-f7da-4d84-8cde-e57e1fc9df17,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-075e4606-a20a-4a62-9044-f5f65c8bdabb,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-f2103b59-d8bc-44f8-9ec0-61f50bb6b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-0fab08c6-b126-4149-8c0e-752bf37c2b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-63e0dbc5-fe19-42cc-a601-df88eb97b98a,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-39b0a6a3-f062-4ade-8731-3a61e5b11018,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-b02e6c3b-fc7c-4861-b87c-8d5e50ef90fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54691975-172.17.0.16-1596878792841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-d2e04d40-9682-444f-94d6-e11efb409a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-b79afb61-8863-4a68-8093-e2d3c9b62ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-dab81fb7-2373-4777-b9f7-69665ff2b243,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-4f6a3924-d542-4720-9a44-f143b2239135,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-c6acff72-7396-400e-9324-06a1ef0c055b,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-e0a36573-d5c6-4483-bfb0-05574a0c5310,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-00441678-694c-48f8-9e2c-116d22c20ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-72b9a682-6f77-4097-9d50-0d90d227d188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54691975-172.17.0.16-1596878792841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-d2e04d40-9682-444f-94d6-e11efb409a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-b79afb61-8863-4a68-8093-e2d3c9b62ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-dab81fb7-2373-4777-b9f7-69665ff2b243,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-4f6a3924-d542-4720-9a44-f143b2239135,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-c6acff72-7396-400e-9324-06a1ef0c055b,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-e0a36573-d5c6-4483-bfb0-05574a0c5310,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-00441678-694c-48f8-9e2c-116d22c20ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-72b9a682-6f77-4097-9d50-0d90d227d188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118521503-172.17.0.16-1596878945449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40693,DS-4a852564-ed14-4695-8d92-e0c3a14335e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-134e8166-1679-4281-a378-0f6299eed17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-3e2f3a22-970c-4f07-b4b5-3fa3e987fb06,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-3e745c9e-761f-45e4-aec3-36b4493d8aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-b5184983-63c4-44ab-84fe-3902eff5e0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-c93334b3-4445-4d8d-b8eb-f9b08d60410b,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-94d06e13-89ed-4442-814a-4f2b0e1e4a15,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-d9bd8b2b-fd69-43ef-87cd-303b903cf000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118521503-172.17.0.16-1596878945449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40693,DS-4a852564-ed14-4695-8d92-e0c3a14335e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-134e8166-1679-4281-a378-0f6299eed17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-3e2f3a22-970c-4f07-b4b5-3fa3e987fb06,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-3e745c9e-761f-45e4-aec3-36b4493d8aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-b5184983-63c4-44ab-84fe-3902eff5e0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-c93334b3-4445-4d8d-b8eb-f9b08d60410b,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-94d06e13-89ed-4442-814a-4f2b0e1e4a15,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-d9bd8b2b-fd69-43ef-87cd-303b903cf000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159893051-172.17.0.16-1596879178863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43513,DS-8aa17631-5b01-4924-970b-471892e3cf20,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-43a68b7a-f924-4b89-ab17-94d388d4cca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-5195d343-b279-4a5e-8f98-5094d0689baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-e6d077a4-c22f-49e5-8a4b-1d1d7538d130,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-5a5dd61f-4a2d-4d45-91f0-8ff03558b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-f86d14d6-3e84-4af0-92e6-1cd4202a60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-42b2c915-0b67-4ee4-adb9-bca72e9e729f,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-f4354003-7051-4804-b9c0-0b26a2978936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159893051-172.17.0.16-1596879178863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43513,DS-8aa17631-5b01-4924-970b-471892e3cf20,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-43a68b7a-f924-4b89-ab17-94d388d4cca0,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-5195d343-b279-4a5e-8f98-5094d0689baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-e6d077a4-c22f-49e5-8a4b-1d1d7538d130,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-5a5dd61f-4a2d-4d45-91f0-8ff03558b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-f86d14d6-3e84-4af0-92e6-1cd4202a60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-42b2c915-0b67-4ee4-adb9-bca72e9e729f,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-f4354003-7051-4804-b9c0-0b26a2978936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902474245-172.17.0.16-1596879216323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42220,DS-f641965a-9cef-414f-8cb9-becb266a79fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-4c0a4fcc-08d5-43eb-ba25-660a247ddd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-5bbbd582-c496-41ca-9ca0-f6e66ee552b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-1aedec9d-7609-438d-bfcc-7e1a9aefdaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-962b2ad0-0dac-4459-8583-c1eae29b981c,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-6bc74743-a1fc-4fec-b2f7-9406feacf9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-bf0baa48-598a-4e58-af96-20dc874e10c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-53dfcfc4-641c-4dde-8ae9-db8162bc385a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902474245-172.17.0.16-1596879216323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42220,DS-f641965a-9cef-414f-8cb9-becb266a79fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-4c0a4fcc-08d5-43eb-ba25-660a247ddd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-5bbbd582-c496-41ca-9ca0-f6e66ee552b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-1aedec9d-7609-438d-bfcc-7e1a9aefdaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-962b2ad0-0dac-4459-8583-c1eae29b981c,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-6bc74743-a1fc-4fec-b2f7-9406feacf9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-bf0baa48-598a-4e58-af96-20dc874e10c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-53dfcfc4-641c-4dde-8ae9-db8162bc385a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786070778-172.17.0.16-1596879473450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-8468c9f7-dd22-42ca-bedb-6d0526e4fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-c0a45416-a953-4fdb-8087-9c2c9a6aedf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-02a384eb-ab71-4ffc-929a-dc293a632328,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-d449d57c-c98c-4422-bea6-fa426d2b87a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-c75f761e-b3c2-4594-9cdf-e51b2086f1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-364c86cf-e105-4ed4-879a-cb7ceee060eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-fd9733df-70f4-4f30-81bd-74c3f6e82a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-dd85f250-a87f-4068-b5b0-32aeb9f906d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786070778-172.17.0.16-1596879473450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-8468c9f7-dd22-42ca-bedb-6d0526e4fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-c0a45416-a953-4fdb-8087-9c2c9a6aedf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-02a384eb-ab71-4ffc-929a-dc293a632328,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-d449d57c-c98c-4422-bea6-fa426d2b87a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-c75f761e-b3c2-4594-9cdf-e51b2086f1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-364c86cf-e105-4ed4-879a-cb7ceee060eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-fd9733df-70f4-4f30-81bd-74c3f6e82a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-dd85f250-a87f-4068-b5b0-32aeb9f906d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831817289-172.17.0.16-1596880009351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-9a7db789-05ba-49b2-be63-240fba34e4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-ad549db8-fc37-4042-ae21-b052d87525a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-c951e0d8-7ed0-47b3-b1b1-bc109ae98d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-996ef989-338f-4eda-bb50-f549fd36be2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-e8791b09-0688-4ae8-b65b-f2b8d773c891,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-75205fa3-a636-42eb-abfc-898be75d958b,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-2cc43a4f-c51b-41c4-80a2-43afcbb4d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-1c5c3df8-d368-4163-bc58-83da0950909b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831817289-172.17.0.16-1596880009351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-9a7db789-05ba-49b2-be63-240fba34e4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-ad549db8-fc37-4042-ae21-b052d87525a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-c951e0d8-7ed0-47b3-b1b1-bc109ae98d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-996ef989-338f-4eda-bb50-f549fd36be2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-e8791b09-0688-4ae8-b65b-f2b8d773c891,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-75205fa3-a636-42eb-abfc-898be75d958b,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-2cc43a4f-c51b-41c4-80a2-43afcbb4d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-1c5c3df8-d368-4163-bc58-83da0950909b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496716668-172.17.0.16-1596880293697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-426a31ef-4c5e-4392-9aa7-bdb971a8fce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-105810ec-176e-4249-a77f-b5e7833f3237,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-b3984dfa-7be9-4794-97f2-794264fe41eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-7cf6dd82-c397-46ef-94b3-771c050bb5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-cdfb067f-d126-415b-b825-6add0569cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-c420ed3d-71fe-4d16-9101-548c0e190889,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-09c515e8-ea9a-44e4-9b29-5e6fb4381b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-5f0f1d05-4f54-40ff-bd12-e0547c71c872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496716668-172.17.0.16-1596880293697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-426a31ef-4c5e-4392-9aa7-bdb971a8fce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-105810ec-176e-4249-a77f-b5e7833f3237,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-b3984dfa-7be9-4794-97f2-794264fe41eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-7cf6dd82-c397-46ef-94b3-771c050bb5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-cdfb067f-d126-415b-b825-6add0569cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-c420ed3d-71fe-4d16-9101-548c0e190889,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-09c515e8-ea9a-44e4-9b29-5e6fb4381b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-5f0f1d05-4f54-40ff-bd12-e0547c71c872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532521751-172.17.0.16-1596880373918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-4b12ba90-d327-43e4-bfc4-bd5dd1d8c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-a1b643d3-ee02-479d-9ea4-091365b0b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-e94590f2-b30f-4ea9-9b18-ff420fe56824,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-c49f1a2a-f3aa-4c6c-a983-a11508e9f375,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-d27fdfda-0ea3-4b31-840f-8aad8295c999,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-c5c1bd4d-39d2-4256-9763-b4e15c673682,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-0af75486-7938-464d-a228-c6d181e45ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-3713487b-eb36-4bd6-8b1c-ce8b8a7eb6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532521751-172.17.0.16-1596880373918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-4b12ba90-d327-43e4-bfc4-bd5dd1d8c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-a1b643d3-ee02-479d-9ea4-091365b0b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-e94590f2-b30f-4ea9-9b18-ff420fe56824,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-c49f1a2a-f3aa-4c6c-a983-a11508e9f375,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-d27fdfda-0ea3-4b31-840f-8aad8295c999,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-c5c1bd4d-39d2-4256-9763-b4e15c673682,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-0af75486-7938-464d-a228-c6d181e45ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-3713487b-eb36-4bd6-8b1c-ce8b8a7eb6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548642576-172.17.0.16-1596880573315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-75ea45bf-54f4-48f7-b4be-2695ee896d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-75c825bf-fe48-44a2-be39-b447db790912,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-05041fd0-da93-4741-821e-d224283b4c93,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-fe89fe51-9f46-4c81-88f8-568de96d578b,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-a2de7ddf-1763-4fa4-931e-3f3a6245479c,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-52275824-0b58-4b6c-8f07-70823af50669,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-2180eaca-304c-4c21-a1a6-92e4df98db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-5e31abd2-d7a6-4544-b42c-32465749e436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548642576-172.17.0.16-1596880573315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-75ea45bf-54f4-48f7-b4be-2695ee896d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-75c825bf-fe48-44a2-be39-b447db790912,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-05041fd0-da93-4741-821e-d224283b4c93,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-fe89fe51-9f46-4c81-88f8-568de96d578b,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-a2de7ddf-1763-4fa4-931e-3f3a6245479c,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-52275824-0b58-4b6c-8f07-70823af50669,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-2180eaca-304c-4c21-a1a6-92e4df98db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-5e31abd2-d7a6-4544-b42c-32465749e436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191668504-172.17.0.16-1596880847316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-19b6d403-47a2-4359-9e80-37fa3005b214,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-00d8690b-e07d-45e5-8a58-e0cefd0f4a39,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-64180fa9-aee8-4638-b130-0a47883fca86,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-ff6cf3ea-a3cf-4807-86b3-76f9acb4c47c,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-295a1626-0cc3-4796-9383-a6ec6520e2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-a3247ba1-c46f-4f5b-ae86-f8a9f150f02b,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-9389dc45-5f4d-4200-8d51-6abc98b59492,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-95226930-dfab-4a13-bb7b-c56b232edbff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191668504-172.17.0.16-1596880847316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-19b6d403-47a2-4359-9e80-37fa3005b214,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-00d8690b-e07d-45e5-8a58-e0cefd0f4a39,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-64180fa9-aee8-4638-b130-0a47883fca86,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-ff6cf3ea-a3cf-4807-86b3-76f9acb4c47c,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-295a1626-0cc3-4796-9383-a6ec6520e2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-a3247ba1-c46f-4f5b-ae86-f8a9f150f02b,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-9389dc45-5f4d-4200-8d51-6abc98b59492,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-95226930-dfab-4a13-bb7b-c56b232edbff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318328705-172.17.0.16-1596880985528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35294,DS-c6b20ab5-7c2e-4be3-970b-1b29700151fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-61d0aa59-938c-438d-8291-2aa01f7c1540,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-0daf2cbd-c39a-46dd-b6f3-edb1aa5adb82,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-b45729e7-0025-489a-a2f3-2730e3f4efec,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-c114220b-ff4b-452c-bc0b-683aebbd6d71,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-1080e5bf-d042-408c-a5fb-26f5951d703d,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-61ad9e02-2ddc-4dc8-a736-baf5b183662d,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-4118ea22-31fc-448e-a52d-d35ca50e6569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318328705-172.17.0.16-1596880985528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35294,DS-c6b20ab5-7c2e-4be3-970b-1b29700151fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-61d0aa59-938c-438d-8291-2aa01f7c1540,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-0daf2cbd-c39a-46dd-b6f3-edb1aa5adb82,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-b45729e7-0025-489a-a2f3-2730e3f4efec,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-c114220b-ff4b-452c-bc0b-683aebbd6d71,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-1080e5bf-d042-408c-a5fb-26f5951d703d,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-61ad9e02-2ddc-4dc8-a736-baf5b183662d,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-4118ea22-31fc-448e-a52d-d35ca50e6569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251228014-172.17.0.16-1596881383688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35309,DS-127549e8-8bcc-4c97-891c-f1754a910659,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-dd9e7552-9d83-4a4c-96d6-f5de14a1cee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-5a86299b-388d-4edd-9f05-91924dbdae53,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-2397801c-248c-49cb-9cc3-787505390daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-49ebac0d-26ee-48ef-bba7-bf1641ce563b,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-1ef67a45-499f-4169-b924-68fe9b90b174,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-611fc21d-d769-4d63-b97b-eadff4a96d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-02eac92d-c772-42dd-b6d8-cb1291194f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251228014-172.17.0.16-1596881383688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35309,DS-127549e8-8bcc-4c97-891c-f1754a910659,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-dd9e7552-9d83-4a4c-96d6-f5de14a1cee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-5a86299b-388d-4edd-9f05-91924dbdae53,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-2397801c-248c-49cb-9cc3-787505390daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-49ebac0d-26ee-48ef-bba7-bf1641ce563b,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-1ef67a45-499f-4169-b924-68fe9b90b174,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-611fc21d-d769-4d63-b97b-eadff4a96d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-02eac92d-c772-42dd-b6d8-cb1291194f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5282
