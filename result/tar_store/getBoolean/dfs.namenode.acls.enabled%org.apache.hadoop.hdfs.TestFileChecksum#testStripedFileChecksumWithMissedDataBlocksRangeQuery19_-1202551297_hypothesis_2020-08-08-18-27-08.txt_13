reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003678090-172.17.0.17-1596911278488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-1c18488c-649d-4f24-9e79-0bbe6c0a4be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-5cbaf5eb-affc-4605-be7b-3c73b5d01753,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-28ca6ad4-38dd-4be7-8343-92c6ec361f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-4819c99b-ffe4-444b-b9d2-4a41f4b7b0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-3d35eff8-3852-4b35-99b0-748b3ffb1f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-6848bd26-47b2-4203-ac9a-45937b4629c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-9ff3ce64-015f-47b2-a649-a909441f5cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-a86207ae-14d8-4450-a809-2146b1873d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003678090-172.17.0.17-1596911278488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-1c18488c-649d-4f24-9e79-0bbe6c0a4be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-5cbaf5eb-affc-4605-be7b-3c73b5d01753,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-28ca6ad4-38dd-4be7-8343-92c6ec361f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-4819c99b-ffe4-444b-b9d2-4a41f4b7b0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-3d35eff8-3852-4b35-99b0-748b3ffb1f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-6848bd26-47b2-4203-ac9a-45937b4629c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-9ff3ce64-015f-47b2-a649-a909441f5cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-a86207ae-14d8-4450-a809-2146b1873d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713702018-172.17.0.17-1596911850054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-b29370fc-4169-45fd-a634-a3cf2bfbb7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-cd735680-6a4a-4b1d-97e5-d8326dff3c91,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-de8da4d8-7b3e-4436-9e7a-4e8798aed89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-c1be79cb-7914-4395-bb2b-17bac0651f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-84970a73-b035-46a0-b5b2-f49887df9bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-d50c3303-0eef-46b8-b6af-25553abe83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-a31e5089-bf81-4e45-bbc2-c48fe79563d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-a0343037-2fb6-443f-91b2-5a1d573eb3c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713702018-172.17.0.17-1596911850054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-b29370fc-4169-45fd-a634-a3cf2bfbb7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-cd735680-6a4a-4b1d-97e5-d8326dff3c91,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-de8da4d8-7b3e-4436-9e7a-4e8798aed89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-c1be79cb-7914-4395-bb2b-17bac0651f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-84970a73-b035-46a0-b5b2-f49887df9bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-d50c3303-0eef-46b8-b6af-25553abe83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-a31e5089-bf81-4e45-bbc2-c48fe79563d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-a0343037-2fb6-443f-91b2-5a1d573eb3c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665816141-172.17.0.17-1596912327740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-3e6fc323-1ec1-43e1-a04d-972472337c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-96551299-c8f3-4520-bdf4-8b4d3e3099e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-dfb51446-5a24-4285-bd58-f875f8c34e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-2e55b24f-0da4-4943-80cc-912e39775a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-73c37e6a-8bad-4bc3-9fea-643da4dc2d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-34d8c56b-6483-417d-9866-2a8da33c09ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-efec2fa7-f11e-4269-b409-3b1ce33619e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-250618a5-c4fd-4e8f-b450-6bf42e26e941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665816141-172.17.0.17-1596912327740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-3e6fc323-1ec1-43e1-a04d-972472337c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-96551299-c8f3-4520-bdf4-8b4d3e3099e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-dfb51446-5a24-4285-bd58-f875f8c34e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-2e55b24f-0da4-4943-80cc-912e39775a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-73c37e6a-8bad-4bc3-9fea-643da4dc2d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-34d8c56b-6483-417d-9866-2a8da33c09ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-efec2fa7-f11e-4269-b409-3b1ce33619e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-250618a5-c4fd-4e8f-b450-6bf42e26e941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503956788-172.17.0.17-1596913112710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-c54455fd-e7fb-4b34-bb0d-da09e06d28a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-c6e13589-ca70-42e3-a689-a44092a893f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-95afd326-8346-458b-a786-cbb1c31019ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-45401078-59e1-4341-9fa5-6f371a001ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-9db4fc54-433f-4105-9499-2d26c4279c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-8845877f-47d6-4e65-80a2-e7228e3472e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-26225d21-95f9-4894-845e-ed5dbde9b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-506eceb7-331f-4a83-8c38-2352aaa6a6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503956788-172.17.0.17-1596913112710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-c54455fd-e7fb-4b34-bb0d-da09e06d28a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-c6e13589-ca70-42e3-a689-a44092a893f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-95afd326-8346-458b-a786-cbb1c31019ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-45401078-59e1-4341-9fa5-6f371a001ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-9db4fc54-433f-4105-9499-2d26c4279c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-8845877f-47d6-4e65-80a2-e7228e3472e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-26225d21-95f9-4894-845e-ed5dbde9b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-506eceb7-331f-4a83-8c38-2352aaa6a6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766961436-172.17.0.17-1596913924771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-7f445661-52c9-4f24-86c9-ef64884c0475,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-5ce2cfa6-5b40-49bc-a0fb-d9aebcbf37e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-9fcc4762-8568-491d-865b-6de98f48244d,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-49815d2d-29f9-41eb-b5e4-e31cb6ea3562,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-2644a002-454b-49ef-a5b1-4bec8235e701,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-b8002367-e7f5-424d-bc2b-0f2643c447e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-87edcf3d-0a8e-48b9-af36-a8825d18514e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-2af94fa2-6b85-4836-915f-f1f5088cfd3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766961436-172.17.0.17-1596913924771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-7f445661-52c9-4f24-86c9-ef64884c0475,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-5ce2cfa6-5b40-49bc-a0fb-d9aebcbf37e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-9fcc4762-8568-491d-865b-6de98f48244d,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-49815d2d-29f9-41eb-b5e4-e31cb6ea3562,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-2644a002-454b-49ef-a5b1-4bec8235e701,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-b8002367-e7f5-424d-bc2b-0f2643c447e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-87edcf3d-0a8e-48b9-af36-a8825d18514e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-2af94fa2-6b85-4836-915f-f1f5088cfd3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531931504-172.17.0.17-1596914044764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-38094207-e3d8-4847-b7c6-65babb9308c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-18d20f9d-90da-4eca-a79d-db265d86e29c,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-1f78cd3b-8d22-4fc9-bad2-5c2253757b10,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-7d0cca6e-1d92-4edb-85d7-2627fa0ca1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-faf775a8-ff46-479c-b160-d0bf265aea47,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-4347978e-0643-47d1-9e62-7583101ab64e,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-07d23b5e-2e5f-48d0-8373-a1bc30355e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-f46c58a8-d826-4ef1-8c4a-5e2a51af13ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531931504-172.17.0.17-1596914044764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-38094207-e3d8-4847-b7c6-65babb9308c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-18d20f9d-90da-4eca-a79d-db265d86e29c,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-1f78cd3b-8d22-4fc9-bad2-5c2253757b10,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-7d0cca6e-1d92-4edb-85d7-2627fa0ca1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-faf775a8-ff46-479c-b160-d0bf265aea47,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-4347978e-0643-47d1-9e62-7583101ab64e,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-07d23b5e-2e5f-48d0-8373-a1bc30355e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-f46c58a8-d826-4ef1-8c4a-5e2a51af13ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798558278-172.17.0.17-1596914225523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34032,DS-654d43f7-1c4e-44a1-9276-023a901fb30c,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-18c339df-b74e-4d63-9f4e-0073eabd2a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-794e5cdb-44f0-4a9b-b443-5fedda7070e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-2a4fcf14-5861-4142-a376-9964559b5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-fdd2d6f7-746d-434b-8638-d912a5b05625,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-d1ca2794-ffe5-4fcd-b69b-b77354c4157d,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-04106cfb-a029-4a24-aa22-51afe44039eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-0c7e256e-e8ae-4105-9cc6-e577e352e914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798558278-172.17.0.17-1596914225523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34032,DS-654d43f7-1c4e-44a1-9276-023a901fb30c,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-18c339df-b74e-4d63-9f4e-0073eabd2a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-794e5cdb-44f0-4a9b-b443-5fedda7070e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-2a4fcf14-5861-4142-a376-9964559b5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-fdd2d6f7-746d-434b-8638-d912a5b05625,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-d1ca2794-ffe5-4fcd-b69b-b77354c4157d,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-04106cfb-a029-4a24-aa22-51afe44039eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-0c7e256e-e8ae-4105-9cc6-e577e352e914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342728774-172.17.0.17-1596914334307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-834dfe4b-c080-4ac2-bcc3-c9ab8989dc46,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-aeda57e9-a51d-45cc-9ecc-69da2eff0959,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-30b0cb84-76c0-4a80-a243-e5b8a2c042be,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-b486d655-00e7-4985-9639-4b0a24f3fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-e56b179a-d1db-4110-b199-9431394beb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-10f807fc-fe21-4f24-884e-fe77b1146c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-23ec56c0-0b4a-4c85-bad9-bcdd0eb92e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-e23567ac-923f-404d-8224-0c23b1a14acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342728774-172.17.0.17-1596914334307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-834dfe4b-c080-4ac2-bcc3-c9ab8989dc46,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-aeda57e9-a51d-45cc-9ecc-69da2eff0959,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-30b0cb84-76c0-4a80-a243-e5b8a2c042be,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-b486d655-00e7-4985-9639-4b0a24f3fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-e56b179a-d1db-4110-b199-9431394beb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-10f807fc-fe21-4f24-884e-fe77b1146c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-23ec56c0-0b4a-4c85-bad9-bcdd0eb92e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-e23567ac-923f-404d-8224-0c23b1a14acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097460352-172.17.0.17-1596914625367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40535,DS-5ad31238-1ae0-4418-8f73-ab9cf446baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-53c15da9-a039-4db2-bf5f-84a6f6846aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-ed1f20c0-3751-4ed4-a6f8-3c6b12ed094b,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-d750441b-2bdb-4cb5-ad2c-cc13ba9db663,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-ec9f524a-df29-41d8-ae3b-e87917a03fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-451510fc-caeb-4519-aa35-8be16ded882f,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-e3bb04ae-f1b9-46c2-b95e-23912fe5d79e,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-45120fe3-a837-4850-8a43-af1ab9dbfe1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097460352-172.17.0.17-1596914625367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40535,DS-5ad31238-1ae0-4418-8f73-ab9cf446baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-53c15da9-a039-4db2-bf5f-84a6f6846aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-ed1f20c0-3751-4ed4-a6f8-3c6b12ed094b,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-d750441b-2bdb-4cb5-ad2c-cc13ba9db663,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-ec9f524a-df29-41d8-ae3b-e87917a03fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-451510fc-caeb-4519-aa35-8be16ded882f,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-e3bb04ae-f1b9-46c2-b95e-23912fe5d79e,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-45120fe3-a837-4850-8a43-af1ab9dbfe1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110238733-172.17.0.17-1596915348994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-2bd25382-bd29-440f-8824-425079ac5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-b1f71901-dbed-4a30-a414-1d495e6b98d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-6da874e1-fa7f-432a-9f65-f2cab27c65d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-3f7f7863-d3ec-4673-a339-59b5f1b3456c,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-ce714db6-71c1-43d7-8517-018ce5777837,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-bcf4abfe-3e7c-4ed2-97ed-a81cef73ca23,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8f90eb4b-4c6b-4a32-8efe-209ca36121da,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-00fb529f-34e8-4219-920d-04ff688cd6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110238733-172.17.0.17-1596915348994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-2bd25382-bd29-440f-8824-425079ac5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-b1f71901-dbed-4a30-a414-1d495e6b98d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-6da874e1-fa7f-432a-9f65-f2cab27c65d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-3f7f7863-d3ec-4673-a339-59b5f1b3456c,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-ce714db6-71c1-43d7-8517-018ce5777837,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-bcf4abfe-3e7c-4ed2-97ed-a81cef73ca23,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8f90eb4b-4c6b-4a32-8efe-209ca36121da,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-00fb529f-34e8-4219-920d-04ff688cd6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065959483-172.17.0.17-1596916261384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-6a3f4fc2-00d8-4e16-b11e-e8a99aa5c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-fa812592-b607-4ae1-9f64-4d47578a51ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-90903b12-fe8c-4823-a0fc-6eb219fb2b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-dabc197f-6cf5-485a-a8e9-5efd606ec81c,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-1588c309-22f7-4a6c-b710-997c6c023c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-c142c9f2-c765-436c-9f72-653a478cf024,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-0fc8f563-5395-416e-9163-dc322759544f,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-2dfcd031-34b5-4059-b604-754209d2ec46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065959483-172.17.0.17-1596916261384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-6a3f4fc2-00d8-4e16-b11e-e8a99aa5c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-fa812592-b607-4ae1-9f64-4d47578a51ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-90903b12-fe8c-4823-a0fc-6eb219fb2b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-dabc197f-6cf5-485a-a8e9-5efd606ec81c,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-1588c309-22f7-4a6c-b710-997c6c023c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-c142c9f2-c765-436c-9f72-653a478cf024,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-0fc8f563-5395-416e-9163-dc322759544f,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-2dfcd031-34b5-4059-b604-754209d2ec46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807993240-172.17.0.17-1596916452799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38535,DS-3b945d41-83f0-4cc7-8ff9-60628380f371,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-c00896ad-ae05-47de-995c-e00a46d4309a,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-738f2a03-262c-4b6d-bda5-4375412fc0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-096a1aa5-8a6d-4f8c-8b8d-be11a0f8fd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-55b40907-1fdc-4c92-b590-b0a831b254eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-fe117beb-17d1-4792-bdb6-8fc6f435d491,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-47d49463-79e4-452d-8b95-22a44f6c7b79,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-7ed5aab1-644b-401d-a72a-58d786fac3c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807993240-172.17.0.17-1596916452799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38535,DS-3b945d41-83f0-4cc7-8ff9-60628380f371,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-c00896ad-ae05-47de-995c-e00a46d4309a,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-738f2a03-262c-4b6d-bda5-4375412fc0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-096a1aa5-8a6d-4f8c-8b8d-be11a0f8fd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-55b40907-1fdc-4c92-b590-b0a831b254eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-fe117beb-17d1-4792-bdb6-8fc6f435d491,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-47d49463-79e4-452d-8b95-22a44f6c7b79,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-7ed5aab1-644b-401d-a72a-58d786fac3c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5556
