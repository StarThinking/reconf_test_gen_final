reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884181740-172.17.0.5-1596887106887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-319b4d8e-1bf7-4b23-bcb2-a7a6f86dacc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-d49f92da-14ba-4bcf-a435-36174ed834dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-a8ac4ca7-7e26-45d0-9ced-c44dc32ec735,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-2765a279-fe7d-4a9f-b693-6ac21c047d39,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-465bf136-c218-456e-be3c-6c980dab30e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-048cadeb-f1f9-4f3d-aacd-fcfe58900b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-20ea486d-e574-42e3-a35a-6f72ba645dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-1d1f9ea6-0a45-4f20-92c7-ab0622bd62df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884181740-172.17.0.5-1596887106887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-319b4d8e-1bf7-4b23-bcb2-a7a6f86dacc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-d49f92da-14ba-4bcf-a435-36174ed834dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-a8ac4ca7-7e26-45d0-9ced-c44dc32ec735,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-2765a279-fe7d-4a9f-b693-6ac21c047d39,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-465bf136-c218-456e-be3c-6c980dab30e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-048cadeb-f1f9-4f3d-aacd-fcfe58900b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-20ea486d-e574-42e3-a35a-6f72ba645dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-1d1f9ea6-0a45-4f20-92c7-ab0622bd62df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726166546-172.17.0.5-1596887702750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-5cad27e2-d54b-4808-ad2d-9996fa488b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-be143214-b38c-466b-913b-c2380a0a8933,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-877dea0a-e580-4378-be4e-833aa5e4f269,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-8f80b449-de1a-46c1-8bdc-5dd83e506350,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-68ca2113-3022-441d-88fb-c5d76997526a,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-393b0d21-d546-4d54-99d6-b9cb06535547,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-0e7c532a-05c0-4f51-9731-e9f320aa6f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-4515ddd2-225d-45ac-b921-8528e65e2f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726166546-172.17.0.5-1596887702750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-5cad27e2-d54b-4808-ad2d-9996fa488b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-be143214-b38c-466b-913b-c2380a0a8933,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-877dea0a-e580-4378-be4e-833aa5e4f269,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-8f80b449-de1a-46c1-8bdc-5dd83e506350,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-68ca2113-3022-441d-88fb-c5d76997526a,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-393b0d21-d546-4d54-99d6-b9cb06535547,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-0e7c532a-05c0-4f51-9731-e9f320aa6f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-4515ddd2-225d-45ac-b921-8528e65e2f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858013072-172.17.0.5-1596888073411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-a51ec2de-c27a-445c-a615-318448e9a28d,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-cda86478-c92e-4712-926d-1a428b8f26e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-6d9c0855-7427-420d-b1a4-0e9acbd90e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-9bad3ecc-c77a-4d7c-80ca-a43c48731df4,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-24d6edbd-dc5b-460c-af14-dbf8d6398e56,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-44922ed9-7232-4eea-91ed-ba8ff3b196ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-ad9d7e07-ec34-4bc6-a33d-eead8a77e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-9f94c870-c54f-4024-9880-3731aa4a2177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858013072-172.17.0.5-1596888073411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-a51ec2de-c27a-445c-a615-318448e9a28d,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-cda86478-c92e-4712-926d-1a428b8f26e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-6d9c0855-7427-420d-b1a4-0e9acbd90e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-9bad3ecc-c77a-4d7c-80ca-a43c48731df4,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-24d6edbd-dc5b-460c-af14-dbf8d6398e56,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-44922ed9-7232-4eea-91ed-ba8ff3b196ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-ad9d7e07-ec34-4bc6-a33d-eead8a77e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-9f94c870-c54f-4024-9880-3731aa4a2177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874392791-172.17.0.5-1596888282487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42788,DS-42dff2a6-b25d-4e8a-9732-ad25bf0a64a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-c9a02d7e-1240-4136-91dc-5f264449e003,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-d8e3617d-be5e-44a0-937b-343bbdab5d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-5721535f-ff1c-484e-95aa-756012875bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-3eb4cfe9-7b6d-4ef6-b7f4-7ab06756d331,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-32b77e86-9436-415c-b694-e22af9f65583,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-37161e89-2084-4a80-85f0-f48630186290,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-cd94d968-133c-4464-94f1-b02e9b7a129d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874392791-172.17.0.5-1596888282487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42788,DS-42dff2a6-b25d-4e8a-9732-ad25bf0a64a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-c9a02d7e-1240-4136-91dc-5f264449e003,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-d8e3617d-be5e-44a0-937b-343bbdab5d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-5721535f-ff1c-484e-95aa-756012875bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-3eb4cfe9-7b6d-4ef6-b7f4-7ab06756d331,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-32b77e86-9436-415c-b694-e22af9f65583,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-37161e89-2084-4a80-85f0-f48630186290,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-cd94d968-133c-4464-94f1-b02e9b7a129d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497416474-172.17.0.5-1596888321823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42810,DS-c02eb758-05a4-42a0-aac8-16c729db4025,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-b7e18384-0758-4353-ba49-d4b134f0f580,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-414cde67-2e44-4d78-95d4-d0e1edc210e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-bc488412-1c5a-4df9-b5d4-a9d92be4d6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-48a59bbe-6f26-4a1c-9a6d-47968b5fc2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-7928368a-ad6d-4e6f-9221-250d3097e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-881daa28-ded8-4a25-bcac-7328dc7004b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-49a21645-2673-46c6-82ff-0c9aba13a3c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497416474-172.17.0.5-1596888321823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42810,DS-c02eb758-05a4-42a0-aac8-16c729db4025,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-b7e18384-0758-4353-ba49-d4b134f0f580,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-414cde67-2e44-4d78-95d4-d0e1edc210e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-bc488412-1c5a-4df9-b5d4-a9d92be4d6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-48a59bbe-6f26-4a1c-9a6d-47968b5fc2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-7928368a-ad6d-4e6f-9221-250d3097e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-881daa28-ded8-4a25-bcac-7328dc7004b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-49a21645-2673-46c6-82ff-0c9aba13a3c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284752235-172.17.0.5-1596888561107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33765,DS-d54c9a48-72e1-4f4b-8b98-39c17247dc06,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-eb82a634-a701-4ab4-a548-97feeac8ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-8d8c1c23-bdaf-47ee-acb5-78458465c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-8c546923-fe53-403c-8f3c-449cfd3608b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-ea95d43c-e4a0-41e1-9a58-87ace7fa93c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-b7a1e919-a076-4d32-b7bd-fdf751f0de66,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-3b0d06db-2a12-4578-81c7-0c0bee6b1bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-ebe2f71d-cd9d-4035-8350-17d2dc47427b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284752235-172.17.0.5-1596888561107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33765,DS-d54c9a48-72e1-4f4b-8b98-39c17247dc06,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-eb82a634-a701-4ab4-a548-97feeac8ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-8d8c1c23-bdaf-47ee-acb5-78458465c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-8c546923-fe53-403c-8f3c-449cfd3608b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-ea95d43c-e4a0-41e1-9a58-87ace7fa93c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-b7a1e919-a076-4d32-b7bd-fdf751f0de66,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-3b0d06db-2a12-4578-81c7-0c0bee6b1bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-ebe2f71d-cd9d-4035-8350-17d2dc47427b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053783206-172.17.0.5-1596888936867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-bec0a6e0-0fbb-4203-ab57-cc25c2a94c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-7ca22c21-4b87-4e4e-a971-fcab5696b3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-20a725fc-7d5c-47ca-baa7-9404615f31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-20b38db3-0edd-43d9-b7a5-9fd5cfa32e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-5982a328-4f56-42ca-908a-e78874210663,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-9a1ae64f-4346-432e-984b-1017511bf497,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-64a52113-3e3e-44d7-9f2d-74356cd827e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-b80609ab-dc5f-4ff3-b333-cf31f80a7033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053783206-172.17.0.5-1596888936867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-bec0a6e0-0fbb-4203-ab57-cc25c2a94c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-7ca22c21-4b87-4e4e-a971-fcab5696b3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-20a725fc-7d5c-47ca-baa7-9404615f31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-20b38db3-0edd-43d9-b7a5-9fd5cfa32e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-5982a328-4f56-42ca-908a-e78874210663,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-9a1ae64f-4346-432e-984b-1017511bf497,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-64a52113-3e3e-44d7-9f2d-74356cd827e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-b80609ab-dc5f-4ff3-b333-cf31f80a7033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825231546-172.17.0.5-1596889801166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42539,DS-dcfb6f4d-10a9-412b-95ec-00b72863736f,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-6b792c7e-cf13-4932-bc20-893b748dfbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-a4e916b1-7f3a-429f-9135-00d3614ae327,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-e24e8548-3b2a-4ece-9276-a45a4294c072,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-1441bcf9-aee2-449f-9f01-07217817fead,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-2c7dbfec-26e7-4f56-8e22-9d6f527c2317,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-eebd8c21-ccdd-48cc-8fa7-1f5192dcd372,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-ef3831a4-8c06-438f-b7a6-79a1ea1382b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825231546-172.17.0.5-1596889801166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42539,DS-dcfb6f4d-10a9-412b-95ec-00b72863736f,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-6b792c7e-cf13-4932-bc20-893b748dfbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-a4e916b1-7f3a-429f-9135-00d3614ae327,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-e24e8548-3b2a-4ece-9276-a45a4294c072,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-1441bcf9-aee2-449f-9f01-07217817fead,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-2c7dbfec-26e7-4f56-8e22-9d6f527c2317,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-eebd8c21-ccdd-48cc-8fa7-1f5192dcd372,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-ef3831a4-8c06-438f-b7a6-79a1ea1382b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102705553-172.17.0.5-1596889946113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-1696020c-a8a2-42cd-83ba-758ea8010dad,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-ead05127-0d36-4f5a-9afd-3b6c77735023,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-278928b0-4115-459f-a326-8ba02a0874f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-c36365c9-822e-4983-844a-b8764b51735c,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-f0432518-6f58-4e42-ba2a-0294f21d8552,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-3887cd0c-3836-4511-a3ef-8d80cd96153f,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-262ccf8f-2772-40de-aade-9c29c96fd704,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-b48a47aa-2559-4f18-9aac-4d777229366b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102705553-172.17.0.5-1596889946113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-1696020c-a8a2-42cd-83ba-758ea8010dad,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-ead05127-0d36-4f5a-9afd-3b6c77735023,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-278928b0-4115-459f-a326-8ba02a0874f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-c36365c9-822e-4983-844a-b8764b51735c,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-f0432518-6f58-4e42-ba2a-0294f21d8552,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-3887cd0c-3836-4511-a3ef-8d80cd96153f,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-262ccf8f-2772-40de-aade-9c29c96fd704,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-b48a47aa-2559-4f18-9aac-4d777229366b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319394558-172.17.0.5-1596889985100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42743,DS-14492540-7baf-4af6-8843-d771be7be51f,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-7ce48cd9-0159-40ad-9c48-d42ef90dd609,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-bfef8723-8bac-4a0e-8c09-22d4206dd455,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-305eb0b7-bad8-4c5d-bfce-5b46c9e1438b,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-a7e89bde-8398-4f6f-b656-8f7c620e123e,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-2d770dfd-daad-4450-98ed-dfb49665b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-a429698a-9607-4cca-bbf6-fad6314a6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-97e40744-a3d6-4c37-be6c-779d5a48eb06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319394558-172.17.0.5-1596889985100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42743,DS-14492540-7baf-4af6-8843-d771be7be51f,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-7ce48cd9-0159-40ad-9c48-d42ef90dd609,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-bfef8723-8bac-4a0e-8c09-22d4206dd455,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-305eb0b7-bad8-4c5d-bfce-5b46c9e1438b,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-a7e89bde-8398-4f6f-b656-8f7c620e123e,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-2d770dfd-daad-4450-98ed-dfb49665b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-a429698a-9607-4cca-bbf6-fad6314a6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-97e40744-a3d6-4c37-be6c-779d5a48eb06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472525052-172.17.0.5-1596890281639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45318,DS-5fdf3b75-e175-4085-a1d8-626d6e046dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-300322db-d8ec-426a-9526-cdd5395fb774,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-3f3cdb32-8756-4a8b-b237-37c8c11f8635,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-99f694a7-0347-4a18-8919-1ba15ab1118d,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-c0290d6c-1db2-4df4-8dfe-cf65d1152f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-ca94cd4a-69d4-42d0-8121-e92f8ad1a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-440edf09-a31c-4a24-83b8-b019728a60c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-4cba8381-fe29-499d-aaf0-eb0e677b9780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472525052-172.17.0.5-1596890281639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45318,DS-5fdf3b75-e175-4085-a1d8-626d6e046dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-300322db-d8ec-426a-9526-cdd5395fb774,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-3f3cdb32-8756-4a8b-b237-37c8c11f8635,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-99f694a7-0347-4a18-8919-1ba15ab1118d,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-c0290d6c-1db2-4df4-8dfe-cf65d1152f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-ca94cd4a-69d4-42d0-8121-e92f8ad1a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-440edf09-a31c-4a24-83b8-b019728a60c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-4cba8381-fe29-499d-aaf0-eb0e677b9780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606607962-172.17.0.5-1596890630848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-23d447da-7fc9-4ca2-ad8e-a96cb13719b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-90755ef6-9241-4005-ac57-c856bc45f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-6337455b-2a08-49f2-836c-f650817ddef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-45aa90c4-f1d3-4aef-af26-f85f64d5bfba,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-04f8dedf-09d7-45dc-af7b-3f7d59a05edf,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-b772cbc4-59e9-465f-a75b-668a0018ec34,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-9cff0e4b-56cc-4424-a78d-bdedde852448,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-d6f189af-e096-424e-9671-d27351a708a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606607962-172.17.0.5-1596890630848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-23d447da-7fc9-4ca2-ad8e-a96cb13719b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-90755ef6-9241-4005-ac57-c856bc45f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-6337455b-2a08-49f2-836c-f650817ddef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-45aa90c4-f1d3-4aef-af26-f85f64d5bfba,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-04f8dedf-09d7-45dc-af7b-3f7d59a05edf,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-b772cbc4-59e9-465f-a75b-668a0018ec34,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-9cff0e4b-56cc-4424-a78d-bdedde852448,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-d6f189af-e096-424e-9671-d27351a708a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410969668-172.17.0.5-1596891093863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39500,DS-39c97129-5367-401a-b45f-55f83d9a7e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-184b3458-5a99-4c7b-9466-d1b29645e110,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-246c7444-4f68-4e10-ac4b-920302c06128,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-4326cb8b-cff7-47d0-aa47-e0b6424e405b,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-5f9e5534-ae60-4d35-bb56-b2282f84ffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-615eba13-6c32-4a63-b665-9f64e472a67b,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-145957b3-47b3-49e0-8ed9-0f49cdb8a144,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-9b998963-71f1-4dc8-a649-dc468ebc9df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410969668-172.17.0.5-1596891093863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39500,DS-39c97129-5367-401a-b45f-55f83d9a7e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-184b3458-5a99-4c7b-9466-d1b29645e110,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-246c7444-4f68-4e10-ac4b-920302c06128,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-4326cb8b-cff7-47d0-aa47-e0b6424e405b,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-5f9e5534-ae60-4d35-bb56-b2282f84ffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-615eba13-6c32-4a63-b665-9f64e472a67b,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-145957b3-47b3-49e0-8ed9-0f49cdb8a144,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-9b998963-71f1-4dc8-a649-dc468ebc9df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5516
