reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604120422-172.17.0.5-1596951329729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-85208752-c6b6-4f5a-8f74-61996ba0445f,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-1773234c-16d7-4f11-acc3-41e34bdb7993,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-3eba7dce-0f2f-4d6a-9e21-c96fe5e50025,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-5f620535-05b3-40b6-807f-943bba671ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-19395588-4b48-404f-9ebd-92b7753bee32,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-9bd06d2e-1f04-43fc-8568-8401354b4a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-2aa2c6e4-b10d-4ae8-8279-6d3e6ebee5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-fbdaa2f9-8276-463e-b7d0-685e6599fc04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604120422-172.17.0.5-1596951329729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-85208752-c6b6-4f5a-8f74-61996ba0445f,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-1773234c-16d7-4f11-acc3-41e34bdb7993,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-3eba7dce-0f2f-4d6a-9e21-c96fe5e50025,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-5f620535-05b3-40b6-807f-943bba671ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-19395588-4b48-404f-9ebd-92b7753bee32,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-9bd06d2e-1f04-43fc-8568-8401354b4a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-2aa2c6e4-b10d-4ae8-8279-6d3e6ebee5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-fbdaa2f9-8276-463e-b7d0-685e6599fc04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286436344-172.17.0.5-1596951503296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-f310ee90-5d3f-4fd2-96db-e7a99e02edcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-e57ba40a-71ba-43f2-aeca-df45edd74a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-c053e52c-7da9-47ab-9596-0895b78ca91f,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-9e10018a-b66e-45eb-bd93-86ec94a1af3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-00c8af29-4695-4fad-b626-c61fd4ace9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-599c2372-f94e-4b4b-833f-b07947547ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-b4763b33-081b-438b-b462-ba0f4c06e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-66d24885-0a54-49e3-8c4e-250b16a448ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286436344-172.17.0.5-1596951503296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-f310ee90-5d3f-4fd2-96db-e7a99e02edcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-e57ba40a-71ba-43f2-aeca-df45edd74a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-c053e52c-7da9-47ab-9596-0895b78ca91f,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-9e10018a-b66e-45eb-bd93-86ec94a1af3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-00c8af29-4695-4fad-b626-c61fd4ace9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-599c2372-f94e-4b4b-833f-b07947547ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-b4763b33-081b-438b-b462-ba0f4c06e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-66d24885-0a54-49e3-8c4e-250b16a448ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187747378-172.17.0.5-1596952273503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37232,DS-b9198bf5-dad6-46d2-9e26-85c25b525518,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-53463428-4be7-46f4-af7e-7c0bc41c33c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-da947bda-d52e-4fc7-bb3f-05fc03e50342,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-ec2085c1-d535-4938-a648-68f27683cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-b55e3c51-05c5-4ef1-9b58-c3d33f0dedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-7453b238-da6f-4975-a058-57538d707bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-fc8cfa8d-5e14-4522-9c7e-fcce76435738,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-28748438-3a8c-43af-9918-8aaec8f4dbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187747378-172.17.0.5-1596952273503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37232,DS-b9198bf5-dad6-46d2-9e26-85c25b525518,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-53463428-4be7-46f4-af7e-7c0bc41c33c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-da947bda-d52e-4fc7-bb3f-05fc03e50342,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-ec2085c1-d535-4938-a648-68f27683cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-b55e3c51-05c5-4ef1-9b58-c3d33f0dedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-7453b238-da6f-4975-a058-57538d707bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-fc8cfa8d-5e14-4522-9c7e-fcce76435738,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-28748438-3a8c-43af-9918-8aaec8f4dbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439730756-172.17.0.5-1596952369619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-66557a08-57ff-4434-a6c8-10dbffb0fcff,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-fc42cebe-5ea0-4292-8b3d-d9cc6c0bbc42,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-b0fe8221-c442-425c-8fd2-c64dd795395e,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-ea31c81e-2007-4d59-82db-4797a39b4ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-057000bb-4d75-41b3-9103-0a35f73d65d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-78ed8ce0-be2d-46fa-802a-55e9c50478cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-bd3828cc-af34-40d3-a6fa-a9a00e20fd22,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-192d773c-0bac-48d8-b3ae-b8351e23f6eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439730756-172.17.0.5-1596952369619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-66557a08-57ff-4434-a6c8-10dbffb0fcff,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-fc42cebe-5ea0-4292-8b3d-d9cc6c0bbc42,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-b0fe8221-c442-425c-8fd2-c64dd795395e,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-ea31c81e-2007-4d59-82db-4797a39b4ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-057000bb-4d75-41b3-9103-0a35f73d65d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-78ed8ce0-be2d-46fa-802a-55e9c50478cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-bd3828cc-af34-40d3-a6fa-a9a00e20fd22,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-192d773c-0bac-48d8-b3ae-b8351e23f6eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486446990-172.17.0.5-1596952409158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-8e68a05c-f63d-48b1-b3b2-49e6b772f622,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-5894b76a-9fcd-4080-9278-3fdd5631bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-4e875ce8-06eb-4339-b78b-9b3a97b13c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-47050c64-6aa5-4150-af68-1c4a779accd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-a3f3e780-e6dd-4cdc-b9f8-507170191e93,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-2c827f31-3ab2-40f3-8bc9-48d6ec5815ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-fe20dbad-a247-467a-9235-1175ee8741c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-a71397de-8e61-4ec4-bf4a-6830418e5e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486446990-172.17.0.5-1596952409158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-8e68a05c-f63d-48b1-b3b2-49e6b772f622,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-5894b76a-9fcd-4080-9278-3fdd5631bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-4e875ce8-06eb-4339-b78b-9b3a97b13c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-47050c64-6aa5-4150-af68-1c4a779accd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-a3f3e780-e6dd-4cdc-b9f8-507170191e93,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-2c827f31-3ab2-40f3-8bc9-48d6ec5815ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-fe20dbad-a247-467a-9235-1175ee8741c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-a71397de-8e61-4ec4-bf4a-6830418e5e33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882930096-172.17.0.5-1596952761991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-f807e037-735c-44e4-b259-08185506cd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-d39d1bb4-99d0-4846-a3dc-0ff76450f44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-4809d6bb-36e9-40c2-b65e-b14556732f63,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-28a25d3a-c228-450a-adf8-26795c8a00f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-c3a00179-85fe-4b77-9225-54b546bbe85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-d68f0cae-7ca9-46da-bb05-030345e6bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-2a20f0e0-bf41-4742-9e99-7d5e25b88650,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-187227f1-1948-4c82-9927-e5d1a75dd827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882930096-172.17.0.5-1596952761991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-f807e037-735c-44e4-b259-08185506cd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-d39d1bb4-99d0-4846-a3dc-0ff76450f44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-4809d6bb-36e9-40c2-b65e-b14556732f63,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-28a25d3a-c228-450a-adf8-26795c8a00f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-c3a00179-85fe-4b77-9225-54b546bbe85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-d68f0cae-7ca9-46da-bb05-030345e6bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-2a20f0e0-bf41-4742-9e99-7d5e25b88650,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-187227f1-1948-4c82-9927-e5d1a75dd827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602296330-172.17.0.5-1596953292060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-e9130c70-04c3-46c7-8324-df1d012edb63,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-5bdd35b8-4c55-41ea-976b-5eccd3375005,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-c3b23728-c895-49b2-9b5a-2e6f51397066,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-c5873a94-ec82-42cc-9853-065a032bcb03,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-030f2f13-0d1b-40e0-a08a-390c1028ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-0bbf7c7a-149c-491e-94a9-a03e997cb50b,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-a2fa5563-96b0-4e99-94db-7513713f66e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-8fc2c5ed-2b2b-4c6b-b999-c4d4824a0b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602296330-172.17.0.5-1596953292060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-e9130c70-04c3-46c7-8324-df1d012edb63,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-5bdd35b8-4c55-41ea-976b-5eccd3375005,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-c3b23728-c895-49b2-9b5a-2e6f51397066,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-c5873a94-ec82-42cc-9853-065a032bcb03,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-030f2f13-0d1b-40e0-a08a-390c1028ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-0bbf7c7a-149c-491e-94a9-a03e997cb50b,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-a2fa5563-96b0-4e99-94db-7513713f66e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-8fc2c5ed-2b2b-4c6b-b999-c4d4824a0b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956919649-172.17.0.5-1596953574871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33365,DS-cc55c1a4-e144-4647-879f-4e03fc203e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-52cb89fe-6fd4-4cff-bba2-316bd4b8fa11,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-004a8791-6c1c-41df-8e31-02d9e4e7884c,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-4e56c0b4-406f-41e7-b3c0-aaf9463855a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-c0b000ee-a604-49f7-a67c-e88cf84c6c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-6bdf358f-1d9b-4a2f-8200-a74e748e3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-85a967b9-f012-460d-b128-d135b50affcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-23a9d8e9-6e1e-46aa-8910-83e6b25248d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956919649-172.17.0.5-1596953574871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33365,DS-cc55c1a4-e144-4647-879f-4e03fc203e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-52cb89fe-6fd4-4cff-bba2-316bd4b8fa11,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-004a8791-6c1c-41df-8e31-02d9e4e7884c,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-4e56c0b4-406f-41e7-b3c0-aaf9463855a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-c0b000ee-a604-49f7-a67c-e88cf84c6c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-6bdf358f-1d9b-4a2f-8200-a74e748e3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-85a967b9-f012-460d-b128-d135b50affcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-23a9d8e9-6e1e-46aa-8910-83e6b25248d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651861184-172.17.0.5-1596953688709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-d52b2365-ed49-49f6-bee7-a99a3b5173b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-11490666-23e5-4ef0-86aa-2bbe85c58b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-fe0aa7d2-b1db-4a6a-8e60-215309393423,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-a71045f9-0dbc-4764-a6a1-b499b6f2efbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-14fdab3b-544c-4779-9f6a-d018dc69f7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-8216bca4-35d1-4061-abb5-92e29c3444b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-39cbad89-849a-46fe-b288-f0915ed6770b,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-ba7ac572-a714-4f38-8ce8-2935ef0bb254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651861184-172.17.0.5-1596953688709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-d52b2365-ed49-49f6-bee7-a99a3b5173b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-11490666-23e5-4ef0-86aa-2bbe85c58b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-fe0aa7d2-b1db-4a6a-8e60-215309393423,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-a71045f9-0dbc-4764-a6a1-b499b6f2efbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-14fdab3b-544c-4779-9f6a-d018dc69f7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-8216bca4-35d1-4061-abb5-92e29c3444b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-39cbad89-849a-46fe-b288-f0915ed6770b,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-ba7ac572-a714-4f38-8ce8-2935ef0bb254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112245968-172.17.0.5-1596953793535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-bb21495c-2ace-4a9d-9098-70f70583bd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-776eec84-7a09-482c-914a-78401c6db892,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-7776ee1e-b5b1-46b1-9ccc-dc29ce0000ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-cdaaeef7-52f0-441e-be45-e91a1af4d408,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-c0f29ff4-275a-48ec-abe3-4dde9c1539ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-1a9de5a0-4039-4631-a2dd-dd04af86ef96,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-b1694274-e9dc-4fb5-bccc-3289c3b9120d,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-58217703-74c3-40f6-ad5e-bfeeccade2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112245968-172.17.0.5-1596953793535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-bb21495c-2ace-4a9d-9098-70f70583bd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-776eec84-7a09-482c-914a-78401c6db892,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-7776ee1e-b5b1-46b1-9ccc-dc29ce0000ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-cdaaeef7-52f0-441e-be45-e91a1af4d408,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-c0f29ff4-275a-48ec-abe3-4dde9c1539ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-1a9de5a0-4039-4631-a2dd-dd04af86ef96,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-b1694274-e9dc-4fb5-bccc-3289c3b9120d,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-58217703-74c3-40f6-ad5e-bfeeccade2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251941497-172.17.0.5-1596953896238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38412,DS-cab6f66e-386c-44cc-85c5-09ea8eb16792,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-39e4104b-413d-452f-b3c4-c221bd31aa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-c3e3686e-1a50-435d-9052-881b20f14d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-45b8f2b0-1f67-48f4-9fff-ea4f44a125e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-a2f1001b-f370-4935-a25f-e9392e807d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-a3f94c42-335b-4715-b718-d27e40cdf4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-9f047b4a-30ef-4c41-9824-94307b1604a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-65c29a69-51b5-4e12-9d47-d9ba80953fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251941497-172.17.0.5-1596953896238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38412,DS-cab6f66e-386c-44cc-85c5-09ea8eb16792,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-39e4104b-413d-452f-b3c4-c221bd31aa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-c3e3686e-1a50-435d-9052-881b20f14d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-45b8f2b0-1f67-48f4-9fff-ea4f44a125e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-a2f1001b-f370-4935-a25f-e9392e807d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-a3f94c42-335b-4715-b718-d27e40cdf4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-9f047b4a-30ef-4c41-9824-94307b1604a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-65c29a69-51b5-4e12-9d47-d9ba80953fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252416845-172.17.0.5-1596954047034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33272,DS-6e6d4e0c-65d7-4ca1-8e6b-4c2b91549598,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-9cade3ce-fa34-4290-b752-9e1eb278cff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-bc645fca-9350-4332-887c-fb6bd043ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-95457e14-9d81-4f14-9aab-18ac191e0d33,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-d2c4f0c9-9c92-4104-abd9-5765ecacc194,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-7d4014ce-fbe4-4e36-951f-b8831f96b3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-1467a6c4-6698-49bf-9e2f-b311af2b3d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-33a4122f-8290-45a8-867b-6e7c6e115dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252416845-172.17.0.5-1596954047034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33272,DS-6e6d4e0c-65d7-4ca1-8e6b-4c2b91549598,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-9cade3ce-fa34-4290-b752-9e1eb278cff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-bc645fca-9350-4332-887c-fb6bd043ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-95457e14-9d81-4f14-9aab-18ac191e0d33,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-d2c4f0c9-9c92-4104-abd9-5765ecacc194,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-7d4014ce-fbe4-4e36-951f-b8831f96b3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-1467a6c4-6698-49bf-9e2f-b311af2b3d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-33a4122f-8290-45a8-867b-6e7c6e115dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615521660-172.17.0.5-1596954348739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43136,DS-c4250cc3-420c-4a6f-835b-dd0429652ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-56d4ad22-53d9-40ba-bcc9-dedb05d63c71,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-0c9c64d7-6386-4967-a0d8-50b1ddc822b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-48282231-1bf1-4f02-ab76-1c3665de0d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-16d21d76-909a-4bff-88e6-eff0fd3b054e,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-1bb4153d-840a-41c6-a9f7-57049ba046de,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-d660bbe5-90a6-453b-a25b-6dd3f650d481,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-0a2d785e-476a-42d5-b80d-43e0cbfa410e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615521660-172.17.0.5-1596954348739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43136,DS-c4250cc3-420c-4a6f-835b-dd0429652ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-56d4ad22-53d9-40ba-bcc9-dedb05d63c71,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-0c9c64d7-6386-4967-a0d8-50b1ddc822b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-48282231-1bf1-4f02-ab76-1c3665de0d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-16d21d76-909a-4bff-88e6-eff0fd3b054e,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-1bb4153d-840a-41c6-a9f7-57049ba046de,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-d660bbe5-90a6-453b-a25b-6dd3f650d481,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-0a2d785e-476a-42d5-b80d-43e0cbfa410e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897530229-172.17.0.5-1596954681823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-2d2fe092-ca1a-4fd7-bb66-3cfe59bf9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-e4c8c115-5549-4bf9-9ec7-86b62fc3f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-0736b8fe-89ca-4c4a-a890-968f7f094d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-0f242711-d2d7-4b87-9b83-1919b4275436,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-66ddea7b-cbac-4312-ae1b-d5707c346d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-15bb0ae9-bf10-4757-b213-43927199856f,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-f3019026-aa54-4930-8451-010d2b7bec15,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-0577981f-c6b5-403b-b3a3-199290ad4ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897530229-172.17.0.5-1596954681823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-2d2fe092-ca1a-4fd7-bb66-3cfe59bf9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-e4c8c115-5549-4bf9-9ec7-86b62fc3f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-0736b8fe-89ca-4c4a-a890-968f7f094d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-0f242711-d2d7-4b87-9b83-1919b4275436,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-66ddea7b-cbac-4312-ae1b-d5707c346d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-15bb0ae9-bf10-4757-b213-43927199856f,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-f3019026-aa54-4930-8451-010d2b7bec15,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-0577981f-c6b5-403b-b3a3-199290ad4ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858420515-172.17.0.5-1596954841282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-4d2c6d0c-7139-46f9-8712-a0f1f31241b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-df9aabd2-c383-490c-8374-bff256d7fcec,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-951bddd5-3688-45bb-a10d-0b94b8669442,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-28fb4877-21ea-41ed-8273-fe701b033b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-0551fb7c-104e-4513-9cfd-fe57cf096dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-1a475ea4-f97c-4f69-a32b-fb18c994ff83,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-dd955370-ced1-4450-923b-7ec8c333a8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-b9369897-9ede-4dd8-92a4-188e0e1c3b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858420515-172.17.0.5-1596954841282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-4d2c6d0c-7139-46f9-8712-a0f1f31241b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-df9aabd2-c383-490c-8374-bff256d7fcec,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-951bddd5-3688-45bb-a10d-0b94b8669442,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-28fb4877-21ea-41ed-8273-fe701b033b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-0551fb7c-104e-4513-9cfd-fe57cf096dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-1a475ea4-f97c-4f69-a32b-fb18c994ff83,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-dd955370-ced1-4450-923b-7ec8c333a8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-b9369897-9ede-4dd8-92a4-188e0e1c3b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345681937-172.17.0.5-1596955281091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-1c32317d-32e2-4217-a9f6-606eaabf9642,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-d60e1e72-b205-428c-8f81-d7dcc3a3bd78,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-1ea026b5-19e1-4ccc-8cd5-4f4e6a74da44,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-46029eba-2f5f-486c-ba87-3b252a6cc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-23f0c72a-a1e5-459d-b749-f84cbbe2003c,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-793d9fe1-af44-4366-9bb1-24ae56014b50,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-1b8b4842-42c7-4c5b-b7ac-f2df5e5ca918,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-d5959609-67e3-4ec0-9527-8d9e3bed1e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345681937-172.17.0.5-1596955281091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-1c32317d-32e2-4217-a9f6-606eaabf9642,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-d60e1e72-b205-428c-8f81-d7dcc3a3bd78,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-1ea026b5-19e1-4ccc-8cd5-4f4e6a74da44,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-46029eba-2f5f-486c-ba87-3b252a6cc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-23f0c72a-a1e5-459d-b749-f84cbbe2003c,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-793d9fe1-af44-4366-9bb1-24ae56014b50,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-1b8b4842-42c7-4c5b-b7ac-f2df5e5ca918,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-d5959609-67e3-4ec0-9527-8d9e3bed1e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698931678-172.17.0.5-1596955630292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-3135d26c-511d-4ac4-8f8b-bc19a597b095,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-2bd77dea-a907-4beb-9c07-fea09cfc75bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-8f07fe6f-b6e8-4ab3-8776-c27191e3470c,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-fbfcaa60-b147-4547-93c0-15aa7aedef77,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-0a645985-4665-4d0b-8ffc-ec6eccd48a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-6b996c40-9bf8-4d22-8b17-bfeb61f12c45,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-6f31eebb-c646-4d92-abbd-c251266d4d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-2a3e0a4b-7cb7-4458-9e4e-1fe355fb6bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698931678-172.17.0.5-1596955630292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-3135d26c-511d-4ac4-8f8b-bc19a597b095,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-2bd77dea-a907-4beb-9c07-fea09cfc75bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-8f07fe6f-b6e8-4ab3-8776-c27191e3470c,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-fbfcaa60-b147-4547-93c0-15aa7aedef77,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-0a645985-4665-4d0b-8ffc-ec6eccd48a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-6b996c40-9bf8-4d22-8b17-bfeb61f12c45,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-6f31eebb-c646-4d92-abbd-c251266d4d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-2a3e0a4b-7cb7-4458-9e4e-1fe355fb6bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910431573-172.17.0.5-1596955756484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-85db31ec-1258-4d61-9b10-4cba3f3e19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-9e3d6340-8165-4243-8ce4-00cf166d2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-3f6899ea-ef56-4585-975b-3865e6842e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-2308f2c0-f852-43d9-b046-f5359f95f042,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-2020b709-cb44-457e-8094-3a26f659ee40,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-d29a06dd-f99d-493b-8694-14edbb487820,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-11467ff0-4a29-4f5c-b965-60c844d21c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-980e79ce-1d6b-4c00-afa3-7032841bd9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910431573-172.17.0.5-1596955756484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-85db31ec-1258-4d61-9b10-4cba3f3e19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-9e3d6340-8165-4243-8ce4-00cf166d2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-3f6899ea-ef56-4585-975b-3865e6842e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-2308f2c0-f852-43d9-b046-f5359f95f042,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-2020b709-cb44-457e-8094-3a26f659ee40,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-d29a06dd-f99d-493b-8694-14edbb487820,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-11467ff0-4a29-4f5c-b965-60c844d21c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-980e79ce-1d6b-4c00-afa3-7032841bd9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834327566-172.17.0.5-1596955791988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-1b9d1118-9799-4384-bc01-d1bba9d67741,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-5e49301f-84d4-4d8e-a349-ebd3228451e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-27611901-160b-47bf-8e3b-c5180edd8972,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-135dcfe4-3444-41be-90fe-87ecbb55c6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-f142eefd-64ef-439e-b3dc-d8f781673329,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-53606640-45e0-43ed-8072-b7699d3933d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-210b2bec-b2e2-4e4b-8d22-57979aecabf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-efad1a5c-5db1-4681-a85a-f0f644a707e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834327566-172.17.0.5-1596955791988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-1b9d1118-9799-4384-bc01-d1bba9d67741,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-5e49301f-84d4-4d8e-a349-ebd3228451e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-27611901-160b-47bf-8e3b-c5180edd8972,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-135dcfe4-3444-41be-90fe-87ecbb55c6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-f142eefd-64ef-439e-b3dc-d8f781673329,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-53606640-45e0-43ed-8072-b7699d3933d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-210b2bec-b2e2-4e4b-8d22-57979aecabf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-efad1a5c-5db1-4681-a85a-f0f644a707e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568400394-172.17.0.5-1596955988859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-828d357f-cca5-4d01-bce5-031fbbfd1c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-53487de2-fac3-491a-8d31-0517fd6e0686,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-5664edac-3ff6-4693-b10b-a7e388314c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-58c58408-0bdb-4d66-b112-fc212468280c,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-81cb77fb-3317-4d3a-8f22-e07845c9e985,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-f194d3cf-eaa1-4fc2-8296-2eba5d53cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-b7a6b2b1-05e7-4af3-abe6-249f41597383,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-2d4b7fb5-876f-49f7-be67-35a4331b583b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568400394-172.17.0.5-1596955988859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-828d357f-cca5-4d01-bce5-031fbbfd1c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-53487de2-fac3-491a-8d31-0517fd6e0686,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-5664edac-3ff6-4693-b10b-a7e388314c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-58c58408-0bdb-4d66-b112-fc212468280c,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-81cb77fb-3317-4d3a-8f22-e07845c9e985,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-f194d3cf-eaa1-4fc2-8296-2eba5d53cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-b7a6b2b1-05e7-4af3-abe6-249f41597383,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-2d4b7fb5-876f-49f7-be67-35a4331b583b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324814647-172.17.0.5-1596956082935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44127,DS-12384bd2-3122-4d04-8c8a-465a832c44cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-fe7f7e70-2405-48f9-a960-a6d8275e0707,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-728bf1ef-03a0-4037-ae75-aa157173c013,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-6b5b7d7a-b20e-427b-b2b4-5b6a841e88dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-2b50e204-465d-48ce-87d3-b076c4e66f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-fae67814-6f6c-4bff-91e9-289de8c46489,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-ff01537e-319b-4c83-9404-d35fea6b52ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-5b4b2338-9ef6-4ca3-b69e-4213994d644b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324814647-172.17.0.5-1596956082935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44127,DS-12384bd2-3122-4d04-8c8a-465a832c44cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-fe7f7e70-2405-48f9-a960-a6d8275e0707,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-728bf1ef-03a0-4037-ae75-aa157173c013,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-6b5b7d7a-b20e-427b-b2b4-5b6a841e88dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-2b50e204-465d-48ce-87d3-b076c4e66f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-fae67814-6f6c-4bff-91e9-289de8c46489,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-ff01537e-319b-4c83-9404-d35fea6b52ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-5b4b2338-9ef6-4ca3-b69e-4213994d644b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5029
