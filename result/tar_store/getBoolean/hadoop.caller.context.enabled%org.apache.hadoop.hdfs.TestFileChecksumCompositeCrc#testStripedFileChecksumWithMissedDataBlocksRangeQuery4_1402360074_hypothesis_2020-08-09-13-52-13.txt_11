reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537887350-172.17.0.3-1596981148916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44582,DS-dc66866d-f01d-4132-ba5a-78c8b407da37,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-2618fd69-26ba-445c-a338-8d781efed70c,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-cbdf9bfa-16c9-4de4-a40a-ebb31be4cccc,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-bad63d5f-99e0-4ca6-b6be-a27e91ee19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-93671d5e-fe83-4fe7-a4b5-fe0744b67e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-8a93ab7d-a5ec-4913-8a96-8b4da370872d,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-0477c436-8bd1-4941-9720-5e58b672438b,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-9c6c4e2e-1185-4186-b0e2-53d323135325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537887350-172.17.0.3-1596981148916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44582,DS-dc66866d-f01d-4132-ba5a-78c8b407da37,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-2618fd69-26ba-445c-a338-8d781efed70c,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-cbdf9bfa-16c9-4de4-a40a-ebb31be4cccc,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-bad63d5f-99e0-4ca6-b6be-a27e91ee19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-93671d5e-fe83-4fe7-a4b5-fe0744b67e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-8a93ab7d-a5ec-4913-8a96-8b4da370872d,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-0477c436-8bd1-4941-9720-5e58b672438b,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-9c6c4e2e-1185-4186-b0e2-53d323135325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304045578-172.17.0.3-1596981345507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35163,DS-7b52c6a0-5183-41b7-aa72-b1f182535856,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-4f76055a-122e-4f7a-a472-b0afd9d8f4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-473cf3ce-800d-4f14-abf8-ab428df7a003,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-14714acb-ede3-4ea0-96a6-3b696eb0cefb,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-dad5f3bd-a183-4b2e-9948-c56011fda5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-93189f71-b81a-4a87-9dd5-ac6e0ee623f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-09ba6526-509c-421c-959c-53926a8c1369,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-c17ca045-f52a-46be-bd8f-606e7b4fc961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304045578-172.17.0.3-1596981345507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35163,DS-7b52c6a0-5183-41b7-aa72-b1f182535856,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-4f76055a-122e-4f7a-a472-b0afd9d8f4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-473cf3ce-800d-4f14-abf8-ab428df7a003,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-14714acb-ede3-4ea0-96a6-3b696eb0cefb,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-dad5f3bd-a183-4b2e-9948-c56011fda5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-93189f71-b81a-4a87-9dd5-ac6e0ee623f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-09ba6526-509c-421c-959c-53926a8c1369,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-c17ca045-f52a-46be-bd8f-606e7b4fc961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113428913-172.17.0.3-1596981594228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-6754aee5-741e-4846-9281-eb60906ef4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-63b6711d-2051-4310-8e67-85fffe83eb08,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-f3605c59-0150-4369-9a92-365a922f1ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-db0dc9d0-adbb-4cf0-afa6-39f6efe5ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-286a4542-c5b6-4c70-bdca-353100ccca34,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-01a3282e-3fe6-4dcf-ae3e-9267430a0d23,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-c0c7ea5c-c185-41e4-986f-be05de58862b,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-debcf0e4-f24f-4403-bce3-acc621df30ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113428913-172.17.0.3-1596981594228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-6754aee5-741e-4846-9281-eb60906ef4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-63b6711d-2051-4310-8e67-85fffe83eb08,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-f3605c59-0150-4369-9a92-365a922f1ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-db0dc9d0-adbb-4cf0-afa6-39f6efe5ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-286a4542-c5b6-4c70-bdca-353100ccca34,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-01a3282e-3fe6-4dcf-ae3e-9267430a0d23,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-c0c7ea5c-c185-41e4-986f-be05de58862b,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-debcf0e4-f24f-4403-bce3-acc621df30ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505843504-172.17.0.3-1596981762742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-7f8a3d55-e98f-4f6e-9f6b-18cad31ddcac,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-c9969b06-43f8-4567-8c3e-1c11b88eb317,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-8df9f626-d6ad-4345-813b-acabef337777,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-841382eb-61d1-4497-bc7a-5b61a4cad096,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-9b6a73da-f276-46e6-959b-7a5efee99b29,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-fb018dc2-f5e2-4cc3-bc2a-b86c6fa00a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-ca302c3d-2745-4df1-a1ad-620d2991f7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-7cfd2e74-5b63-4318-b9d1-4b4734816712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505843504-172.17.0.3-1596981762742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-7f8a3d55-e98f-4f6e-9f6b-18cad31ddcac,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-c9969b06-43f8-4567-8c3e-1c11b88eb317,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-8df9f626-d6ad-4345-813b-acabef337777,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-841382eb-61d1-4497-bc7a-5b61a4cad096,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-9b6a73da-f276-46e6-959b-7a5efee99b29,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-fb018dc2-f5e2-4cc3-bc2a-b86c6fa00a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-ca302c3d-2745-4df1-a1ad-620d2991f7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-7cfd2e74-5b63-4318-b9d1-4b4734816712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667272229-172.17.0.3-1596982140382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-fa203010-66a9-47f0-94e5-797af03829c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-f233b7a3-c5e2-4fd9-86d0-830db5e24201,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-0c5a244d-52dd-47af-91ce-1a2baa6ee33a,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-17964ca3-d7c4-4bf0-8482-97f14b1ea94b,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-77e6df1d-7df0-4f46-ac76-a9f59bb41108,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-42340f3e-6b54-45b5-9ef8-5931dc74ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-c869d84b-be82-4d65-a9ed-cd7495453d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-2ea4311f-7289-46fd-8a63-73b3c6979484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667272229-172.17.0.3-1596982140382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-fa203010-66a9-47f0-94e5-797af03829c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-f233b7a3-c5e2-4fd9-86d0-830db5e24201,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-0c5a244d-52dd-47af-91ce-1a2baa6ee33a,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-17964ca3-d7c4-4bf0-8482-97f14b1ea94b,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-77e6df1d-7df0-4f46-ac76-a9f59bb41108,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-42340f3e-6b54-45b5-9ef8-5931dc74ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-c869d84b-be82-4d65-a9ed-cd7495453d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-2ea4311f-7289-46fd-8a63-73b3c6979484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936054470-172.17.0.3-1596982368789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-63c2ee9c-4d34-4079-8ead-df1fd463ec8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-7804f371-4d65-4f5d-bff2-4a4213b77ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-863e0002-119f-4d5b-84f6-da0d6978079f,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-2a29970a-f025-4075-8054-ef80663e7dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-44908e9a-1045-4c77-885d-bb9280d41e34,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-6d3a1695-436f-4c7b-a985-f5b746a29025,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-e4de63c9-caeb-42c1-8268-7f55252db680,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-963ae025-1828-4696-96ec-f2eeeabb5553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936054470-172.17.0.3-1596982368789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-63c2ee9c-4d34-4079-8ead-df1fd463ec8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-7804f371-4d65-4f5d-bff2-4a4213b77ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-863e0002-119f-4d5b-84f6-da0d6978079f,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-2a29970a-f025-4075-8054-ef80663e7dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-44908e9a-1045-4c77-885d-bb9280d41e34,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-6d3a1695-436f-4c7b-a985-f5b746a29025,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-e4de63c9-caeb-42c1-8268-7f55252db680,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-963ae025-1828-4696-96ec-f2eeeabb5553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878895632-172.17.0.3-1596982397291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43806,DS-29a82c51-e191-46a8-91e1-034715317a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-e1c61156-212b-428a-9d4a-d8324d2331e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-72a2f958-fa25-4cab-9f3b-e42a0ee0dfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-a3f13df4-8bcf-40f6-a8de-88e17d2fb31e,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-9de6ad5e-c8ef-421e-92d9-fe9b47d355e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-25e512a4-6dd7-4c16-8871-743ec0b382f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-ee3031c1-b147-4092-9494-2f6bf866c330,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-d4ab9ed3-5b0b-4258-b44e-56b80487f7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878895632-172.17.0.3-1596982397291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43806,DS-29a82c51-e191-46a8-91e1-034715317a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-e1c61156-212b-428a-9d4a-d8324d2331e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-72a2f958-fa25-4cab-9f3b-e42a0ee0dfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-a3f13df4-8bcf-40f6-a8de-88e17d2fb31e,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-9de6ad5e-c8ef-421e-92d9-fe9b47d355e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-25e512a4-6dd7-4c16-8871-743ec0b382f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-ee3031c1-b147-4092-9494-2f6bf866c330,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-d4ab9ed3-5b0b-4258-b44e-56b80487f7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598490246-172.17.0.3-1596982498293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-52f3c1c3-9e71-4938-947a-ec162e6cb86f,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-770e58a8-2c2b-4b87-9b09-c259d3496875,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-8a248854-a86d-4f54-90d9-273736b16d86,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-000631c0-a109-4842-88a3-57ba7c2166f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-ffad1868-6a10-45be-aa06-877f2461b32c,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-e373e9f2-15b1-4621-b49c-f68db27c7295,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-db031b6d-b4f6-4204-b392-d88d8aec44c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-01b3125c-8150-4ff0-8f2c-c2456f763042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598490246-172.17.0.3-1596982498293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-52f3c1c3-9e71-4938-947a-ec162e6cb86f,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-770e58a8-2c2b-4b87-9b09-c259d3496875,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-8a248854-a86d-4f54-90d9-273736b16d86,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-000631c0-a109-4842-88a3-57ba7c2166f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-ffad1868-6a10-45be-aa06-877f2461b32c,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-e373e9f2-15b1-4621-b49c-f68db27c7295,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-db031b6d-b4f6-4204-b392-d88d8aec44c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-01b3125c-8150-4ff0-8f2c-c2456f763042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653113845-172.17.0.3-1596982865596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40106,DS-d2629c20-77a7-42b0-8d10-6cc14d8bc70f,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-4a339d7d-1123-4f7c-92c5-1fea83622054,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-88c9702b-e92b-443b-b2c1-a72d3b795e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-30f11151-23f9-4ad4-bb9c-81d4b83c3051,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-c50e819c-05a0-4117-88d6-3e7b2fe51489,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-d6d8407b-0be7-41e4-af65-d2170966bbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-a18e158c-df57-417e-881d-4e67415efc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-29e89e51-535c-4cc5-b0af-2ce5acd1d98d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653113845-172.17.0.3-1596982865596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40106,DS-d2629c20-77a7-42b0-8d10-6cc14d8bc70f,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-4a339d7d-1123-4f7c-92c5-1fea83622054,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-88c9702b-e92b-443b-b2c1-a72d3b795e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-30f11151-23f9-4ad4-bb9c-81d4b83c3051,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-c50e819c-05a0-4117-88d6-3e7b2fe51489,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-d6d8407b-0be7-41e4-af65-d2170966bbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-a18e158c-df57-417e-881d-4e67415efc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-29e89e51-535c-4cc5-b0af-2ce5acd1d98d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968208184-172.17.0.3-1596983650421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-856b1b04-e78e-4abc-9502-e7941afa6a91,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-4f6f2226-8361-4616-aa93-98fd2fa73319,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-6665fa6c-4c61-497d-9d91-3f4186d8323c,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-5d7828d2-02b5-464a-833b-67f7a2a8983a,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-3e3b372b-ad3d-44bc-aa57-87e54d5a2770,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-0b1153a3-5267-4db3-a120-f8673c5540e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-12ffbc00-243a-444e-9a7d-3419e5a96af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-af199829-18b9-44cb-89e4-7bb1668ab2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968208184-172.17.0.3-1596983650421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-856b1b04-e78e-4abc-9502-e7941afa6a91,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-4f6f2226-8361-4616-aa93-98fd2fa73319,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-6665fa6c-4c61-497d-9d91-3f4186d8323c,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-5d7828d2-02b5-464a-833b-67f7a2a8983a,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-3e3b372b-ad3d-44bc-aa57-87e54d5a2770,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-0b1153a3-5267-4db3-a120-f8673c5540e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-12ffbc00-243a-444e-9a7d-3419e5a96af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-af199829-18b9-44cb-89e4-7bb1668ab2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045540234-172.17.0.3-1596983687361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43558,DS-2a1a7666-6f25-4774-9aeb-9b103e8240c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-f234aaa8-fb1c-42e5-a5e8-8d40c266489f,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-2a6ca9d9-45da-4099-9da1-8edb57b73359,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-9db59116-a267-4541-9ad7-754cfbd5a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-ba9466f0-92c1-42d9-bb0d-6447ff7ad0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-c75e83da-53ff-4380-b4d7-a178e928bc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-f25b88e8-4fcf-43d7-9993-7660eb24f345,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-b4a223e8-4596-4fd3-beba-cf271470def4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045540234-172.17.0.3-1596983687361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43558,DS-2a1a7666-6f25-4774-9aeb-9b103e8240c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-f234aaa8-fb1c-42e5-a5e8-8d40c266489f,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-2a6ca9d9-45da-4099-9da1-8edb57b73359,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-9db59116-a267-4541-9ad7-754cfbd5a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-ba9466f0-92c1-42d9-bb0d-6447ff7ad0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-c75e83da-53ff-4380-b4d7-a178e928bc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-f25b88e8-4fcf-43d7-9993-7660eb24f345,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-b4a223e8-4596-4fd3-beba-cf271470def4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048119935-172.17.0.3-1596983723223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39228,DS-1bf5119c-aca3-4563-a19d-369804647b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-b10882c8-8041-4fdb-8d17-ac3914b64d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-6498d9cb-20d9-4624-8f7e-9503f877f10f,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-9c55aaa3-5fca-4109-9508-9156f81eccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-9cbf4871-4a0d-4769-bbe5-7b5c9fe433c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-b466d6bf-aaf0-4331-9759-554c16aa88d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-782d9acf-cd2a-42e0-a1e7-ec8371aa2308,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-2c4b9db8-85ec-4d23-8151-75ce9a0d2fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048119935-172.17.0.3-1596983723223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39228,DS-1bf5119c-aca3-4563-a19d-369804647b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-b10882c8-8041-4fdb-8d17-ac3914b64d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-6498d9cb-20d9-4624-8f7e-9503f877f10f,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-9c55aaa3-5fca-4109-9508-9156f81eccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-9cbf4871-4a0d-4769-bbe5-7b5c9fe433c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-b466d6bf-aaf0-4331-9759-554c16aa88d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-782d9acf-cd2a-42e0-a1e7-ec8371aa2308,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-2c4b9db8-85ec-4d23-8151-75ce9a0d2fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163419209-172.17.0.3-1596984149522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45075,DS-5a25eefe-ddc8-4b30-9529-3c01d45256a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-2dc2b6cb-fe99-41a5-8bc9-6e85719d1d62,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-be5aeb50-dd2f-4a0d-ba77-2da6bed1be6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-336804c1-ddd8-4278-912f-ed38ed937d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-fc3adc56-b7b6-424f-ba8d-e750d530f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-f583c737-1755-4d35-be87-555306036d51,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-725215cc-736d-4687-b4f9-1b0fa230cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-767b5507-4549-4476-a26c-1587d201b1e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163419209-172.17.0.3-1596984149522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45075,DS-5a25eefe-ddc8-4b30-9529-3c01d45256a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-2dc2b6cb-fe99-41a5-8bc9-6e85719d1d62,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-be5aeb50-dd2f-4a0d-ba77-2da6bed1be6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-336804c1-ddd8-4278-912f-ed38ed937d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-fc3adc56-b7b6-424f-ba8d-e750d530f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-f583c737-1755-4d35-be87-555306036d51,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-725215cc-736d-4687-b4f9-1b0fa230cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-767b5507-4549-4476-a26c-1587d201b1e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823546219-172.17.0.3-1596984221094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-f0c3cfe9-fbd7-4fe9-add7-1ecd450d6860,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-524a3a71-dcf6-4998-938b-00965325b021,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-0ff57127-4206-4f04-8202-5ec5992abb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-4857304d-8ee7-4667-be46-41a0acb7c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-390cb71c-b162-4dc1-939b-7a6f9928cc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-7122929b-4803-4ac8-81af-9ec89e321cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-28362e31-8405-4d73-a9bf-38fd4f80e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-c145fcd3-0a5f-45e9-9e87-bae315516663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823546219-172.17.0.3-1596984221094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-f0c3cfe9-fbd7-4fe9-add7-1ecd450d6860,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-524a3a71-dcf6-4998-938b-00965325b021,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-0ff57127-4206-4f04-8202-5ec5992abb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-4857304d-8ee7-4667-be46-41a0acb7c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-390cb71c-b162-4dc1-939b-7a6f9928cc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-7122929b-4803-4ac8-81af-9ec89e321cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-28362e31-8405-4d73-a9bf-38fd4f80e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-c145fcd3-0a5f-45e9-9e87-bae315516663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725083959-172.17.0.3-1596984387262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-f552c3b0-a20a-49cb-9dca-ed7ed9ada055,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-314a09aa-53c6-4509-9abc-ada95ec2a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-bb6a8bb1-b16c-4169-a3f4-9d9cf2c38c66,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-2dbea7f6-922d-494c-b193-36eb82049f67,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-a28c79e5-531d-48cb-9d40-cc9fa2283f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-d5eca013-e7f2-4143-b74b-b56b07adc353,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-17c44acf-3fad-422a-9a47-25ad45b768fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-fe0fce41-e801-4929-b0ef-74a6141f2159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725083959-172.17.0.3-1596984387262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-f552c3b0-a20a-49cb-9dca-ed7ed9ada055,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-314a09aa-53c6-4509-9abc-ada95ec2a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-bb6a8bb1-b16c-4169-a3f4-9d9cf2c38c66,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-2dbea7f6-922d-494c-b193-36eb82049f67,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-a28c79e5-531d-48cb-9d40-cc9fa2283f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-d5eca013-e7f2-4143-b74b-b56b07adc353,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-17c44acf-3fad-422a-9a47-25ad45b768fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-fe0fce41-e801-4929-b0ef-74a6141f2159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351135642-172.17.0.3-1596984630017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34975,DS-586e061d-bdee-49cc-b28f-5b1b9b7a0302,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-0e89bc20-2350-414d-82ed-e89303c06789,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-0f0afdba-69e5-4cda-8e79-84c9ba7a534c,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-15c19d7b-bc42-41c5-8da6-57dd7b6bd16a,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-269980df-31bf-4a9e-8caa-ad9b5e3faaac,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-0062d31f-a2c8-4355-b2c0-0cd723e59eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-d09497ce-04a3-4708-89fb-7587263789d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-d8e8b976-0ede-42d0-854a-9e62c4785a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351135642-172.17.0.3-1596984630017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34975,DS-586e061d-bdee-49cc-b28f-5b1b9b7a0302,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-0e89bc20-2350-414d-82ed-e89303c06789,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-0f0afdba-69e5-4cda-8e79-84c9ba7a534c,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-15c19d7b-bc42-41c5-8da6-57dd7b6bd16a,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-269980df-31bf-4a9e-8caa-ad9b5e3faaac,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-0062d31f-a2c8-4355-b2c0-0cd723e59eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-d09497ce-04a3-4708-89fb-7587263789d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-d8e8b976-0ede-42d0-854a-9e62c4785a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430090967-172.17.0.3-1596984867175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40344,DS-eb230c37-3cf7-4ff1-ac95-63d74622df36,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-873ef557-c8fd-4e3f-8f5f-78435953ac65,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-c9349827-8348-47ff-ac14-818d7013e46b,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-61d80cf3-5072-449e-88cd-f863e7017381,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-b2f2d5df-b779-41b0-ab1c-c8b3bfcb88be,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-98003cfb-ea15-4579-822f-bfcd3f6ab86a,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-81291355-5f88-4b84-837c-b8be5396181b,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-010da51d-dd23-4833-b514-ca4ead0e1030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430090967-172.17.0.3-1596984867175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40344,DS-eb230c37-3cf7-4ff1-ac95-63d74622df36,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-873ef557-c8fd-4e3f-8f5f-78435953ac65,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-c9349827-8348-47ff-ac14-818d7013e46b,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-61d80cf3-5072-449e-88cd-f863e7017381,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-b2f2d5df-b779-41b0-ab1c-c8b3bfcb88be,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-98003cfb-ea15-4579-822f-bfcd3f6ab86a,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-81291355-5f88-4b84-837c-b8be5396181b,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-010da51d-dd23-4833-b514-ca4ead0e1030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942254154-172.17.0.3-1596985131815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43278,DS-ebd649d4-9c73-44df-a48f-8f0d8d8c265a,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-da14cba7-57cc-4609-8902-5dd4ca378287,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-655c1672-c57d-47c2-8cdb-b25fa54f5dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-3806f42a-024e-45e5-b2c2-f1c6d8bd9df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-7456b4ca-c25d-46a5-b148-3f14dff7dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-c46749b4-e061-46bf-bcf8-d4328607aba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-c4db0e45-9f7c-47b4-ba57-10638bfa7595,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-9941fce3-543e-4df9-8531-ea4a6a2a3dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942254154-172.17.0.3-1596985131815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43278,DS-ebd649d4-9c73-44df-a48f-8f0d8d8c265a,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-da14cba7-57cc-4609-8902-5dd4ca378287,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-655c1672-c57d-47c2-8cdb-b25fa54f5dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-3806f42a-024e-45e5-b2c2-f1c6d8bd9df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-7456b4ca-c25d-46a5-b148-3f14dff7dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-c46749b4-e061-46bf-bcf8-d4328607aba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-c4db0e45-9f7c-47b4-ba57-10638bfa7595,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-9941fce3-543e-4df9-8531-ea4a6a2a3dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046946447-172.17.0.3-1596985167524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42790,DS-8d23fe6b-1d4e-407a-8752-3be0a96783f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-3ef38ff1-2a5a-4907-ae0e-8310272f4787,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-4436f2c9-eaeb-44d4-91ab-35989d83a206,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-228db088-f11a-4696-bd87-732c14c55919,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-9b2620a8-8478-4764-80ed-4d0f644ff17c,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-e8d57f86-115e-4e3a-9260-6128a6af9145,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-3a1282d1-52e7-4520-a662-e3ed0c3b6e46,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-d900cd95-c832-4889-ad8f-6e348fedd20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046946447-172.17.0.3-1596985167524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42790,DS-8d23fe6b-1d4e-407a-8752-3be0a96783f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-3ef38ff1-2a5a-4907-ae0e-8310272f4787,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-4436f2c9-eaeb-44d4-91ab-35989d83a206,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-228db088-f11a-4696-bd87-732c14c55919,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-9b2620a8-8478-4764-80ed-4d0f644ff17c,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-e8d57f86-115e-4e3a-9260-6128a6af9145,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-3a1282d1-52e7-4520-a662-e3ed0c3b6e46,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-d900cd95-c832-4889-ad8f-6e348fedd20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873383774-172.17.0.3-1596985723264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44727,DS-891d9113-0ce8-4443-b8da-06696b4cfb13,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-91011fdc-6adc-45d6-b9bd-4542bbbcd7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-ec4b59de-6fc7-4d5b-b263-5363aa493fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-d64d04fa-9471-424f-a154-126e06f58eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-2e6ee7f6-003d-4551-b4a1-3da7b2822ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-cad6359c-2598-42e5-8719-f6b6278dab82,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-b2a9af07-3ae6-4a86-9d43-3ffe860c1a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-b8e952c7-cd3d-4031-a0a0-bb7e44e46c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873383774-172.17.0.3-1596985723264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44727,DS-891d9113-0ce8-4443-b8da-06696b4cfb13,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-91011fdc-6adc-45d6-b9bd-4542bbbcd7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-ec4b59de-6fc7-4d5b-b263-5363aa493fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-d64d04fa-9471-424f-a154-126e06f58eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-2e6ee7f6-003d-4551-b4a1-3da7b2822ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-cad6359c-2598-42e5-8719-f6b6278dab82,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-b2a9af07-3ae6-4a86-9d43-3ffe860c1a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-b8e952c7-cd3d-4031-a0a0-bb7e44e46c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421923707-172.17.0.3-1596985873822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-a990ee01-b997-4f86-9ddd-a84d0f07dea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-dd3f9086-ab25-476d-a99c-4ad51b180362,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-c61d5690-3a50-40ae-a200-e7722ac77b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-4a91fecc-02f4-49e5-80d1-ea495299e0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-56539cc6-fc22-4d1c-bec2-c9fd70acc358,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-cf303cdb-4b37-4883-8321-e8a6bcb787d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-2769f6ae-fd19-47bd-a42b-13d1e031e470,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-423b05e0-4d73-4ad1-a4f0-be2f5be128a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421923707-172.17.0.3-1596985873822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-a990ee01-b997-4f86-9ddd-a84d0f07dea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-dd3f9086-ab25-476d-a99c-4ad51b180362,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-c61d5690-3a50-40ae-a200-e7722ac77b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-4a91fecc-02f4-49e5-80d1-ea495299e0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-56539cc6-fc22-4d1c-bec2-c9fd70acc358,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-cf303cdb-4b37-4883-8321-e8a6bcb787d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-2769f6ae-fd19-47bd-a42b-13d1e031e470,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-423b05e0-4d73-4ad1-a4f0-be2f5be128a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229965797-172.17.0.3-1596985906246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-63895404-2bec-42c1-b73f-dc6fcce594d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-6c31c344-0c96-4db1-8ca3-4e42a01d5123,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-83e6632a-0958-480e-8f27-4463a70261ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-7f1d28ca-4ef7-4232-b7aa-349c02f36c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-ff0ae270-57c4-472b-a0b2-9e676cff4e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-46760bd4-669a-4526-82b6-00c7063b8492,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ee1b759f-7c52-4656-8798-80902baccd35,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-c0c64326-3d33-4860-a725-b132adaad3c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229965797-172.17.0.3-1596985906246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-63895404-2bec-42c1-b73f-dc6fcce594d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-6c31c344-0c96-4db1-8ca3-4e42a01d5123,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-83e6632a-0958-480e-8f27-4463a70261ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-7f1d28ca-4ef7-4232-b7aa-349c02f36c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-ff0ae270-57c4-472b-a0b2-9e676cff4e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-46760bd4-669a-4526-82b6-00c7063b8492,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ee1b759f-7c52-4656-8798-80902baccd35,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-c0c64326-3d33-4860-a725-b132adaad3c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929921365-172.17.0.3-1596985956006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42518,DS-f1397aa3-1879-45ec-8b9e-2f7ca36207cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-6dfd7ed8-e004-4f12-b0c5-0a74944e1865,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-773ca1ed-380d-4d59-ba63-19d247ce80cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-47dffa1d-3e79-4f88-b280-1e28373850c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-a1c37c26-9f93-4421-b7b5-58779f2a0893,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-34a71c89-418e-40f7-b888-a21ee70955e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-fdf74711-c6f8-4d66-bea3-f76c7c175b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-e1584156-d0fe-4869-8f5e-bf4b3fbbee42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929921365-172.17.0.3-1596985956006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42518,DS-f1397aa3-1879-45ec-8b9e-2f7ca36207cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-6dfd7ed8-e004-4f12-b0c5-0a74944e1865,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-773ca1ed-380d-4d59-ba63-19d247ce80cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-47dffa1d-3e79-4f88-b280-1e28373850c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-a1c37c26-9f93-4421-b7b5-58779f2a0893,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-34a71c89-418e-40f7-b888-a21ee70955e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-fdf74711-c6f8-4d66-bea3-f76c7c175b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-e1584156-d0fe-4869-8f5e-bf4b3fbbee42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4880
