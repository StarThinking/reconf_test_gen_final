reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524481841-172.17.0.6-1596983735375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-dda36a67-afe2-417b-bca7-2ff9a61075c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-a0302206-9aa8-44f7-a7a8-7921ae8d8840,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a402bf62-fd8d-4e93-a0a2-e9c04c6f04d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-a43a8405-94e6-4c79-9fa4-0d861e81e154,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-f0246952-3148-42cb-abc2-eba7ba35697c,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-ece14804-a048-410d-a45c-1b88add89d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-4c3eb4db-b942-4254-86fd-668477078814,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-82e71a8d-7ba9-4247-aea3-652e9f9a12fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524481841-172.17.0.6-1596983735375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-dda36a67-afe2-417b-bca7-2ff9a61075c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-a0302206-9aa8-44f7-a7a8-7921ae8d8840,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a402bf62-fd8d-4e93-a0a2-e9c04c6f04d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-a43a8405-94e6-4c79-9fa4-0d861e81e154,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-f0246952-3148-42cb-abc2-eba7ba35697c,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-ece14804-a048-410d-a45c-1b88add89d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-4c3eb4db-b942-4254-86fd-668477078814,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-82e71a8d-7ba9-4247-aea3-652e9f9a12fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420379369-172.17.0.6-1596983990828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34152,DS-887cbe7d-546e-448e-8645-3588b0e9a151,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-64624a30-2fdd-4e0d-b0ed-2491673e6827,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-eaad5b1d-146d-4bd4-a6bc-ead4b40124a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-3a1507f9-2f90-4135-8d42-e33a8aa985d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-b07ac8ec-4bcb-4552-b2f0-48534f3b1bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-649e2248-65c8-4d4b-9ee8-717223c50eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-5f3263d6-4c49-4953-8fc7-a41d110bbe02,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-f4edf177-c681-4108-a592-c6b1bee9fb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420379369-172.17.0.6-1596983990828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34152,DS-887cbe7d-546e-448e-8645-3588b0e9a151,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-64624a30-2fdd-4e0d-b0ed-2491673e6827,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-eaad5b1d-146d-4bd4-a6bc-ead4b40124a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-3a1507f9-2f90-4135-8d42-e33a8aa985d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-b07ac8ec-4bcb-4552-b2f0-48534f3b1bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-649e2248-65c8-4d4b-9ee8-717223c50eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-5f3263d6-4c49-4953-8fc7-a41d110bbe02,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-f4edf177-c681-4108-a592-c6b1bee9fb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450252036-172.17.0.6-1596984065466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-389f0e79-3903-4b44-9df8-d774b01d2283,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-640c7a84-ab9f-40be-8377-5f39d88245ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-d2cba315-3d92-457f-89f7-18d073383291,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-36f7d46d-cf3c-4165-80bc-25bff9e3b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-cf97c0be-6a74-44f9-9f8d-d3d002a35ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-28bfe6c3-fb5b-458b-b1c7-65d3c3289b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-810a5221-dd73-4868-9306-39a98ddf055a,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-7f4ac2f6-cfb0-40ac-b303-64d7eadc80e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450252036-172.17.0.6-1596984065466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-389f0e79-3903-4b44-9df8-d774b01d2283,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-640c7a84-ab9f-40be-8377-5f39d88245ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-d2cba315-3d92-457f-89f7-18d073383291,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-36f7d46d-cf3c-4165-80bc-25bff9e3b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-cf97c0be-6a74-44f9-9f8d-d3d002a35ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-28bfe6c3-fb5b-458b-b1c7-65d3c3289b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-810a5221-dd73-4868-9306-39a98ddf055a,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-7f4ac2f6-cfb0-40ac-b303-64d7eadc80e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889215543-172.17.0.6-1596984281216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37550,DS-716872e8-4b34-44eb-9c09-c320d6af51eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-b78feef8-a18e-4033-af8e-3b9813e38d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-9a584a7f-c8a0-49a7-900f-203c12d4d718,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-45682518-df49-488d-8c42-de1aa3cb3ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-08039f77-e91a-449d-bfc7-65c330879217,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-cda9f1df-c8b6-4bde-b74e-ef6dbc83cc53,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-d41e9c59-4cbc-49f9-8ac6-076bc2acfb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-4e44193e-1019-4c6d-8279-6a42775d300c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889215543-172.17.0.6-1596984281216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37550,DS-716872e8-4b34-44eb-9c09-c320d6af51eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-b78feef8-a18e-4033-af8e-3b9813e38d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-9a584a7f-c8a0-49a7-900f-203c12d4d718,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-45682518-df49-488d-8c42-de1aa3cb3ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-08039f77-e91a-449d-bfc7-65c330879217,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-cda9f1df-c8b6-4bde-b74e-ef6dbc83cc53,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-d41e9c59-4cbc-49f9-8ac6-076bc2acfb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-4e44193e-1019-4c6d-8279-6a42775d300c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818182829-172.17.0.6-1596984584145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42224,DS-9f00e633-2cf5-4165-9774-91bbf96862fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-eb79478b-f566-4dca-8b0d-ed742fbeabb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-404a920f-a902-4cbe-a340-0c347f90b356,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-7e04756f-dbcc-41f9-8a79-497b4225d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-e028778a-729a-4e03-8afe-715291ccd9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-3a9a89ea-d53c-4e06-8914-27e0d1859ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-418a28a6-f785-4e31-99c7-4d6562549777,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-bc38f52c-5979-48d2-9421-276e904a178f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818182829-172.17.0.6-1596984584145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42224,DS-9f00e633-2cf5-4165-9774-91bbf96862fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-eb79478b-f566-4dca-8b0d-ed742fbeabb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-404a920f-a902-4cbe-a340-0c347f90b356,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-7e04756f-dbcc-41f9-8a79-497b4225d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-e028778a-729a-4e03-8afe-715291ccd9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-3a9a89ea-d53c-4e06-8914-27e0d1859ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-418a28a6-f785-4e31-99c7-4d6562549777,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-bc38f52c-5979-48d2-9421-276e904a178f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019505893-172.17.0.6-1596984733340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34089,DS-34297a09-fd64-4889-8950-0501cbc9a961,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-b140c544-4d26-4e0e-b8db-4d15ec10d492,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-25b92536-01be-46a0-9337-cf527747886b,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-f3d30e46-b0ce-4310-a57b-f3f4427d6dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-bbe919a7-b80c-46c1-8b3a-b0d1934756cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-6158b52e-5c5c-4fc1-a9e2-a30faf803eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-451c1398-99f4-4c3a-bfac-5340ba737885,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-98ed6eaf-b52d-407d-bfe6-9691d1dad00a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019505893-172.17.0.6-1596984733340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34089,DS-34297a09-fd64-4889-8950-0501cbc9a961,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-b140c544-4d26-4e0e-b8db-4d15ec10d492,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-25b92536-01be-46a0-9337-cf527747886b,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-f3d30e46-b0ce-4310-a57b-f3f4427d6dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-bbe919a7-b80c-46c1-8b3a-b0d1934756cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-6158b52e-5c5c-4fc1-a9e2-a30faf803eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-451c1398-99f4-4c3a-bfac-5340ba737885,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-98ed6eaf-b52d-407d-bfe6-9691d1dad00a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20535907-172.17.0.6-1596984895219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39385,DS-a934d7d6-d73d-410c-8497-190922f373a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-68b0477c-5033-40b8-9942-2adb5885a969,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-11514f8f-890a-4ee2-8df7-cef28c43f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-ca458863-267b-4234-a303-96d71ca6adc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-29e35773-ddc2-4a3e-a78e-97cfeaf0b631,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-0287f0df-8010-43df-81c2-12ef40ebde2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-68357bf3-7338-47c2-af15-954df63f2884,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-8dae82dc-9e75-4590-8290-b9145e7767f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20535907-172.17.0.6-1596984895219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39385,DS-a934d7d6-d73d-410c-8497-190922f373a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-68b0477c-5033-40b8-9942-2adb5885a969,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-11514f8f-890a-4ee2-8df7-cef28c43f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-ca458863-267b-4234-a303-96d71ca6adc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-29e35773-ddc2-4a3e-a78e-97cfeaf0b631,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-0287f0df-8010-43df-81c2-12ef40ebde2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-68357bf3-7338-47c2-af15-954df63f2884,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-8dae82dc-9e75-4590-8290-b9145e7767f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244556103-172.17.0.6-1596985224926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-9062210b-e02b-4e12-a1e8-fd8cb777b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-52139272-b230-4959-ad83-8c30c70e4de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-51272d85-a527-4498-85fd-3e99bda8a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-acd6a3f2-4f47-4853-8a28-e3600a03e026,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-1239f308-7723-4648-9a79-4ffa1fd2d3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-1bf1201b-7a67-4519-afec-64def4305329,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-60597ec3-6289-4f92-9c97-7cd13144583f,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-e440b529-367e-4d7d-9a1d-73e3f55bf251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244556103-172.17.0.6-1596985224926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43494,DS-9062210b-e02b-4e12-a1e8-fd8cb777b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-52139272-b230-4959-ad83-8c30c70e4de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-51272d85-a527-4498-85fd-3e99bda8a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-acd6a3f2-4f47-4853-8a28-e3600a03e026,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-1239f308-7723-4648-9a79-4ffa1fd2d3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-1bf1201b-7a67-4519-afec-64def4305329,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-60597ec3-6289-4f92-9c97-7cd13144583f,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-e440b529-367e-4d7d-9a1d-73e3f55bf251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665158208-172.17.0.6-1596985465571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-dfa8adbd-8835-4d38-83f5-1344da6582f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-6926957e-5f1c-44d0-83f1-19816b7c9f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-a8d0b205-9681-43e6-8379-d8055f57df44,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-0ab46916-2fc4-4a09-9213-f1d64e258587,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-96b8ae81-f822-4764-b1d3-a9e6f5d720b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-4d898f71-5130-4a17-b223-7fec900ac3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-f0a2cab9-09ca-4f74-885c-035e8371fdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-eaec44fc-0e59-425d-91a7-c6832a25bca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665158208-172.17.0.6-1596985465571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-dfa8adbd-8835-4d38-83f5-1344da6582f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-6926957e-5f1c-44d0-83f1-19816b7c9f83,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-a8d0b205-9681-43e6-8379-d8055f57df44,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-0ab46916-2fc4-4a09-9213-f1d64e258587,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-96b8ae81-f822-4764-b1d3-a9e6f5d720b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-4d898f71-5130-4a17-b223-7fec900ac3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-f0a2cab9-09ca-4f74-885c-035e8371fdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-eaec44fc-0e59-425d-91a7-c6832a25bca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416718588-172.17.0.6-1596986544485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39932,DS-eb6ee57a-79e2-402f-a650-0b30d934f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-0c5d2f67-f49c-4748-b0d3-66496d50f522,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-8490d258-1f65-421b-b94a-e5e81ca9ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-facecad0-8bab-4a24-a9c9-7859763e5a25,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-a7f8f33b-34cf-4256-a1a1-81ed19bdbd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-7cca8ff7-7399-4861-981c-2a3be213e241,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-161d9ab5-49f7-4c34-8f84-475d8d7e15d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-af3a92c9-6218-4ca0-9896-4a8f231a59d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416718588-172.17.0.6-1596986544485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39932,DS-eb6ee57a-79e2-402f-a650-0b30d934f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-0c5d2f67-f49c-4748-b0d3-66496d50f522,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-8490d258-1f65-421b-b94a-e5e81ca9ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-facecad0-8bab-4a24-a9c9-7859763e5a25,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-a7f8f33b-34cf-4256-a1a1-81ed19bdbd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-7cca8ff7-7399-4861-981c-2a3be213e241,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-161d9ab5-49f7-4c34-8f84-475d8d7e15d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-af3a92c9-6218-4ca0-9896-4a8f231a59d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964386581-172.17.0.6-1596986783065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-595a938c-53c3-484d-a412-acda878757ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-dff69cd0-11a4-4d73-b01a-80690cf42163,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-502aff98-ccd0-454b-b90a-05b51a3aed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-f6b95708-3a32-476e-aba6-d87bb0de080c,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-c41cc9f1-7367-4848-a066-e20b2828175a,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-abd5e9a8-666c-4053-972e-c25469ca8d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-b5e9d85a-a670-4f89-ad17-0a2332fd5761,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-5ffee259-a685-4de9-b6a5-97b11a300593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964386581-172.17.0.6-1596986783065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-595a938c-53c3-484d-a412-acda878757ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-dff69cd0-11a4-4d73-b01a-80690cf42163,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-502aff98-ccd0-454b-b90a-05b51a3aed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-f6b95708-3a32-476e-aba6-d87bb0de080c,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-c41cc9f1-7367-4848-a066-e20b2828175a,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-abd5e9a8-666c-4053-972e-c25469ca8d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-b5e9d85a-a670-4f89-ad17-0a2332fd5761,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-5ffee259-a685-4de9-b6a5-97b11a300593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966360894-172.17.0.6-1596986928040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-2b369dd2-6f41-4b49-9020-9cb659a73d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-2e64a02d-0417-406a-88eb-1f0d57efc1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-71661691-839a-434c-872c-c1de890b4f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-38ef2154-4034-4a6e-ac4d-825a5493f209,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-197075e9-8ff4-4b4a-a4d8-ae94f65db1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-50972aab-80c0-41db-a981-7ede5150670f,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-de7a0b75-ca2c-4129-b022-3cf3de0069f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-aeba7d55-6b88-4075-9382-bc96d1c0b074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966360894-172.17.0.6-1596986928040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-2b369dd2-6f41-4b49-9020-9cb659a73d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-2e64a02d-0417-406a-88eb-1f0d57efc1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-71661691-839a-434c-872c-c1de890b4f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-38ef2154-4034-4a6e-ac4d-825a5493f209,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-197075e9-8ff4-4b4a-a4d8-ae94f65db1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-50972aab-80c0-41db-a981-7ede5150670f,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-de7a0b75-ca2c-4129-b022-3cf3de0069f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-aeba7d55-6b88-4075-9382-bc96d1c0b074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036622835-172.17.0.6-1596987313679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34101,DS-09a63033-910c-44e9-8d38-3feba77c154b,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-b4e0d124-4459-480d-a6b7-234939efea67,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-c49843ee-eefd-4a53-9d8c-bae924162fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-97c25aaf-833a-450d-92bf-e866a07e6329,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-262ac84f-d6e3-4678-a9da-96da783f6f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-91c83a31-a1cb-444f-8988-038c210a65fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-948251bb-af0b-4d58-8d4b-b1a4e801bf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-3531fb2e-da60-45b4-822b-ec2c2a4c2be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036622835-172.17.0.6-1596987313679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34101,DS-09a63033-910c-44e9-8d38-3feba77c154b,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-b4e0d124-4459-480d-a6b7-234939efea67,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-c49843ee-eefd-4a53-9d8c-bae924162fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-97c25aaf-833a-450d-92bf-e866a07e6329,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-262ac84f-d6e3-4678-a9da-96da783f6f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-91c83a31-a1cb-444f-8988-038c210a65fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-948251bb-af0b-4d58-8d4b-b1a4e801bf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-3531fb2e-da60-45b4-822b-ec2c2a4c2be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340043791-172.17.0.6-1596987523043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-86543497-d350-4bae-b7e0-24c382121957,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-f16ca12c-4753-4870-88dd-d79ff147d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-442c730c-82a4-4970-8220-9637f94dd2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-03083eba-c16c-4d6d-aede-6420986cc603,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-9dadd966-f1f1-4f08-925a-e0742c797847,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-823e9c07-26b9-460a-9a98-90ea91e18770,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-5ac3821d-315c-40c4-a8bb-f8b676aa9cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-dc58d65a-2c10-4531-99d1-d9ce68b456f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340043791-172.17.0.6-1596987523043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37876,DS-86543497-d350-4bae-b7e0-24c382121957,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-f16ca12c-4753-4870-88dd-d79ff147d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-442c730c-82a4-4970-8220-9637f94dd2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-03083eba-c16c-4d6d-aede-6420986cc603,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-9dadd966-f1f1-4f08-925a-e0742c797847,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-823e9c07-26b9-460a-9a98-90ea91e18770,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-5ac3821d-315c-40c4-a8bb-f8b676aa9cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-dc58d65a-2c10-4531-99d1-d9ce68b456f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26191261-172.17.0.6-1596987858739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-40576c91-2ef6-44b3-8b55-368fa4c26edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-dc929acc-2282-4246-ac23-149c88a23ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-59762913-1624-4f41-a40e-a9ebbf1101a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-261e2911-ce47-46dc-8990-8ae9d9daf07b,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-fed1f51e-fc01-4f16-bf61-76355b905820,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-5c3eda95-7cd9-43c8-bc99-39bc336e3d49,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-187f26af-2ecf-4557-b373-d3a67d05595d,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-f47f9279-7720-4b60-8b5d-58d06c4fd28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26191261-172.17.0.6-1596987858739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-40576c91-2ef6-44b3-8b55-368fa4c26edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-dc929acc-2282-4246-ac23-149c88a23ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-59762913-1624-4f41-a40e-a9ebbf1101a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-261e2911-ce47-46dc-8990-8ae9d9daf07b,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-fed1f51e-fc01-4f16-bf61-76355b905820,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-5c3eda95-7cd9-43c8-bc99-39bc336e3d49,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-187f26af-2ecf-4557-b373-d3a67d05595d,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-f47f9279-7720-4b60-8b5d-58d06c4fd28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238463916-172.17.0.6-1596988079679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40827,DS-201c6cb7-bdb2-4e43-beda-4b4a751e933e,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-48d89c5d-9604-4d7f-b0fe-9704d0d60146,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-a8c49935-371b-492a-8e00-c3fdbf557b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-daae73dc-cc5c-4d62-90dc-ee0a232c74db,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-9b2d33c3-4ad4-4073-a8bd-8d8d25f21838,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-b1ec7dc9-ad12-4b08-991b-f4aafc9626a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-8775cdc9-5110-4772-89ab-a75876d15523,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-74b14051-fc53-4d10-b5ad-389c0f887630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238463916-172.17.0.6-1596988079679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40827,DS-201c6cb7-bdb2-4e43-beda-4b4a751e933e,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-48d89c5d-9604-4d7f-b0fe-9704d0d60146,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-a8c49935-371b-492a-8e00-c3fdbf557b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-daae73dc-cc5c-4d62-90dc-ee0a232c74db,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-9b2d33c3-4ad4-4073-a8bd-8d8d25f21838,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-b1ec7dc9-ad12-4b08-991b-f4aafc9626a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-8775cdc9-5110-4772-89ab-a75876d15523,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-74b14051-fc53-4d10-b5ad-389c0f887630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144832967-172.17.0.6-1596988136246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-d832b5ec-c72c-4152-8254-4e8cfae55c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-e8af61af-9ba3-4cb5-8417-a812e228c3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-21ebae2d-9690-468c-bb96-72998efb472e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-765a88dc-ddfa-4cb9-913d-d4b4f0d52683,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-24a45c66-1a40-4171-b22e-524111e557f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-b7f4fc19-3444-4348-9f4b-76708dd40727,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-e02d3590-2d07-4d41-a63c-228ce936fa30,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-65e7dab6-5bfa-488f-b726-fea923168600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144832967-172.17.0.6-1596988136246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-d832b5ec-c72c-4152-8254-4e8cfae55c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-e8af61af-9ba3-4cb5-8417-a812e228c3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-21ebae2d-9690-468c-bb96-72998efb472e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-765a88dc-ddfa-4cb9-913d-d4b4f0d52683,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-24a45c66-1a40-4171-b22e-524111e557f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-b7f4fc19-3444-4348-9f4b-76708dd40727,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-e02d3590-2d07-4d41-a63c-228ce936fa30,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-65e7dab6-5bfa-488f-b726-fea923168600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104684075-172.17.0.6-1596988213164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34953,DS-8f776a8b-8fba-454d-bda8-fcd0e70fa307,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-f76e1a47-6bc2-4def-819c-ebe83eeb4135,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-4968e2b4-837d-4f4f-9942-c03561cdb54f,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-38d25270-e1aa-4447-bd1a-bb5549980f04,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-7d5aefd2-d2ec-4b6a-9fdf-778f78c55acd,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-7eb61c40-9d21-492a-b23c-556fea056452,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-3e01e257-a798-46ec-8032-24df3acbfdca,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-78d81622-adde-4a54-a015-beaf64262f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104684075-172.17.0.6-1596988213164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34953,DS-8f776a8b-8fba-454d-bda8-fcd0e70fa307,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-f76e1a47-6bc2-4def-819c-ebe83eeb4135,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-4968e2b4-837d-4f4f-9942-c03561cdb54f,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-38d25270-e1aa-4447-bd1a-bb5549980f04,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-7d5aefd2-d2ec-4b6a-9fdf-778f78c55acd,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-7eb61c40-9d21-492a-b23c-556fea056452,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-3e01e257-a798-46ec-8032-24df3acbfdca,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-78d81622-adde-4a54-a015-beaf64262f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4991
