reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61046991-172.17.0.12-1596965482722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43061,DS-5eaa01db-1e3c-4b1c-a523-6c2f1ec80008,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-9bc96b17-a6b8-449b-9a87-aedc48be5e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-1a31bb9f-71a6-45b8-9302-33e819532ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-09088cd8-d5b8-492b-b553-a11e68273f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-37b4afad-48f9-4cbf-914c-46450526b995,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-ab191f04-713d-4324-acf8-e8936e86e7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-794b675b-19b0-4b73-af02-e0150749ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-794b678a-c5c0-431d-8f62-a3b1fafe32af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61046991-172.17.0.12-1596965482722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43061,DS-5eaa01db-1e3c-4b1c-a523-6c2f1ec80008,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-9bc96b17-a6b8-449b-9a87-aedc48be5e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-1a31bb9f-71a6-45b8-9302-33e819532ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-09088cd8-d5b8-492b-b553-a11e68273f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-37b4afad-48f9-4cbf-914c-46450526b995,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-ab191f04-713d-4324-acf8-e8936e86e7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-794b675b-19b0-4b73-af02-e0150749ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-794b678a-c5c0-431d-8f62-a3b1fafe32af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202946698-172.17.0.12-1596966001392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-44ec9429-34b3-474c-9b45-1e0a33b204f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-a599154a-4ff9-48cc-b29c-929af65a7d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-8d1ea167-f86e-43a8-8647-df51e41667a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-36026569-ef26-4e58-a703-5c1acecbc69e,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-9a2ec534-8dc8-46cc-ac3e-5a3e00f3d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-d2816fdd-7f68-4fa0-9938-252fe5db3019,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-68bb8dad-a26c-4f11-93a3-f4994f428162,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-bcb9fa36-134e-42e3-8eba-32d0c55a5dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202946698-172.17.0.12-1596966001392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-44ec9429-34b3-474c-9b45-1e0a33b204f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-a599154a-4ff9-48cc-b29c-929af65a7d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-8d1ea167-f86e-43a8-8647-df51e41667a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-36026569-ef26-4e58-a703-5c1acecbc69e,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-9a2ec534-8dc8-46cc-ac3e-5a3e00f3d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-d2816fdd-7f68-4fa0-9938-252fe5db3019,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-68bb8dad-a26c-4f11-93a3-f4994f428162,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-bcb9fa36-134e-42e3-8eba-32d0c55a5dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618312665-172.17.0.12-1596966180179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35411,DS-6c30215e-b84a-4ba2-9bba-b7bd3ace05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-d93adf23-8be9-4dfc-a26e-2f58eb68ae07,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-7457d4b4-1f98-47d2-93a7-46b05daa1f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-42475bc9-c913-495d-844a-f5a4b72018bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-2c6a2225-75d3-47e7-a6f1-80c64829ecdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-46ac478e-3036-4f77-9151-63c76c0f3f23,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-85da4272-8935-4558-bb72-41e5b2ad5607,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-e5a95341-5506-43b1-973a-72c2d84f6580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618312665-172.17.0.12-1596966180179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35411,DS-6c30215e-b84a-4ba2-9bba-b7bd3ace05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-d93adf23-8be9-4dfc-a26e-2f58eb68ae07,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-7457d4b4-1f98-47d2-93a7-46b05daa1f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-42475bc9-c913-495d-844a-f5a4b72018bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-2c6a2225-75d3-47e7-a6f1-80c64829ecdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-46ac478e-3036-4f77-9151-63c76c0f3f23,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-85da4272-8935-4558-bb72-41e5b2ad5607,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-e5a95341-5506-43b1-973a-72c2d84f6580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009290433-172.17.0.12-1596966389463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44009,DS-a99843a9-10f4-4124-babd-bd04732d0053,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-ea5a6d76-d95c-46b1-a3a9-7722838d7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-51a0a75d-d135-490c-989e-1089f61444b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-aea3a9ed-cde6-4f82-a933-2f58e94b6d21,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-8e631cdf-a0bb-4d16-8d70-97629dd733aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-79a5feb9-3003-4dd6-84c9-d2043f5055e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-31f1769e-d4a2-4ecb-9cc9-7411650113d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-1c6da47d-0fdd-49cb-9ca9-786969dd7fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009290433-172.17.0.12-1596966389463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44009,DS-a99843a9-10f4-4124-babd-bd04732d0053,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-ea5a6d76-d95c-46b1-a3a9-7722838d7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-51a0a75d-d135-490c-989e-1089f61444b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-aea3a9ed-cde6-4f82-a933-2f58e94b6d21,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-8e631cdf-a0bb-4d16-8d70-97629dd733aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-79a5feb9-3003-4dd6-84c9-d2043f5055e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-31f1769e-d4a2-4ecb-9cc9-7411650113d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-1c6da47d-0fdd-49cb-9ca9-786969dd7fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143410453-172.17.0.12-1596967141146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-438cf873-85b3-42a9-a4cf-430a70a88844,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-d3e3ed58-b61f-4a71-8dd7-266040e0fe8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-7edf0d68-6c5d-4f01-9102-9d3e0fbcbb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-8e642cc5-1398-4562-ae14-601111808fca,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-b8d70970-7996-410d-9a2b-eae945e167ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-08fbd277-10aa-408f-b8ae-0aea703b60d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-dfadf90c-16db-4578-8355-dc5f3aff7ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-52e2756b-e358-4e53-bf15-5fbec2b0b61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143410453-172.17.0.12-1596967141146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-438cf873-85b3-42a9-a4cf-430a70a88844,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-d3e3ed58-b61f-4a71-8dd7-266040e0fe8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-7edf0d68-6c5d-4f01-9102-9d3e0fbcbb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-8e642cc5-1398-4562-ae14-601111808fca,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-b8d70970-7996-410d-9a2b-eae945e167ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-08fbd277-10aa-408f-b8ae-0aea703b60d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-dfadf90c-16db-4578-8355-dc5f3aff7ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-52e2756b-e358-4e53-bf15-5fbec2b0b61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587779526-172.17.0.12-1596967182964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-c7bf2805-aa28-40ef-ad02-83ec83bd2ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-c582b7e3-858c-4bce-a924-b92bc0a3ae46,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-c88ea4c7-0c4a-4bc6-b87b-8428397ab577,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-17964ccf-aa91-40ad-9c0f-8fa805caab14,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-fd0d5a7e-7288-412a-8f6e-1d7ef69168f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-553f336f-9ebb-463e-beb2-55ef44a65117,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-d68bc469-0316-4c07-903d-69704545bd13,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-c205aa26-a65a-47c4-8f8c-7a8fca37c248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587779526-172.17.0.12-1596967182964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-c7bf2805-aa28-40ef-ad02-83ec83bd2ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-c582b7e3-858c-4bce-a924-b92bc0a3ae46,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-c88ea4c7-0c4a-4bc6-b87b-8428397ab577,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-17964ccf-aa91-40ad-9c0f-8fa805caab14,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-fd0d5a7e-7288-412a-8f6e-1d7ef69168f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-553f336f-9ebb-463e-beb2-55ef44a65117,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-d68bc469-0316-4c07-903d-69704545bd13,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-c205aa26-a65a-47c4-8f8c-7a8fca37c248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462529745-172.17.0.12-1596967275553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35730,DS-1f801b61-00e3-455f-b3af-e015c94a7159,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-0611ac3d-7018-4618-a6ae-a25c5ae766b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-95fe2b86-dd39-4a8f-adb9-2233bb58c769,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-dbed5ccc-c58b-4ee5-ac15-9047f7d13b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-98dfb9a1-c1e7-4d35-9b27-26c4536f82cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-49c7be71-a14f-4bd0-b311-dae2532d7bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-cdaf34ff-22d0-48c5-8a24-42adc91d031b,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-ad2d692d-0b5d-44a3-8db2-98f6b3bd1977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462529745-172.17.0.12-1596967275553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35730,DS-1f801b61-00e3-455f-b3af-e015c94a7159,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-0611ac3d-7018-4618-a6ae-a25c5ae766b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-95fe2b86-dd39-4a8f-adb9-2233bb58c769,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-dbed5ccc-c58b-4ee5-ac15-9047f7d13b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-98dfb9a1-c1e7-4d35-9b27-26c4536f82cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-49c7be71-a14f-4bd0-b311-dae2532d7bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-cdaf34ff-22d0-48c5-8a24-42adc91d031b,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-ad2d692d-0b5d-44a3-8db2-98f6b3bd1977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169140766-172.17.0.12-1596967362810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46597,DS-bc0fd047-c94a-4eb5-9b22-3093bf112b64,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-cbb9f8f7-0b49-4cb9-a426-c00eda1b8194,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-e934d5e3-64dc-4f50-aa6e-ae39b9786ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-9bd8e25e-9877-4ff8-b25b-02e7c0b2d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-dd9b8bbd-ab90-4d1c-ada3-e2f6d99b3484,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-dbef6909-72a8-431c-aa25-56826004486b,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-1dd8c22e-0e63-48e0-9763-72e4d89fec17,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-64b816f2-566a-418a-b023-c24f95e3fb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169140766-172.17.0.12-1596967362810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46597,DS-bc0fd047-c94a-4eb5-9b22-3093bf112b64,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-cbb9f8f7-0b49-4cb9-a426-c00eda1b8194,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-e934d5e3-64dc-4f50-aa6e-ae39b9786ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-9bd8e25e-9877-4ff8-b25b-02e7c0b2d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-dd9b8bbd-ab90-4d1c-ada3-e2f6d99b3484,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-dbef6909-72a8-431c-aa25-56826004486b,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-1dd8c22e-0e63-48e0-9763-72e4d89fec17,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-64b816f2-566a-418a-b023-c24f95e3fb76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800714622-172.17.0.12-1596967537267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44661,DS-3ece87c5-d8da-4388-b096-3da78b16919e,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-6f53c5a1-3251-4df9-b9a9-f7210839b096,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-16367694-4ff9-4357-9cce-b148777b8600,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-b8a3db21-a68a-428d-adb3-a8f04eb8ab4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-f92835b0-32c0-4c06-a77b-6d3189c55366,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-a43237b1-df6a-4726-8fa7-0779e624ff73,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-f62e5862-f892-44bd-a8c7-ec2ede7f024f,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-332aed71-424c-48ea-a81f-a41cad4c79d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800714622-172.17.0.12-1596967537267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44661,DS-3ece87c5-d8da-4388-b096-3da78b16919e,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-6f53c5a1-3251-4df9-b9a9-f7210839b096,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-16367694-4ff9-4357-9cce-b148777b8600,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-b8a3db21-a68a-428d-adb3-a8f04eb8ab4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-f92835b0-32c0-4c06-a77b-6d3189c55366,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-a43237b1-df6a-4726-8fa7-0779e624ff73,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-f62e5862-f892-44bd-a8c7-ec2ede7f024f,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-332aed71-424c-48ea-a81f-a41cad4c79d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230869163-172.17.0.12-1596968102814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-954d3b55-eee1-494d-90db-17b6180ddac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-0759d953-147c-4b5a-bb84-8b1175e0229f,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-bb6a459f-529e-49f1-a27f-6080994b5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-a2715996-f466-4742-a87f-935eddd45ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-bd442440-46d8-4925-9cef-9d4472eb9a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-0762f462-49a0-49ba-8360-ec1f03996573,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-a6c85eb4-5bfb-4cbc-beb2-8ad810f15e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-6320aebe-6c1e-48ac-b9d2-4603bd08fba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230869163-172.17.0.12-1596968102814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-954d3b55-eee1-494d-90db-17b6180ddac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-0759d953-147c-4b5a-bb84-8b1175e0229f,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-bb6a459f-529e-49f1-a27f-6080994b5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-a2715996-f466-4742-a87f-935eddd45ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-bd442440-46d8-4925-9cef-9d4472eb9a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-0762f462-49a0-49ba-8360-ec1f03996573,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-a6c85eb4-5bfb-4cbc-beb2-8ad810f15e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-6320aebe-6c1e-48ac-b9d2-4603bd08fba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026729588-172.17.0.12-1596968410193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-25a27971-b243-4707-99e6-064ebddc2ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-c6b72969-77f6-4724-90de-04d9bf7348f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-a5c2059d-78a5-4b1f-a13a-c9674b88912c,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-e76954d0-3b3e-4feb-b7bd-b46dfe9ac0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-feee854b-4893-4235-a280-3a8098160ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-13923b57-b62e-4ac9-8b1c-e890fbe4678c,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-2b8148f0-fd65-442f-904d-56a629b3a0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-a0fa39d8-4f03-499b-be45-c971341c8aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026729588-172.17.0.12-1596968410193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-25a27971-b243-4707-99e6-064ebddc2ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-c6b72969-77f6-4724-90de-04d9bf7348f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-a5c2059d-78a5-4b1f-a13a-c9674b88912c,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-e76954d0-3b3e-4feb-b7bd-b46dfe9ac0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-feee854b-4893-4235-a280-3a8098160ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-13923b57-b62e-4ac9-8b1c-e890fbe4678c,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-2b8148f0-fd65-442f-904d-56a629b3a0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-a0fa39d8-4f03-499b-be45-c971341c8aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508218788-172.17.0.12-1596968923771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36379,DS-68070061-cc86-48ec-ac5a-5bf457232f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-300fe97c-e418-4477-82cc-11d5c9c5d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-26014084-8042-4477-870f-775522d15bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-1f217246-2f43-47ef-81f9-1e92f1769f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-41891c46-4288-4a82-b21b-bb43f851aac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-e58b4eb0-d9bd-4809-ad99-f5c32c72ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-e0626593-fe63-4882-ab96-4000a776f3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-ceb9fe6a-9c0e-4020-8821-f082bc5e05e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508218788-172.17.0.12-1596968923771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36379,DS-68070061-cc86-48ec-ac5a-5bf457232f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-300fe97c-e418-4477-82cc-11d5c9c5d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-26014084-8042-4477-870f-775522d15bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-1f217246-2f43-47ef-81f9-1e92f1769f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-41891c46-4288-4a82-b21b-bb43f851aac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-e58b4eb0-d9bd-4809-ad99-f5c32c72ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-e0626593-fe63-4882-ab96-4000a776f3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-ceb9fe6a-9c0e-4020-8821-f082bc5e05e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489343027-172.17.0.12-1596969356977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45378,DS-fe731040-9317-472c-81ff-216173b69093,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-2baac94e-fa40-4d06-a3a0-133f8f0836ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-e57609ed-924d-46c4-9307-eb4ed4a46d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-2d41b26f-63f1-4efb-9d81-353024dadad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-53c1d49d-4a35-49fa-8440-f3bb39c92c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-eb2666f9-75de-4631-89df-349ac8727a50,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-351a1d96-96f0-4199-a32d-93d96369de3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-e5a78313-9236-4ff5-b583-bae0f2c9e9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489343027-172.17.0.12-1596969356977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45378,DS-fe731040-9317-472c-81ff-216173b69093,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-2baac94e-fa40-4d06-a3a0-133f8f0836ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-e57609ed-924d-46c4-9307-eb4ed4a46d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-2d41b26f-63f1-4efb-9d81-353024dadad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-53c1d49d-4a35-49fa-8440-f3bb39c92c97,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-eb2666f9-75de-4631-89df-349ac8727a50,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-351a1d96-96f0-4199-a32d-93d96369de3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-e5a78313-9236-4ff5-b583-bae0f2c9e9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932184978-172.17.0.12-1596969483661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46417,DS-a610069b-e090-4df3-b326-2aee12d61b35,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-cc4450ad-b929-4f4e-9a47-fecef69ef1db,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-98f21908-7aad-4863-93ab-c0497ea46801,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-cad3426e-290e-4cb5-8149-9377b88194aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-782d75ac-52bf-4e88-8d2c-a02ac4af8d20,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-c4b0199a-b4af-49d9-8ca2-9deb40941c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-b09e59cf-ac93-408c-9f06-e8225d8ee449,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-310f7bde-8d40-44b0-9026-08ed4c40edfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932184978-172.17.0.12-1596969483661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46417,DS-a610069b-e090-4df3-b326-2aee12d61b35,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-cc4450ad-b929-4f4e-9a47-fecef69ef1db,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-98f21908-7aad-4863-93ab-c0497ea46801,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-cad3426e-290e-4cb5-8149-9377b88194aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-782d75ac-52bf-4e88-8d2c-a02ac4af8d20,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-c4b0199a-b4af-49d9-8ca2-9deb40941c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-b09e59cf-ac93-408c-9f06-e8225d8ee449,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-310f7bde-8d40-44b0-9026-08ed4c40edfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791692839-172.17.0.12-1596969961911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-d8bad775-4961-4744-bbcd-58867994ad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-c95d4c3b-702e-41c8-8b2e-812f9d8b8520,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-66b3651a-ca28-4411-b1aa-4d245fceef11,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-23aa6811-8e21-4104-9906-3ec74d3ab483,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-4f8a366c-020b-49df-add0-c127273b7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-11ea007c-6e47-45f9-aa97-d1aa4d5e02b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-95736d9f-00c8-40e5-bf88-e2aeda842ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-5fcd4be9-2231-40b2-8125-447c897d9272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791692839-172.17.0.12-1596969961911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-d8bad775-4961-4744-bbcd-58867994ad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-c95d4c3b-702e-41c8-8b2e-812f9d8b8520,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-66b3651a-ca28-4411-b1aa-4d245fceef11,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-23aa6811-8e21-4104-9906-3ec74d3ab483,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-4f8a366c-020b-49df-add0-c127273b7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-11ea007c-6e47-45f9-aa97-d1aa4d5e02b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-95736d9f-00c8-40e5-bf88-e2aeda842ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-5fcd4be9-2231-40b2-8125-447c897d9272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957200999-172.17.0.12-1596970054683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-fa3ca284-c412-4cf4-8c5f-8d5a902c8ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-bb6ddbe6-8d07-4b75-a8a5-e47210a5e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-ec23f576-09a3-4048-a597-8cccda44df44,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-4ed0f1eb-1f49-410c-9930-5017c34cd1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-3b1e19a7-36e2-4dd7-9590-a10196b2155b,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-f0d46088-2d15-4605-a96c-1a7328726b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-501ac0d9-bb90-409c-aa30-47ab1c21e39e,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-2d12d7e9-f472-4750-a668-8e30b1c9b51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957200999-172.17.0.12-1596970054683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35756,DS-fa3ca284-c412-4cf4-8c5f-8d5a902c8ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-bb6ddbe6-8d07-4b75-a8a5-e47210a5e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-ec23f576-09a3-4048-a597-8cccda44df44,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-4ed0f1eb-1f49-410c-9930-5017c34cd1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-3b1e19a7-36e2-4dd7-9590-a10196b2155b,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-f0d46088-2d15-4605-a96c-1a7328726b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-501ac0d9-bb90-409c-aa30-47ab1c21e39e,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-2d12d7e9-f472-4750-a668-8e30b1c9b51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129323803-172.17.0.12-1596970439791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44875,DS-ce3e5951-d6f7-48ca-9598-3f3fee01184a,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-9621923b-6e59-4cd6-9e5a-bac3f7b50bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-061c28a0-7fe1-440c-9336-cefcccde5185,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-f7a34a0e-43d3-4948-bc60-b8e5ada9b619,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-565eecfa-dfaa-4fe4-811d-3976d704a9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-046216f1-cdf6-47fd-9216-a3226cf178ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-b6a1f3be-d2e0-4f1f-9685-b2ee1fff759b,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-1f1a4a75-2bbe-411a-80a4-cf1a13042992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129323803-172.17.0.12-1596970439791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44875,DS-ce3e5951-d6f7-48ca-9598-3f3fee01184a,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-9621923b-6e59-4cd6-9e5a-bac3f7b50bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-061c28a0-7fe1-440c-9336-cefcccde5185,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-f7a34a0e-43d3-4948-bc60-b8e5ada9b619,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-565eecfa-dfaa-4fe4-811d-3976d704a9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-046216f1-cdf6-47fd-9216-a3226cf178ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-b6a1f3be-d2e0-4f1f-9685-b2ee1fff759b,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-1f1a4a75-2bbe-411a-80a4-cf1a13042992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158233212-172.17.0.12-1596971652143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-6ad0570d-4fe2-4043-824a-64b57f30c0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-ded78ed0-5d1f-4acd-9b52-50a5b8a2b1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-32783e4c-18bd-4ac7-b577-2f7fa1da92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-33226d0f-fda2-4475-bf28-5307bdbcb0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-756e60ce-eb53-48b6-9913-7fd01a710f11,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-e2e22f56-bfc6-4ccf-b386-ba5156e3d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-406c6da1-0488-4fed-8a9b-129ae6daabe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-9707f18a-878d-4923-9d6d-f785239b77d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158233212-172.17.0.12-1596971652143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-6ad0570d-4fe2-4043-824a-64b57f30c0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-ded78ed0-5d1f-4acd-9b52-50a5b8a2b1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-32783e4c-18bd-4ac7-b577-2f7fa1da92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-33226d0f-fda2-4475-bf28-5307bdbcb0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-756e60ce-eb53-48b6-9913-7fd01a710f11,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-e2e22f56-bfc6-4ccf-b386-ba5156e3d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-406c6da1-0488-4fed-8a9b-129ae6daabe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-9707f18a-878d-4923-9d6d-f785239b77d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6510
