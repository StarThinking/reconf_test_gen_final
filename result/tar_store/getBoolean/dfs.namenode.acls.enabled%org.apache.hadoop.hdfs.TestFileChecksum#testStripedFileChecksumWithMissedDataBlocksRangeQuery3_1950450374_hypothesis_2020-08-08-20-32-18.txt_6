reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010433902-172.17.0.5-1596920007351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40165,DS-ffaf2026-913a-47bc-9894-22f8731fda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-5452119e-26d6-40d0-ba89-ffeb6c42d5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-05bef67b-42c3-4b7b-829c-00b1d3e80010,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-e597ee27-5943-4ce3-9508-a1fab41a81ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-823436fe-c5a2-4652-9c90-2457434f4560,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-3da919a7-ee54-4c4e-a555-afa02ec64ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-17afe029-356d-4201-bd5a-e6277114249d,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-f98997b7-2f07-409c-899e-6f9d7bf52b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010433902-172.17.0.5-1596920007351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40165,DS-ffaf2026-913a-47bc-9894-22f8731fda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-5452119e-26d6-40d0-ba89-ffeb6c42d5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-05bef67b-42c3-4b7b-829c-00b1d3e80010,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-e597ee27-5943-4ce3-9508-a1fab41a81ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-823436fe-c5a2-4652-9c90-2457434f4560,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-3da919a7-ee54-4c4e-a555-afa02ec64ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-17afe029-356d-4201-bd5a-e6277114249d,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-f98997b7-2f07-409c-899e-6f9d7bf52b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703948973-172.17.0.5-1596920600480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37851,DS-689b9bad-6c89-4bc2-83c8-41686d030d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-830612b4-4281-49be-863a-cfc63e44bd15,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-9e7b0f6f-bab6-4ffb-a0be-e80949b1b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-52e5afee-e4fd-48b8-9bdf-a7321784b8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-1bd895a9-0172-4ee7-a337-833b489ea27d,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-d6c361f8-f937-4f26-b0ff-b8c821e671bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-693af496-3463-4629-9c3f-747292cee14a,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-59e2e31a-eb07-4fb5-a39b-01d62b138a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703948973-172.17.0.5-1596920600480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37851,DS-689b9bad-6c89-4bc2-83c8-41686d030d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-830612b4-4281-49be-863a-cfc63e44bd15,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-9e7b0f6f-bab6-4ffb-a0be-e80949b1b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-52e5afee-e4fd-48b8-9bdf-a7321784b8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-1bd895a9-0172-4ee7-a337-833b489ea27d,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-d6c361f8-f937-4f26-b0ff-b8c821e671bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-693af496-3463-4629-9c3f-747292cee14a,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-59e2e31a-eb07-4fb5-a39b-01d62b138a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113790726-172.17.0.5-1596920840329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33340,DS-abd912f6-e033-4ead-8c29-c783f017e259,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-215bd20d-c3ae-4b76-8597-b916a5ed0c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-7c78a7ea-2be1-4059-9aa5-d01b83cab7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-22507b44-3c09-4c7d-9606-86cf6f05dc95,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-f41f30ec-90f6-4b40-bb11-cae1751bce67,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-1bc8b4cb-d3ee-4eff-97f9-e8d7ad99a31a,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-c0da7eae-0d03-4f0a-8515-dafea3ed82eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-acf1522c-a83f-46a7-95fb-61445ea7a79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113790726-172.17.0.5-1596920840329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33340,DS-abd912f6-e033-4ead-8c29-c783f017e259,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-215bd20d-c3ae-4b76-8597-b916a5ed0c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-7c78a7ea-2be1-4059-9aa5-d01b83cab7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-22507b44-3c09-4c7d-9606-86cf6f05dc95,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-f41f30ec-90f6-4b40-bb11-cae1751bce67,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-1bc8b4cb-d3ee-4eff-97f9-e8d7ad99a31a,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-c0da7eae-0d03-4f0a-8515-dafea3ed82eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-acf1522c-a83f-46a7-95fb-61445ea7a79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536095013-172.17.0.5-1596920876858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-1b38ae9b-1c0d-4517-a697-80a29a55efdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-959f30b0-49a5-4ebf-93bd-53603bc1d74d,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-9cf2130a-83c0-490f-ad0f-5fc75d7abcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-32371aa7-0454-4053-991f-3626a3a8197a,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-aa585a5b-da74-41be-b7b4-d5602aa14cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-66a5d996-6447-4142-ae72-af6432d8db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-624ea528-2a39-4bba-b239-faf3e4ef7a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-978de8dc-cd76-4198-beb3-949bb8e64f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536095013-172.17.0.5-1596920876858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-1b38ae9b-1c0d-4517-a697-80a29a55efdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-959f30b0-49a5-4ebf-93bd-53603bc1d74d,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-9cf2130a-83c0-490f-ad0f-5fc75d7abcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-32371aa7-0454-4053-991f-3626a3a8197a,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-aa585a5b-da74-41be-b7b4-d5602aa14cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-66a5d996-6447-4142-ae72-af6432d8db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-624ea528-2a39-4bba-b239-faf3e4ef7a88,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-978de8dc-cd76-4198-beb3-949bb8e64f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981903450-172.17.0.5-1596921060370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-78ab42dd-5a46-4ccb-8c41-145a2b3861af,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-5d422996-d9e1-47db-b5fa-55d319aa4e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-82a65065-9f5f-42b7-b184-db191d08eb21,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-75689d34-5aee-4b81-a878-2f51d426c982,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-5eab34f2-4e1b-4316-b8bf-996b2aa9487c,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-967f48a5-cc01-4c00-927b-96606a04c920,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-72996e03-d2cc-4ecb-a94a-294b10bd3750,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-c44e7676-ea2b-4280-9ca8-2362c1dfaea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981903450-172.17.0.5-1596921060370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39725,DS-78ab42dd-5a46-4ccb-8c41-145a2b3861af,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-5d422996-d9e1-47db-b5fa-55d319aa4e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-82a65065-9f5f-42b7-b184-db191d08eb21,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-75689d34-5aee-4b81-a878-2f51d426c982,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-5eab34f2-4e1b-4316-b8bf-996b2aa9487c,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-967f48a5-cc01-4c00-927b-96606a04c920,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-72996e03-d2cc-4ecb-a94a-294b10bd3750,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-c44e7676-ea2b-4280-9ca8-2362c1dfaea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334438490-172.17.0.5-1596921600965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34088,DS-23446160-f916-472b-994a-f9dc6e4923ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-1a225f44-ca0e-4a2d-a23c-02be161a0185,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-93eaa287-3325-4128-8acf-6c09ec90273f,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-0b29c691-71ae-4207-bf97-70f37d06d1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-4eae5814-372c-4232-86de-1d08b8330ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-d96739bc-033c-4d6d-b1aa-429c0efb835f,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-fcb20d07-0e3f-456c-ad12-b501201c913b,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-2e4ef9a9-22cd-4434-8bcd-828621e905af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334438490-172.17.0.5-1596921600965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34088,DS-23446160-f916-472b-994a-f9dc6e4923ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-1a225f44-ca0e-4a2d-a23c-02be161a0185,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-93eaa287-3325-4128-8acf-6c09ec90273f,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-0b29c691-71ae-4207-bf97-70f37d06d1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-4eae5814-372c-4232-86de-1d08b8330ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-d96739bc-033c-4d6d-b1aa-429c0efb835f,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-fcb20d07-0e3f-456c-ad12-b501201c913b,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-2e4ef9a9-22cd-4434-8bcd-828621e905af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767339628-172.17.0.5-1596921688804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-46d87363-c9c3-476e-851e-be31c937f1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-50ae8250-41b7-4e7f-b9ff-df77c4767986,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-609aa55d-e80d-4fbd-be6d-fe884025a492,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-a8695fd5-9ce3-4d37-84ba-6ac45eba2a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-1f74e85a-6edb-473c-8dbd-325bc0c96256,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-d88abfb7-e23d-4052-ae05-30e61e01cd55,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-53dfbd19-25fd-47cf-bde9-6d314169c5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-5fc2ccb3-9a58-4058-b2cc-7b5e9ef070c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767339628-172.17.0.5-1596921688804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-46d87363-c9c3-476e-851e-be31c937f1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-50ae8250-41b7-4e7f-b9ff-df77c4767986,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-609aa55d-e80d-4fbd-be6d-fe884025a492,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-a8695fd5-9ce3-4d37-84ba-6ac45eba2a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-1f74e85a-6edb-473c-8dbd-325bc0c96256,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-d88abfb7-e23d-4052-ae05-30e61e01cd55,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-53dfbd19-25fd-47cf-bde9-6d314169c5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-5fc2ccb3-9a58-4058-b2cc-7b5e9ef070c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84818081-172.17.0.5-1596922422122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-49e55df0-3bc6-4d6a-b6f4-df2578552adc,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-125f583c-ba9c-490d-af5a-06ea6f35d4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-514b3f42-287e-4d64-84ae-107e6ba6145e,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-e6169041-5745-4cf1-8a74-7abedd24f734,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-48711a9c-0891-428d-90a8-94b86facd5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-42f5d14a-7f2c-4ab6-b1e2-91669f7b4e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-33e0bf41-ee44-48dd-93a0-17ea59885442,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-1cd1fbd6-5360-460c-814c-32f2a9b9f8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84818081-172.17.0.5-1596922422122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-49e55df0-3bc6-4d6a-b6f4-df2578552adc,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-125f583c-ba9c-490d-af5a-06ea6f35d4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-514b3f42-287e-4d64-84ae-107e6ba6145e,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-e6169041-5745-4cf1-8a74-7abedd24f734,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-48711a9c-0891-428d-90a8-94b86facd5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-42f5d14a-7f2c-4ab6-b1e2-91669f7b4e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-33e0bf41-ee44-48dd-93a0-17ea59885442,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-1cd1fbd6-5360-460c-814c-32f2a9b9f8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909338801-172.17.0.5-1596922732647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-5f8c21b3-d8a0-4edf-a312-e62d8f73eff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-0a51a5e6-2c82-4c01-8484-b798e92c4710,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-f1a7a553-f5aa-4aef-a40e-25147fe1a950,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-70c06bf5-ca09-4eb0-afc6-36dafd6e9f62,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-268c7201-a44d-4335-8ddb-9b33c4a2c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-42864891-7a3d-460c-a1dc-e872663eb939,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-16de1fa0-5d33-4193-954b-05d941fd1800,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-b79077f0-72ba-46ea-b0f5-2babfdfe0fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909338801-172.17.0.5-1596922732647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-5f8c21b3-d8a0-4edf-a312-e62d8f73eff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-0a51a5e6-2c82-4c01-8484-b798e92c4710,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-f1a7a553-f5aa-4aef-a40e-25147fe1a950,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-70c06bf5-ca09-4eb0-afc6-36dafd6e9f62,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-268c7201-a44d-4335-8ddb-9b33c4a2c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-42864891-7a3d-460c-a1dc-e872663eb939,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-16de1fa0-5d33-4193-954b-05d941fd1800,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-b79077f0-72ba-46ea-b0f5-2babfdfe0fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361811731-172.17.0.5-1596922878432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-5a9dda54-c487-4cf3-b576-ec2ffad7048a,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-437b321a-b832-446a-9de4-bb15a6c430ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-e044bbeb-da0d-4f7b-b555-4ea0419aff22,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-7f82896b-a679-4dc2-80c9-1b02f51facea,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-557db136-0ef6-4d57-8440-7fb61885f42a,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-7db91e48-5964-4f68-baaf-58c84c3a2405,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-eacdb48b-a35f-45df-9988-cf0eb6d93e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-75b019ef-ee4b-486e-8350-a9e2c4f7d08c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361811731-172.17.0.5-1596922878432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-5a9dda54-c487-4cf3-b576-ec2ffad7048a,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-437b321a-b832-446a-9de4-bb15a6c430ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-e044bbeb-da0d-4f7b-b555-4ea0419aff22,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-7f82896b-a679-4dc2-80c9-1b02f51facea,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-557db136-0ef6-4d57-8440-7fb61885f42a,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-7db91e48-5964-4f68-baaf-58c84c3a2405,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-eacdb48b-a35f-45df-9988-cf0eb6d93e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-75b019ef-ee4b-486e-8350-a9e2c4f7d08c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486844522-172.17.0.5-1596923090552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-92871774-9961-4869-806f-5761c8ba78de,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-4331de3d-80d4-4fe7-bcde-a106f5358115,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-a480634a-3c5b-4938-bec2-5f7be4fca978,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-3a82ef91-a95e-446e-96ab-94a78fb956ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-ba9aa9ea-5b1c-4b66-be61-b3cfe3c267cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-60730e77-a474-4a28-a706-c1f3e7587d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-ed14127f-fe46-4a07-8ebb-f38e3e02162b,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-7d39746c-2607-448b-8ba4-2e6b772d59f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486844522-172.17.0.5-1596923090552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-92871774-9961-4869-806f-5761c8ba78de,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-4331de3d-80d4-4fe7-bcde-a106f5358115,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-a480634a-3c5b-4938-bec2-5f7be4fca978,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-3a82ef91-a95e-446e-96ab-94a78fb956ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-ba9aa9ea-5b1c-4b66-be61-b3cfe3c267cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-60730e77-a474-4a28-a706-c1f3e7587d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-ed14127f-fe46-4a07-8ebb-f38e3e02162b,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-7d39746c-2607-448b-8ba4-2e6b772d59f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332044677-172.17.0.5-1596923709614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-4e91ccdc-d660-46fa-a9e6-265592f9b3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-5a5fb162-4a5e-4829-bfeb-12629908a212,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-c485cfe2-030a-43a0-9fb2-f42cf9edd695,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-0bf71d3b-f718-44c3-ab99-3902d6b6c3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-388ea969-7b9c-461f-9382-bba3fe4e0a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-04324813-62a7-4658-b529-8a5a185f1792,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-216f2785-0f6d-4131-8e8f-e46332c8c56a,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-7b84d4b6-3990-4e75-9be0-1d17765dc6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332044677-172.17.0.5-1596923709614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-4e91ccdc-d660-46fa-a9e6-265592f9b3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-5a5fb162-4a5e-4829-bfeb-12629908a212,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-c485cfe2-030a-43a0-9fb2-f42cf9edd695,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-0bf71d3b-f718-44c3-ab99-3902d6b6c3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-388ea969-7b9c-461f-9382-bba3fe4e0a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-04324813-62a7-4658-b529-8a5a185f1792,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-216f2785-0f6d-4131-8e8f-e46332c8c56a,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-7b84d4b6-3990-4e75-9be0-1d17765dc6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803002719-172.17.0.5-1596924100891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38438,DS-3713d085-bb7f-4453-9fac-de970403f2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-6ef8a675-f85c-48e9-97cd-303c4e96bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c1e6c779-a7eb-4ab0-9839-77678fc30653,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-b4686ea5-c1c9-446c-973e-8944fe798ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-aa9c6584-7ed4-43d6-aec7-0f8c6ca1c7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-a0facf57-fe27-47e6-818b-e7574ae95474,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-e699d934-a9a0-47f1-afed-10dedbf05c43,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-c8551d7d-2c15-4f82-a469-e13e6845ef38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803002719-172.17.0.5-1596924100891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38438,DS-3713d085-bb7f-4453-9fac-de970403f2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-6ef8a675-f85c-48e9-97cd-303c4e96bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c1e6c779-a7eb-4ab0-9839-77678fc30653,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-b4686ea5-c1c9-446c-973e-8944fe798ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-aa9c6584-7ed4-43d6-aec7-0f8c6ca1c7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-a0facf57-fe27-47e6-818b-e7574ae95474,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-e699d934-a9a0-47f1-afed-10dedbf05c43,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-c8551d7d-2c15-4f82-a469-e13e6845ef38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754119219-172.17.0.5-1596924135962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-55e3e21a-3b8f-4725-90a1-fbb31dbc3075,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-e20b4331-5c6a-4698-9b37-5834a1886606,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-9833668e-7374-499e-a3b7-e27f1389594a,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-3814c568-c591-4cb5-bd2d-0d37b6b982a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-d3704d0b-f2ca-4112-b410-0d64a8a35ace,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-6237eb91-b0d6-46d7-8ee9-b3c5e87e1c34,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-c677e9bf-cadb-4aa8-9394-53ee74fc8a78,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-f516e16a-0ee3-4a31-be50-4c2ef5224587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754119219-172.17.0.5-1596924135962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-55e3e21a-3b8f-4725-90a1-fbb31dbc3075,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-e20b4331-5c6a-4698-9b37-5834a1886606,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-9833668e-7374-499e-a3b7-e27f1389594a,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-3814c568-c591-4cb5-bd2d-0d37b6b982a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-d3704d0b-f2ca-4112-b410-0d64a8a35ace,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-6237eb91-b0d6-46d7-8ee9-b3c5e87e1c34,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-c677e9bf-cadb-4aa8-9394-53ee74fc8a78,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-f516e16a-0ee3-4a31-be50-4c2ef5224587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5496
