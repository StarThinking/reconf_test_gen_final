reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082974842-172.17.0.4-1596913720187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43432,DS-7f0e1aa4-d71c-42d0-9640-30ea982afd18,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-6092d164-8c9e-438e-b995-20b925c0a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-155764c8-676f-44c3-a706-79dff9255678,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-1f63d216-1f85-4d96-809f-dfceb63d969e,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-5851072c-9d57-4fed-9172-8dccabdc62dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-70b3c4e6-58ee-412a-bfb7-86e7e33e532a,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-948bc82a-5699-4b36-800a-6015e6294f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-30654a7b-34a2-4ac4-ad86-ca5a57e7d4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082974842-172.17.0.4-1596913720187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43432,DS-7f0e1aa4-d71c-42d0-9640-30ea982afd18,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-6092d164-8c9e-438e-b995-20b925c0a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-155764c8-676f-44c3-a706-79dff9255678,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-1f63d216-1f85-4d96-809f-dfceb63d969e,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-5851072c-9d57-4fed-9172-8dccabdc62dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-70b3c4e6-58ee-412a-bfb7-86e7e33e532a,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-948bc82a-5699-4b36-800a-6015e6294f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-30654a7b-34a2-4ac4-ad86-ca5a57e7d4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967824548-172.17.0.4-1596913788599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40987,DS-67632bc1-d3f6-4f0c-bc69-6c96d5b6bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-d54721e1-6f66-4501-80ce-15b0eae3f551,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-969f1b7c-8405-4e15-aa8a-cdc871cbd163,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-7578d164-40f8-443b-9c83-8041bf102d81,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-cf19f44f-30c8-492b-9b72-3a4a1bbab527,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-47de0a8c-69ac-45a2-b802-206f672e0a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-a95f9b34-b0bb-4b8a-b823-ba2812a96484,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-9a78dc2e-a9a4-47a4-9f27-2cdb0fd15c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967824548-172.17.0.4-1596913788599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40987,DS-67632bc1-d3f6-4f0c-bc69-6c96d5b6bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-d54721e1-6f66-4501-80ce-15b0eae3f551,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-969f1b7c-8405-4e15-aa8a-cdc871cbd163,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-7578d164-40f8-443b-9c83-8041bf102d81,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-cf19f44f-30c8-492b-9b72-3a4a1bbab527,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-47de0a8c-69ac-45a2-b802-206f672e0a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-a95f9b34-b0bb-4b8a-b823-ba2812a96484,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-9a78dc2e-a9a4-47a4-9f27-2cdb0fd15c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131851419-172.17.0.4-1596913979781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-2ee40a62-d2d9-41d7-8c5f-57cb7ba0efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-9b675dd4-ed4a-4596-be21-ca0e29acd4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-d4635964-9f5e-440c-b99e-ae56950efd37,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-98c6414d-89c0-4253-b5b5-b7bfbee2a6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-e8639fd1-644a-41f3-98f6-8a427fe7de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-e23949ba-c7cf-4900-a5c6-cb4feec82eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-69050c39-a825-4253-a273-c22a78bbf6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-af59fd81-7553-46de-90b3-a3e6684b1cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131851419-172.17.0.4-1596913979781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-2ee40a62-d2d9-41d7-8c5f-57cb7ba0efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-9b675dd4-ed4a-4596-be21-ca0e29acd4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-d4635964-9f5e-440c-b99e-ae56950efd37,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-98c6414d-89c0-4253-b5b5-b7bfbee2a6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-e8639fd1-644a-41f3-98f6-8a427fe7de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-e23949ba-c7cf-4900-a5c6-cb4feec82eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-69050c39-a825-4253-a273-c22a78bbf6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-af59fd81-7553-46de-90b3-a3e6684b1cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91539515-172.17.0.4-1596914169298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-f371b306-9226-478a-8d43-25db9694ab92,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-e2f7660f-a52c-4495-b6d2-5cc0300615ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f09ad529-622a-4482-82d9-9b32934372e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-dd2916fb-ce81-4d63-b770-72855032647d,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-7ac42235-a9be-4af5-97da-12d05d43015c,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-a0c54121-6210-44f9-ba88-04b7a977fa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-0165f3d6-09b2-4afe-868b-d284642a6380,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-1adf0960-eb8f-4259-b093-398c226a2746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91539515-172.17.0.4-1596914169298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-f371b306-9226-478a-8d43-25db9694ab92,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-e2f7660f-a52c-4495-b6d2-5cc0300615ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f09ad529-622a-4482-82d9-9b32934372e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-dd2916fb-ce81-4d63-b770-72855032647d,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-7ac42235-a9be-4af5-97da-12d05d43015c,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-a0c54121-6210-44f9-ba88-04b7a977fa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-0165f3d6-09b2-4afe-868b-d284642a6380,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-1adf0960-eb8f-4259-b093-398c226a2746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369081044-172.17.0.4-1596914319343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-803d3281-9e55-4a5b-9c55-a3079056e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-951c4932-3e06-475e-89c7-c26698f36ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-7e63fa7d-2acb-49ba-bc98-65247db7a1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-407cb78c-2505-424b-8d0d-bd8d5e0a471f,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-073904b4-63cb-44df-88b8-b1c1e6269c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-333ed39b-1dfd-461c-a8d8-3a09bec0a8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-176f93fd-d46c-4a64-aa0f-9257dc14a8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-073fb903-78cb-423d-a1d8-7779b57a3d57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369081044-172.17.0.4-1596914319343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-803d3281-9e55-4a5b-9c55-a3079056e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-951c4932-3e06-475e-89c7-c26698f36ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-7e63fa7d-2acb-49ba-bc98-65247db7a1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-407cb78c-2505-424b-8d0d-bd8d5e0a471f,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-073904b4-63cb-44df-88b8-b1c1e6269c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-333ed39b-1dfd-461c-a8d8-3a09bec0a8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-176f93fd-d46c-4a64-aa0f-9257dc14a8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-073fb903-78cb-423d-a1d8-7779b57a3d57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710976492-172.17.0.4-1596914467269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-36b395bb-8fb2-4d9a-900f-fa2233157215,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-bb1b2b4b-a26b-4c91-a1bd-82e91cf3a803,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-37c4f835-1f6c-486e-a86f-a9e045febd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-7fea03c7-b0ba-43c2-a858-969ae6737938,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-3476056a-2f18-4ebb-9767-396a4ff35cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-b5d13310-ef6d-41f7-b774-0cf43e662a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-bcf5b642-680c-4406-8d3e-43b699711497,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-c1608dc6-2d45-42de-9a91-659d1b025dbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710976492-172.17.0.4-1596914467269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-36b395bb-8fb2-4d9a-900f-fa2233157215,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-bb1b2b4b-a26b-4c91-a1bd-82e91cf3a803,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-37c4f835-1f6c-486e-a86f-a9e045febd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-7fea03c7-b0ba-43c2-a858-969ae6737938,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-3476056a-2f18-4ebb-9767-396a4ff35cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-b5d13310-ef6d-41f7-b774-0cf43e662a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-bcf5b642-680c-4406-8d3e-43b699711497,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-c1608dc6-2d45-42de-9a91-659d1b025dbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649591610-172.17.0.4-1596914619037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-09127eb2-5335-47b1-bafd-1be7a4aa7f91,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-19238c11-ff7a-4a70-b25f-5268fec53fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-f2fad1b6-95db-4bcf-8cbc-555f5c1e8278,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-165067a3-3797-4165-b37d-751a6027f957,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-2eb660f4-42a4-4d81-b986-393cb1b8d0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-55720003-52be-4733-9bf4-ce3dab63a544,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-d75f8242-ca50-4013-87b4-2ef81feaa99d,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-48b7e520-0465-477a-b605-3c978201c312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649591610-172.17.0.4-1596914619037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-09127eb2-5335-47b1-bafd-1be7a4aa7f91,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-19238c11-ff7a-4a70-b25f-5268fec53fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-f2fad1b6-95db-4bcf-8cbc-555f5c1e8278,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-165067a3-3797-4165-b37d-751a6027f957,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-2eb660f4-42a4-4d81-b986-393cb1b8d0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-55720003-52be-4733-9bf4-ce3dab63a544,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-d75f8242-ca50-4013-87b4-2ef81feaa99d,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-48b7e520-0465-477a-b605-3c978201c312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798753083-172.17.0.4-1596914698654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38734,DS-9fd104a7-3fb1-4a68-bacd-850aa0a7c406,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-4ee05fb0-059a-49e8-be60-a203900db779,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-7c41ff81-44b7-4c24-9d97-0409e1b919fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-d71e4c04-b6b8-47bf-a872-8b3c17dfc9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-5f987301-c1d7-40f6-be6a-6166f997ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-7ee7454d-9ede-45ff-a59b-81446d195a86,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-e18558b8-508c-415d-ae67-553db031c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5f19ac40-0f72-4260-99a9-6cb1f1ace468,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798753083-172.17.0.4-1596914698654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38734,DS-9fd104a7-3fb1-4a68-bacd-850aa0a7c406,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-4ee05fb0-059a-49e8-be60-a203900db779,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-7c41ff81-44b7-4c24-9d97-0409e1b919fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-d71e4c04-b6b8-47bf-a872-8b3c17dfc9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-5f987301-c1d7-40f6-be6a-6166f997ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-7ee7454d-9ede-45ff-a59b-81446d195a86,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-e18558b8-508c-415d-ae67-553db031c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5f19ac40-0f72-4260-99a9-6cb1f1ace468,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700651767-172.17.0.4-1596914806454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40974,DS-c739b767-669d-458f-84ce-9b9d3d224b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-8fa59b1a-7889-448b-9219-97c437915e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-5637d1d8-7e42-46c3-a64c-fd44ed8b3140,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-3cfde52a-1d4f-41ac-a79c-b14cb4725702,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-89db3fa9-02de-42be-a72d-1753d1a5b2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-6a6f68ac-199a-47fc-b7f0-64c2ec3c4738,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-1a2f924d-d9d8-4dda-834b-5c096eea8ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-abbcfd3e-a8ed-4953-98bf-658420ab370a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700651767-172.17.0.4-1596914806454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40974,DS-c739b767-669d-458f-84ce-9b9d3d224b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-8fa59b1a-7889-448b-9219-97c437915e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-5637d1d8-7e42-46c3-a64c-fd44ed8b3140,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-3cfde52a-1d4f-41ac-a79c-b14cb4725702,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-89db3fa9-02de-42be-a72d-1753d1a5b2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-6a6f68ac-199a-47fc-b7f0-64c2ec3c4738,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-1a2f924d-d9d8-4dda-834b-5c096eea8ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-abbcfd3e-a8ed-4953-98bf-658420ab370a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612223608-172.17.0.4-1596914982615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-5d2ca6a6-be5d-4ab2-a66f-cde98b9945e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-5f88a51b-bff4-4b9f-bceb-33cc081bd507,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-a2e5a379-6bb9-440c-b2b7-019ed6e7ed3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-52ad805a-e74e-4d86-91ff-b4f40ae6c040,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-4f146925-0861-4fde-99e9-69e69a44ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-f78e9889-cb91-4b27-b6c6-7d283e90415c,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-bc5ad2e2-3279-43e4-af8c-4bc964b1634e,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-5cc6c31a-884f-4120-a9b0-da6b3f17ace9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612223608-172.17.0.4-1596914982615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-5d2ca6a6-be5d-4ab2-a66f-cde98b9945e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-5f88a51b-bff4-4b9f-bceb-33cc081bd507,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-a2e5a379-6bb9-440c-b2b7-019ed6e7ed3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-52ad805a-e74e-4d86-91ff-b4f40ae6c040,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-4f146925-0861-4fde-99e9-69e69a44ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-f78e9889-cb91-4b27-b6c6-7d283e90415c,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-bc5ad2e2-3279-43e4-af8c-4bc964b1634e,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-5cc6c31a-884f-4120-a9b0-da6b3f17ace9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999976570-172.17.0.4-1596915251190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-8e5a9e72-a47a-417f-9777-998dc0579a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-16b271ff-8942-4fbb-86f9-36b3955ebc60,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-2d0d4857-1265-4bb9-bf87-ec7d396a5e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-f49ea5d4-f6a3-42f8-b6d1-62f2fed17d03,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-ad135738-c46a-4270-a092-368064c454fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-1920a115-8654-458f-82c4-3618089a0c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-5d0e8693-762b-405a-8d1b-7e18ac32a31e,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-ceed3534-ae70-4c54-9f7b-13aca2b5babe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999976570-172.17.0.4-1596915251190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-8e5a9e72-a47a-417f-9777-998dc0579a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-16b271ff-8942-4fbb-86f9-36b3955ebc60,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-2d0d4857-1265-4bb9-bf87-ec7d396a5e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-f49ea5d4-f6a3-42f8-b6d1-62f2fed17d03,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-ad135738-c46a-4270-a092-368064c454fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-1920a115-8654-458f-82c4-3618089a0c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-5d0e8693-762b-405a-8d1b-7e18ac32a31e,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-ceed3534-ae70-4c54-9f7b-13aca2b5babe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775898502-172.17.0.4-1596915296811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32829,DS-3a0de406-f29a-4d02-b5db-d1a290f02ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-bd7bc88e-0338-4c93-a2b8-96ac3f047e85,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-0593b25e-f55f-43e1-9d0e-a66e792373f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-649d2ddf-7a81-4bfe-a0b6-4cd6cbe2bd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-0156ddaf-65c5-4db4-9fd3-0978f94caaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-50f7ea56-37f4-4aea-9938-e80292dd2860,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-6df8480c-b0ed-4c61-8385-8226d672c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-2a918b1a-a9e2-4a6e-89f6-874a173e42a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775898502-172.17.0.4-1596915296811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32829,DS-3a0de406-f29a-4d02-b5db-d1a290f02ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-bd7bc88e-0338-4c93-a2b8-96ac3f047e85,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-0593b25e-f55f-43e1-9d0e-a66e792373f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-649d2ddf-7a81-4bfe-a0b6-4cd6cbe2bd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-0156ddaf-65c5-4db4-9fd3-0978f94caaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-50f7ea56-37f4-4aea-9938-e80292dd2860,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-6df8480c-b0ed-4c61-8385-8226d672c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-2a918b1a-a9e2-4a6e-89f6-874a173e42a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111555886-172.17.0.4-1596915331117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33607,DS-8b443a99-7f85-4d80-a896-5a7a99a48601,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-da901114-4bda-43e7-acbb-fb24475a190e,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-d419b5af-06df-4f5c-a973-f30d53af041c,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-b7ea9c2a-13e8-4f55-befe-fca2c3d80775,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-29ed435b-c0a9-4af7-b411-084cf6400c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-78bbf247-243e-4508-8da2-2ce9945395ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-43eae6ba-453c-4cc8-9175-95701078281e,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-8603a2d4-8b07-416b-b7fe-0c3dc4d7b0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111555886-172.17.0.4-1596915331117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33607,DS-8b443a99-7f85-4d80-a896-5a7a99a48601,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-da901114-4bda-43e7-acbb-fb24475a190e,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-d419b5af-06df-4f5c-a973-f30d53af041c,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-b7ea9c2a-13e8-4f55-befe-fca2c3d80775,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-29ed435b-c0a9-4af7-b411-084cf6400c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-78bbf247-243e-4508-8da2-2ce9945395ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-43eae6ba-453c-4cc8-9175-95701078281e,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-8603a2d4-8b07-416b-b7fe-0c3dc4d7b0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736247516-172.17.0.4-1596915451804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46453,DS-d042a5f9-49ed-4a52-a2c2-cb0389b69603,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-96f61bcb-f26c-49f3-a507-01cf890fc3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-06143942-86da-47da-b1e3-1afd015ae20e,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-26e928c3-ddf0-4b8b-8c92-547aca49ff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-76ed366d-35dc-4f8e-9c76-d8e5b21d0c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-4a7dabea-a973-45ac-be77-68a048be8563,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-35e0bc91-09fe-42c8-b73a-2f7cbcf9e4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-1638b3fa-911e-46e3-b4f9-50ef2e53455c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736247516-172.17.0.4-1596915451804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46453,DS-d042a5f9-49ed-4a52-a2c2-cb0389b69603,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-96f61bcb-f26c-49f3-a507-01cf890fc3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-06143942-86da-47da-b1e3-1afd015ae20e,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-26e928c3-ddf0-4b8b-8c92-547aca49ff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-76ed366d-35dc-4f8e-9c76-d8e5b21d0c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-4a7dabea-a973-45ac-be77-68a048be8563,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-35e0bc91-09fe-42c8-b73a-2f7cbcf9e4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-1638b3fa-911e-46e3-b4f9-50ef2e53455c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753539018-172.17.0.4-1596915528627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37367,DS-9389afec-6431-40eb-a1b6-2cd336ff1e13,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-b25c61c1-1dd9-4275-bc6d-dc8ebdf9df60,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-9ca2a649-613b-4ea3-bac8-ea7a31d52dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-06cf294a-6f9f-4088-96a0-543ed997bfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-e5645579-1abd-4d2b-9ef8-7654755b871d,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-bcb9e236-56bc-49b1-b5ff-6da25ed3f5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-cc6f01b8-61e0-4140-8ad7-cbf90c0d00ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-db5911c8-8298-4d05-acb7-98bd26d0d9dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753539018-172.17.0.4-1596915528627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37367,DS-9389afec-6431-40eb-a1b6-2cd336ff1e13,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-b25c61c1-1dd9-4275-bc6d-dc8ebdf9df60,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-9ca2a649-613b-4ea3-bac8-ea7a31d52dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-06cf294a-6f9f-4088-96a0-543ed997bfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-e5645579-1abd-4d2b-9ef8-7654755b871d,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-bcb9e236-56bc-49b1-b5ff-6da25ed3f5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-cc6f01b8-61e0-4140-8ad7-cbf90c0d00ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-db5911c8-8298-4d05-acb7-98bd26d0d9dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077513652-172.17.0.4-1596915559372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-7332ca5d-3380-4168-ad13-07005647d5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-4ec1bacc-8e39-4e2e-ac42-b5f1120c8822,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-98a7556d-0b10-407b-ae16-9a22c1bcda3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-a1b1adf2-e4b4-4124-ae36-d554af5fde9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-b10d886c-5aae-4e42-94bb-8b4328195679,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-7f8c3322-55db-43eb-8929-94df839aa522,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-e33ed452-2206-407a-b89a-82709b15f0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-22f9a4e2-176a-42da-b2c1-900130282761,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077513652-172.17.0.4-1596915559372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-7332ca5d-3380-4168-ad13-07005647d5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-4ec1bacc-8e39-4e2e-ac42-b5f1120c8822,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-98a7556d-0b10-407b-ae16-9a22c1bcda3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-a1b1adf2-e4b4-4124-ae36-d554af5fde9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-b10d886c-5aae-4e42-94bb-8b4328195679,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-7f8c3322-55db-43eb-8929-94df839aa522,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-e33ed452-2206-407a-b89a-82709b15f0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-22f9a4e2-176a-42da-b2c1-900130282761,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595586739-172.17.0.4-1596915804382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33809,DS-cd2e18a6-69f9-428d-8413-5b84da0d7827,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-fa149a23-5e9c-4cba-96fb-5cfad3929716,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-66aabf66-4e1d-4f01-bb0b-3e4848381fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-53759f68-db6b-45d1-999a-60ea0f6c5b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-ca90f80a-3bc3-4026-9deb-dd04765116c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-f54bde3f-24f1-4cd3-82f2-8564bf82aa50,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-d99e1208-648c-499c-bbf7-18187b45fcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-04238c96-12ce-4bda-a39f-6860c2304613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595586739-172.17.0.4-1596915804382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33809,DS-cd2e18a6-69f9-428d-8413-5b84da0d7827,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-fa149a23-5e9c-4cba-96fb-5cfad3929716,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-66aabf66-4e1d-4f01-bb0b-3e4848381fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-53759f68-db6b-45d1-999a-60ea0f6c5b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-ca90f80a-3bc3-4026-9deb-dd04765116c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-f54bde3f-24f1-4cd3-82f2-8564bf82aa50,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-d99e1208-648c-499c-bbf7-18187b45fcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-04238c96-12ce-4bda-a39f-6860c2304613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359628861-172.17.0.4-1596915879821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35359,DS-f5ff8f4b-fa7c-48f7-a693-22e78b32e0af,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-eee23a8d-6f10-4730-9083-fbf4ff7d7a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-0a4e9001-6619-4baa-814f-7a31b5f45268,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-b21ee6e6-ceab-4989-908f-52ed39edb524,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-50bfc54e-36a3-4c8f-bba4-a6dc90e747d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-cc9114af-caea-4540-8c36-fd7ec5b66139,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-cccf7b71-a567-4d4d-803e-30e964e351a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-98c7422d-28e1-47fe-b8fb-97e1167643d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359628861-172.17.0.4-1596915879821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35359,DS-f5ff8f4b-fa7c-48f7-a693-22e78b32e0af,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-eee23a8d-6f10-4730-9083-fbf4ff7d7a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-0a4e9001-6619-4baa-814f-7a31b5f45268,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-b21ee6e6-ceab-4989-908f-52ed39edb524,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-50bfc54e-36a3-4c8f-bba4-a6dc90e747d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-cc9114af-caea-4540-8c36-fd7ec5b66139,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-cccf7b71-a567-4d4d-803e-30e964e351a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-98c7422d-28e1-47fe-b8fb-97e1167643d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211195211-172.17.0.4-1596916084889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41819,DS-73d6f219-0b8d-4577-bd16-0e1fc69894dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-c8447d64-41f7-492e-90ef-f15182b5b83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-0cdfa090-1331-4acf-a635-e7b38d81e796,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-7d1d8bc5-4864-4cc6-85a1-563cfb34c3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-2d18e13c-0c4d-4d69-ae04-a408858a5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-a48ca095-0200-410f-8fbb-7d3b308bd8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-57ca1fd9-925e-4d16-9dca-103358c03b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-d934cb91-7d1b-41b0-8603-ad7f404845be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211195211-172.17.0.4-1596916084889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41819,DS-73d6f219-0b8d-4577-bd16-0e1fc69894dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-c8447d64-41f7-492e-90ef-f15182b5b83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-0cdfa090-1331-4acf-a635-e7b38d81e796,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-7d1d8bc5-4864-4cc6-85a1-563cfb34c3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-2d18e13c-0c4d-4d69-ae04-a408858a5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-a48ca095-0200-410f-8fbb-7d3b308bd8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-57ca1fd9-925e-4d16-9dca-103358c03b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-d934cb91-7d1b-41b0-8603-ad7f404845be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472477483-172.17.0.4-1596916242602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-10705360-4046-4d62-a385-f88eccddc4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-fe5bd5ca-b850-44f6-b4af-b3a94423f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-13719c94-8410-4fe5-9d6e-b766bda383eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-b15f9a4f-9ece-41d3-a97b-437cf7f520f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-ff2a7a56-5323-4ce8-9010-a2f5642ba986,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-50bf15e6-1db2-4170-af98-d1a5680a9fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-55fedeb3-fd59-438a-8a88-c10a19a84fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-ef5490e6-93a1-4bdd-957a-eb2d9dc572ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472477483-172.17.0.4-1596916242602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-10705360-4046-4d62-a385-f88eccddc4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-fe5bd5ca-b850-44f6-b4af-b3a94423f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-13719c94-8410-4fe5-9d6e-b766bda383eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-b15f9a4f-9ece-41d3-a97b-437cf7f520f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-ff2a7a56-5323-4ce8-9010-a2f5642ba986,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-50bf15e6-1db2-4170-af98-d1a5680a9fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-55fedeb3-fd59-438a-8a88-c10a19a84fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-ef5490e6-93a1-4bdd-957a-eb2d9dc572ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737435229-172.17.0.4-1596916485015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46787,DS-3661b801-6eb8-4a7c-b95b-4990cf2a4e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4f0fefcb-20f7-4b63-9db0-bf43780cc1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-512a42f8-5f65-415c-a4de-e5654c514b29,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-d29a51ff-843d-4166-963b-786dbcf22d66,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-19a0f9c8-febf-41dc-b3e7-25ead5ca39b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-19b401e3-fcdd-4b08-8481-a0d616cd8006,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-37673911-87a2-4028-87ae-653e2099f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-e89c0948-b183-4f69-a967-3de9cd1b516c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737435229-172.17.0.4-1596916485015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46787,DS-3661b801-6eb8-4a7c-b95b-4990cf2a4e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4f0fefcb-20f7-4b63-9db0-bf43780cc1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-512a42f8-5f65-415c-a4de-e5654c514b29,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-d29a51ff-843d-4166-963b-786dbcf22d66,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-19a0f9c8-febf-41dc-b3e7-25ead5ca39b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-19b401e3-fcdd-4b08-8481-a0d616cd8006,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-37673911-87a2-4028-87ae-653e2099f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-e89c0948-b183-4f69-a967-3de9cd1b516c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293009430-172.17.0.4-1596916533228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41620,DS-36dcd21f-0938-4c52-a498-a4027bf73b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-586f7463-323e-470a-ba25-ca2974856946,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-0ca3bf19-90f0-467a-a9f8-d037c8a88ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-5f7ca9ff-266f-4fc3-9242-7464c1e16425,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-5cddfdda-010b-4dfe-9142-a5bc378ccbce,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-9f694877-4b10-46be-a764-ee8df122cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-7ecb3264-de9f-4e4b-8b8d-4240d4dd5546,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-103952c1-d544-4d44-9082-74333a347439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293009430-172.17.0.4-1596916533228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41620,DS-36dcd21f-0938-4c52-a498-a4027bf73b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-586f7463-323e-470a-ba25-ca2974856946,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-0ca3bf19-90f0-467a-a9f8-d037c8a88ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-5f7ca9ff-266f-4fc3-9242-7464c1e16425,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-5cddfdda-010b-4dfe-9142-a5bc378ccbce,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-9f694877-4b10-46be-a764-ee8df122cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-7ecb3264-de9f-4e4b-8b8d-4240d4dd5546,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-103952c1-d544-4d44-9082-74333a347439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109192483-172.17.0.4-1596916612645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46436,DS-6ad70330-5b20-421a-b377-d23da80bfef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-0dd7b471-6343-4557-b1b5-be3cbda5e449,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-46c96080-ed0a-430f-ba0b-92d9f5953068,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-c50131e6-334c-4b48-8ca4-f667db73eb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-19c545d3-98af-444f-9921-ffaf26463f43,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-e5181162-a1cb-435e-a284-fde283cbb451,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-013548a0-db38-44ad-8eac-740f06da5e11,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-1c090528-8e1b-4643-a5a4-5cff61a725a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109192483-172.17.0.4-1596916612645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46436,DS-6ad70330-5b20-421a-b377-d23da80bfef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-0dd7b471-6343-4557-b1b5-be3cbda5e449,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-46c96080-ed0a-430f-ba0b-92d9f5953068,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-c50131e6-334c-4b48-8ca4-f667db73eb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-19c545d3-98af-444f-9921-ffaf26463f43,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-e5181162-a1cb-435e-a284-fde283cbb451,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-013548a0-db38-44ad-8eac-740f06da5e11,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-1c090528-8e1b-4643-a5a4-5cff61a725a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430893938-172.17.0.4-1596916846931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38067,DS-ac1e8a66-774d-4599-86b3-3a5bc6e98643,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-9b278e2a-c4c5-4514-9478-bcd15c570c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-16037d99-b84d-4828-a8e2-782a3dd2698d,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-d739f773-6287-4bd2-9249-9e82b66b5856,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f38ce37c-4d95-40d1-a5df-9380dfb742d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-1113ae46-6775-4ff1-81a7-b51687082fac,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-340455d3-389c-4443-b9e9-6fc9ef46b683,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-39edfa66-86b8-41b4-b161-6effd06db15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430893938-172.17.0.4-1596916846931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38067,DS-ac1e8a66-774d-4599-86b3-3a5bc6e98643,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-9b278e2a-c4c5-4514-9478-bcd15c570c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-16037d99-b84d-4828-a8e2-782a3dd2698d,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-d739f773-6287-4bd2-9249-9e82b66b5856,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f38ce37c-4d95-40d1-a5df-9380dfb742d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-1113ae46-6775-4ff1-81a7-b51687082fac,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-340455d3-389c-4443-b9e9-6fc9ef46b683,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-39edfa66-86b8-41b4-b161-6effd06db15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999208106-172.17.0.4-1596917007220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-aae96f24-ec32-4d20-80bb-24043221d7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-da68da48-df25-4031-a167-2389bf4762e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-56ebf09c-c7b5-4319-9c3d-c7f8316dc43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-813f0375-bbf5-4676-90a4-5eebc7bf0738,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-83227b53-d9d6-4cd5-986a-5dfbb176a6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-461a7f9d-b2d1-4aa8-8d8b-1760d787f7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-36b124c8-3e0a-4fb1-b3c1-e1c49840463f,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-db8a7378-2290-4f59-83c0-fb35d5ccfc87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999208106-172.17.0.4-1596917007220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-aae96f24-ec32-4d20-80bb-24043221d7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-da68da48-df25-4031-a167-2389bf4762e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-56ebf09c-c7b5-4319-9c3d-c7f8316dc43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-813f0375-bbf5-4676-90a4-5eebc7bf0738,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-83227b53-d9d6-4cd5-986a-5dfbb176a6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-461a7f9d-b2d1-4aa8-8d8b-1760d787f7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-36b124c8-3e0a-4fb1-b3c1-e1c49840463f,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-db8a7378-2290-4f59-83c0-fb35d5ccfc87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110448366-172.17.0.4-1596917047875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-2979ec37-4959-4842-8157-b0636c7c4f48,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-f4b6af02-f5df-438c-8ce0-9f19e2d90364,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-e83cfd74-41f9-419e-8bbe-f69fe9938ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-007c7860-ac78-4412-8c9e-6bbb2d62546d,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-b0ced767-5019-4b20-b475-bbc56b89881a,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-b8e5dd2a-ae63-4f30-a402-fff0a720ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-de95faf1-df33-42c5-8284-cb5f62b15124,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-aaba157a-b800-4dba-9eb6-32b760d8118d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110448366-172.17.0.4-1596917047875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-2979ec37-4959-4842-8157-b0636c7c4f48,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-f4b6af02-f5df-438c-8ce0-9f19e2d90364,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-e83cfd74-41f9-419e-8bbe-f69fe9938ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-007c7860-ac78-4412-8c9e-6bbb2d62546d,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-b0ced767-5019-4b20-b475-bbc56b89881a,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-b8e5dd2a-ae63-4f30-a402-fff0a720ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-de95faf1-df33-42c5-8284-cb5f62b15124,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-aaba157a-b800-4dba-9eb6-32b760d8118d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535836854-172.17.0.4-1596917093038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32904,DS-9e9b9df1-e4da-4fc3-be38-80c62a348671,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ec932f63-756c-4efc-bb6d-da7187fee2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-26a1e056-6c11-4bf9-b076-f1415d9509ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-3da51dd1-f8e6-4699-8365-49ffcbac9dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-07c69002-c710-4a34-845c-7b4ab239ab16,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-87827a9b-8d28-462f-a55a-a9f0d6cd15f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-9795adec-b356-4f40-b0c4-37a5f7fd2926,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-f8dc776d-85d4-48f9-97c4-09acf02215b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535836854-172.17.0.4-1596917093038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32904,DS-9e9b9df1-e4da-4fc3-be38-80c62a348671,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-ec932f63-756c-4efc-bb6d-da7187fee2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-26a1e056-6c11-4bf9-b076-f1415d9509ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-3da51dd1-f8e6-4699-8365-49ffcbac9dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-07c69002-c710-4a34-845c-7b4ab239ab16,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-87827a9b-8d28-462f-a55a-a9f0d6cd15f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-9795adec-b356-4f40-b0c4-37a5f7fd2926,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-f8dc776d-85d4-48f9-97c4-09acf02215b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160209598-172.17.0.4-1596917167015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33365,DS-baf0967b-b401-4831-97c1-22c330fed09e,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-f204fbc1-6fe1-4b13-9dc6-5eb283ea94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-c6bb5b24-bd53-4887-87f0-4ef951c36171,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-4a67bfa8-6e11-4594-8534-46721f80f608,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-204046ef-bf7a-4584-b5e8-29131309c0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-c05962ef-068f-47d8-b06e-45e5b4fe5ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-eb68a641-e159-4ac4-91f4-0c3d37023100,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-164b52d3-2cc1-4c9c-935e-7df05a1daddb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160209598-172.17.0.4-1596917167015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33365,DS-baf0967b-b401-4831-97c1-22c330fed09e,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-f204fbc1-6fe1-4b13-9dc6-5eb283ea94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-c6bb5b24-bd53-4887-87f0-4ef951c36171,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-4a67bfa8-6e11-4594-8534-46721f80f608,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-204046ef-bf7a-4584-b5e8-29131309c0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-c05962ef-068f-47d8-b06e-45e5b4fe5ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-eb68a641-e159-4ac4-91f4-0c3d37023100,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-164b52d3-2cc1-4c9c-935e-7df05a1daddb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049077192-172.17.0.4-1596917510506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-fa20f1f5-f44b-410b-aeb6-5ad0bb4dfa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-104f02fb-d5a5-4e1d-9ae3-88eeaf23f2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-2bd43db6-458d-4e9c-9ed6-8da823cf9683,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-8455730a-d9d5-442c-b8ad-4beb2564b287,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-f90ef67f-9efc-49e9-814c-e7b26d283f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-92f19cf7-63d1-43bf-86e7-06bee62910c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-7578e5e0-9421-48cd-a2bf-0882b6a33ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-83bac4d6-4ea4-468a-8ee6-fb4ac119d9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049077192-172.17.0.4-1596917510506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-fa20f1f5-f44b-410b-aeb6-5ad0bb4dfa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-104f02fb-d5a5-4e1d-9ae3-88eeaf23f2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-2bd43db6-458d-4e9c-9ed6-8da823cf9683,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-8455730a-d9d5-442c-b8ad-4beb2564b287,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-f90ef67f-9efc-49e9-814c-e7b26d283f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-92f19cf7-63d1-43bf-86e7-06bee62910c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-7578e5e0-9421-48cd-a2bf-0882b6a33ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-83bac4d6-4ea4-468a-8ee6-fb4ac119d9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161630651-172.17.0.4-1596917667819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40532,DS-3cedc91d-eaa0-4578-89e3-41e7c25ee840,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-3c445ab2-53a0-405a-8ec4-596ce062dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-e0784162-a4ba-4aed-88a9-45884ea73d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-9821b7dd-6bae-41ca-bf64-259766bfe066,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-a30ea13d-c6ef-4434-a396-3a0aa3f558ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-244e00fc-c39b-4e42-9eb5-aab5aac32755,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-820f9dcb-040e-4175-a561-8b35d7da8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-c23d0e49-622d-4601-870c-967e2a099a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161630651-172.17.0.4-1596917667819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40532,DS-3cedc91d-eaa0-4578-89e3-41e7c25ee840,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-3c445ab2-53a0-405a-8ec4-596ce062dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-e0784162-a4ba-4aed-88a9-45884ea73d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-9821b7dd-6bae-41ca-bf64-259766bfe066,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-a30ea13d-c6ef-4434-a396-3a0aa3f558ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-244e00fc-c39b-4e42-9eb5-aab5aac32755,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-820f9dcb-040e-4175-a561-8b35d7da8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-c23d0e49-622d-4601-870c-967e2a099a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991323831-172.17.0.4-1596918174811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-8b5a2407-e41f-4695-8670-f7cf7d7654b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-a0927ed7-cc90-4c92-83e6-fd4726a3dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-f152abe7-2378-43ab-83a0-65e556e1fddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-1ad2d224-9b4e-424e-8257-b12977c5b565,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-876a1ed8-7632-4513-8ac5-e4cdb7040b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-3117cdba-d471-4e59-8d89-9b19535606d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-b30e67e1-25e2-49eb-b29e-d51573355f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-4f007afc-5547-4483-8db6-8e1abc793ee7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991323831-172.17.0.4-1596918174811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-8b5a2407-e41f-4695-8670-f7cf7d7654b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-a0927ed7-cc90-4c92-83e6-fd4726a3dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-f152abe7-2378-43ab-83a0-65e556e1fddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-1ad2d224-9b4e-424e-8257-b12977c5b565,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-876a1ed8-7632-4513-8ac5-e4cdb7040b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-3117cdba-d471-4e59-8d89-9b19535606d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-b30e67e1-25e2-49eb-b29e-d51573355f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-4f007afc-5547-4483-8db6-8e1abc793ee7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109467882-172.17.0.4-1596918211213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39626,DS-82a7a250-04ff-4a30-9c70-1755ee8ae48e,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-e03a5781-74cc-448f-8b3f-c8b2abd2ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-da5694eb-7605-4cf6-900a-9eb9e3630202,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-95c04e0d-d04c-49c6-8299-1e1acd5fb464,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-25453f39-682b-43d2-862f-1936aff41f52,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-9379f14a-457a-48f4-b8e5-6d102b8e4f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-56f409e3-c542-46ef-b617-d5d49a86ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-1f5375c8-a711-4452-a821-202ac1507751,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109467882-172.17.0.4-1596918211213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39626,DS-82a7a250-04ff-4a30-9c70-1755ee8ae48e,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-e03a5781-74cc-448f-8b3f-c8b2abd2ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-da5694eb-7605-4cf6-900a-9eb9e3630202,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-95c04e0d-d04c-49c6-8299-1e1acd5fb464,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-25453f39-682b-43d2-862f-1936aff41f52,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-9379f14a-457a-48f4-b8e5-6d102b8e4f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-56f409e3-c542-46ef-b617-d5d49a86ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-1f5375c8-a711-4452-a821-202ac1507751,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555028724-172.17.0.4-1596918335384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-02d01351-08e8-4c3e-a9ed-9550052c3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-352503f5-6bfd-4177-a702-89aa6345da42,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-ed27be42-8d93-4aa3-bba4-05331eb0f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-f8929e92-1b03-4efd-b471-d75293f576aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-11c09994-63f6-43bd-8e10-44f2d6439756,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-0d01c8e7-46ec-4f59-90fd-37e4e03f5131,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-8cae5014-cf52-4194-9367-3b5710d0bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-e6ac7c4a-7318-4c13-9809-d04dcab3df3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555028724-172.17.0.4-1596918335384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-02d01351-08e8-4c3e-a9ed-9550052c3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-352503f5-6bfd-4177-a702-89aa6345da42,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-ed27be42-8d93-4aa3-bba4-05331eb0f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-f8929e92-1b03-4efd-b471-d75293f576aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-11c09994-63f6-43bd-8e10-44f2d6439756,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-0d01c8e7-46ec-4f59-90fd-37e4e03f5131,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-8cae5014-cf52-4194-9367-3b5710d0bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-e6ac7c4a-7318-4c13-9809-d04dcab3df3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222765082-172.17.0.4-1596918371388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38609,DS-55629cb5-cf81-48b6-973b-b4c863e8e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-80619bf6-d64a-424e-a7c3-fcee14946d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-06ae0a30-f5a8-4ac3-9e95-20588c302c20,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-c6df89ce-2a2f-4bc0-91de-263db9a225cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-dd2bc0b4-8d9f-466e-a670-e68e6af56f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-987a9fcd-aba2-47c7-ae97-2bc800145dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-0177c08c-132a-44f9-bcd2-21b19e178455,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-9f38b68d-4cb7-4919-a33d-e4178c743707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222765082-172.17.0.4-1596918371388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38609,DS-55629cb5-cf81-48b6-973b-b4c863e8e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-80619bf6-d64a-424e-a7c3-fcee14946d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-06ae0a30-f5a8-4ac3-9e95-20588c302c20,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-c6df89ce-2a2f-4bc0-91de-263db9a225cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-dd2bc0b4-8d9f-466e-a670-e68e6af56f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-987a9fcd-aba2-47c7-ae97-2bc800145dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-0177c08c-132a-44f9-bcd2-21b19e178455,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-9f38b68d-4cb7-4919-a33d-e4178c743707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162890994-172.17.0.4-1596918435448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43438,DS-cf8b02c2-b5af-4d56-9da6-db15760682c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-67a51407-da23-44f5-af25-e04c838f88d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-7208a638-2895-4531-a6ab-9fbf7d0448d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-ac12eb7f-497e-40cd-9418-83e7f7a41b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-023b11cd-b92e-4cec-b3ea-80416295babf,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-d85be0a4-1e74-4554-bf56-f72f6c97cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-618c4eeb-0a00-4c56-86ec-5389a2d90aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-a973044e-8193-40b2-a6fa-bfd2186c349d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162890994-172.17.0.4-1596918435448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43438,DS-cf8b02c2-b5af-4d56-9da6-db15760682c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-67a51407-da23-44f5-af25-e04c838f88d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-7208a638-2895-4531-a6ab-9fbf7d0448d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-ac12eb7f-497e-40cd-9418-83e7f7a41b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-023b11cd-b92e-4cec-b3ea-80416295babf,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-d85be0a4-1e74-4554-bf56-f72f6c97cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-618c4eeb-0a00-4c56-86ec-5389a2d90aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-a973044e-8193-40b2-a6fa-bfd2186c349d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408611052-172.17.0.4-1596919330107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-4a1366bd-8431-44ab-b418-86530e9a433d,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-a6a0754c-f411-48e9-aa47-a4cd5ad72432,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-7c710d8f-278f-42fc-a0fb-3e0ef7ad83f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-3bf6f716-b9aa-4731-9cc5-0e87ca8e785b,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-101923e1-115e-4b79-b965-4130c15c2848,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-8155c29a-fdf7-4450-a160-df748555922d,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-5f9447f9-300d-4cd6-a7f4-cec8881987d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-2b12edc0-5b04-4209-b9c7-a2a73049d8fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408611052-172.17.0.4-1596919330107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-4a1366bd-8431-44ab-b418-86530e9a433d,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-a6a0754c-f411-48e9-aa47-a4cd5ad72432,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-7c710d8f-278f-42fc-a0fb-3e0ef7ad83f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-3bf6f716-b9aa-4731-9cc5-0e87ca8e785b,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-101923e1-115e-4b79-b965-4130c15c2848,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-8155c29a-fdf7-4450-a160-df748555922d,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-5f9447f9-300d-4cd6-a7f4-cec8881987d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-2b12edc0-5b04-4209-b9c7-a2a73049d8fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5772
