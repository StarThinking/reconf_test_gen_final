reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053839575-172.17.0.17-1596954904359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33511,DS-afbb7169-ed6e-41c3-8bef-0c1d771758cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-6e5260a2-3f98-4114-9886-bff4e1b99aac,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-7ce7f0f0-2fd8-4725-8fe4-87505fcdaba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-3d130b4c-ea20-41f4-8151-d2aa6d37d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-58a33c1a-3116-48bc-a2fa-0f37f64122e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-cbca3568-bab1-4c36-831c-ce503267685d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-9fbf527b-77d4-4f94-a76c-b7a4eaba75d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-949ae5a3-091c-4717-85e6-e131bc7b9509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053839575-172.17.0.17-1596954904359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33511,DS-afbb7169-ed6e-41c3-8bef-0c1d771758cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-6e5260a2-3f98-4114-9886-bff4e1b99aac,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-7ce7f0f0-2fd8-4725-8fe4-87505fcdaba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-3d130b4c-ea20-41f4-8151-d2aa6d37d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-58a33c1a-3116-48bc-a2fa-0f37f64122e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-cbca3568-bab1-4c36-831c-ce503267685d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-9fbf527b-77d4-4f94-a76c-b7a4eaba75d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-949ae5a3-091c-4717-85e6-e131bc7b9509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378212376-172.17.0.17-1596954982127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-b224812e-40a3-4a03-927d-c9cad269a70e,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-5260869c-709a-4852-877b-bd699ae45bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-8017cc68-a1c0-4623-a2ea-3bbe29a85b22,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-e9aa36a9-a6ff-4354-9e3c-898c1c08abb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-14328dc6-45f2-4c92-9606-20be646793e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-589f12ea-efb0-4c33-b237-5c05e9846785,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-949a1c45-f7f3-4e01-b1c8-d5ca41539176,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-01ef05bb-6474-4b75-aa3a-5eea7aae3297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378212376-172.17.0.17-1596954982127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-b224812e-40a3-4a03-927d-c9cad269a70e,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-5260869c-709a-4852-877b-bd699ae45bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-8017cc68-a1c0-4623-a2ea-3bbe29a85b22,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-e9aa36a9-a6ff-4354-9e3c-898c1c08abb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-14328dc6-45f2-4c92-9606-20be646793e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-589f12ea-efb0-4c33-b237-5c05e9846785,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-949a1c45-f7f3-4e01-b1c8-d5ca41539176,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-01ef05bb-6474-4b75-aa3a-5eea7aae3297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998858816-172.17.0.17-1596955063495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-04ad24d7-dcea-4ba2-b2e7-f368cd5abb90,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-03dd1597-fa72-4aed-94e1-dba68730eaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-a9bf5e21-e710-4f9a-b24b-7c36bb9dc798,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-9244d7a7-8e56-41a2-9248-6f211e50834d,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-668d3503-3b83-47fa-94b1-6e6602d9910e,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-f29df653-9561-4e54-b7f5-f376f4e57171,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-1e350fa5-5353-4d8e-8004-9b7b330de4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-6513b454-5deb-4635-a4fc-43eb385ec24d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998858816-172.17.0.17-1596955063495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-04ad24d7-dcea-4ba2-b2e7-f368cd5abb90,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-03dd1597-fa72-4aed-94e1-dba68730eaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-a9bf5e21-e710-4f9a-b24b-7c36bb9dc798,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-9244d7a7-8e56-41a2-9248-6f211e50834d,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-668d3503-3b83-47fa-94b1-6e6602d9910e,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-f29df653-9561-4e54-b7f5-f376f4e57171,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-1e350fa5-5353-4d8e-8004-9b7b330de4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-6513b454-5deb-4635-a4fc-43eb385ec24d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517034610-172.17.0.17-1596956015292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35958,DS-49868d96-1a15-4868-be16-0c05dca6e6be,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-63170a44-19a1-409e-89b4-c4503aa6034e,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-280f376a-7bd1-4d20-9a29-221906253541,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-5081d5e7-eca9-4b3e-a0c7-c8884522239e,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-76def3ed-883a-431d-b042-765a3b1c2d81,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-38157a18-c457-4bd5-82b1-ea3c49f6f84f,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-a31dee43-5a12-4f23-a79e-50b3cde26177,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-04ea2735-bc36-41be-9863-7d3661ad0872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517034610-172.17.0.17-1596956015292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35958,DS-49868d96-1a15-4868-be16-0c05dca6e6be,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-63170a44-19a1-409e-89b4-c4503aa6034e,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-280f376a-7bd1-4d20-9a29-221906253541,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-5081d5e7-eca9-4b3e-a0c7-c8884522239e,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-76def3ed-883a-431d-b042-765a3b1c2d81,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-38157a18-c457-4bd5-82b1-ea3c49f6f84f,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-a31dee43-5a12-4f23-a79e-50b3cde26177,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-04ea2735-bc36-41be-9863-7d3661ad0872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717709518-172.17.0.17-1596956136677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33721,DS-2900df46-8a17-4491-9539-4f1941ce2371,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-be74e038-6f13-4f4c-a7e3-7b087550f8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-e28b6542-c381-4713-bc9a-78e45a6647d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-c2a04bf0-3d0d-4fa7-8f89-36b48d5ac26d,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-9fafad0e-86e7-460b-9b20-12f9901d57bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-e6caa4bd-9a56-4b96-800e-dd3129014a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-2b0ab8e5-f67a-4993-8416-0f409da74b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-381de032-2d03-4a87-a87c-480e01318c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717709518-172.17.0.17-1596956136677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33721,DS-2900df46-8a17-4491-9539-4f1941ce2371,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-be74e038-6f13-4f4c-a7e3-7b087550f8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-e28b6542-c381-4713-bc9a-78e45a6647d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-c2a04bf0-3d0d-4fa7-8f89-36b48d5ac26d,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-9fafad0e-86e7-460b-9b20-12f9901d57bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-e6caa4bd-9a56-4b96-800e-dd3129014a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-2b0ab8e5-f67a-4993-8416-0f409da74b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-381de032-2d03-4a87-a87c-480e01318c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630904778-172.17.0.17-1596958151891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36610,DS-480779fe-09b5-4ed8-ac71-616e3b9f71c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-b856495c-9ade-437c-83a5-4f5440ce6b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-ca4b0bf6-fc86-44ea-a398-0f8cd70d57df,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-6df4b927-666c-4812-b202-146b016b06a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-5da7cecd-082c-40dd-b731-afa4a9059052,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-731b756d-c31e-4fe7-8981-c5b092f7b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-375b23dd-44df-4d4e-adbf-018a85d66100,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-3e4b5f2c-e9ae-449e-a934-d840a3d88cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630904778-172.17.0.17-1596958151891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36610,DS-480779fe-09b5-4ed8-ac71-616e3b9f71c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-b856495c-9ade-437c-83a5-4f5440ce6b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-ca4b0bf6-fc86-44ea-a398-0f8cd70d57df,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-6df4b927-666c-4812-b202-146b016b06a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-5da7cecd-082c-40dd-b731-afa4a9059052,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-731b756d-c31e-4fe7-8981-c5b092f7b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-375b23dd-44df-4d4e-adbf-018a85d66100,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-3e4b5f2c-e9ae-449e-a934-d840a3d88cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763583875-172.17.0.17-1596958633814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36446,DS-1afe80c3-eee8-4017-8dbb-2fabf4b49f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-a0e84cde-eb78-45fa-9a88-dcb7ff71a67a,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-0ae04665-0cc1-4b91-b237-279f60973a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-8f73dc09-1b90-446a-9038-5f520c27e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-6dadca41-a253-45b7-9487-303a089bca9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-052ec5f9-57fb-4502-a5fb-d830699d72db,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-2147a52a-d110-4bf0-b191-d4a6062317fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-2e4def34-577a-4133-8e37-88ec2dce3983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763583875-172.17.0.17-1596958633814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36446,DS-1afe80c3-eee8-4017-8dbb-2fabf4b49f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-a0e84cde-eb78-45fa-9a88-dcb7ff71a67a,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-0ae04665-0cc1-4b91-b237-279f60973a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-8f73dc09-1b90-446a-9038-5f520c27e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-6dadca41-a253-45b7-9487-303a089bca9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-052ec5f9-57fb-4502-a5fb-d830699d72db,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-2147a52a-d110-4bf0-b191-d4a6062317fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-2e4def34-577a-4133-8e37-88ec2dce3983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039893624-172.17.0.17-1596958802341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35738,DS-961d4c0e-7927-423e-bee9-6e16183a8cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-bc91f2ef-fc23-463a-829c-82bfa967d683,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-ec0e851a-3054-4807-aaac-2195f25a5c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-4ab75dd4-47f2-4d3e-a29d-ad3f8c2e79a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-6d9701a4-a386-449a-b941-e49e4d2b2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-e3c7ce21-7e58-40cd-bd13-22cbb7f1d395,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-d03db921-4d25-408b-8eb3-66a87671b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-3ea681d8-7bf2-459e-8fb9-eac0e20f1a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039893624-172.17.0.17-1596958802341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35738,DS-961d4c0e-7927-423e-bee9-6e16183a8cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-bc91f2ef-fc23-463a-829c-82bfa967d683,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-ec0e851a-3054-4807-aaac-2195f25a5c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-4ab75dd4-47f2-4d3e-a29d-ad3f8c2e79a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-6d9701a4-a386-449a-b941-e49e4d2b2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-e3c7ce21-7e58-40cd-bd13-22cbb7f1d395,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-d03db921-4d25-408b-8eb3-66a87671b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-3ea681d8-7bf2-459e-8fb9-eac0e20f1a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008654143-172.17.0.17-1596959250913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-af19d613-ed95-436e-93d7-711481b79b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-32ef9727-0ca5-4449-99d2-163918611286,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-6eded02c-4e22-48ee-bfaa-7f1a97a5d662,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-3577a67f-e279-4950-a5d3-8f63154f1015,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-0f4a9662-b59a-4a53-bce6-5e1e35bc2cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-c53c438b-b1d8-43a2-ac12-4f12f9f9da5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-dcb33b3c-998d-4894-9b88-a5ea0837ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-ff022b5e-f40f-481b-9689-0c9a118806c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008654143-172.17.0.17-1596959250913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-af19d613-ed95-436e-93d7-711481b79b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-32ef9727-0ca5-4449-99d2-163918611286,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-6eded02c-4e22-48ee-bfaa-7f1a97a5d662,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-3577a67f-e279-4950-a5d3-8f63154f1015,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-0f4a9662-b59a-4a53-bce6-5e1e35bc2cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-c53c438b-b1d8-43a2-ac12-4f12f9f9da5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-dcb33b3c-998d-4894-9b88-a5ea0837ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-ff022b5e-f40f-481b-9689-0c9a118806c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580832292-172.17.0.17-1596959591324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41365,DS-e6d71c8f-e428-45e6-a1c4-d36dbe6f30d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-e48c42fc-132a-40d3-91e4-32c52646955b,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-c70dddab-19e9-4f66-a08d-e1466feeecad,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-f6421755-814a-42d0-9d49-98e85defe520,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-056e7049-bbd6-4ad1-a1a9-ed7505837091,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-592eef93-0b7b-4ac0-8193-6e23040e5721,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-33d13ee9-30b6-4c80-8675-103c9106847f,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-186385e2-2d75-47c5-8cf9-ceec0285af85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580832292-172.17.0.17-1596959591324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41365,DS-e6d71c8f-e428-45e6-a1c4-d36dbe6f30d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-e48c42fc-132a-40d3-91e4-32c52646955b,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-c70dddab-19e9-4f66-a08d-e1466feeecad,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-f6421755-814a-42d0-9d49-98e85defe520,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-056e7049-bbd6-4ad1-a1a9-ed7505837091,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-592eef93-0b7b-4ac0-8193-6e23040e5721,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-33d13ee9-30b6-4c80-8675-103c9106847f,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-186385e2-2d75-47c5-8cf9-ceec0285af85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395423844-172.17.0.17-1596959966288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-c0c24944-dbd5-4eca-9d5f-91bc4d7e6572,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-705e2255-23fb-4c9b-9d44-57202d26b6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-8a3ab094-7860-4d33-bb59-c990abd0a1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-c0e10cff-ab36-4eb6-ad74-eba8848453c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-2a94e237-d394-40ca-ab63-8ca754b7c7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-d29b01f1-84e9-4f2b-bf29-6e616636cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-2558b1ed-bca4-4719-ac36-dce640aaab28,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-bb206183-bf3c-4332-b6f6-fc1c0722c0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395423844-172.17.0.17-1596959966288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-c0c24944-dbd5-4eca-9d5f-91bc4d7e6572,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-705e2255-23fb-4c9b-9d44-57202d26b6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-8a3ab094-7860-4d33-bb59-c990abd0a1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-c0e10cff-ab36-4eb6-ad74-eba8848453c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-2a94e237-d394-40ca-ab63-8ca754b7c7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-d29b01f1-84e9-4f2b-bf29-6e616636cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-2558b1ed-bca4-4719-ac36-dce640aaab28,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-bb206183-bf3c-4332-b6f6-fc1c0722c0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6206
