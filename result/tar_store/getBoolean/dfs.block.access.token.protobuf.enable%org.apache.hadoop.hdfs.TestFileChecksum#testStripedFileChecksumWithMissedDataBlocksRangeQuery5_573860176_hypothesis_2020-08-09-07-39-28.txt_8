reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330455887-172.17.0.5-1596958980692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-31f615b7-0ccc-46be-9f0e-fd6e8a8ef56c,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-14eca8f8-9ed6-4072-89ac-65704d9c3188,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-ddb20914-127c-4cd9-b4d0-f1cde47e8d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-35a8e509-c93b-4aaf-8bf8-9c128b3529c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-b82b13cb-14a7-4e4a-b2f5-c6d94655bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-e4fc55e8-0e82-4bbd-aca4-c5cc3dedb558,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-87ccac6c-addf-4b03-8bf4-5d87fc1191df,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-4e4c08ad-b2cb-40af-aec0-ee5e56517f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330455887-172.17.0.5-1596958980692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-31f615b7-0ccc-46be-9f0e-fd6e8a8ef56c,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-14eca8f8-9ed6-4072-89ac-65704d9c3188,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-ddb20914-127c-4cd9-b4d0-f1cde47e8d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-35a8e509-c93b-4aaf-8bf8-9c128b3529c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-b82b13cb-14a7-4e4a-b2f5-c6d94655bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-e4fc55e8-0e82-4bbd-aca4-c5cc3dedb558,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-87ccac6c-addf-4b03-8bf4-5d87fc1191df,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-4e4c08ad-b2cb-40af-aec0-ee5e56517f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567918496-172.17.0.5-1596959194492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46350,DS-d2368961-0704-4570-b51b-5feed663e748,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-aeb936e9-7de3-43ef-a6f3-df6e30b4b9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-9d9a9ba3-0917-444e-bd1a-46faa8683814,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-635bd7c7-e289-4185-a9f8-1712fbb4e651,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-47101d0f-4886-4e6a-beb8-74b9ab56a5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-4d1ae128-e666-4a4b-80e8-8a51c93971f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-b8ce896b-89a2-4a57-83c9-a513fb3d61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-750654bc-072e-4585-908c-21ef54c3afa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567918496-172.17.0.5-1596959194492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46350,DS-d2368961-0704-4570-b51b-5feed663e748,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-aeb936e9-7de3-43ef-a6f3-df6e30b4b9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-9d9a9ba3-0917-444e-bd1a-46faa8683814,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-635bd7c7-e289-4185-a9f8-1712fbb4e651,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-47101d0f-4886-4e6a-beb8-74b9ab56a5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-4d1ae128-e666-4a4b-80e8-8a51c93971f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-b8ce896b-89a2-4a57-83c9-a513fb3d61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-750654bc-072e-4585-908c-21ef54c3afa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335482789-172.17.0.5-1596959344467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-f2f07b5b-bfd3-44dc-8985-d607ae1f8442,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-836b9c99-f694-4006-a59d-37967d766ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-9f8eb097-1da9-4c4a-8937-802b49093d60,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-631921d1-8392-430c-9fe7-eea3c44eac56,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-86e2383e-f893-4ce9-86e1-269ae775ca74,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-a27c07da-41cd-47c1-8fad-9b786e8b39ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-b3365299-0f2d-40e1-9fd0-fb39b8ee88d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-c7fa8927-d286-4075-a641-946f053221d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335482789-172.17.0.5-1596959344467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43360,DS-f2f07b5b-bfd3-44dc-8985-d607ae1f8442,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-836b9c99-f694-4006-a59d-37967d766ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-9f8eb097-1da9-4c4a-8937-802b49093d60,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-631921d1-8392-430c-9fe7-eea3c44eac56,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-86e2383e-f893-4ce9-86e1-269ae775ca74,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-a27c07da-41cd-47c1-8fad-9b786e8b39ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-b3365299-0f2d-40e1-9fd0-fb39b8ee88d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-c7fa8927-d286-4075-a641-946f053221d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457745455-172.17.0.5-1596959589559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-a68da571-f4e5-4d20-9e22-5ac40912568c,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-74c4d032-15b4-430f-9fa1-cc3a3ac2d225,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-9d9707df-5546-4bc6-bf2e-67c4f090ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-8e4e66ca-ee77-4f0e-b2dd-6e735dfce351,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1d78f0a6-8a11-4427-ab92-7b1571f066be,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-aad78e7e-1859-49fa-8bd0-b63c296ef5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-e8ad08db-819d-456d-bb26-cebf07ae301a,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-c24d85d8-1db9-4429-a04c-ae3a5280d26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457745455-172.17.0.5-1596959589559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-a68da571-f4e5-4d20-9e22-5ac40912568c,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-74c4d032-15b4-430f-9fa1-cc3a3ac2d225,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-9d9707df-5546-4bc6-bf2e-67c4f090ced8,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-8e4e66ca-ee77-4f0e-b2dd-6e735dfce351,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1d78f0a6-8a11-4427-ab92-7b1571f066be,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-aad78e7e-1859-49fa-8bd0-b63c296ef5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-e8ad08db-819d-456d-bb26-cebf07ae301a,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-c24d85d8-1db9-4429-a04c-ae3a5280d26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780904905-172.17.0.5-1596959882382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40227,DS-aad8266d-38bd-439f-b205-f3bf8efda5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-920fb893-9656-4e81-8ac5-5a56f3c1c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-2bdf0223-916a-4c3d-91e4-2063f3143a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-aff2a1be-5e92-4ad3-9977-d46918e0c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-777039a5-963b-405e-99a7-8abbee732470,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-56098fff-10ad-4f50-99b5-1bb53bb1634c,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-a87ef0ba-d733-4b75-a019-c4fdb29a9e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-b204063e-c175-477a-9d1f-0798dd957da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780904905-172.17.0.5-1596959882382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40227,DS-aad8266d-38bd-439f-b205-f3bf8efda5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-920fb893-9656-4e81-8ac5-5a56f3c1c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-2bdf0223-916a-4c3d-91e4-2063f3143a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-aff2a1be-5e92-4ad3-9977-d46918e0c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-777039a5-963b-405e-99a7-8abbee732470,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-56098fff-10ad-4f50-99b5-1bb53bb1634c,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-a87ef0ba-d733-4b75-a019-c4fdb29a9e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-b204063e-c175-477a-9d1f-0798dd957da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620325138-172.17.0.5-1596959940063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-b9e9b6e2-f67b-417a-ba40-3fe1af3ba1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-bf52cb66-ca85-4d35-817b-d8dec062e929,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-19e64419-6ed2-41e0-a5a1-a3daf4102ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-78b42e13-3801-432a-9da5-f8dc062102bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-638ae2fa-fcc0-474b-9e43-aff92433d4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-b98f470f-7ea4-4af9-89ab-18d3c5cdc54a,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-4d54a07d-fc00-4e56-a668-274e655cb02d,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-4e7bf76a-aa54-4319-8979-c290312a75e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620325138-172.17.0.5-1596959940063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-b9e9b6e2-f67b-417a-ba40-3fe1af3ba1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-bf52cb66-ca85-4d35-817b-d8dec062e929,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-19e64419-6ed2-41e0-a5a1-a3daf4102ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-78b42e13-3801-432a-9da5-f8dc062102bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-638ae2fa-fcc0-474b-9e43-aff92433d4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-b98f470f-7ea4-4af9-89ab-18d3c5cdc54a,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-4d54a07d-fc00-4e56-a668-274e655cb02d,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-4e7bf76a-aa54-4319-8979-c290312a75e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690375118-172.17.0.5-1596960071091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44455,DS-97e2b7d9-5637-41c3-ad48-c7e865da7103,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-a7ff430d-dc5f-4104-8f9a-2ed2271f3ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-cf9a27c4-03d1-4226-886c-77c189faa41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-f86a1a58-d558-47e5-bf6d-650337852d29,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-d08d7ac3-82e8-476a-8fa2-18f28e6edff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-ba17d689-42eb-4a5d-8f10-95ab562381d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-f70c148d-38d1-4f11-89f5-cc20ef65eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-e55c7d19-eff7-4047-a765-6d334cd58ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690375118-172.17.0.5-1596960071091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44455,DS-97e2b7d9-5637-41c3-ad48-c7e865da7103,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-a7ff430d-dc5f-4104-8f9a-2ed2271f3ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-cf9a27c4-03d1-4226-886c-77c189faa41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-f86a1a58-d558-47e5-bf6d-650337852d29,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-d08d7ac3-82e8-476a-8fa2-18f28e6edff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-ba17d689-42eb-4a5d-8f10-95ab562381d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-f70c148d-38d1-4f11-89f5-cc20ef65eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-e55c7d19-eff7-4047-a765-6d334cd58ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961604801-172.17.0.5-1596960095656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38156,DS-6bc5f5bc-fe2e-43f8-bd5a-7b6c9fa5e24e,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-2604c295-5734-496a-9950-033e228b2529,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-2e425ff5-b916-4883-a1e0-3efca638ce7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-9215641a-aa13-4bdd-aff3-f0eb266b0723,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-2fe1ccbc-fdb3-43ed-bfb5-1d2d975b4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-fbc87996-2af7-435f-a9b4-ee88c6507e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-85b45b7e-2056-4df4-8807-146ed134c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-e111a06f-00cd-45dc-8168-1c071556532c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961604801-172.17.0.5-1596960095656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38156,DS-6bc5f5bc-fe2e-43f8-bd5a-7b6c9fa5e24e,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-2604c295-5734-496a-9950-033e228b2529,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-2e425ff5-b916-4883-a1e0-3efca638ce7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-9215641a-aa13-4bdd-aff3-f0eb266b0723,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-2fe1ccbc-fdb3-43ed-bfb5-1d2d975b4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-fbc87996-2af7-435f-a9b4-ee88c6507e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-85b45b7e-2056-4df4-8807-146ed134c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-e111a06f-00cd-45dc-8168-1c071556532c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948436240-172.17.0.5-1596960255509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37739,DS-0c81085c-0a5b-4d4c-871c-e464eb4af350,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-41fd03a6-5b12-431a-9a52-b5d51d4e330e,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-2b370d8f-9b39-47da-bf9f-03838e711f60,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-4e869faa-3dc9-4ad8-bd4c-e3ad04824c47,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-90cd2615-3282-469c-8c9c-867763b16255,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-58121416-c62e-46d0-9402-942d85348533,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-63525eb3-f7a6-4b23-aa95-b9d8280f88b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-c20957f6-eaf2-4780-9eb7-0623174b29f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948436240-172.17.0.5-1596960255509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37739,DS-0c81085c-0a5b-4d4c-871c-e464eb4af350,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-41fd03a6-5b12-431a-9a52-b5d51d4e330e,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-2b370d8f-9b39-47da-bf9f-03838e711f60,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-4e869faa-3dc9-4ad8-bd4c-e3ad04824c47,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-90cd2615-3282-469c-8c9c-867763b16255,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-58121416-c62e-46d0-9402-942d85348533,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-63525eb3-f7a6-4b23-aa95-b9d8280f88b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-c20957f6-eaf2-4780-9eb7-0623174b29f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531563494-172.17.0.5-1596960409362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-0e6b30b2-64db-4b58-8752-6b968663e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-0453ecba-ce1e-4c38-9207-7dcbd17277b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-2a4037de-7f70-41cb-9979-80fcb2340bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-62bde4f1-c956-422e-aec6-241fe5477c75,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-2f8a2cb8-277e-4d63-b47a-4640b81487bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-d9830781-d6d1-43db-9c12-12921d0ff9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-f7429d52-bd4d-4b70-86de-67f4f9f26c48,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-58ccdcbd-e6d3-438a-a249-6be38b933a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531563494-172.17.0.5-1596960409362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-0e6b30b2-64db-4b58-8752-6b968663e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-0453ecba-ce1e-4c38-9207-7dcbd17277b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-2a4037de-7f70-41cb-9979-80fcb2340bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-62bde4f1-c956-422e-aec6-241fe5477c75,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-2f8a2cb8-277e-4d63-b47a-4640b81487bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-d9830781-d6d1-43db-9c12-12921d0ff9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-f7429d52-bd4d-4b70-86de-67f4f9f26c48,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-58ccdcbd-e6d3-438a-a249-6be38b933a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079356249-172.17.0.5-1596960488618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-8e4f6595-58c7-4d98-8135-72540dcd2c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-d451309b-657e-45ec-87b0-7c256ce024be,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-1eeb2138-0a23-4ede-b66f-c1bec2fceabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-e2d10141-dd28-4187-829a-afc67c299566,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-e96554b5-fe0d-4f41-9e80-baa05e751910,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-8644c593-b56b-41d9-bc4f-3f9d193c04e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-115fcdc9-7df6-450e-aed9-97918b8a5dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-899209b9-49fc-466f-b35a-e839b3ff5fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079356249-172.17.0.5-1596960488618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34823,DS-8e4f6595-58c7-4d98-8135-72540dcd2c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-d451309b-657e-45ec-87b0-7c256ce024be,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-1eeb2138-0a23-4ede-b66f-c1bec2fceabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-e2d10141-dd28-4187-829a-afc67c299566,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-e96554b5-fe0d-4f41-9e80-baa05e751910,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-8644c593-b56b-41d9-bc4f-3f9d193c04e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-115fcdc9-7df6-450e-aed9-97918b8a5dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-899209b9-49fc-466f-b35a-e839b3ff5fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060463880-172.17.0.5-1596960565890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-69ccf30a-2d23-40a0-a4e2-02fc8bfc4c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-7407f92e-8484-47d6-a3ec-0061a44f2eda,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-8d922296-d952-45fa-a0a1-9e2880084cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-14597ed0-2540-4218-980a-0ad5a6e2d1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-2e1c582a-c85e-47fc-954a-449677665ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-36081cb6-d0f0-40b5-819d-48a39125d8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-06e3d24d-b9d5-4cfb-a972-d9be1798b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-f633211d-1ce3-4652-a3a7-3040e93e65c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060463880-172.17.0.5-1596960565890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-69ccf30a-2d23-40a0-a4e2-02fc8bfc4c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-7407f92e-8484-47d6-a3ec-0061a44f2eda,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-8d922296-d952-45fa-a0a1-9e2880084cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-14597ed0-2540-4218-980a-0ad5a6e2d1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-2e1c582a-c85e-47fc-954a-449677665ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-36081cb6-d0f0-40b5-819d-48a39125d8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-06e3d24d-b9d5-4cfb-a972-d9be1798b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-f633211d-1ce3-4652-a3a7-3040e93e65c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916039747-172.17.0.5-1596960646723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-7bbcaa1d-c296-47e1-91ee-657d710912e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-50f305f5-c9cf-4315-9c31-be99ec7999c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-3b25fb2a-ccb9-46da-999e-8f10cc53c3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-6d8b755c-ef20-4941-b2ee-66042d0c114b,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-f19560d7-78e7-47e1-b7dc-f5e84ef7d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-288a71b5-c943-4254-b5cd-75a1cdb44889,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-c7bf4c39-2397-4ea2-92ea-2763f9d8c575,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-93a4835d-ec3a-40b6-a550-63658c31506f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916039747-172.17.0.5-1596960646723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-7bbcaa1d-c296-47e1-91ee-657d710912e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-50f305f5-c9cf-4315-9c31-be99ec7999c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-3b25fb2a-ccb9-46da-999e-8f10cc53c3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-6d8b755c-ef20-4941-b2ee-66042d0c114b,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-f19560d7-78e7-47e1-b7dc-f5e84ef7d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-288a71b5-c943-4254-b5cd-75a1cdb44889,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-c7bf4c39-2397-4ea2-92ea-2763f9d8c575,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-93a4835d-ec3a-40b6-a550-63658c31506f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889677862-172.17.0.5-1596960825735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36311,DS-d0423ffb-ff14-49f6-b551-ded403b2e707,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-01189aae-459f-414c-a1f4-405b38c8abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-e77486ea-2e0b-484d-96b1-7c5a2834419e,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-7f0652fd-21cb-4c85-9eac-2d6eb5d6bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-ea9e9723-90a8-4d9f-83c3-d06556dd4936,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-2c4eb0e8-7dbd-41e0-86aa-2acb0ab48ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-70afaa65-9be9-4af3-accd-97ca828eea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-5fcf8e57-5630-49bb-8188-6dc2f8e43900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889677862-172.17.0.5-1596960825735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36311,DS-d0423ffb-ff14-49f6-b551-ded403b2e707,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-01189aae-459f-414c-a1f4-405b38c8abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-e77486ea-2e0b-484d-96b1-7c5a2834419e,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-7f0652fd-21cb-4c85-9eac-2d6eb5d6bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-ea9e9723-90a8-4d9f-83c3-d06556dd4936,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-2c4eb0e8-7dbd-41e0-86aa-2acb0ab48ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-70afaa65-9be9-4af3-accd-97ca828eea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-5fcf8e57-5630-49bb-8188-6dc2f8e43900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39615153-172.17.0.5-1596961175264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43397,DS-228b9e7c-9e7d-4743-9116-43aa5879d223,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-c58c4a52-5398-4594-9f40-32767818017a,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-928cad59-4b56-425d-ac84-39ab543ad379,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-851c0c9c-126e-4faf-ad33-3a9fb59aee41,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-879506cf-52f4-41df-9db6-7bf202dcaeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-26db9673-8a0d-41a3-9814-2fb1f5d5a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-e5c8db40-2652-461c-a87f-08923a2437dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-8c3e7d9b-6cff-4b71-915e-c113a6472ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39615153-172.17.0.5-1596961175264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43397,DS-228b9e7c-9e7d-4743-9116-43aa5879d223,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-c58c4a52-5398-4594-9f40-32767818017a,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-928cad59-4b56-425d-ac84-39ab543ad379,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-851c0c9c-126e-4faf-ad33-3a9fb59aee41,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-879506cf-52f4-41df-9db6-7bf202dcaeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-26db9673-8a0d-41a3-9814-2fb1f5d5a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-e5c8db40-2652-461c-a87f-08923a2437dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-8c3e7d9b-6cff-4b71-915e-c113a6472ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134410113-172.17.0.5-1596961201263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41951,DS-a1ae7bc5-9d2e-4957-bc78-b383f85cd746,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-8717b43b-79ab-4eb6-a38a-54c473795a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-ef4da0e3-e7b2-416c-b742-404c6b4c64ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-4f66e426-82bf-47ea-bd16-b90b935d0988,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-91935b77-84dc-48c1-ae72-0e21857da1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-955a9d38-1686-4df4-b7e6-6d5df561c26b,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-038aa642-f02e-4d17-9762-deb56511c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-ced9ce4f-55f6-4322-8bef-04069d02bc25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134410113-172.17.0.5-1596961201263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41951,DS-a1ae7bc5-9d2e-4957-bc78-b383f85cd746,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-8717b43b-79ab-4eb6-a38a-54c473795a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-ef4da0e3-e7b2-416c-b742-404c6b4c64ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-4f66e426-82bf-47ea-bd16-b90b935d0988,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-91935b77-84dc-48c1-ae72-0e21857da1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-955a9d38-1686-4df4-b7e6-6d5df561c26b,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-038aa642-f02e-4d17-9762-deb56511c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-ced9ce4f-55f6-4322-8bef-04069d02bc25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530075579-172.17.0.5-1596961416097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-539e8411-bdee-473e-8b89-e42614e91fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-f2387f30-8ff9-4be4-a6f6-39738cd27e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-3fea18ce-cbb6-4b8e-b43c-d458057855d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-55f41568-bc81-4076-a924-657fb3af28ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-b7af943f-9e17-485c-bc3e-31fd4e5e65e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-7b64aeb3-2d7b-482e-ae30-5b350d189b89,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-f9db92d8-421b-4a19-8372-ce4f94b686a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-bff84575-9383-4bc9-b371-40d237ed00c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530075579-172.17.0.5-1596961416097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-539e8411-bdee-473e-8b89-e42614e91fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-f2387f30-8ff9-4be4-a6f6-39738cd27e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-3fea18ce-cbb6-4b8e-b43c-d458057855d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-55f41568-bc81-4076-a924-657fb3af28ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-b7af943f-9e17-485c-bc3e-31fd4e5e65e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-7b64aeb3-2d7b-482e-ae30-5b350d189b89,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-f9db92d8-421b-4a19-8372-ce4f94b686a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-bff84575-9383-4bc9-b371-40d237ed00c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343460751-172.17.0.5-1596961495826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-f7a297b3-d10c-4043-9f44-f35ef3070d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-99a52085-b58a-4888-91a1-a91a189e2d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-730b87c0-92a2-42ef-9553-750a2bf78548,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-e7a1afb7-f8d3-4476-b09b-ae2bf2b9757b,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-7b5eddb6-7d9c-411c-b135-9437c584b282,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-0046318b-967e-484a-8d89-54916986f8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-17d81c57-9c84-4d36-893b-260c2cd21980,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-f386056b-5917-4055-964e-49d8f1dba6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343460751-172.17.0.5-1596961495826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-f7a297b3-d10c-4043-9f44-f35ef3070d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-99a52085-b58a-4888-91a1-a91a189e2d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-730b87c0-92a2-42ef-9553-750a2bf78548,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-e7a1afb7-f8d3-4476-b09b-ae2bf2b9757b,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-7b5eddb6-7d9c-411c-b135-9437c584b282,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-0046318b-967e-484a-8d89-54916986f8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-17d81c57-9c84-4d36-893b-260c2cd21980,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-f386056b-5917-4055-964e-49d8f1dba6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579034658-172.17.0.5-1596961795622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-f3af23d3-9a9e-407a-9911-08dd68a71fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-f245e118-c3f0-4d9e-ad89-817be352639e,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-c24874be-b21a-467d-81b7-f22c88222b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-646ebfa4-3109-4424-a4ca-fe0739d8372a,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-32a1d52e-f195-40c9-8526-d83549a30281,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-938d7685-cffb-48a5-8d99-d663699cfdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-ffb82939-861a-4f77-8c72-17f51c89c298,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-c407eb92-6755-4f4d-a89d-404b8ba6f350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579034658-172.17.0.5-1596961795622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-f3af23d3-9a9e-407a-9911-08dd68a71fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-f245e118-c3f0-4d9e-ad89-817be352639e,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-c24874be-b21a-467d-81b7-f22c88222b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-646ebfa4-3109-4424-a4ca-fe0739d8372a,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-32a1d52e-f195-40c9-8526-d83549a30281,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-938d7685-cffb-48a5-8d99-d663699cfdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-ffb82939-861a-4f77-8c72-17f51c89c298,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-c407eb92-6755-4f4d-a89d-404b8ba6f350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467707354-172.17.0.5-1596962043572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32828,DS-0beb9969-a045-4b4e-baa7-6b6137b36cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-bd05dd35-ae93-4ef4-a898-fd11e07a4b46,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-e68bed5b-bab9-4ecd-8179-b1550e936729,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-dc2a923d-d615-44a8-8046-1c97d86ba35b,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-b8a20ac2-2544-4664-b652-2d2e38fa4860,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-4c0b8215-f3ae-4ba0-9557-bb3c98f01440,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-45da9ea1-772c-45d0-b3f0-b3089f15b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-a5bef109-b46e-4ad5-bd14-f8be6882c09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467707354-172.17.0.5-1596962043572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32828,DS-0beb9969-a045-4b4e-baa7-6b6137b36cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-bd05dd35-ae93-4ef4-a898-fd11e07a4b46,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-e68bed5b-bab9-4ecd-8179-b1550e936729,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-dc2a923d-d615-44a8-8046-1c97d86ba35b,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-b8a20ac2-2544-4664-b652-2d2e38fa4860,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-4c0b8215-f3ae-4ba0-9557-bb3c98f01440,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-45da9ea1-772c-45d0-b3f0-b3089f15b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-a5bef109-b46e-4ad5-bd14-f8be6882c09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203837641-172.17.0.5-1596962248031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-7042cf37-2e72-48da-855b-e50eabc94f54,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-3a065b49-287c-4e5e-bdab-81b7cdf0777f,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-55166911-54f1-4bf0-a946-92a94e110b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-d99aa395-71f2-49f4-9dab-b89c5bccf223,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-9f9a8a88-345c-46a7-8e10-37417e4b7482,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-2538090b-0705-437a-bd9f-ea204607d658,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-6705ae7e-3ac0-400c-a419-cd7516620d71,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-18eb5a1f-7928-4606-bd3c-936d2c461bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203837641-172.17.0.5-1596962248031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-7042cf37-2e72-48da-855b-e50eabc94f54,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-3a065b49-287c-4e5e-bdab-81b7cdf0777f,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-55166911-54f1-4bf0-a946-92a94e110b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-d99aa395-71f2-49f4-9dab-b89c5bccf223,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-9f9a8a88-345c-46a7-8e10-37417e4b7482,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-2538090b-0705-437a-bd9f-ea204607d658,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-6705ae7e-3ac0-400c-a419-cd7516620d71,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-18eb5a1f-7928-4606-bd3c-936d2c461bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276249694-172.17.0.5-1596962632705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-3477fa00-1ede-4c38-bee2-b35f9a73f914,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-deba203e-22ce-428b-bdf1-596f5de47146,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-ffd02361-d544-4002-9908-573c2194ec2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-373c1ba9-087b-48f6-961d-54735130ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-32058a98-36b6-45ae-a533-1bb8152b6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-014b7865-3cfd-4d01-993c-e9df04e150b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-11d29da5-d601-40c4-8e78-5b8aad295c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-8ee510f3-e27f-4777-ad04-98511f3d4101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276249694-172.17.0.5-1596962632705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-3477fa00-1ede-4c38-bee2-b35f9a73f914,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-deba203e-22ce-428b-bdf1-596f5de47146,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-ffd02361-d544-4002-9908-573c2194ec2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-373c1ba9-087b-48f6-961d-54735130ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-32058a98-36b6-45ae-a533-1bb8152b6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-014b7865-3cfd-4d01-993c-e9df04e150b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-11d29da5-d601-40c4-8e78-5b8aad295c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-8ee510f3-e27f-4777-ad04-98511f3d4101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4022
