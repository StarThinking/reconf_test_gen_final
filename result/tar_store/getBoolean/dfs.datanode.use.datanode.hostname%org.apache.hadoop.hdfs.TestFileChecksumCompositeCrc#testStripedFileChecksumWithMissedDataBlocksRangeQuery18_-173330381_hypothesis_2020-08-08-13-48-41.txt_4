reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764674982-172.17.0.16-1596894973813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39623,DS-31d9b459-297f-423e-a13f-9ec0b3ebc60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-fe8c4d15-8933-429c-803e-d6b01fcecd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-60b985c0-a1c2-42b9-a56b-1faa07183eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-5df964d1-7cbe-4a52-8991-ddbb61533857,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-545a68eb-6839-46e9-922a-6034900070be,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-77e159c0-67b1-4d52-8ddb-8bc2ab65b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-dd2fd4be-1a51-44c9-a7c1-5b3d32b50430,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-064c2c1d-fed5-425d-a506-0ffb50d257d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764674982-172.17.0.16-1596894973813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39623,DS-31d9b459-297f-423e-a13f-9ec0b3ebc60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-fe8c4d15-8933-429c-803e-d6b01fcecd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-60b985c0-a1c2-42b9-a56b-1faa07183eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-5df964d1-7cbe-4a52-8991-ddbb61533857,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-545a68eb-6839-46e9-922a-6034900070be,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-77e159c0-67b1-4d52-8ddb-8bc2ab65b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-dd2fd4be-1a51-44c9-a7c1-5b3d32b50430,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-064c2c1d-fed5-425d-a506-0ffb50d257d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990428-172.17.0.16-1596895245344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44406,DS-bc4a8602-6657-4c00-a556-ec1f691e14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-db202369-bde7-4e40-8cfe-facdf8ee8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-d2f58d27-dfd5-4472-b3e1-2c3edca8a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-5985befc-2237-4558-bd6a-65de1f92b067,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-0e5a8225-e58f-4f5e-8aba-9262a833f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-28cbdf32-8522-469c-bd3a-5c1d65a422c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-a26a975c-0a0a-486a-bdf5-3b63082fd365,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-513d7486-d6b5-4150-90ed-63ccc3d09b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990428-172.17.0.16-1596895245344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44406,DS-bc4a8602-6657-4c00-a556-ec1f691e14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-db202369-bde7-4e40-8cfe-facdf8ee8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-d2f58d27-dfd5-4472-b3e1-2c3edca8a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-5985befc-2237-4558-bd6a-65de1f92b067,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-0e5a8225-e58f-4f5e-8aba-9262a833f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-28cbdf32-8522-469c-bd3a-5c1d65a422c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-a26a975c-0a0a-486a-bdf5-3b63082fd365,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-513d7486-d6b5-4150-90ed-63ccc3d09b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809472818-172.17.0.16-1596895278394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34955,DS-228261f8-183e-4cd0-9cf0-208e1aeef497,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-27d10557-bdb7-4aa5-b74d-c9c508696be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-62fa7189-29c5-4d29-8aed-a09ff6fa903d,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-30a9e825-d5e8-4b8c-a25d-08f8dcf2dce1,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-96cce293-55f3-4ede-91c8-8bf3d0c6712e,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-086532a7-9a44-44d9-8881-db9dc334904b,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-3bd1b23c-7168-490c-bd45-9534d33b94f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-2ff978c6-7df0-4f17-aa67-8b21958cf3ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809472818-172.17.0.16-1596895278394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34955,DS-228261f8-183e-4cd0-9cf0-208e1aeef497,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-27d10557-bdb7-4aa5-b74d-c9c508696be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-62fa7189-29c5-4d29-8aed-a09ff6fa903d,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-30a9e825-d5e8-4b8c-a25d-08f8dcf2dce1,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-96cce293-55f3-4ede-91c8-8bf3d0c6712e,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-086532a7-9a44-44d9-8881-db9dc334904b,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-3bd1b23c-7168-490c-bd45-9534d33b94f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-2ff978c6-7df0-4f17-aa67-8b21958cf3ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42834276-172.17.0.16-1596895622090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44212,DS-5b41dae2-bdfc-44f4-b07f-d83e65491102,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-82e0bc6b-d2c6-462b-a38b-f6278fabad28,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-9d4da215-2abd-4ed0-9d43-8e215a00cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-17e956d9-23df-436c-ab20-dd76394149d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-2ffb99d3-0bc6-4601-9e12-5e5a4d0cb6af,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-1697357f-9c5f-4c90-bb90-d936809a01aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-17a17638-09bd-4a00-9551-bdfb7b0c3564,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-566c2a89-b7aa-442c-a960-e1ad0c0feae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42834276-172.17.0.16-1596895622090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44212,DS-5b41dae2-bdfc-44f4-b07f-d83e65491102,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-82e0bc6b-d2c6-462b-a38b-f6278fabad28,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-9d4da215-2abd-4ed0-9d43-8e215a00cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-17e956d9-23df-436c-ab20-dd76394149d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-2ffb99d3-0bc6-4601-9e12-5e5a4d0cb6af,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-1697357f-9c5f-4c90-bb90-d936809a01aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-17a17638-09bd-4a00-9551-bdfb7b0c3564,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-566c2a89-b7aa-442c-a960-e1ad0c0feae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463514953-172.17.0.16-1596895763690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35893,DS-5e1183c6-96ae-4499-be7d-7b23a6e83957,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-fa932ac8-19aa-4dc7-ae8e-2abb022f8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-9778cc90-fa45-4587-b7a7-0e201ec15873,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-04ed74fa-26c8-4157-a219-b85592c43e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-b43e2399-d098-4504-bb6b-efbdf3577f98,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-92093ec4-2cda-4990-9450-79cfe99074c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-a39e7968-190c-4d78-a652-8200bfa9874d,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-dc6e240f-127a-48eb-816f-eb098daf4bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463514953-172.17.0.16-1596895763690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35893,DS-5e1183c6-96ae-4499-be7d-7b23a6e83957,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-fa932ac8-19aa-4dc7-ae8e-2abb022f8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-9778cc90-fa45-4587-b7a7-0e201ec15873,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-04ed74fa-26c8-4157-a219-b85592c43e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-b43e2399-d098-4504-bb6b-efbdf3577f98,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-92093ec4-2cda-4990-9450-79cfe99074c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-a39e7968-190c-4d78-a652-8200bfa9874d,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-dc6e240f-127a-48eb-816f-eb098daf4bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606256967-172.17.0.16-1596895892864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45219,DS-c2fd78f4-9326-40fb-bfd3-9ebbe69928fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-c1a205b3-bd1d-453d-a99f-b7c4dfbb189f,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-cfacdefc-ee5e-4ec7-89b0-689acee192ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-747d1c2e-b83f-4e7e-9852-3a4a0683a872,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-1d50e793-d288-49c4-a318-64dbe0aac528,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-f854dab2-ecd7-4aae-89a7-f277fbd02e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-0dddce47-a66f-4921-9893-7ff30f551c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-c0e807f8-a331-4009-bf24-6ae1243cfd1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606256967-172.17.0.16-1596895892864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45219,DS-c2fd78f4-9326-40fb-bfd3-9ebbe69928fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-c1a205b3-bd1d-453d-a99f-b7c4dfbb189f,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-cfacdefc-ee5e-4ec7-89b0-689acee192ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-747d1c2e-b83f-4e7e-9852-3a4a0683a872,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-1d50e793-d288-49c4-a318-64dbe0aac528,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-f854dab2-ecd7-4aae-89a7-f277fbd02e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-0dddce47-a66f-4921-9893-7ff30f551c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-c0e807f8-a331-4009-bf24-6ae1243cfd1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284437298-172.17.0.16-1596895969132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38033,DS-2a476832-a752-4cfd-ab02-96f90ca0ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-6c3999ce-9640-447c-b47d-5980a43684c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-8f67278c-fbf3-4f4d-a8df-32cb3c673861,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-6e317183-4a60-4a5b-8de0-4db80a56f649,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-22a14f9f-5626-4364-8afa-a62b4e932642,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-aa7aaa30-86b0-4fdf-98e5-eddb50375be1,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-9d335e42-7fff-44ff-9ed1-48025a110c01,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-281904f5-35b3-48a6-973a-cca85aa1997c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284437298-172.17.0.16-1596895969132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38033,DS-2a476832-a752-4cfd-ab02-96f90ca0ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-6c3999ce-9640-447c-b47d-5980a43684c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-8f67278c-fbf3-4f4d-a8df-32cb3c673861,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-6e317183-4a60-4a5b-8de0-4db80a56f649,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-22a14f9f-5626-4364-8afa-a62b4e932642,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-aa7aaa30-86b0-4fdf-98e5-eddb50375be1,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-9d335e42-7fff-44ff-9ed1-48025a110c01,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-281904f5-35b3-48a6-973a-cca85aa1997c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325532294-172.17.0.16-1596896508164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39238,DS-190af175-7aad-4213-a49d-58cc95ec7097,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-cfed0a31-8e79-42c5-a97b-34491524ac62,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-454f48bb-3e45-40d2-94d0-642e0cd8c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-a1ed4866-0a75-4115-b32c-575e829af165,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-e6f383a4-d29e-4282-b838-e9d8ac7fcca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-f5ec0eff-a3d9-4689-9389-e8886cd7cb45,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-09b79a69-14a6-46c7-bd65-0fdc7d40d29f,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-79941ed2-28b2-432e-b6cb-47d6d9953771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325532294-172.17.0.16-1596896508164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39238,DS-190af175-7aad-4213-a49d-58cc95ec7097,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-cfed0a31-8e79-42c5-a97b-34491524ac62,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-454f48bb-3e45-40d2-94d0-642e0cd8c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-a1ed4866-0a75-4115-b32c-575e829af165,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-e6f383a4-d29e-4282-b838-e9d8ac7fcca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-f5ec0eff-a3d9-4689-9389-e8886cd7cb45,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-09b79a69-14a6-46c7-bd65-0fdc7d40d29f,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-79941ed2-28b2-432e-b6cb-47d6d9953771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762630320-172.17.0.16-1596896876390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-3b9b0f8b-6769-4b50-a9f6-41b9adb94602,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-1a14c8fa-12d5-4fee-8641-7972484557c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-d88e2ed6-5b26-4e14-8a09-5d003b55ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-407431d5-6e9c-43a2-8055-02fffe8fc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-cd317eca-f622-4ab8-9d03-fc9b22bada85,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-73f68474-43e1-4f82-ad05-a5dc97eea87f,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-d4d645a4-527f-49ca-b636-6bc5ee301131,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-8fb0bccf-3e56-4f51-b3e1-bd9a5890f425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762630320-172.17.0.16-1596896876390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-3b9b0f8b-6769-4b50-a9f6-41b9adb94602,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-1a14c8fa-12d5-4fee-8641-7972484557c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-d88e2ed6-5b26-4e14-8a09-5d003b55ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-407431d5-6e9c-43a2-8055-02fffe8fc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-cd317eca-f622-4ab8-9d03-fc9b22bada85,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-73f68474-43e1-4f82-ad05-a5dc97eea87f,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-d4d645a4-527f-49ca-b636-6bc5ee301131,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-8fb0bccf-3e56-4f51-b3e1-bd9a5890f425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519681934-172.17.0.16-1596897043540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-db2fb1a5-8f26-4d7a-843e-5515e2dd8d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-cc1378f0-e70a-4c3d-9cee-3b1d32681494,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-03bee2f7-722a-42a6-9d4f-df4f2fd7a056,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-4ad5e0e0-6794-4a45-91ee-5a1fb0fe6528,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-5ca4b214-138f-473c-a260-da21981de589,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-43d887f9-9564-4165-93f7-167e1a5d3f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-6b4bce6c-555b-437f-9a9c-4bba1313919f,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-6b41f725-2d9a-4f25-9616-d26aa6e737d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519681934-172.17.0.16-1596897043540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-db2fb1a5-8f26-4d7a-843e-5515e2dd8d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-cc1378f0-e70a-4c3d-9cee-3b1d32681494,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-03bee2f7-722a-42a6-9d4f-df4f2fd7a056,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-4ad5e0e0-6794-4a45-91ee-5a1fb0fe6528,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-5ca4b214-138f-473c-a260-da21981de589,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-43d887f9-9564-4165-93f7-167e1a5d3f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-6b4bce6c-555b-437f-9a9c-4bba1313919f,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-6b41f725-2d9a-4f25-9616-d26aa6e737d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203857445-172.17.0.16-1596897261453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36768,DS-a9fb5eb5-1595-45f9-b097-9d15372b4b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-cd749478-4ffd-4716-8fd9-482aa4a0698b,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-efd535ab-ba4a-414a-b004-81d0181f4745,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-06850c20-4179-4294-8452-0ab8736cb598,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-4d133edd-ee9b-4a9b-aeec-285bb71df31b,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-e264f375-fb35-4589-a647-cd23662e06e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-6b2621c9-c794-4056-af98-6f2cde2e36da,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-4587b4c3-b42d-405e-8ffc-7d5010c2dca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203857445-172.17.0.16-1596897261453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36768,DS-a9fb5eb5-1595-45f9-b097-9d15372b4b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-cd749478-4ffd-4716-8fd9-482aa4a0698b,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-efd535ab-ba4a-414a-b004-81d0181f4745,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-06850c20-4179-4294-8452-0ab8736cb598,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-4d133edd-ee9b-4a9b-aeec-285bb71df31b,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-e264f375-fb35-4589-a647-cd23662e06e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-6b2621c9-c794-4056-af98-6f2cde2e36da,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-4587b4c3-b42d-405e-8ffc-7d5010c2dca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166376195-172.17.0.16-1596897553020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43769,DS-cdd438fa-da07-487f-a10d-3894e0c16625,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-5c8b748d-f923-4a22-b126-d581af9b2848,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-94f15d22-1e4e-43b9-97eb-fa21e5aa7140,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-ad88b076-6f18-4400-bb08-330d9a32fab3,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-bbeb4a04-713c-4315-b1f9-889609b5e967,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-633c6877-66f8-44eb-9ae8-82de70076bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-a3268b5e-5475-4b09-b66c-87037b7fb7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-eaafb9ee-cbf1-4e82-8758-8a40c538aa2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166376195-172.17.0.16-1596897553020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43769,DS-cdd438fa-da07-487f-a10d-3894e0c16625,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-5c8b748d-f923-4a22-b126-d581af9b2848,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-94f15d22-1e4e-43b9-97eb-fa21e5aa7140,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-ad88b076-6f18-4400-bb08-330d9a32fab3,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-bbeb4a04-713c-4315-b1f9-889609b5e967,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-633c6877-66f8-44eb-9ae8-82de70076bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-a3268b5e-5475-4b09-b66c-87037b7fb7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-eaafb9ee-cbf1-4e82-8758-8a40c538aa2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919388912-172.17.0.16-1596898367201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-84b71db1-c84c-4ed4-85be-b9c24793893b,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-2264bbe0-1897-4225-9a41-9272f8f14cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-be0cd77f-ff24-46ac-9bc3-598756d28acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-3cbc50cd-9738-48a4-b495-01c44412e4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-26d95aad-1a88-4a95-b4dc-8668b9a114a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-5c09fe8e-4ca2-4d40-8647-78d044329eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-445f5df5-a923-48a4-ba01-0844f9c5bae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-e51defea-39fd-4b6c-974e-12c9ddb69ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919388912-172.17.0.16-1596898367201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-84b71db1-c84c-4ed4-85be-b9c24793893b,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-2264bbe0-1897-4225-9a41-9272f8f14cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-be0cd77f-ff24-46ac-9bc3-598756d28acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-3cbc50cd-9738-48a4-b495-01c44412e4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-26d95aad-1a88-4a95-b4dc-8668b9a114a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-5c09fe8e-4ca2-4d40-8647-78d044329eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-445f5df5-a923-48a4-ba01-0844f9c5bae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-e51defea-39fd-4b6c-974e-12c9ddb69ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898670101-172.17.0.16-1596898783646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43343,DS-0fc11f29-3118-42ea-9ef5-5e28d1434fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-e32db7ae-932c-4de9-adc1-f334dd615d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-993b7dbb-7b62-456c-8f3d-364ec43a3aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-450d2f05-0d07-4292-b5dc-2e1fef695a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-638c3720-847d-436a-94b2-24a14e983198,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-0acf5940-c865-47c4-9ecd-9917fefb92f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-af01dd69-9e87-446a-9f98-3532ad907349,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-b07fbbd0-d266-4204-b175-81ced9a69c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898670101-172.17.0.16-1596898783646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43343,DS-0fc11f29-3118-42ea-9ef5-5e28d1434fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-e32db7ae-932c-4de9-adc1-f334dd615d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-993b7dbb-7b62-456c-8f3d-364ec43a3aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-450d2f05-0d07-4292-b5dc-2e1fef695a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-638c3720-847d-436a-94b2-24a14e983198,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-0acf5940-c865-47c4-9ecd-9917fefb92f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-af01dd69-9e87-446a-9f98-3532ad907349,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-b07fbbd0-d266-4204-b175-81ced9a69c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124447937-172.17.0.16-1596899088758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-151021c8-4c7f-45e1-91e3-c2ef10bdb937,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-bb2b874c-5052-4595-ad18-19b387982bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-1e4eae14-e2be-474f-9628-66b28b03b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-ba8bc901-e63c-47fa-ae6f-3f0a67b7b8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-a16e51e6-bd81-4a1d-8361-85f869063c13,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-b1c19b1d-223f-444b-86ba-b1797abae5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-d87b724a-96ff-4ab8-9ee9-5048049362d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-72120edd-4962-4431-b8d0-63627c091129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124447937-172.17.0.16-1596899088758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-151021c8-4c7f-45e1-91e3-c2ef10bdb937,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-bb2b874c-5052-4595-ad18-19b387982bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-1e4eae14-e2be-474f-9628-66b28b03b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-ba8bc901-e63c-47fa-ae6f-3f0a67b7b8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-a16e51e6-bd81-4a1d-8361-85f869063c13,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-b1c19b1d-223f-444b-86ba-b1797abae5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-d87b724a-96ff-4ab8-9ee9-5048049362d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-72120edd-4962-4431-b8d0-63627c091129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24663155-172.17.0.16-1596899381721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-ed84c1b6-658a-447b-bbd1-e9be9397708b,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-681d2623-fbc5-46c9-b280-cb0db23e68e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-1d5b761c-6fcd-42b5-8e06-2e8e117690f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-ee342a67-fe89-44d5-8d37-337627b59ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-2621781d-db40-49a7-8359-e981d36c6ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-f7aee36a-2a4a-4ef7-982a-fbb011e5d3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-d7e32fe5-60b6-4d5d-8138-f04151501ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-77afad78-220f-431e-895b-ff5587c7eaab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24663155-172.17.0.16-1596899381721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-ed84c1b6-658a-447b-bbd1-e9be9397708b,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-681d2623-fbc5-46c9-b280-cb0db23e68e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-1d5b761c-6fcd-42b5-8e06-2e8e117690f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-ee342a67-fe89-44d5-8d37-337627b59ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-2621781d-db40-49a7-8359-e981d36c6ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-f7aee36a-2a4a-4ef7-982a-fbb011e5d3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-d7e32fe5-60b6-4d5d-8138-f04151501ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-77afad78-220f-431e-895b-ff5587c7eaab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5237
