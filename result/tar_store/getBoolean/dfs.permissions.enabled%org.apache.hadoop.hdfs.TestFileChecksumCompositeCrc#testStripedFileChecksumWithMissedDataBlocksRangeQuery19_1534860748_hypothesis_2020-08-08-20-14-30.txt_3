reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821765992-172.17.0.14-1596918213480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-879dcefa-2b23-43fd-b267-74beb28ab49b,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-47e694a3-ce5e-4f54-b61f-0c7d36f18bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-42c31a5d-8457-4a00-a97e-30bddf20d2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-6cb663a8-165a-423c-b20a-f5bb80366c92,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-e16ccbff-ca26-4bb8-be7e-10bf31f941cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-7b76dda7-3e0b-4ac6-98f7-ea9e125999cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-eb0d3ccd-6937-49d3-b0d3-5577c4f46f00,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-8e824f8a-b9ca-4aff-b26e-04642b83dfe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821765992-172.17.0.14-1596918213480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-879dcefa-2b23-43fd-b267-74beb28ab49b,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-47e694a3-ce5e-4f54-b61f-0c7d36f18bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-42c31a5d-8457-4a00-a97e-30bddf20d2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-6cb663a8-165a-423c-b20a-f5bb80366c92,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-e16ccbff-ca26-4bb8-be7e-10bf31f941cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-7b76dda7-3e0b-4ac6-98f7-ea9e125999cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-eb0d3ccd-6937-49d3-b0d3-5577c4f46f00,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-8e824f8a-b9ca-4aff-b26e-04642b83dfe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131184320-172.17.0.14-1596918511189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-bfcfba9e-39ab-4237-8f44-f300efca4f16,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-c05755a0-1d83-44be-bbeb-09ed76b23ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-d6432dda-17fd-4d6d-a439-c459db61c6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-35f0c9ef-43a4-4fa1-afc5-ae17d9f1c095,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-d813cffe-d679-4644-982d-9003a8c31e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-c5bd3c9e-01cb-484b-90e8-6b348cedde5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-203f38d4-8876-49f9-9eb5-004e1b6de65e,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-95e4df96-beb7-45fb-9e9d-7d85609325ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131184320-172.17.0.14-1596918511189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-bfcfba9e-39ab-4237-8f44-f300efca4f16,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-c05755a0-1d83-44be-bbeb-09ed76b23ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-d6432dda-17fd-4d6d-a439-c459db61c6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-35f0c9ef-43a4-4fa1-afc5-ae17d9f1c095,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-d813cffe-d679-4644-982d-9003a8c31e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-c5bd3c9e-01cb-484b-90e8-6b348cedde5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-203f38d4-8876-49f9-9eb5-004e1b6de65e,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-95e4df96-beb7-45fb-9e9d-7d85609325ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168434132-172.17.0.14-1596918789946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-e1211413-887d-454a-9694-bd75230e69ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-36d5a5a1-1e2a-48ae-80c7-6d3473f70fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-406730ee-01e8-49f0-bb20-c68a4778a809,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-9a5d5ccd-6a1e-40a0-92a7-553876caf047,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-4ba23249-dc3b-449a-a190-cefb64b5c5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-43739dfb-a277-4194-9709-987f8a01fdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-60a851e5-b10c-4cef-b8f2-a58912c9675c,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-422db31f-eadf-429c-b762-13a516653ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168434132-172.17.0.14-1596918789946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-e1211413-887d-454a-9694-bd75230e69ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-36d5a5a1-1e2a-48ae-80c7-6d3473f70fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-406730ee-01e8-49f0-bb20-c68a4778a809,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-9a5d5ccd-6a1e-40a0-92a7-553876caf047,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-4ba23249-dc3b-449a-a190-cefb64b5c5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-43739dfb-a277-4194-9709-987f8a01fdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-60a851e5-b10c-4cef-b8f2-a58912c9675c,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-422db31f-eadf-429c-b762-13a516653ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533912332-172.17.0.14-1596919551138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33803,DS-42277d4e-f6ca-40d6-9ed7-ae7f4990909a,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-0e4735f7-0bb2-479a-a22d-8ca4c378f18c,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-bf359081-128e-49b6-96d1-e7d9924b8d52,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-1e9ee96d-40e3-4bed-a731-d7213a3351ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-c715333d-2e7b-4ef8-93c7-3f9be7dc7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-8673affd-8fb9-4ed8-ad1e-db2bbdd3792d,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-38930ea5-8298-43b6-83f8-73cdf7bcb260,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-77117f06-54b8-4d27-aef7-9bed7875a89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533912332-172.17.0.14-1596919551138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33803,DS-42277d4e-f6ca-40d6-9ed7-ae7f4990909a,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-0e4735f7-0bb2-479a-a22d-8ca4c378f18c,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-bf359081-128e-49b6-96d1-e7d9924b8d52,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-1e9ee96d-40e3-4bed-a731-d7213a3351ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-c715333d-2e7b-4ef8-93c7-3f9be7dc7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-8673affd-8fb9-4ed8-ad1e-db2bbdd3792d,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-38930ea5-8298-43b6-83f8-73cdf7bcb260,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-77117f06-54b8-4d27-aef7-9bed7875a89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875976744-172.17.0.14-1596919685752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36279,DS-7e3e0e1b-c5fa-40c7-87a3-5b75a307e66e,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-05145044-d57e-4f0c-b84e-ea0ff6cd2236,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-86af72e0-0bfa-4f67-9f3c-d7aff038b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-43445306-abd1-40bd-ad53-baf1b068e501,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-d47e6b41-c994-4991-86de-1ad73b6289a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-89579adf-aff6-4983-a7cd-5009de8e966a,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-0425b3f6-86f2-4e6c-ab71-420f56d7c78f,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-449c8a32-f7f5-4e82-95cf-4ae3579d9d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875976744-172.17.0.14-1596919685752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36279,DS-7e3e0e1b-c5fa-40c7-87a3-5b75a307e66e,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-05145044-d57e-4f0c-b84e-ea0ff6cd2236,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-86af72e0-0bfa-4f67-9f3c-d7aff038b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-43445306-abd1-40bd-ad53-baf1b068e501,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-d47e6b41-c994-4991-86de-1ad73b6289a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-89579adf-aff6-4983-a7cd-5009de8e966a,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-0425b3f6-86f2-4e6c-ab71-420f56d7c78f,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-449c8a32-f7f5-4e82-95cf-4ae3579d9d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637639592-172.17.0.14-1596919722753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43616,DS-cd5a9e9d-3308-41bb-ad88-61a2f806250d,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-abe23a71-ada2-4a2e-83d2-12ff5bddc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-f13ef905-9308-415f-aaa9-b847b7958982,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-9a7079bb-9786-48ab-854a-7cdbe5cc8286,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-8e57eddb-03f7-4180-aaf0-7036e954ea64,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-3d742b47-12aa-4b9d-a9e8-0fea5a947268,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-439bc17f-018a-401a-bebe-48fe015ce622,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-69decf46-fb92-4a30-a05c-41d7951b4bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637639592-172.17.0.14-1596919722753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43616,DS-cd5a9e9d-3308-41bb-ad88-61a2f806250d,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-abe23a71-ada2-4a2e-83d2-12ff5bddc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-f13ef905-9308-415f-aaa9-b847b7958982,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-9a7079bb-9786-48ab-854a-7cdbe5cc8286,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-8e57eddb-03f7-4180-aaf0-7036e954ea64,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-3d742b47-12aa-4b9d-a9e8-0fea5a947268,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-439bc17f-018a-401a-bebe-48fe015ce622,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-69decf46-fb92-4a30-a05c-41d7951b4bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785567362-172.17.0.14-1596919997151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-5c0f2c27-6ff1-4949-b869-78b1499d810c,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-e03b1d32-20b2-481e-be55-dd964a7e49bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-cbec8938-91ed-42c8-841e-c3cd2eaa07b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-9908553e-faa0-4559-85eb-7a1802a680b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-0654997d-3c35-444d-8482-51c54754f635,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-6b5e8b67-da7d-4ac7-bd1c-83d182c38e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-69052da4-b5d5-46c8-b391-d779a6572f63,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-44944719-ac2b-47c2-bc12-6431abd60331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785567362-172.17.0.14-1596919997151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-5c0f2c27-6ff1-4949-b869-78b1499d810c,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-e03b1d32-20b2-481e-be55-dd964a7e49bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-cbec8938-91ed-42c8-841e-c3cd2eaa07b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-9908553e-faa0-4559-85eb-7a1802a680b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-0654997d-3c35-444d-8482-51c54754f635,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-6b5e8b67-da7d-4ac7-bd1c-83d182c38e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-69052da4-b5d5-46c8-b391-d779a6572f63,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-44944719-ac2b-47c2-bc12-6431abd60331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303542805-172.17.0.14-1596920107583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-d416df6e-08f7-4412-9f98-df73f950992e,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-88d87994-3f21-460e-b6e7-0959af9a10de,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-417a6e01-0202-40bd-9b11-4dd7918cd99a,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-7e505a28-1d1f-47bb-8401-072042ec09b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-3fc959a3-7624-4fbe-971b-8ef83eb12bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-a5b73eb8-cf32-4d3f-b82e-405fc81e4b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-2dc98c81-1e0d-4f6b-bb95-330a34981e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-a3808630-bb60-4c23-9051-fa7eec6937fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303542805-172.17.0.14-1596920107583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-d416df6e-08f7-4412-9f98-df73f950992e,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-88d87994-3f21-460e-b6e7-0959af9a10de,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-417a6e01-0202-40bd-9b11-4dd7918cd99a,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-7e505a28-1d1f-47bb-8401-072042ec09b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-3fc959a3-7624-4fbe-971b-8ef83eb12bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-a5b73eb8-cf32-4d3f-b82e-405fc81e4b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-2dc98c81-1e0d-4f6b-bb95-330a34981e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-a3808630-bb60-4c23-9051-fa7eec6937fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034956422-172.17.0.14-1596920431487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37197,DS-38e9722b-e96d-47d9-bbe7-5b413328f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-b23c13a7-b5dd-4c99-9fc4-294de3bfd4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-3bdce05b-3656-4918-898e-ee7391859ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-d22bbaff-a42c-4bf2-987a-49b86485ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-c23d4190-7cc4-4b78-bf1c-bcaaac2bb507,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-14964429-2116-4683-a0ee-72acbed2d680,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-b7412aaf-ce53-486b-b541-58bbd3141be1,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-0730a4e6-4fec-4415-be50-1ad3f2a8d871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034956422-172.17.0.14-1596920431487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37197,DS-38e9722b-e96d-47d9-bbe7-5b413328f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-b23c13a7-b5dd-4c99-9fc4-294de3bfd4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-3bdce05b-3656-4918-898e-ee7391859ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-d22bbaff-a42c-4bf2-987a-49b86485ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-c23d4190-7cc4-4b78-bf1c-bcaaac2bb507,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-14964429-2116-4683-a0ee-72acbed2d680,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-b7412aaf-ce53-486b-b541-58bbd3141be1,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-0730a4e6-4fec-4415-be50-1ad3f2a8d871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983823291-172.17.0.14-1596921524560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-b5ba0b5b-878b-4074-afd1-0510b7ead277,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-2750d5f2-f51f-4f1b-be6a-5f0e69bdfa93,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-170a11ef-4103-4b35-a799-0a5a66eb5717,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-7517f28a-e08d-4a23-8a02-63a0fbe850b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-39694926-d8e6-41db-b7a9-4b5e4d0b8530,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-e539e41f-b270-4895-9be6-0086ba470903,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-2541a37e-a71f-496e-9ab9-ec01028aca14,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-7e38add4-b9be-404c-aeb1-f52dc5395ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983823291-172.17.0.14-1596921524560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-b5ba0b5b-878b-4074-afd1-0510b7ead277,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-2750d5f2-f51f-4f1b-be6a-5f0e69bdfa93,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-170a11ef-4103-4b35-a799-0a5a66eb5717,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-7517f28a-e08d-4a23-8a02-63a0fbe850b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-39694926-d8e6-41db-b7a9-4b5e4d0b8530,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-e539e41f-b270-4895-9be6-0086ba470903,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-2541a37e-a71f-496e-9ab9-ec01028aca14,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-7e38add4-b9be-404c-aeb1-f52dc5395ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132074821-172.17.0.14-1596921749266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-216f6f47-24a8-484a-8716-51f09a581ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-acb79e9d-98aa-442f-95cc-ff233d3f107e,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-20e379e6-8af2-4feb-b2c0-df76cad72576,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-5a543c9f-4537-4a8d-a2a5-86f94095b35a,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-c467ba13-9467-4347-a100-1a3f60d395a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-6c4ef1c4-767a-43e8-9494-17bec4735019,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-99ceefdd-66df-4cbb-a831-99dcf3860f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-f28016ce-c91e-4c4d-a544-cf74d2837beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132074821-172.17.0.14-1596921749266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-216f6f47-24a8-484a-8716-51f09a581ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-acb79e9d-98aa-442f-95cc-ff233d3f107e,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-20e379e6-8af2-4feb-b2c0-df76cad72576,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-5a543c9f-4537-4a8d-a2a5-86f94095b35a,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-c467ba13-9467-4347-a100-1a3f60d395a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-6c4ef1c4-767a-43e8-9494-17bec4735019,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-99ceefdd-66df-4cbb-a831-99dcf3860f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-f28016ce-c91e-4c4d-a544-cf74d2837beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800339314-172.17.0.14-1596921849573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44026,DS-0f2e290d-70d2-4554-b912-64974a3f4579,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-612942f9-91f1-4296-9427-e4deda27ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-23ad4d6f-770f-426b-bdbc-93b175689d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-2e68969d-1274-4efd-a476-9df9d16966b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-5da802c1-a0d2-4b0a-b590-52ddc91296d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-e2fcb0fe-18b9-41e7-907a-29f8b2cf4680,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-93f47e40-cf65-4a66-8567-3678397f0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-eae78934-d196-42dc-b97d-ffe776d6fc20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800339314-172.17.0.14-1596921849573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44026,DS-0f2e290d-70d2-4554-b912-64974a3f4579,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-612942f9-91f1-4296-9427-e4deda27ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-23ad4d6f-770f-426b-bdbc-93b175689d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-2e68969d-1274-4efd-a476-9df9d16966b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-5da802c1-a0d2-4b0a-b590-52ddc91296d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-e2fcb0fe-18b9-41e7-907a-29f8b2cf4680,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-93f47e40-cf65-4a66-8567-3678397f0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-eae78934-d196-42dc-b97d-ffe776d6fc20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288094333-172.17.0.14-1596922420588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-56bb6f9c-83e8-4933-ad1b-95ed4262b722,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-c421140e-cca8-45e9-a94f-efac92bc6ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-2b1c4557-0d97-4e01-b0c2-f579c17ebcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-8158f1a4-4f4f-4bac-81cb-03d3651135a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-55c65186-286c-41e6-94d6-141e3de2b0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-e916160a-9d55-4db8-b90d-62efdc658816,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-5a413b8e-1093-4ae2-8f9a-81982c3ed72b,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-adfd9957-fc75-4018-9411-60b533abcf95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288094333-172.17.0.14-1596922420588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-56bb6f9c-83e8-4933-ad1b-95ed4262b722,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-c421140e-cca8-45e9-a94f-efac92bc6ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-2b1c4557-0d97-4e01-b0c2-f579c17ebcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-8158f1a4-4f4f-4bac-81cb-03d3651135a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-55c65186-286c-41e6-94d6-141e3de2b0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-e916160a-9d55-4db8-b90d-62efdc658816,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-5a413b8e-1093-4ae2-8f9a-81982c3ed72b,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-adfd9957-fc75-4018-9411-60b533abcf95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5062
