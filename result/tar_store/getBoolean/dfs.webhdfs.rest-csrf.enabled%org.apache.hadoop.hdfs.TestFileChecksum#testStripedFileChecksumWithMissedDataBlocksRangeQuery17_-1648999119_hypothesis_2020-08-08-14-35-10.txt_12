reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649529289-172.17.0.9-1596897425750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41651,DS-bd71c99e-c25e-4a5f-b0c4-10208c7d458f,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-c1ae755c-515b-4711-b5ba-8e27e59f9db4,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-8dd33226-ff3a-4f2d-8fcd-2941b9522211,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-f3399dd1-9d23-4fff-84f9-4098eba26dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-4aeb7f3e-6193-434d-b947-75289c7eaea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-9cf43e57-2dae-465f-94da-9c75b79ad34e,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-505bfec0-45a9-4953-854d-bdcdd8cc8eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-a9f91b25-75c0-44e0-b83d-8d8df7935b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649529289-172.17.0.9-1596897425750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41651,DS-bd71c99e-c25e-4a5f-b0c4-10208c7d458f,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-c1ae755c-515b-4711-b5ba-8e27e59f9db4,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-8dd33226-ff3a-4f2d-8fcd-2941b9522211,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-f3399dd1-9d23-4fff-84f9-4098eba26dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-4aeb7f3e-6193-434d-b947-75289c7eaea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-9cf43e57-2dae-465f-94da-9c75b79ad34e,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-505bfec0-45a9-4953-854d-bdcdd8cc8eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-a9f91b25-75c0-44e0-b83d-8d8df7935b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012564573-172.17.0.9-1596897719989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-a07ec8f1-be0c-49a9-94ff-9307a43fa470,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-06268c4c-70cb-4566-9af6-c4de70d13ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-15b00686-4e6d-4b8f-b2d0-8710e6f40242,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-3ecfa156-3572-4a7d-b956-1382d7481e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-99ae6799-645a-4baf-8876-84e28f443555,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-94101b00-cd36-40e9-b6da-6c2784ca7a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-75736c70-8427-4de2-806d-9781b3adb865,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-9843816d-1157-4390-81ed-8fc597a10898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012564573-172.17.0.9-1596897719989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-a07ec8f1-be0c-49a9-94ff-9307a43fa470,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-06268c4c-70cb-4566-9af6-c4de70d13ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-15b00686-4e6d-4b8f-b2d0-8710e6f40242,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-3ecfa156-3572-4a7d-b956-1382d7481e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-99ae6799-645a-4baf-8876-84e28f443555,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-94101b00-cd36-40e9-b6da-6c2784ca7a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-75736c70-8427-4de2-806d-9781b3adb865,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-9843816d-1157-4390-81ed-8fc597a10898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51415691-172.17.0.9-1596898894266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-fd47e9be-9edc-4c20-9990-7ad61a3a4f21,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-f8a4382f-7d32-4ac3-9741-b6dd979887ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-d524a8df-796d-4300-b453-ab7c32d9c790,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-cc1e0610-9c3f-4b68-9f8d-54f4121d9602,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-5934fd61-cb95-41f9-93a3-05135eb7bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-67968503-9dc4-4471-b473-8b6b32752b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-d8bc1f76-ea71-4baa-a761-c0c8bf28b1be,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-77147116-7851-49dc-8884-90d5691db95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51415691-172.17.0.9-1596898894266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-fd47e9be-9edc-4c20-9990-7ad61a3a4f21,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-f8a4382f-7d32-4ac3-9741-b6dd979887ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-d524a8df-796d-4300-b453-ab7c32d9c790,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-cc1e0610-9c3f-4b68-9f8d-54f4121d9602,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-5934fd61-cb95-41f9-93a3-05135eb7bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-67968503-9dc4-4471-b473-8b6b32752b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-d8bc1f76-ea71-4baa-a761-c0c8bf28b1be,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-77147116-7851-49dc-8884-90d5691db95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026678581-172.17.0.9-1596899242249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-4285e17a-90b9-42c9-bb22-544d6485dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-2c481862-4bc4-4df9-8125-f60955840cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-3128f861-15d0-485b-b3fd-314ff2154cac,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-ac4d4dea-e8dc-48c7-8e36-e8c0ae804fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-0bf15531-c712-478a-a402-d78435d5c14e,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-5ebd6ced-38d1-4a5a-ba34-8bb02197aaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-b673e446-c711-4c79-8ec9-2872d51a4c31,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-99ad33ef-b20d-4626-8108-8d376afe5dec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026678581-172.17.0.9-1596899242249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-4285e17a-90b9-42c9-bb22-544d6485dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-2c481862-4bc4-4df9-8125-f60955840cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-3128f861-15d0-485b-b3fd-314ff2154cac,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-ac4d4dea-e8dc-48c7-8e36-e8c0ae804fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-0bf15531-c712-478a-a402-d78435d5c14e,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-5ebd6ced-38d1-4a5a-ba34-8bb02197aaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-b673e446-c711-4c79-8ec9-2872d51a4c31,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-99ad33ef-b20d-4626-8108-8d376afe5dec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942044141-172.17.0.9-1596899603000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-97bc66be-494a-4922-a05d-d674efba4508,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-98f26c4c-60a9-417e-a239-8fc34c0d5616,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-94e95e09-7e95-4649-9c28-7711f40eaabd,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-e803d6d8-8112-491c-899b-a4170c60ea82,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-767d5e0a-87cd-46b3-bb5d-0c5aa5464236,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-6d992ff3-bf2f-4e3c-a021-2c3478fe724c,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-405f34ca-dc9a-4565-9e68-c64a2fb5228d,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-b6ec0e54-2391-4384-b481-f561331f9d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942044141-172.17.0.9-1596899603000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-97bc66be-494a-4922-a05d-d674efba4508,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-98f26c4c-60a9-417e-a239-8fc34c0d5616,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-94e95e09-7e95-4649-9c28-7711f40eaabd,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-e803d6d8-8112-491c-899b-a4170c60ea82,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-767d5e0a-87cd-46b3-bb5d-0c5aa5464236,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-6d992ff3-bf2f-4e3c-a021-2c3478fe724c,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-405f34ca-dc9a-4565-9e68-c64a2fb5228d,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-b6ec0e54-2391-4384-b481-f561331f9d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244352368-172.17.0.9-1596899914154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-8d825d29-a732-4945-b81d-8895bb56f528,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-e6ac91d1-1f3c-416b-89a7-17a9da63ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-21d4a398-0b01-4c7f-bf63-a23d9f5bc49d,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-45434541-5265-4da8-b207-d327e7ed262f,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-881863b2-e287-4baf-be67-2b0cf421dfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-823e1688-9255-44b4-914c-e220065b4e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-c4e54e2f-fd9b-4f15-8c93-e015cdb05f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-06f7f735-2a80-47d3-8e5c-0adef07c7d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244352368-172.17.0.9-1596899914154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-8d825d29-a732-4945-b81d-8895bb56f528,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-e6ac91d1-1f3c-416b-89a7-17a9da63ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-21d4a398-0b01-4c7f-bf63-a23d9f5bc49d,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-45434541-5265-4da8-b207-d327e7ed262f,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-881863b2-e287-4baf-be67-2b0cf421dfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-823e1688-9255-44b4-914c-e220065b4e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-c4e54e2f-fd9b-4f15-8c93-e015cdb05f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-06f7f735-2a80-47d3-8e5c-0adef07c7d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973657921-172.17.0.9-1596899978940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-890f8dbe-d8c3-4b6e-ac73-b1e55470a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-036b55ef-b43e-480b-ba01-23a29d9c9331,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-def8bc57-8c71-4ad8-8286-c5b5d8b45ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-0b353acc-b770-4c7b-aef3-1015b633d1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-04fd4c58-5940-4a49-9a4b-c5a875da0b39,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-4937ba1e-f481-4450-9c5a-9e4de70ff9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-af9450ea-1f94-4213-8041-d793265c8119,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-56ddd40c-6992-4bae-91ed-6693729c9216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973657921-172.17.0.9-1596899978940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-890f8dbe-d8c3-4b6e-ac73-b1e55470a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-036b55ef-b43e-480b-ba01-23a29d9c9331,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-def8bc57-8c71-4ad8-8286-c5b5d8b45ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-0b353acc-b770-4c7b-aef3-1015b633d1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-04fd4c58-5940-4a49-9a4b-c5a875da0b39,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-4937ba1e-f481-4450-9c5a-9e4de70ff9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-af9450ea-1f94-4213-8041-d793265c8119,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-56ddd40c-6992-4bae-91ed-6693729c9216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150841167-172.17.0.9-1596900126764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35069,DS-a1ed7c81-389b-4e47-ae5c-e835d07def40,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-fc60d179-3fbe-4531-aa4c-5dd49fabb89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-ecd482d2-9c8c-4f7c-88d3-a248ae6f67b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-dcf1dd4e-9b49-421d-9014-73eb27f9682e,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-6b459345-d850-407c-84b2-1dd9cfa72418,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-b6e40f6d-fd42-4034-9fe4-0bb19c9006e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-d0319453-f360-4e89-838b-c035e1173095,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-d5c87778-ec9b-4621-80b8-991b90b7d834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150841167-172.17.0.9-1596900126764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35069,DS-a1ed7c81-389b-4e47-ae5c-e835d07def40,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-fc60d179-3fbe-4531-aa4c-5dd49fabb89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-ecd482d2-9c8c-4f7c-88d3-a248ae6f67b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-dcf1dd4e-9b49-421d-9014-73eb27f9682e,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-6b459345-d850-407c-84b2-1dd9cfa72418,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-b6e40f6d-fd42-4034-9fe4-0bb19c9006e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-d0319453-f360-4e89-838b-c035e1173095,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-d5c87778-ec9b-4621-80b8-991b90b7d834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-258490487-172.17.0.9-1596900834845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-6fd18364-8547-465e-b6ef-42b05654b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-79cf64c5-9fd6-41ff-bc6f-7b0bacf95e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-18b31000-6e80-4821-be41-419ed0fdcca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-f3736216-dbb5-4e08-8feb-8279f0fa2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-214dac34-a905-4bc0-b67c-a3045b6ee32e,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-836c7740-6752-45de-b150-9565e0d67520,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-5e6dc3e9-7e03-40e4-a1b7-2eb635f1a87b,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-1f9c899c-3f90-41cc-9417-131e2f1d9674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-258490487-172.17.0.9-1596900834845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-6fd18364-8547-465e-b6ef-42b05654b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-79cf64c5-9fd6-41ff-bc6f-7b0bacf95e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-18b31000-6e80-4821-be41-419ed0fdcca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-f3736216-dbb5-4e08-8feb-8279f0fa2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-214dac34-a905-4bc0-b67c-a3045b6ee32e,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-836c7740-6752-45de-b150-9565e0d67520,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-5e6dc3e9-7e03-40e4-a1b7-2eb635f1a87b,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-1f9c899c-3f90-41cc-9417-131e2f1d9674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966336586-172.17.0.9-1596900938094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37026,DS-38690c03-1347-4c62-8e94-841cb8688aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-84524b11-1c80-4788-b86a-c443cad9bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-8a4b73f6-55ea-4a55-9d91-12fbc1b16842,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-cf351082-ca18-4814-8a7e-008d795d905c,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-0813f021-864b-42d7-8e1a-6a130828a52d,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-5e551a75-8539-4ac7-b730-4fdd8065fc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-740d598c-7f8c-44fc-8efd-7354bdd33e60,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-0427f538-b3c3-48c6-b11d-6800c3d1e61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966336586-172.17.0.9-1596900938094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37026,DS-38690c03-1347-4c62-8e94-841cb8688aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-84524b11-1c80-4788-b86a-c443cad9bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-8a4b73f6-55ea-4a55-9d91-12fbc1b16842,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-cf351082-ca18-4814-8a7e-008d795d905c,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-0813f021-864b-42d7-8e1a-6a130828a52d,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-5e551a75-8539-4ac7-b730-4fdd8065fc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-740d598c-7f8c-44fc-8efd-7354bdd33e60,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-0427f538-b3c3-48c6-b11d-6800c3d1e61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515702082-172.17.0.9-1596901145165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33286,DS-a5333aba-b432-48b8-8300-b0d15e3800ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-197918b9-16b5-4536-825e-79c330347069,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-ca625107-4443-41c2-aad3-f729f8107155,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-652cb2b6-d90b-41ee-a58c-be9954f31a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-ee8d516f-e3a8-4849-bb63-624e18905442,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-3a6ec298-de49-4a1c-9c7a-d6fc42a6714f,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-688e61f6-222e-473e-9a96-d4d3b79b7539,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-3782eca6-73bb-4bf5-a36c-a4ee1f054568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515702082-172.17.0.9-1596901145165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33286,DS-a5333aba-b432-48b8-8300-b0d15e3800ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-197918b9-16b5-4536-825e-79c330347069,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-ca625107-4443-41c2-aad3-f729f8107155,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-652cb2b6-d90b-41ee-a58c-be9954f31a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-ee8d516f-e3a8-4849-bb63-624e18905442,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-3a6ec298-de49-4a1c-9c7a-d6fc42a6714f,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-688e61f6-222e-473e-9a96-d4d3b79b7539,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-3782eca6-73bb-4bf5-a36c-a4ee1f054568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240111299-172.17.0.9-1596901181284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-f27f3c15-23fb-422f-8b2c-f1112b17d191,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-5370fc60-c5f3-4435-8608-affde71df113,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-b9c504a9-e915-4833-84f6-88adfc812427,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-e33e8419-ec8a-4fca-9501-4d16202be923,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-715f121d-8c77-464c-966e-f3e5aabeeba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-d1d46394-6d08-4c4f-b46c-6999f0fc2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-84627af9-d3d7-4fc8-842d-8b69dc08e6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-d44896da-6383-4655-9aae-9f4735ca3e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240111299-172.17.0.9-1596901181284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-f27f3c15-23fb-422f-8b2c-f1112b17d191,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-5370fc60-c5f3-4435-8608-affde71df113,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-b9c504a9-e915-4833-84f6-88adfc812427,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-e33e8419-ec8a-4fca-9501-4d16202be923,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-715f121d-8c77-464c-966e-f3e5aabeeba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-d1d46394-6d08-4c4f-b46c-6999f0fc2be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-84627af9-d3d7-4fc8-842d-8b69dc08e6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-d44896da-6383-4655-9aae-9f4735ca3e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027657370-172.17.0.9-1596901326790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-8d05be0c-8d1a-411a-bd39-f568ca35a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-f900b362-94db-4c44-8f64-8e699933deba,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-5ce6b2cb-4773-474a-b78f-d64e9cea26cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-65959f85-0bbf-43b3-b449-05a0c5864c09,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-edc973d0-d9bf-4934-a86f-895f336eba13,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-0764da85-37fa-4117-bb08-79eaa78ebdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-55dad8ef-aeb8-4cf6-8fad-352858bf6799,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-d12feede-5d20-4a23-984d-7807022597d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027657370-172.17.0.9-1596901326790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-8d05be0c-8d1a-411a-bd39-f568ca35a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-f900b362-94db-4c44-8f64-8e699933deba,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-5ce6b2cb-4773-474a-b78f-d64e9cea26cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-65959f85-0bbf-43b3-b449-05a0c5864c09,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-edc973d0-d9bf-4934-a86f-895f336eba13,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-0764da85-37fa-4117-bb08-79eaa78ebdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-55dad8ef-aeb8-4cf6-8fad-352858bf6799,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-d12feede-5d20-4a23-984d-7807022597d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984000679-172.17.0.9-1596901360846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41707,DS-a4ebd724-a081-4727-ba18-c222e3226fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-cfb5c0cc-a3e3-4e1d-8bf8-78c557d28571,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-44f4e455-f320-4e16-88bd-cca74f05eb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-93e7b99b-9470-4ffc-a31f-84141561cffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-d942be6e-59e6-4841-819d-7a5914245192,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-23b7c548-917a-48d3-9510-e2a5fc33e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-cb49a1bb-5385-47dd-a62d-866c30eaa6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-33952896-b9bb-4c25-847a-eea6d010ca09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984000679-172.17.0.9-1596901360846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41707,DS-a4ebd724-a081-4727-ba18-c222e3226fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-cfb5c0cc-a3e3-4e1d-8bf8-78c557d28571,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-44f4e455-f320-4e16-88bd-cca74f05eb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-93e7b99b-9470-4ffc-a31f-84141561cffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-d942be6e-59e6-4841-819d-7a5914245192,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-23b7c548-917a-48d3-9510-e2a5fc33e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-cb49a1bb-5385-47dd-a62d-866c30eaa6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-33952896-b9bb-4c25-847a-eea6d010ca09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309163785-172.17.0.9-1596901504397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-a7770009-6810-4b79-8463-6d739045d5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-edcc943b-a7e1-44cc-ba85-592e3e6aa7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-5e7d2d6c-e32b-4709-9670-3c7bf5cc80a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-ffb89fb4-1b20-419a-8bc8-2fdc43e837b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-db6e6559-e0e8-4044-bf57-22ca8cca172a,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-84b9e92b-75d6-43c8-acfa-e44ee1301838,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-134453e5-8148-48a6-bb33-83c0457a8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-ccfd3864-7720-4e58-a812-be350cef542d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309163785-172.17.0.9-1596901504397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-a7770009-6810-4b79-8463-6d739045d5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-edcc943b-a7e1-44cc-ba85-592e3e6aa7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-5e7d2d6c-e32b-4709-9670-3c7bf5cc80a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-ffb89fb4-1b20-419a-8bc8-2fdc43e837b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-db6e6559-e0e8-4044-bf57-22ca8cca172a,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-84b9e92b-75d6-43c8-acfa-e44ee1301838,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-134453e5-8148-48a6-bb33-83c0457a8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-ccfd3864-7720-4e58-a812-be350cef542d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2143029694-172.17.0.9-1596901976033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46006,DS-51246759-eabf-420c-a27b-f00e9d0f385d,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-209efa05-837d-4aa2-82f1-2097612feefb,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-f6d3067f-ce22-4a7d-91e0-8287c734d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-66f15148-cfdf-4c1d-88ab-f1cf426c9f30,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-1327454f-f34f-4e3a-be75-5d8891f41707,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-717f93e6-cac7-453a-b3d2-aafda4ddd567,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-66817b4f-f513-4fec-9a3d-d5d7052aebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-79674f4e-0a1a-4766-9d8e-02e033c59b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2143029694-172.17.0.9-1596901976033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46006,DS-51246759-eabf-420c-a27b-f00e9d0f385d,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-209efa05-837d-4aa2-82f1-2097612feefb,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-f6d3067f-ce22-4a7d-91e0-8287c734d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-66f15148-cfdf-4c1d-88ab-f1cf426c9f30,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-1327454f-f34f-4e3a-be75-5d8891f41707,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-717f93e6-cac7-453a-b3d2-aafda4ddd567,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-66817b4f-f513-4fec-9a3d-d5d7052aebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-79674f4e-0a1a-4766-9d8e-02e033c59b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5232
