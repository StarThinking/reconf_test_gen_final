reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360010889-172.17.0.8-1596933267126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39337,DS-4d562fd5-98a5-4bf2-94f1-4a937cc1031e,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-5a26cd2d-46b7-4e85-a528-e07020b05a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-6c4b6058-b138-46a9-8bb3-0692eb658c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-a61212c1-9f2d-4152-93e7-be709a905d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-76f5ca05-fa7b-401a-b7ea-8ea48ad33f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-f979e527-0e17-4721-b3fb-9513cde29ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-b917745f-f246-41f8-b43d-2f5112a0cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-31510288-5dc2-4b3d-b804-07d2a585d30a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360010889-172.17.0.8-1596933267126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39337,DS-4d562fd5-98a5-4bf2-94f1-4a937cc1031e,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-5a26cd2d-46b7-4e85-a528-e07020b05a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-6c4b6058-b138-46a9-8bb3-0692eb658c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-a61212c1-9f2d-4152-93e7-be709a905d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-76f5ca05-fa7b-401a-b7ea-8ea48ad33f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-f979e527-0e17-4721-b3fb-9513cde29ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-b917745f-f246-41f8-b43d-2f5112a0cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-31510288-5dc2-4b3d-b804-07d2a585d30a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560173869-172.17.0.8-1596933866444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-e5df4cdb-2153-439e-acfd-46b28a5416ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-b37877d5-8ebb-4a87-a70a-566a5fce8849,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-c2213fb1-5b97-4339-b395-1118a49cf2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-f9e1868f-b23d-41b3-aa47-6848b74f157b,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-c7e17259-795e-4fbb-99df-a6b5ec95bcde,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-b15650d7-9ada-4831-a48b-e18233525e82,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-c2514e82-3199-403e-84e2-e060b91bf8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-69262e4d-3447-4e13-87c9-c98326c57106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560173869-172.17.0.8-1596933866444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-e5df4cdb-2153-439e-acfd-46b28a5416ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-b37877d5-8ebb-4a87-a70a-566a5fce8849,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-c2213fb1-5b97-4339-b395-1118a49cf2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-f9e1868f-b23d-41b3-aa47-6848b74f157b,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-c7e17259-795e-4fbb-99df-a6b5ec95bcde,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-b15650d7-9ada-4831-a48b-e18233525e82,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-c2514e82-3199-403e-84e2-e060b91bf8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-69262e4d-3447-4e13-87c9-c98326c57106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682879598-172.17.0.8-1596934086328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-c06984fa-4a03-42dc-a46a-b571ddb6394b,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-44c9339a-bc9e-4a69-b1d2-a3a0adb64caa,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-42fd1067-14bf-4399-b562-b924ce9d0c82,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-fbb9f8d8-d858-4494-b63c-ffd3e2e56f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-2cc02d39-02d4-486b-8cb3-f7acc24b1506,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-e4634c59-b4e5-477c-a3b6-20f872dddf27,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-ac9fa1ce-ad2e-4577-a43f-0a450a7470a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-8d050ddc-7476-48d3-949a-3efc0a6b6698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682879598-172.17.0.8-1596934086328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-c06984fa-4a03-42dc-a46a-b571ddb6394b,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-44c9339a-bc9e-4a69-b1d2-a3a0adb64caa,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-42fd1067-14bf-4399-b562-b924ce9d0c82,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-fbb9f8d8-d858-4494-b63c-ffd3e2e56f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-2cc02d39-02d4-486b-8cb3-f7acc24b1506,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-e4634c59-b4e5-477c-a3b6-20f872dddf27,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-ac9fa1ce-ad2e-4577-a43f-0a450a7470a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-8d050ddc-7476-48d3-949a-3efc0a6b6698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979726011-172.17.0.8-1596934120946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35324,DS-56ea4540-59fd-4963-b2be-cd965b0a3391,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-5470c68c-835f-4dd1-8363-9f372545d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-43370445-a0c0-47f2-8d03-4b851e3bfd28,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-c863c3b4-324f-4aa6-b863-68652192708f,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-0f43a50b-4b6c-44c9-912a-0a5a7f9503e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-0b428a5e-6fdc-41ab-859e-249d4d5a816e,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-fb1b969f-3196-44f1-a62a-aa17b236646a,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-f230ec47-2925-41ab-b2ef-3cf6961df5f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1979726011-172.17.0.8-1596934120946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35324,DS-56ea4540-59fd-4963-b2be-cd965b0a3391,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-5470c68c-835f-4dd1-8363-9f372545d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-43370445-a0c0-47f2-8d03-4b851e3bfd28,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-c863c3b4-324f-4aa6-b863-68652192708f,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-0f43a50b-4b6c-44c9-912a-0a5a7f9503e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-0b428a5e-6fdc-41ab-859e-249d4d5a816e,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-fb1b969f-3196-44f1-a62a-aa17b236646a,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-f230ec47-2925-41ab-b2ef-3cf6961df5f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370208691-172.17.0.8-1596934559453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35790,DS-0e5deca4-5a80-40ac-8136-d05465db2153,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-9c5146b9-7811-4279-aaa5-e259745bccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-fc21cbbd-f246-46fb-ad9c-49fe01e688a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-3e84d4bf-b80f-4b25-8973-2c9b52189015,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-91ee7b19-29a7-460b-bab2-8ace818d87c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-766987fe-6e54-4df2-b614-41455a92739e,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-1640c9cb-07fc-4699-bec0-e7fee5dd56d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-6f6e1a49-3c83-4ec3-8f19-51a4af6a6264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370208691-172.17.0.8-1596934559453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35790,DS-0e5deca4-5a80-40ac-8136-d05465db2153,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-9c5146b9-7811-4279-aaa5-e259745bccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-fc21cbbd-f246-46fb-ad9c-49fe01e688a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-3e84d4bf-b80f-4b25-8973-2c9b52189015,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-91ee7b19-29a7-460b-bab2-8ace818d87c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-766987fe-6e54-4df2-b614-41455a92739e,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-1640c9cb-07fc-4699-bec0-e7fee5dd56d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-6f6e1a49-3c83-4ec3-8f19-51a4af6a6264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005629211-172.17.0.8-1596934655293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-78fa6842-817f-4ae3-805d-d6c781567214,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-5040bb6e-569b-45f0-a634-316135110423,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-57a4fce4-2e56-4a08-a0dd-bad0075ed1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-e0af1f8c-3b4f-48e2-9127-53302574bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-94b77da3-67cc-4cb9-a35e-c683744563b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-36e72d8a-d4e8-4b89-b08e-c5dd8d02d908,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-913f2bba-48ea-4319-b690-f5adf76fdca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-da80efb4-c5c4-4c39-9555-9685873a5aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005629211-172.17.0.8-1596934655293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-78fa6842-817f-4ae3-805d-d6c781567214,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-5040bb6e-569b-45f0-a634-316135110423,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-57a4fce4-2e56-4a08-a0dd-bad0075ed1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-e0af1f8c-3b4f-48e2-9127-53302574bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-94b77da3-67cc-4cb9-a35e-c683744563b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-36e72d8a-d4e8-4b89-b08e-c5dd8d02d908,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-913f2bba-48ea-4319-b690-f5adf76fdca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-da80efb4-c5c4-4c39-9555-9685873a5aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089149839-172.17.0.8-1596934804933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-5d079fb6-913b-4749-9500-4b43fc425243,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-addc155f-c854-4e58-acb7-b1343725ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-ee4a5793-ae9a-4f3b-81bd-97c7fbc8d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-6bf88736-e277-4da2-95dd-cf774e930a70,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-bf67373f-5994-4f9a-ba08-a84b0c7ee8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-4da9a1b5-59db-429c-88ec-0d56f9291858,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-f5998b5c-024e-4725-9ff2-7e7d5771fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-9e2b90b9-29dd-46ae-a0c9-f1c638e3ca44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089149839-172.17.0.8-1596934804933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-5d079fb6-913b-4749-9500-4b43fc425243,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-addc155f-c854-4e58-acb7-b1343725ab25,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-ee4a5793-ae9a-4f3b-81bd-97c7fbc8d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-6bf88736-e277-4da2-95dd-cf774e930a70,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-bf67373f-5994-4f9a-ba08-a84b0c7ee8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-4da9a1b5-59db-429c-88ec-0d56f9291858,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-f5998b5c-024e-4725-9ff2-7e7d5771fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-9e2b90b9-29dd-46ae-a0c9-f1c638e3ca44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216257083-172.17.0.8-1596935010648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-6818e822-a85c-40ae-8983-e45ed898ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-1404ae22-a7c9-43d1-afaf-1c6623784331,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-2f6dbd67-46b2-46ed-a11f-e279cc9ee4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-2b1956b5-6382-4079-8f2f-1d8a7a2f9be5,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-59adbf3b-1fa4-4b0b-864a-5849ec78aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-aae5da33-d62b-4d26-aea2-4fc81eb7d061,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-36f1d88c-b634-4de4-9d7a-ca5554308a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-b69e354d-1cce-421a-934b-a3a51a2d66c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216257083-172.17.0.8-1596935010648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-6818e822-a85c-40ae-8983-e45ed898ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-1404ae22-a7c9-43d1-afaf-1c6623784331,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-2f6dbd67-46b2-46ed-a11f-e279cc9ee4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-2b1956b5-6382-4079-8f2f-1d8a7a2f9be5,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-59adbf3b-1fa4-4b0b-864a-5849ec78aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-aae5da33-d62b-4d26-aea2-4fc81eb7d061,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-36f1d88c-b634-4de4-9d7a-ca5554308a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-b69e354d-1cce-421a-934b-a3a51a2d66c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829000005-172.17.0.8-1596935044382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-f108fd81-58c3-4d40-8003-7976186a27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-e7b98069-e364-4e44-8409-87d523ce49f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-c3795880-a806-49d4-9261-0e3fd3075ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-5bbd1cef-0dfa-4c6a-9caa-a4b17ca5781e,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-95b281ba-3330-447e-895f-f3b1d83d8ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-58299bdf-d868-45f1-8c1b-4f7e2d589395,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-cbaaf412-547e-4357-bdb8-b521657aa8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-82845bee-69bc-4552-8508-a5f51c5fa465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829000005-172.17.0.8-1596935044382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-f108fd81-58c3-4d40-8003-7976186a27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-e7b98069-e364-4e44-8409-87d523ce49f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-c3795880-a806-49d4-9261-0e3fd3075ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-5bbd1cef-0dfa-4c6a-9caa-a4b17ca5781e,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-95b281ba-3330-447e-895f-f3b1d83d8ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-58299bdf-d868-45f1-8c1b-4f7e2d589395,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-cbaaf412-547e-4357-bdb8-b521657aa8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-82845bee-69bc-4552-8508-a5f51c5fa465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203806061-172.17.0.8-1596935177501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-14492294-1b83-46a8-9b36-ff8b93985b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-77297b65-cb58-48b8-89a8-d696c46b300e,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-ed2b8369-cbd0-4fa2-aaa9-3558eea4da60,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-647df054-42ce-4bab-bfc7-87eef20a67af,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-a2197eb5-7a90-4166-8fb3-a8fa8bd6576b,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-2ef7f356-e90e-4d48-9c1c-73a5d564cebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-554f7223-93fe-461e-9217-8022204bb777,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-481f5aa9-e980-433d-b098-1df811a8a355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203806061-172.17.0.8-1596935177501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-14492294-1b83-46a8-9b36-ff8b93985b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-77297b65-cb58-48b8-89a8-d696c46b300e,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-ed2b8369-cbd0-4fa2-aaa9-3558eea4da60,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-647df054-42ce-4bab-bfc7-87eef20a67af,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-a2197eb5-7a90-4166-8fb3-a8fa8bd6576b,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-2ef7f356-e90e-4d48-9c1c-73a5d564cebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-554f7223-93fe-461e-9217-8022204bb777,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-481f5aa9-e980-433d-b098-1df811a8a355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240712184-172.17.0.8-1596935213168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44463,DS-2544e784-1a7a-480d-b23b-90e4186cff0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-63309370-34b9-4c48-81f5-4df4fc24f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-8c4b61a3-bf50-4555-b3e4-982d381de9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-fc2c6c8c-51dc-42ac-91b7-b57b2f69f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-4195d10e-5943-44c5-b956-73ace8b299e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-67591b8c-63c6-4d78-b0f1-9adcab13da05,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-7d21bdff-639e-4153-82cf-c9801deb9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-ad563b03-afc0-4bda-8b96-e0202ac97278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240712184-172.17.0.8-1596935213168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44463,DS-2544e784-1a7a-480d-b23b-90e4186cff0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-63309370-34b9-4c48-81f5-4df4fc24f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-8c4b61a3-bf50-4555-b3e4-982d381de9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-fc2c6c8c-51dc-42ac-91b7-b57b2f69f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-4195d10e-5943-44c5-b956-73ace8b299e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-67591b8c-63c6-4d78-b0f1-9adcab13da05,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-7d21bdff-639e-4153-82cf-c9801deb9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-ad563b03-afc0-4bda-8b96-e0202ac97278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883868313-172.17.0.8-1596935530270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40224,DS-acbccb7f-ced1-4cf6-bcc3-09dd86e85ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-7da453ea-3ccd-4ebf-8e43-74cdbe89609e,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-c21bdf13-ed83-45fe-8719-f565e6575cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-a129b158-515d-4e9e-96f9-b62303ddcb30,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-f95b468e-044b-4b3b-be50-fcc257f05c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-1aa0eff6-4972-498a-8432-cc43cbce3926,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-4d4d3969-20dc-4fef-b5ae-8056b85b9666,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-55cf3a9a-2f8b-48d7-be1d-156247d582d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883868313-172.17.0.8-1596935530270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40224,DS-acbccb7f-ced1-4cf6-bcc3-09dd86e85ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-7da453ea-3ccd-4ebf-8e43-74cdbe89609e,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-c21bdf13-ed83-45fe-8719-f565e6575cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-a129b158-515d-4e9e-96f9-b62303ddcb30,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-f95b468e-044b-4b3b-be50-fcc257f05c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-1aa0eff6-4972-498a-8432-cc43cbce3926,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-4d4d3969-20dc-4fef-b5ae-8056b85b9666,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-55cf3a9a-2f8b-48d7-be1d-156247d582d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172131305-172.17.0.8-1596935799610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-7fd8d317-f6b6-470c-b9b9-7a416d9e32be,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-aa7adc79-b822-4755-8750-e2bd447ece81,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-e50e1470-c5c6-4bfd-9cab-89425e6a3126,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-fc335fa4-d209-4e43-8aba-f43b1afb89ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-9f6b8b3f-c90a-4870-a787-3473f0cfa26f,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-b9b25f15-0e53-43ef-b712-bc06f3330719,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-ff4e2a9a-11ea-4992-8ac0-b54bd170af53,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-682257a2-9c20-4858-8dd9-e2751904d12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172131305-172.17.0.8-1596935799610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-7fd8d317-f6b6-470c-b9b9-7a416d9e32be,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-aa7adc79-b822-4755-8750-e2bd447ece81,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-e50e1470-c5c6-4bfd-9cab-89425e6a3126,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-fc335fa4-d209-4e43-8aba-f43b1afb89ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-9f6b8b3f-c90a-4870-a787-3473f0cfa26f,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-b9b25f15-0e53-43ef-b712-bc06f3330719,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-ff4e2a9a-11ea-4992-8ac0-b54bd170af53,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-682257a2-9c20-4858-8dd9-e2751904d12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560776375-172.17.0.8-1596936462915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40641,DS-4accf4c8-b4f5-408f-9417-d389f96257c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-8b2c13bf-d393-481b-8cff-a2ad29d9f36b,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-308cac7f-bede-4c37-9e0a-8a171dfc697a,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-4d67cd91-2a3f-4ea5-8216-e28444b86897,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-dc162c77-c4f7-4336-a34e-bff195b5ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-242c8e8c-3e8e-4cc7-8e44-21cfd207e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-4200ea6c-2924-49bd-ba58-31b5d2105d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-c811316e-051d-4359-b0e0-d4f881696815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560776375-172.17.0.8-1596936462915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40641,DS-4accf4c8-b4f5-408f-9417-d389f96257c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-8b2c13bf-d393-481b-8cff-a2ad29d9f36b,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-308cac7f-bede-4c37-9e0a-8a171dfc697a,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-4d67cd91-2a3f-4ea5-8216-e28444b86897,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-dc162c77-c4f7-4336-a34e-bff195b5ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-242c8e8c-3e8e-4cc7-8e44-21cfd207e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-4200ea6c-2924-49bd-ba58-31b5d2105d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-c811316e-051d-4359-b0e0-d4f881696815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253481985-172.17.0.8-1596936671799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-2e024535-829d-4bd5-80da-e0c345894bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-850f808d-50b4-4b1b-89e7-2e9cb10441ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-44852e37-f238-417c-8709-a676b45885f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-e4050dd9-31a7-4189-bec9-5be77faeddac,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-46670214-41b0-4056-b8d3-2e51b494bd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-dbb4c121-184c-4498-860e-f77eddca195c,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-43218a4d-0c6e-4705-9962-5c719023d62e,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-9516fce9-63f4-4680-8734-1ffda35d92cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253481985-172.17.0.8-1596936671799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-2e024535-829d-4bd5-80da-e0c345894bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-850f808d-50b4-4b1b-89e7-2e9cb10441ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-44852e37-f238-417c-8709-a676b45885f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-e4050dd9-31a7-4189-bec9-5be77faeddac,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-46670214-41b0-4056-b8d3-2e51b494bd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-dbb4c121-184c-4498-860e-f77eddca195c,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-43218a4d-0c6e-4705-9962-5c719023d62e,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-9516fce9-63f4-4680-8734-1ffda35d92cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842035893-172.17.0.8-1596936982562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-19c759f9-0a20-4d56-97eb-77915eefc221,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-4aafeb78-e99d-4200-a007-418ad1095a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-1fafbc33-7732-4564-a05d-f9b6a9aaf69e,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-c5be1a44-94e4-450b-bb0b-77e41b2cb732,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-927fd4dd-3a41-441b-a44e-748233338cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-6ead28e2-4782-44ea-9119-5aadc58418e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-f1632e58-3eff-4cfe-8a6a-5d5f3d2829c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-63a2577c-5e1a-4265-ad10-d2fcd0689e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842035893-172.17.0.8-1596936982562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-19c759f9-0a20-4d56-97eb-77915eefc221,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-4aafeb78-e99d-4200-a007-418ad1095a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-1fafbc33-7732-4564-a05d-f9b6a9aaf69e,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-c5be1a44-94e4-450b-bb0b-77e41b2cb732,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-927fd4dd-3a41-441b-a44e-748233338cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-6ead28e2-4782-44ea-9119-5aadc58418e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-f1632e58-3eff-4cfe-8a6a-5d5f3d2829c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-63a2577c-5e1a-4265-ad10-d2fcd0689e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001099023-172.17.0.8-1596937341659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-84cae964-9fc0-4993-8672-46422bb6d8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-02f286df-d647-41c5-9d85-0a75d63770ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-cb25bb77-2a2f-4e66-8934-bf2138a6cdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-094f5a23-4952-485e-a8ed-534c197ff46f,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-67f02d64-0a90-4fd3-81f4-e60bc3f8c589,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-4196de3e-8b77-4ed1-8204-8834db27b7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-f6fe7db9-95d3-492a-9832-255ea2d4d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-f63b8750-3ada-4d00-a9ac-0998102ab6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001099023-172.17.0.8-1596937341659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-84cae964-9fc0-4993-8672-46422bb6d8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-02f286df-d647-41c5-9d85-0a75d63770ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-cb25bb77-2a2f-4e66-8934-bf2138a6cdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-094f5a23-4952-485e-a8ed-534c197ff46f,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-67f02d64-0a90-4fd3-81f4-e60bc3f8c589,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-4196de3e-8b77-4ed1-8204-8834db27b7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-f6fe7db9-95d3-492a-9832-255ea2d4d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-f63b8750-3ada-4d00-a9ac-0998102ab6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514066795-172.17.0.8-1596937794188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36665,DS-0e477422-4350-46bd-ab64-af4c946e00f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-20e5a301-6135-4f00-a7fb-e4e9adc81f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-0b45f7ca-a010-4bcb-8af1-8bfa8ec60d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-03c9beb2-a2b8-4a55-9b4f-0950f913cb23,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-fc7ab444-50a8-40c4-a872-8343f7f68229,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-67501549-2bc4-43dd-b7f2-0c785be7aab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-96ab4a57-b1b6-49ad-a8bc-ed5cdbdf315f,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-1fea831e-9c1d-4e57-bd17-57db0fdfeab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514066795-172.17.0.8-1596937794188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36665,DS-0e477422-4350-46bd-ab64-af4c946e00f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-20e5a301-6135-4f00-a7fb-e4e9adc81f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-0b45f7ca-a010-4bcb-8af1-8bfa8ec60d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-03c9beb2-a2b8-4a55-9b4f-0950f913cb23,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-fc7ab444-50a8-40c4-a872-8343f7f68229,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-67501549-2bc4-43dd-b7f2-0c785be7aab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-96ab4a57-b1b6-49ad-a8bc-ed5cdbdf315f,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-1fea831e-9c1d-4e57-bd17-57db0fdfeab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038288626-172.17.0.8-1596937826615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-9f7416be-072d-43e5-9264-601320d3cead,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-e788d79a-3f70-4a6f-a01f-37ac97f2dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-0329447f-060b-4583-be82-283544141668,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-80353047-f912-4a41-9f52-85373ef9b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-bd33ca36-9752-4732-a9ae-8cd8105cc4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-adde9784-5cb9-480a-9777-c2102dcd1413,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-5682e882-0759-45fc-930c-0cc12d124160,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-bd8f7c74-f265-4bbe-b3a4-dc95dd1870ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038288626-172.17.0.8-1596937826615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33512,DS-9f7416be-072d-43e5-9264-601320d3cead,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-e788d79a-3f70-4a6f-a01f-37ac97f2dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-0329447f-060b-4583-be82-283544141668,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-80353047-f912-4a41-9f52-85373ef9b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-bd33ca36-9752-4732-a9ae-8cd8105cc4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-adde9784-5cb9-480a-9777-c2102dcd1413,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-5682e882-0759-45fc-930c-0cc12d124160,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-bd8f7c74-f265-4bbe-b3a4-dc95dd1870ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980027804-172.17.0.8-1596937959927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-99bcdaea-6427-40a2-a869-e074256d3377,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-5bf01357-48e4-44bd-a8e9-f390be9ee681,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-1818321b-413c-4fbe-8ac2-f109a1451b15,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-568b8b93-2376-42e5-922b-4cb783eaca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-72579351-7bad-4ec7-8151-538adf3ff62a,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-df0851e3-5f1e-435d-a02a-d646ecd1f108,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-f0fd2276-300c-4b27-965d-e73c73e32696,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-9525f2c6-34d4-4d5f-a131-1be187e05954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980027804-172.17.0.8-1596937959927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-99bcdaea-6427-40a2-a869-e074256d3377,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-5bf01357-48e4-44bd-a8e9-f390be9ee681,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-1818321b-413c-4fbe-8ac2-f109a1451b15,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-568b8b93-2376-42e5-922b-4cb783eaca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-72579351-7bad-4ec7-8151-538adf3ff62a,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-df0851e3-5f1e-435d-a02a-d646ecd1f108,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-f0fd2276-300c-4b27-965d-e73c73e32696,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-9525f2c6-34d4-4d5f-a131-1be187e05954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5166
