reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580541701-172.17.0.18-1596961349586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-d22ff381-3610-4173-b627-7a9efe6790cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-c8acb2f2-17a5-4c82-ac63-5b54e382b9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-986fc03c-1373-4b9f-be3b-5841492f5ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-09dda128-b7a3-43c8-9a78-f92f8b44f244,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-500686af-6dfd-4271-b1d6-016b5411e554,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-8af7e11d-c3a9-4e3c-8459-fe3b68b9ff26,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-9dd9506d-6c7b-48c3-bb11-1b7cebd38905,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-3c82c191-7156-4a5e-90e0-f08cb22c3d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580541701-172.17.0.18-1596961349586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-d22ff381-3610-4173-b627-7a9efe6790cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-c8acb2f2-17a5-4c82-ac63-5b54e382b9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-986fc03c-1373-4b9f-be3b-5841492f5ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-09dda128-b7a3-43c8-9a78-f92f8b44f244,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-500686af-6dfd-4271-b1d6-016b5411e554,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-8af7e11d-c3a9-4e3c-8459-fe3b68b9ff26,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-9dd9506d-6c7b-48c3-bb11-1b7cebd38905,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-3c82c191-7156-4a5e-90e0-f08cb22c3d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784736017-172.17.0.18-1596961385319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-371d0e3b-4b4b-4606-ac6d-49a65b61c2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-58a3fd4e-afc2-4dc6-917e-198dbddec553,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-c2d56b73-7f0d-4bbe-96f5-df545df3581f,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-a4ebf390-b6f6-4004-ab0b-e124ab6396a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-33cf00aa-3cbd-4a90-85be-37b729b9c9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-6a39f97b-5b4d-47cc-9452-40dadb2532d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-3945fe36-c71d-49eb-b1c6-b12905131cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-c460687c-f570-49df-9154-4f16db88c4c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784736017-172.17.0.18-1596961385319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-371d0e3b-4b4b-4606-ac6d-49a65b61c2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-58a3fd4e-afc2-4dc6-917e-198dbddec553,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-c2d56b73-7f0d-4bbe-96f5-df545df3581f,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-a4ebf390-b6f6-4004-ab0b-e124ab6396a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-33cf00aa-3cbd-4a90-85be-37b729b9c9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-6a39f97b-5b4d-47cc-9452-40dadb2532d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-3945fe36-c71d-49eb-b1c6-b12905131cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-c460687c-f570-49df-9154-4f16db88c4c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506766141-172.17.0.18-1596961751237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42014,DS-6b9be63e-ef54-4f92-b260-cab1e8e3c716,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-292576db-5248-47a4-afea-5c10fb306f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-2a731f37-d8f3-440e-97b3-8936cfa248d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-3bd1096a-d3eb-40e6-93fc-7def4fe9e955,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-f5d933ea-e6ed-4636-816a-6d71e59480ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-48ce64f9-5935-4163-ac1b-ceab704fd453,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-25b95049-68aa-4d01-af94-a3d8e0cd74fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-0075ee39-dd65-42f7-99bf-8829b3330005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506766141-172.17.0.18-1596961751237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42014,DS-6b9be63e-ef54-4f92-b260-cab1e8e3c716,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-292576db-5248-47a4-afea-5c10fb306f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-2a731f37-d8f3-440e-97b3-8936cfa248d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-3bd1096a-d3eb-40e6-93fc-7def4fe9e955,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-f5d933ea-e6ed-4636-816a-6d71e59480ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-48ce64f9-5935-4163-ac1b-ceab704fd453,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-25b95049-68aa-4d01-af94-a3d8e0cd74fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-0075ee39-dd65-42f7-99bf-8829b3330005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702484696-172.17.0.18-1596961924243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36108,DS-c93a163b-09c0-484b-a621-693d6ac58849,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-509094d3-4c0c-4d2a-ace4-14cb89722f47,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-fbfc6d16-c313-4a5f-9316-dadd79d474ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-40f88054-2296-40ee-b95d-627a32940571,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-b522f4fc-9cb0-4663-8b57-a2bf38ad863e,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-fe819462-4839-4e0f-80ee-5d1851c6ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-ffba2358-3133-435e-a7b7-7a950323683e,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-1e91439e-6cbe-43be-a287-2c8925818a22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702484696-172.17.0.18-1596961924243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36108,DS-c93a163b-09c0-484b-a621-693d6ac58849,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-509094d3-4c0c-4d2a-ace4-14cb89722f47,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-fbfc6d16-c313-4a5f-9316-dadd79d474ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-40f88054-2296-40ee-b95d-627a32940571,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-b522f4fc-9cb0-4663-8b57-a2bf38ad863e,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-fe819462-4839-4e0f-80ee-5d1851c6ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-ffba2358-3133-435e-a7b7-7a950323683e,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-1e91439e-6cbe-43be-a287-2c8925818a22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520050208-172.17.0.18-1596962249651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44675,DS-6d21d836-da28-404d-b952-ad9d19ff1f84,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-8171967a-44d2-46ad-9b34-d4ec52071bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-35cf0dd7-ffcb-4128-8edd-7dfcbcaa0adb,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-c8bd79c9-c5cc-44f2-a35f-88c0ffa6929b,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-e4cf16a8-dc21-49fd-94a1-35543687253c,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-ac1dfa52-f8ea-4bfa-9d4c-66ed08f48dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-7da0127c-7524-4deb-890b-e9582847f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-9ce593af-1152-4259-9c3c-7c543a68e3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520050208-172.17.0.18-1596962249651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44675,DS-6d21d836-da28-404d-b952-ad9d19ff1f84,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-8171967a-44d2-46ad-9b34-d4ec52071bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-35cf0dd7-ffcb-4128-8edd-7dfcbcaa0adb,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-c8bd79c9-c5cc-44f2-a35f-88c0ffa6929b,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-e4cf16a8-dc21-49fd-94a1-35543687253c,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-ac1dfa52-f8ea-4bfa-9d4c-66ed08f48dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-7da0127c-7524-4deb-890b-e9582847f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-9ce593af-1152-4259-9c3c-7c543a68e3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308540884-172.17.0.18-1596962488705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-9bf94765-b872-4638-b9e8-de99e630cb93,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-7b1c8e9c-1fa5-46eb-a41f-2f2eb19b94c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-259b3194-614a-42b7-80e3-3bd487cdc19d,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-7cbac8aa-1ae6-4780-a65d-76c39e1ce025,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-bfcbc0d0-22e0-4880-9fdd-6fa8a30e54ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-1a00ac60-d9f9-4a08-bb11-28139dd6ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-c25ba0bc-ee27-4f85-9ee6-433bb978c663,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-162a96f3-6fb1-434c-8d8e-0d89ef92a3a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308540884-172.17.0.18-1596962488705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-9bf94765-b872-4638-b9e8-de99e630cb93,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-7b1c8e9c-1fa5-46eb-a41f-2f2eb19b94c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-259b3194-614a-42b7-80e3-3bd487cdc19d,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-7cbac8aa-1ae6-4780-a65d-76c39e1ce025,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-bfcbc0d0-22e0-4880-9fdd-6fa8a30e54ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-1a00ac60-d9f9-4a08-bb11-28139dd6ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-c25ba0bc-ee27-4f85-9ee6-433bb978c663,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-162a96f3-6fb1-434c-8d8e-0d89ef92a3a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253607182-172.17.0.18-1596962568870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-a13df060-2cd8-4d64-b03e-55257a7e355e,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-3663d480-eb1f-448a-8994-7190d19bed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-7a09c8c0-4859-43ac-bd7e-d3229339354e,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-ead279d0-24f3-4fa5-ab6a-adf1eec6a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-359a7d1a-6725-4b70-be0a-dd4bfc628216,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-852635f6-7255-4f34-b4e7-30841f8b48b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-8cff71ff-0b3d-47b5-88f2-bacc6a6c7561,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-f99e3c2c-ffa0-4c21-85dd-e006a16ba03b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253607182-172.17.0.18-1596962568870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-a13df060-2cd8-4d64-b03e-55257a7e355e,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-3663d480-eb1f-448a-8994-7190d19bed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-7a09c8c0-4859-43ac-bd7e-d3229339354e,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-ead279d0-24f3-4fa5-ab6a-adf1eec6a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-359a7d1a-6725-4b70-be0a-dd4bfc628216,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-852635f6-7255-4f34-b4e7-30841f8b48b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-8cff71ff-0b3d-47b5-88f2-bacc6a6c7561,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-f99e3c2c-ffa0-4c21-85dd-e006a16ba03b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553789332-172.17.0.18-1596962674133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-e2215482-657b-4f6f-98f3-5b5731d5d72a,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-b7db7ed5-af72-4dca-8814-87ced3b26154,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-8e8261a5-fa64-433c-9e0a-b47474156a82,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-e0642f39-3046-4363-b871-a34d37b081fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-3ca3e74b-3a92-4bac-bffb-8811636eac48,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-eec359f8-2e4c-4398-b609-701d9b687b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-bfd97abd-8ae2-4249-8086-9f303f1e59e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-6fb51e86-7e69-499a-82f2-8a174286a775,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553789332-172.17.0.18-1596962674133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-e2215482-657b-4f6f-98f3-5b5731d5d72a,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-b7db7ed5-af72-4dca-8814-87ced3b26154,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-8e8261a5-fa64-433c-9e0a-b47474156a82,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-e0642f39-3046-4363-b871-a34d37b081fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-3ca3e74b-3a92-4bac-bffb-8811636eac48,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-eec359f8-2e4c-4398-b609-701d9b687b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-bfd97abd-8ae2-4249-8086-9f303f1e59e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-6fb51e86-7e69-499a-82f2-8a174286a775,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522028555-172.17.0.18-1596962782931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-b63c2ea9-e44a-4db9-8e0d-7a37e0e32da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-0d3a09cb-a4c5-4b75-a840-d8450dc0b08b,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-5c650af4-0c2c-4f29-a905-a9bf768beb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-61b79205-57db-4ec2-9687-ae73f11012b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-6837da08-648b-4a05-8fae-26836f471439,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-c6c28579-adaa-449c-8f94-1f31444eef59,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-2729cc56-8fba-43ce-8890-01929d2d5a15,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-f5d73e76-b7d6-40a5-8bb3-939944175531,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522028555-172.17.0.18-1596962782931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-b63c2ea9-e44a-4db9-8e0d-7a37e0e32da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-0d3a09cb-a4c5-4b75-a840-d8450dc0b08b,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-5c650af4-0c2c-4f29-a905-a9bf768beb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-61b79205-57db-4ec2-9687-ae73f11012b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-6837da08-648b-4a05-8fae-26836f471439,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-c6c28579-adaa-449c-8f94-1f31444eef59,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-2729cc56-8fba-43ce-8890-01929d2d5a15,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-f5d73e76-b7d6-40a5-8bb3-939944175531,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79866292-172.17.0.18-1596962994326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-05531e95-6245-4cf7-a992-bdebaf0f160f,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-21b0edc8-4658-4869-a422-e96c5f5ba742,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-6a6b6245-32be-4ba8-b9cf-4583f38f2e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-7449a752-fb98-42b0-92db-eb667074385a,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-a3943dbe-e327-4be6-958b-31e7e0df4c19,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-e8a1df1f-978d-4f89-bb8e-4f418888d5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-140e3c18-1bf1-457a-b3e3-f58017b71e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-07ad8093-3387-415c-adcd-26ad38216abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79866292-172.17.0.18-1596962994326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-05531e95-6245-4cf7-a992-bdebaf0f160f,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-21b0edc8-4658-4869-a422-e96c5f5ba742,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-6a6b6245-32be-4ba8-b9cf-4583f38f2e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-7449a752-fb98-42b0-92db-eb667074385a,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-a3943dbe-e327-4be6-958b-31e7e0df4c19,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-e8a1df1f-978d-4f89-bb8e-4f418888d5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-140e3c18-1bf1-457a-b3e3-f58017b71e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-07ad8093-3387-415c-adcd-26ad38216abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613402303-172.17.0.18-1596963036559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35666,DS-a2839ea1-aa97-4185-9c94-10e752092a90,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-bebdd3c9-c6a6-4a08-a71e-edf2eb9532ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-b2611119-ba45-4047-814d-1370b26cf39a,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-4d6d2c8f-9587-41fe-9890-8768328514cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-8a1624fb-da2c-431a-b084-9ae3b1ed4d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-102b2f3f-c5a5-41df-bc5d-3907d275dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-3b2ac73a-8322-4974-9d22-85dbf16ef701,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-736b5237-147e-4c99-ade1-6c605cd4cfc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613402303-172.17.0.18-1596963036559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35666,DS-a2839ea1-aa97-4185-9c94-10e752092a90,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-bebdd3c9-c6a6-4a08-a71e-edf2eb9532ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-b2611119-ba45-4047-814d-1370b26cf39a,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-4d6d2c8f-9587-41fe-9890-8768328514cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-8a1624fb-da2c-431a-b084-9ae3b1ed4d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-102b2f3f-c5a5-41df-bc5d-3907d275dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-3b2ac73a-8322-4974-9d22-85dbf16ef701,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-736b5237-147e-4c99-ade1-6c605cd4cfc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259879842-172.17.0.18-1596963217054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44559,DS-f8b6196a-457b-4b56-80ec-ae8ad126bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-ec8578a5-7d5d-4e0a-8d8b-55c9480be216,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-ac3aa104-0011-4220-8c09-6a140f89a548,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-f31057f3-2f2c-4af8-bb67-6f0d785b7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-e40230d7-cf57-4dca-a501-562932a724dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-2a71dbcd-2db0-496e-ab0a-688dbc2fbc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-eeea539d-5b31-440f-96ef-a433f93a123a,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-54c1024e-de5a-4902-9a8c-9d5f861dc5c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259879842-172.17.0.18-1596963217054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44559,DS-f8b6196a-457b-4b56-80ec-ae8ad126bb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-ec8578a5-7d5d-4e0a-8d8b-55c9480be216,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-ac3aa104-0011-4220-8c09-6a140f89a548,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-f31057f3-2f2c-4af8-bb67-6f0d785b7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-e40230d7-cf57-4dca-a501-562932a724dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-2a71dbcd-2db0-496e-ab0a-688dbc2fbc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-eeea539d-5b31-440f-96ef-a433f93a123a,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-54c1024e-de5a-4902-9a8c-9d5f861dc5c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904127973-172.17.0.18-1596963350343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-b2f7348b-1de9-408e-ae5e-3d18633de0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-7b21d3af-b303-4bcf-9a05-1dd47a2b57c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-89d9cee9-8ce9-42a5-a100-6f0aea6ca7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-52fb249c-a645-4e5c-8fd9-319e2ad41ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-852ddcdb-9a57-4f12-b23b-f68466a5fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-ece2ea17-98fe-4200-a11b-71b1bd73c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-b4152852-78d9-40ef-9430-3d4b223b4b19,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-c7b44850-7fe3-4912-b955-2b499c12bc57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904127973-172.17.0.18-1596963350343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-b2f7348b-1de9-408e-ae5e-3d18633de0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-7b21d3af-b303-4bcf-9a05-1dd47a2b57c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-89d9cee9-8ce9-42a5-a100-6f0aea6ca7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-52fb249c-a645-4e5c-8fd9-319e2ad41ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-852ddcdb-9a57-4f12-b23b-f68466a5fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-ece2ea17-98fe-4200-a11b-71b1bd73c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-b4152852-78d9-40ef-9430-3d4b223b4b19,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-c7b44850-7fe3-4912-b955-2b499c12bc57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708758697-172.17.0.18-1596963459156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-48cf2eb9-17af-47f4-80ef-31a0ad8d4fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-8d6f1130-da1f-4558-82fb-d0eda96b7e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-369ee02d-4d52-421c-a77a-2a3c80f78480,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-49f068b0-b2c8-4591-b070-e9e0974c7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-ffe4f38c-5c59-48ca-a70d-fe7810dd838a,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-d4779992-8b34-4b46-a2a1-8d0ba6888792,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-1291e045-65af-4bd7-90df-b3ba95917129,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-d75bc620-53a7-491c-9aef-922f23d1a3ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708758697-172.17.0.18-1596963459156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-48cf2eb9-17af-47f4-80ef-31a0ad8d4fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-8d6f1130-da1f-4558-82fb-d0eda96b7e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-369ee02d-4d52-421c-a77a-2a3c80f78480,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-49f068b0-b2c8-4591-b070-e9e0974c7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-ffe4f38c-5c59-48ca-a70d-fe7810dd838a,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-d4779992-8b34-4b46-a2a1-8d0ba6888792,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-1291e045-65af-4bd7-90df-b3ba95917129,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-d75bc620-53a7-491c-9aef-922f23d1a3ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878849105-172.17.0.18-1596963495980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34605,DS-a732c81e-30ac-4ab0-b52d-ad8f6445019b,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-6dc2441d-ddcd-40d9-8f59-c5b87e68551d,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-d1b4afc2-c202-4dde-958d-acb76aaf9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-8656e40a-f239-47c1-b48c-a79b99d1e00a,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-c2335e60-0861-4f4d-a6df-2d65b12d21f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-aabeebe5-3f32-457c-b307-6d8705fdd58f,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-7fcc97fb-0dbc-4777-b579-823192b8afc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-7f668ad4-9d47-471f-a9f0-48c9f48cd014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878849105-172.17.0.18-1596963495980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34605,DS-a732c81e-30ac-4ab0-b52d-ad8f6445019b,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-6dc2441d-ddcd-40d9-8f59-c5b87e68551d,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-d1b4afc2-c202-4dde-958d-acb76aaf9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-8656e40a-f239-47c1-b48c-a79b99d1e00a,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-c2335e60-0861-4f4d-a6df-2d65b12d21f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-aabeebe5-3f32-457c-b307-6d8705fdd58f,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-7fcc97fb-0dbc-4777-b579-823192b8afc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-7f668ad4-9d47-471f-a9f0-48c9f48cd014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804324972-172.17.0.18-1596963528066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-a29af50f-619e-4893-9398-1419c018faad,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-b617bb4c-5a40-462c-b6f4-f743608b6867,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-a7fdc6b3-ae54-4a60-8f71-06ebaf25fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-0eb3851a-3c3b-4005-bd08-6545cfbf15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-c9429459-d312-4ecf-8a65-6f81cc377884,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-09c38267-fcc4-40b9-8054-f1550538af68,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-8ed3953b-9bf9-4727-8f2d-1477a5f4d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-bb4fb6cf-3c7a-4573-b3d4-475b1def71cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804324972-172.17.0.18-1596963528066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-a29af50f-619e-4893-9398-1419c018faad,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-b617bb4c-5a40-462c-b6f4-f743608b6867,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-a7fdc6b3-ae54-4a60-8f71-06ebaf25fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-0eb3851a-3c3b-4005-bd08-6545cfbf15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-c9429459-d312-4ecf-8a65-6f81cc377884,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-09c38267-fcc4-40b9-8054-f1550538af68,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-8ed3953b-9bf9-4727-8f2d-1477a5f4d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-bb4fb6cf-3c7a-4573-b3d4-475b1def71cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175959413-172.17.0.18-1596963644199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36273,DS-20f1f07c-3f5d-4ddc-af81-18557d590cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-9982a3ea-27fd-449b-acc7-7c7df529757f,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-ddc79fbe-8959-4caa-b0c3-de762e1cc55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-379f10ff-8fbd-46ef-ba7c-dd2cf7bb1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-fe403eac-dbd1-4104-8ba4-ed034499de01,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-e0196646-3a6f-4f87-b9ce-b556fe254d21,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e2ca76da-35a1-4661-876b-251c6ff97de4,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-648e9433-0316-44ee-8f31-37a56acbcc84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175959413-172.17.0.18-1596963644199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36273,DS-20f1f07c-3f5d-4ddc-af81-18557d590cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-9982a3ea-27fd-449b-acc7-7c7df529757f,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-ddc79fbe-8959-4caa-b0c3-de762e1cc55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-379f10ff-8fbd-46ef-ba7c-dd2cf7bb1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-fe403eac-dbd1-4104-8ba4-ed034499de01,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-e0196646-3a6f-4f87-b9ce-b556fe254d21,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e2ca76da-35a1-4661-876b-251c6ff97de4,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-648e9433-0316-44ee-8f31-37a56acbcc84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644837308-172.17.0.18-1596964190853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-c4a2bd64-f23e-443d-a6b7-1b58d2afc746,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-bc3dca5c-b241-446f-ad97-dcda9d275376,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-bdd5fce7-578c-4f39-ad30-dac2c3985ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-52d3ddce-e91d-4a75-ae6f-c7293666c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-2b972845-8182-4800-bea6-8b30ef034cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-629353e9-d381-465b-94c1-b4c38048a580,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-0b8b18fe-322e-4f9c-84f8-b62e51333742,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-9bf3265f-3f3c-4f33-843b-46b9c4bc2266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644837308-172.17.0.18-1596964190853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-c4a2bd64-f23e-443d-a6b7-1b58d2afc746,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-bc3dca5c-b241-446f-ad97-dcda9d275376,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-bdd5fce7-578c-4f39-ad30-dac2c3985ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-52d3ddce-e91d-4a75-ae6f-c7293666c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-2b972845-8182-4800-bea6-8b30ef034cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-629353e9-d381-465b-94c1-b4c38048a580,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-0b8b18fe-322e-4f9c-84f8-b62e51333742,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-9bf3265f-3f3c-4f33-843b-46b9c4bc2266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770199850-172.17.0.18-1596964256402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43543,DS-1344809d-05a4-4155-9d6d-2123b7b9fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-75fb71f6-d739-42d1-8309-21e90ff440b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-d67f50f2-cacd-445d-a3fd-f007ad88d589,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-57b23374-6001-42ff-9847-a1edfc8ec193,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-4f2781e8-eb01-4341-9513-d3b356f1744e,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-189423b9-2101-40d0-9be2-8d26ac02d7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-0775bfe7-ee7c-437c-bf18-c5733dde8c81,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-aa18f8fe-d457-4e22-b64c-11a92dbdb692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770199850-172.17.0.18-1596964256402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43543,DS-1344809d-05a4-4155-9d6d-2123b7b9fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-75fb71f6-d739-42d1-8309-21e90ff440b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-d67f50f2-cacd-445d-a3fd-f007ad88d589,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-57b23374-6001-42ff-9847-a1edfc8ec193,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-4f2781e8-eb01-4341-9513-d3b356f1744e,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-189423b9-2101-40d0-9be2-8d26ac02d7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-0775bfe7-ee7c-437c-bf18-c5733dde8c81,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-aa18f8fe-d457-4e22-b64c-11a92dbdb692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72858997-172.17.0.18-1596964294692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-975b4f74-ff96-4fdb-a769-4e6786a52b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-562e5c6d-5b99-4ff5-af05-a4a8196116ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-a94605aa-ffd8-4d30-bd06-957a5de707d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-1e8e8aca-249a-424a-a0d2-cda2d86a1bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-8504b383-6ab5-49fd-ad6d-b7bcaeb8f02a,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-eb1884d8-f516-456f-9aa3-1bcee2eafd40,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-8f32076e-d311-435b-b5f3-113bd7c05412,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-791d8d4b-e077-4492-9e0f-b4e67dd14bda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72858997-172.17.0.18-1596964294692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-975b4f74-ff96-4fdb-a769-4e6786a52b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-562e5c6d-5b99-4ff5-af05-a4a8196116ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-a94605aa-ffd8-4d30-bd06-957a5de707d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-1e8e8aca-249a-424a-a0d2-cda2d86a1bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-8504b383-6ab5-49fd-ad6d-b7bcaeb8f02a,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-eb1884d8-f516-456f-9aa3-1bcee2eafd40,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-8f32076e-d311-435b-b5f3-113bd7c05412,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-791d8d4b-e077-4492-9e0f-b4e67dd14bda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499786344-172.17.0.18-1596964364209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45760,DS-0aae6f6d-0064-47a7-b266-4bc8d17d8f89,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-db43d531-1f74-4694-b195-a909d336f2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-78b645eb-a245-4a97-a2f5-e72322b9bf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-0893e7ad-1164-4b68-ba1d-0429ce98ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-fe0bf53c-2049-4e5a-afe7-06647c0eb5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-51024966-daac-4641-8bfc-546299785003,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-4e5e8a30-838a-4e5b-9131-8c786b8bef32,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-7d513222-4451-4460-bd9c-9fe77d00a3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499786344-172.17.0.18-1596964364209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45760,DS-0aae6f6d-0064-47a7-b266-4bc8d17d8f89,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-db43d531-1f74-4694-b195-a909d336f2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-78b645eb-a245-4a97-a2f5-e72322b9bf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-0893e7ad-1164-4b68-ba1d-0429ce98ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-fe0bf53c-2049-4e5a-afe7-06647c0eb5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-51024966-daac-4641-8bfc-546299785003,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-4e5e8a30-838a-4e5b-9131-8c786b8bef32,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-7d513222-4451-4460-bd9c-9fe77d00a3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675378478-172.17.0.18-1596964482685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-0a404da1-c015-4c8a-9b07-f49c54d3429d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-4a437ce4-cc6c-4683-808b-0483c29e05f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-b95646fb-6a5d-4def-962e-812c50bf1200,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-5798e17d-cab7-4cf4-a797-c718294d934f,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-2c0b2498-9fb7-4f2c-9012-f4e8b00025b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-c710a014-794d-414b-9400-ed56374e7994,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-cd0c2e23-099a-4857-adf7-66a2f32b5c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-fd11cb43-1c4e-47a2-9aa5-d01b1282e767,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675378478-172.17.0.18-1596964482685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-0a404da1-c015-4c8a-9b07-f49c54d3429d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-4a437ce4-cc6c-4683-808b-0483c29e05f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-b95646fb-6a5d-4def-962e-812c50bf1200,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-5798e17d-cab7-4cf4-a797-c718294d934f,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-2c0b2498-9fb7-4f2c-9012-f4e8b00025b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-c710a014-794d-414b-9400-ed56374e7994,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-cd0c2e23-099a-4857-adf7-66a2f32b5c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-fd11cb43-1c4e-47a2-9aa5-d01b1282e767,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693906829-172.17.0.18-1596964513896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-9d84056f-ca69-43c5-a589-3c602fdfa725,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-dc2e3528-989e-4ea7-b94e-28f53352145d,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-79058a49-85c5-4a2d-937c-a139d6bb01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-41248790-7a1e-4c23-8331-545f0f3edb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-97edfe54-8094-4cc6-8beb-fa5ffeb7dd29,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-e7c0269b-1fa4-4cd2-a542-b978ecde94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-a518f18b-3882-465f-86e8-064d000b1598,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-f347b34e-d39a-4017-bddc-a56a2a58fc30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693906829-172.17.0.18-1596964513896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-9d84056f-ca69-43c5-a589-3c602fdfa725,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-dc2e3528-989e-4ea7-b94e-28f53352145d,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-79058a49-85c5-4a2d-937c-a139d6bb01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-41248790-7a1e-4c23-8331-545f0f3edb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-97edfe54-8094-4cc6-8beb-fa5ffeb7dd29,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-e7c0269b-1fa4-4cd2-a542-b978ecde94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-a518f18b-3882-465f-86e8-064d000b1598,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-f347b34e-d39a-4017-bddc-a56a2a58fc30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450232727-172.17.0.18-1596964950569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34873,DS-a6d023bd-34be-4faf-be4f-8d21d05013ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-216359ee-c96e-4aa1-ac9f-5081dbba7402,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-be8d1f2d-ede4-47e0-948b-fd0d7fd39b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-77aaba9e-afba-4b27-abe1-7f9f6d65cdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-b27a0fba-b9e7-42b8-baa5-ac5de6a8d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-9f13d6f3-ad56-4a89-9bef-c2469477a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-ca8d3c5b-56c9-4b95-800c-e356e303c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-47b9702f-32e3-4427-a3b3-8af938f9a5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450232727-172.17.0.18-1596964950569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34873,DS-a6d023bd-34be-4faf-be4f-8d21d05013ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-216359ee-c96e-4aa1-ac9f-5081dbba7402,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-be8d1f2d-ede4-47e0-948b-fd0d7fd39b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-77aaba9e-afba-4b27-abe1-7f9f6d65cdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-b27a0fba-b9e7-42b8-baa5-ac5de6a8d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-9f13d6f3-ad56-4a89-9bef-c2469477a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-ca8d3c5b-56c9-4b95-800c-e356e303c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-47b9702f-32e3-4427-a3b3-8af938f9a5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362546524-172.17.0.18-1596965114015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-3132e51b-9ef0-4bd1-ba60-7edb125da6be,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-fd784bb4-34de-4e5a-a1ea-67a0452371ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-e5952539-b04f-46f5-a3f3-f624b2234368,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-5c9f8aad-62ea-4dc0-a236-5ce1e82d55e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-199e7ef6-3272-49da-801c-b2024ebf50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-038177e8-50c4-472e-aaf2-d8ac11b375d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-7e3e3dfa-420f-4e1c-ad38-b38c9d05e9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-a2c5c5bc-2ed3-42df-8fac-43467f8e4fb0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362546524-172.17.0.18-1596965114015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33848,DS-3132e51b-9ef0-4bd1-ba60-7edb125da6be,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-fd784bb4-34de-4e5a-a1ea-67a0452371ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-e5952539-b04f-46f5-a3f3-f624b2234368,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-5c9f8aad-62ea-4dc0-a236-5ce1e82d55e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-199e7ef6-3272-49da-801c-b2024ebf50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-038177e8-50c4-472e-aaf2-d8ac11b375d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-7e3e3dfa-420f-4e1c-ad38-b38c9d05e9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-a2c5c5bc-2ed3-42df-8fac-43467f8e4fb0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812495138-172.17.0.18-1596965154014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36038,DS-db9491e4-347c-40e4-b8e2-493d85f62695,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-f62410c4-3b70-4cd4-9b6c-90e8b49b4433,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-44812066-42ec-48fe-b19b-c3207703b1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-39d35883-4ab7-49e9-a3ef-e6253907db0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-b879c883-d2c2-43b6-8363-54d3cc61563d,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-6444189e-3b9d-4f60-a433-9e3175179385,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-96b231f7-a596-4a51-937a-5d5f001bb017,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-b4c6b28d-186d-4ba2-bf20-c18656ef49d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812495138-172.17.0.18-1596965154014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36038,DS-db9491e4-347c-40e4-b8e2-493d85f62695,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-f62410c4-3b70-4cd4-9b6c-90e8b49b4433,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-44812066-42ec-48fe-b19b-c3207703b1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-39d35883-4ab7-49e9-a3ef-e6253907db0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-b879c883-d2c2-43b6-8363-54d3cc61563d,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-6444189e-3b9d-4f60-a433-9e3175179385,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-96b231f7-a596-4a51-937a-5d5f001bb017,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-b4c6b28d-186d-4ba2-bf20-c18656ef49d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796763931-172.17.0.18-1596965261017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41050,DS-66329b79-0775-4b4f-9817-c12ade8f4e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-d18f6370-9246-4652-ab03-8241e5374b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-f5c8abba-c48d-4b15-aa4f-358ea1cfe61b,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-7d76e4ce-35b4-4f3e-acb8-321fcbc6ddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-1874f868-7e0c-456e-b37e-1a8ba8c20d18,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-942e54a9-96ec-4d0f-95ac-e1a18cd703ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-cf414f0d-a1df-4d76-8d6b-dd507fbe051b,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-54484318-494c-4670-b0d8-bed5385503e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796763931-172.17.0.18-1596965261017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41050,DS-66329b79-0775-4b4f-9817-c12ade8f4e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-d18f6370-9246-4652-ab03-8241e5374b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-f5c8abba-c48d-4b15-aa4f-358ea1cfe61b,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-7d76e4ce-35b4-4f3e-acb8-321fcbc6ddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-1874f868-7e0c-456e-b37e-1a8ba8c20d18,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-942e54a9-96ec-4d0f-95ac-e1a18cd703ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-cf414f0d-a1df-4d76-8d6b-dd507fbe051b,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-54484318-494c-4670-b0d8-bed5385503e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426052341-172.17.0.18-1596965303159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-0879b25a-1ae8-4b8c-8fba-fbd4ea1dea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-a10421d5-8a29-4cb1-87cf-75d91587c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-020bf835-37e1-4345-8a13-221fc7b71efd,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-79f48cec-afd5-4a68-b4e7-d8fd78e51174,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-b9c1a6be-eead-4169-82b0-2c210d560ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-7fb5b51d-4904-4096-aaef-81ce858a9683,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-0bde2ad2-442d-40cd-adeb-606ad9b7b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-57854561-6244-46f4-9751-31a6c24ecdc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426052341-172.17.0.18-1596965303159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-0879b25a-1ae8-4b8c-8fba-fbd4ea1dea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-a10421d5-8a29-4cb1-87cf-75d91587c1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-020bf835-37e1-4345-8a13-221fc7b71efd,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-79f48cec-afd5-4a68-b4e7-d8fd78e51174,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-b9c1a6be-eead-4169-82b0-2c210d560ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-7fb5b51d-4904-4096-aaef-81ce858a9683,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-0bde2ad2-442d-40cd-adeb-606ad9b7b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-57854561-6244-46f4-9751-31a6c24ecdc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83416153-172.17.0.18-1596965343703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-5e845708-2b4e-4506-93a4-636e6a44cdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-fc3f0de1-4935-4d56-9c1e-56629d876ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-1ff2801d-6c96-4f14-bac3-727573758429,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-29c0eda5-741c-43b1-accc-263ccc0ec2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-c576b4a7-190f-48ad-ba1c-dfbb3568ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-23b592d4-5c4e-4c76-b604-be2f6c2cfe2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-ce09aa07-dd44-4e0d-86cd-c8e93bb90c64,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-f0811b34-a26f-4b55-aa45-602835c6f0a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83416153-172.17.0.18-1596965343703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-5e845708-2b4e-4506-93a4-636e6a44cdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-fc3f0de1-4935-4d56-9c1e-56629d876ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-1ff2801d-6c96-4f14-bac3-727573758429,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-29c0eda5-741c-43b1-accc-263ccc0ec2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-c576b4a7-190f-48ad-ba1c-dfbb3568ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-23b592d4-5c4e-4c76-b604-be2f6c2cfe2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-ce09aa07-dd44-4e0d-86cd-c8e93bb90c64,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-f0811b34-a26f-4b55-aa45-602835c6f0a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13312661-172.17.0.18-1596965418954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-a1e2ae98-ca98-481c-8dfd-485ac279205c,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-71753af7-fd9a-47f2-86ce-71121f15c082,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-24f3dd75-b250-42b8-9c26-b4a86330b179,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-0d78cfe5-68bb-4378-9842-c78b73620a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ce53c097-98b2-4bf7-a8bb-ded5100557b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-ddc6eb4c-bbb2-44a4-a6ca-f66dbf70c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-14583782-8f64-4984-8e1f-d32ccaa25f30,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-5b969750-be40-40a2-8589-2c34381e0d67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13312661-172.17.0.18-1596965418954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-a1e2ae98-ca98-481c-8dfd-485ac279205c,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-71753af7-fd9a-47f2-86ce-71121f15c082,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-24f3dd75-b250-42b8-9c26-b4a86330b179,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-0d78cfe5-68bb-4378-9842-c78b73620a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ce53c097-98b2-4bf7-a8bb-ded5100557b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-ddc6eb4c-bbb2-44a4-a6ca-f66dbf70c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-14583782-8f64-4984-8e1f-d32ccaa25f30,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-5b969750-be40-40a2-8589-2c34381e0d67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116591838-172.17.0.18-1596965451486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-0b74c484-77bd-4815-b370-f24129385398,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-498ba94b-3520-4c9f-9b95-8781c660692f,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-c75b709c-3602-4499-a598-2498f093cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-629f8cc4-b724-422e-924c-90478d8e1c41,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-a8b8abea-c71b-4d05-87d0-fa1a67d24c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-56118faa-f7ee-4bbb-8ca3-7c0ab34610d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-c13971eb-48ad-4d94-83a2-4bc43b44c27b,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-cb9d9f04-c865-48a1-b7ea-64b57e543565,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116591838-172.17.0.18-1596965451486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-0b74c484-77bd-4815-b370-f24129385398,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-498ba94b-3520-4c9f-9b95-8781c660692f,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-c75b709c-3602-4499-a598-2498f093cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-629f8cc4-b724-422e-924c-90478d8e1c41,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-a8b8abea-c71b-4d05-87d0-fa1a67d24c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-56118faa-f7ee-4bbb-8ca3-7c0ab34610d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-c13971eb-48ad-4d94-83a2-4bc43b44c27b,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-cb9d9f04-c865-48a1-b7ea-64b57e543565,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739357872-172.17.0.18-1596965488727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34438,DS-6ecb2990-6e62-4ee3-8457-aa7580bd4acb,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-f911ab24-0d40-45cc-97d9-af5e02362e87,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-acd8ba02-4159-4291-8019-fd62dd436da5,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-42dc84c1-dfb5-4662-939c-78547cc66465,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-92f619d2-3c04-43e9-b2de-f1c802e4be5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-fabd612e-e9c3-46d0-8d8e-714a14731e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-2155a7ae-7dbd-40e8-abc1-3730295109a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-96c35b47-f468-4581-8cf1-9cbc640759b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739357872-172.17.0.18-1596965488727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34438,DS-6ecb2990-6e62-4ee3-8457-aa7580bd4acb,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-f911ab24-0d40-45cc-97d9-af5e02362e87,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-acd8ba02-4159-4291-8019-fd62dd436da5,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-42dc84c1-dfb5-4662-939c-78547cc66465,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-92f619d2-3c04-43e9-b2de-f1c802e4be5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-fabd612e-e9c3-46d0-8d8e-714a14731e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-2155a7ae-7dbd-40e8-abc1-3730295109a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-96c35b47-f468-4581-8cf1-9cbc640759b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22296949-172.17.0.18-1596965526580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44161,DS-0d46f8ba-9fa1-4dfe-be5b-5f94f5a663f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-35df3df9-05c9-4dfe-8aa2-82158691362e,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-997368bc-f0af-4eae-baf7-c13b1760ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-2c239894-64cc-4ae7-9dbb-69feaa24a159,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-cf5d4a78-81de-4724-b61a-560b5d0e8728,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-64b2e489-fc92-4855-8ec9-ee8ad59b9d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-a109c4bd-4ae0-4ff8-8885-bb32b1968f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-839ff30c-2c5a-4929-8676-26dd046d77b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22296949-172.17.0.18-1596965526580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44161,DS-0d46f8ba-9fa1-4dfe-be5b-5f94f5a663f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-35df3df9-05c9-4dfe-8aa2-82158691362e,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-997368bc-f0af-4eae-baf7-c13b1760ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-2c239894-64cc-4ae7-9dbb-69feaa24a159,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-cf5d4a78-81de-4724-b61a-560b5d0e8728,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-64b2e489-fc92-4855-8ec9-ee8ad59b9d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-a109c4bd-4ae0-4ff8-8885-bb32b1968f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-839ff30c-2c5a-4929-8676-26dd046d77b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337284637-172.17.0.18-1596965562622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37127,DS-4acccdf5-1a88-4b33-a5a6-b0051ff2973c,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-42064b2d-2886-402e-9eb2-c85e8e8d9619,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-247f204f-bf70-4b62-b2e9-45609864fb34,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-30613680-6714-4661-8c7c-0330bebd69c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-373ba2eb-86a9-41cc-ad5d-78b93d76d544,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-28c76ceb-4053-42ce-a974-957e3d132ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-55422adb-c68d-4ea6-b0cc-1e759a402432,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-672e5143-4007-4717-ac95-3d143907be09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337284637-172.17.0.18-1596965562622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37127,DS-4acccdf5-1a88-4b33-a5a6-b0051ff2973c,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-42064b2d-2886-402e-9eb2-c85e8e8d9619,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-247f204f-bf70-4b62-b2e9-45609864fb34,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-30613680-6714-4661-8c7c-0330bebd69c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-373ba2eb-86a9-41cc-ad5d-78b93d76d544,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-28c76ceb-4053-42ce-a974-957e3d132ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-55422adb-c68d-4ea6-b0cc-1e759a402432,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-672e5143-4007-4717-ac95-3d143907be09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22960678-172.17.0.18-1596965598703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-480ee531-62d3-4271-9e3b-52d93f00166a,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-9863b9f1-69b0-4148-84d1-f71b6984cba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-1f4ac488-9d88-432a-85c2-31be622ef0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-0f50c8f4-6d62-4b56-bf97-b54007e90b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-0b6d222a-fd76-4b2c-aa8f-9e7fe24f5dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-d1a90260-0241-4eb2-9477-0cfc4b81bdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-96a18022-b8a8-4381-b410-71987af68564,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-0797d81a-5fd4-43b4-ad07-4f0391ced69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22960678-172.17.0.18-1596965598703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-480ee531-62d3-4271-9e3b-52d93f00166a,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-9863b9f1-69b0-4148-84d1-f71b6984cba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-1f4ac488-9d88-432a-85c2-31be622ef0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-0f50c8f4-6d62-4b56-bf97-b54007e90b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-0b6d222a-fd76-4b2c-aa8f-9e7fe24f5dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-d1a90260-0241-4eb2-9477-0cfc4b81bdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-96a18022-b8a8-4381-b410-71987af68564,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-0797d81a-5fd4-43b4-ad07-4f0391ced69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790820844-172.17.0.18-1596965784492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36122,DS-d1372d93-8cb1-4d51-a87b-fb0b2cef0bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-d617e289-ed58-4695-a2de-fc9cc8af969c,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-856326eb-189f-4496-a7ec-f613bb27fa82,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-ccb31a91-3c0f-4da8-a383-5cacd070cf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-4fb95016-7575-4bb7-b2bb-e0cce29a01fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-7af485e9-0fce-4ffd-a797-ef74a36b7a56,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-da6a3234-30ac-40b9-a787-22f129d7bdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-0e1fe7e9-b4ca-484b-a7f2-4a9a31159d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790820844-172.17.0.18-1596965784492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36122,DS-d1372d93-8cb1-4d51-a87b-fb0b2cef0bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-d617e289-ed58-4695-a2de-fc9cc8af969c,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-856326eb-189f-4496-a7ec-f613bb27fa82,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-ccb31a91-3c0f-4da8-a383-5cacd070cf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-4fb95016-7575-4bb7-b2bb-e0cce29a01fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-7af485e9-0fce-4ffd-a797-ef74a36b7a56,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-da6a3234-30ac-40b9-a787-22f129d7bdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-0e1fe7e9-b4ca-484b-a7f2-4a9a31159d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662718995-172.17.0.18-1596965963855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33127,DS-4028da93-42c4-48c4-8654-8934fdde3aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-28054f27-9fc2-477b-8c7d-9fb91f4139ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-cf62d5ee-a22f-4472-85d6-51cfe4dca39e,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-14f6aac4-3596-43db-acb7-98c35246ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-1b4032ac-fe52-4f55-abd9-af2de2bd8726,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-bb1b4c60-97e1-4f15-b39c-e7b615d37583,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-94e4953e-5d96-4791-91af-6235210b9780,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-9801c1bd-55bf-432a-b3a8-c6955950d622,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662718995-172.17.0.18-1596965963855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33127,DS-4028da93-42c4-48c4-8654-8934fdde3aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-28054f27-9fc2-477b-8c7d-9fb91f4139ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-cf62d5ee-a22f-4472-85d6-51cfe4dca39e,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-14f6aac4-3596-43db-acb7-98c35246ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-1b4032ac-fe52-4f55-abd9-af2de2bd8726,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-bb1b4c60-97e1-4f15-b39c-e7b615d37583,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-94e4953e-5d96-4791-91af-6235210b9780,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-9801c1bd-55bf-432a-b3a8-c6955950d622,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701523695-172.17.0.18-1596966047793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36708,DS-0d759d7d-e683-465e-9a83-c7aaff8f380e,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-825f0f77-9ca8-4cc1-95a9-6a19c4b7a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-cc26fa7f-02d0-41f4-994c-135aa963b2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-c37cb317-d925-49c2-88ea-a90982221319,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-d82c0d51-bf5e-4cdf-b5bd-77572b1f5211,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-585d5016-4f9f-4ee2-8580-d17f8e9404d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-8c70284e-f078-42ac-8eb3-76a831aade21,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-046ef54e-3962-42be-8af7-3fd90898183f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701523695-172.17.0.18-1596966047793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36708,DS-0d759d7d-e683-465e-9a83-c7aaff8f380e,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-825f0f77-9ca8-4cc1-95a9-6a19c4b7a0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-cc26fa7f-02d0-41f4-994c-135aa963b2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-c37cb317-d925-49c2-88ea-a90982221319,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-d82c0d51-bf5e-4cdf-b5bd-77572b1f5211,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-585d5016-4f9f-4ee2-8580-d17f8e9404d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-8c70284e-f078-42ac-8eb3-76a831aade21,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-046ef54e-3962-42be-8af7-3fd90898183f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5481
