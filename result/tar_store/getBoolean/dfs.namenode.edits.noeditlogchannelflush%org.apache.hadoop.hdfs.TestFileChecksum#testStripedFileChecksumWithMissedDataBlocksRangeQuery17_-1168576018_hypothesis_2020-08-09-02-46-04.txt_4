reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402430449-172.17.0.5-1596942008639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41147,DS-88ed9336-d6e1-4d89-9d7b-d2f00752fa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-fa3e6174-5670-4f15-9a76-9ebc962afd30,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-91992f25-c118-4601-8bb5-2a819d867f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-2de26f20-1cb0-4a91-889d-bc965c0cb2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-b16fc65e-c6f7-406d-9407-3d4b0ca8861a,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-36879273-bcf6-4019-a0db-4c219d6c54ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-171854fc-3382-45cd-852b-a58363a60baf,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-3d3bb290-248f-47d6-a7c1-4468f04cacc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402430449-172.17.0.5-1596942008639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41147,DS-88ed9336-d6e1-4d89-9d7b-d2f00752fa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-fa3e6174-5670-4f15-9a76-9ebc962afd30,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-91992f25-c118-4601-8bb5-2a819d867f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-2de26f20-1cb0-4a91-889d-bc965c0cb2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-b16fc65e-c6f7-406d-9407-3d4b0ca8861a,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-36879273-bcf6-4019-a0db-4c219d6c54ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-171854fc-3382-45cd-852b-a58363a60baf,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-3d3bb290-248f-47d6-a7c1-4468f04cacc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883488706-172.17.0.5-1596942246346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33796,DS-056aab97-1f99-4b0c-9e08-e22386cc8f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-a32c3ef2-6469-4c39-9519-bc27c769f4da,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-85d49572-ecd9-4324-8bb3-9d05580c91f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-8a8fc3ef-5e91-44ee-9724-4d10c3b8db63,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-3c9c3fa3-4f72-4a30-945d-e19650085a76,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-cec08007-b6ac-459a-b186-12ddde8f3daa,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-717e18a0-0984-4eb3-849a-0447c622aada,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-c8c6d183-fb80-4b73-804b-3999a3156de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883488706-172.17.0.5-1596942246346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33796,DS-056aab97-1f99-4b0c-9e08-e22386cc8f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-a32c3ef2-6469-4c39-9519-bc27c769f4da,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-85d49572-ecd9-4324-8bb3-9d05580c91f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-8a8fc3ef-5e91-44ee-9724-4d10c3b8db63,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-3c9c3fa3-4f72-4a30-945d-e19650085a76,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-cec08007-b6ac-459a-b186-12ddde8f3daa,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-717e18a0-0984-4eb3-849a-0447c622aada,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-c8c6d183-fb80-4b73-804b-3999a3156de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287578576-172.17.0.5-1596942508912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44240,DS-aa4efbf9-0481-4cdf-bfea-7e1800282410,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-bbf5c6e7-f3e0-4a10-b3e2-0ce829ea3fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-1f86e21f-c2e6-4242-87e4-b4654c15b747,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-38b950a2-01e5-40e6-a610-e6a8eeb8137d,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-adb9eb66-538f-4492-8b26-779019768344,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-ff495404-d14a-43c4-9ff5-00b8d2b43a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-e0a6dd25-ee65-4154-b466-c4fab1dbe983,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-7e31337b-e46f-4fa2-9843-825ad09e0310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287578576-172.17.0.5-1596942508912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44240,DS-aa4efbf9-0481-4cdf-bfea-7e1800282410,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-bbf5c6e7-f3e0-4a10-b3e2-0ce829ea3fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-1f86e21f-c2e6-4242-87e4-b4654c15b747,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-38b950a2-01e5-40e6-a610-e6a8eeb8137d,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-adb9eb66-538f-4492-8b26-779019768344,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-ff495404-d14a-43c4-9ff5-00b8d2b43a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-e0a6dd25-ee65-4154-b466-c4fab1dbe983,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-7e31337b-e46f-4fa2-9843-825ad09e0310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096110514-172.17.0.5-1596942576599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-21da54b6-b59b-4221-bd5f-1a2cf6711a12,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-0adc2588-7c30-4319-be65-63f455fa9866,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-ed56f4f8-048e-4313-b0a8-ea125f76cbea,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-45b4ad20-994a-4b20-a639-f2a465af2601,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-a0adde7f-51d8-497c-b095-e8c573abb04c,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-f163a5bc-9294-4c70-bcbc-d21ea32f103a,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-fa232457-d452-4dc8-bc09-db6ec1f2e1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-2f82d901-f8d9-4f9b-862c-efa8def898bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096110514-172.17.0.5-1596942576599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-21da54b6-b59b-4221-bd5f-1a2cf6711a12,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-0adc2588-7c30-4319-be65-63f455fa9866,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-ed56f4f8-048e-4313-b0a8-ea125f76cbea,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-45b4ad20-994a-4b20-a639-f2a465af2601,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-a0adde7f-51d8-497c-b095-e8c573abb04c,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-f163a5bc-9294-4c70-bcbc-d21ea32f103a,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-fa232457-d452-4dc8-bc09-db6ec1f2e1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-2f82d901-f8d9-4f9b-862c-efa8def898bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781003747-172.17.0.5-1596942653261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37494,DS-40bc694b-1d6f-4b25-b872-db3120ed9a74,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-30ec947b-ce1a-428a-a6ef-8b28a0aa8396,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-1b46bcf1-a4a1-4e94-9423-00c61fcd030b,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-ef8a5d6e-c821-4b6f-8728-cdc213119652,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-9c7cde6f-9723-4562-9b93-c7af49472aff,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-f3750718-6cee-4fd6-86cc-ad3a42564cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-d6f46409-b18f-4852-95b4-d20bde9e1773,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-622cc6b2-cd37-437d-afe9-b29717f84ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781003747-172.17.0.5-1596942653261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37494,DS-40bc694b-1d6f-4b25-b872-db3120ed9a74,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-30ec947b-ce1a-428a-a6ef-8b28a0aa8396,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-1b46bcf1-a4a1-4e94-9423-00c61fcd030b,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-ef8a5d6e-c821-4b6f-8728-cdc213119652,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-9c7cde6f-9723-4562-9b93-c7af49472aff,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-f3750718-6cee-4fd6-86cc-ad3a42564cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-d6f46409-b18f-4852-95b4-d20bde9e1773,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-622cc6b2-cd37-437d-afe9-b29717f84ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466985179-172.17.0.5-1596942911283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-7a267565-7954-4b1d-a481-c37156b880b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-dc31cfcf-b7fa-4141-8158-e23f52b087c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-9b6a5da1-b9b3-492d-8b0c-d3348808e6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-43e1ba6b-18f2-42b4-9b1d-96b2e9eb4c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-b5836e27-aadf-4429-ad27-9e9533352efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-f160cb3f-4de8-46fa-9d6c-9f635615ef82,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-112d16ec-d85a-430f-a67d-5483d5cb5cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-9d6e91a4-d6fa-430f-9802-53d85507211c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466985179-172.17.0.5-1596942911283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-7a267565-7954-4b1d-a481-c37156b880b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-dc31cfcf-b7fa-4141-8158-e23f52b087c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-9b6a5da1-b9b3-492d-8b0c-d3348808e6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-43e1ba6b-18f2-42b4-9b1d-96b2e9eb4c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-b5836e27-aadf-4429-ad27-9e9533352efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-f160cb3f-4de8-46fa-9d6c-9f635615ef82,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-112d16ec-d85a-430f-a67d-5483d5cb5cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-9d6e91a4-d6fa-430f-9802-53d85507211c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2038561789-172.17.0.5-1596942984467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-af5aed76-c4f7-487d-a846-3ea528cc8f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-2d9f7911-aaca-4b3e-99f1-12eacee19381,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-3f1fd2d2-8cf7-4392-912c-2d03de4579b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-8eef7db1-da29-4d16-937a-5770a865a37b,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a27f0bf2-c7f3-491d-870c-0a7f33a3d43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-c7c28eca-5912-48cb-ae6a-9879d2f9a52a,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-bdb9581a-af6e-468d-ad4a-b5f5335a81e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-82774eb6-1118-44e7-b307-71ce3b08b499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2038561789-172.17.0.5-1596942984467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-af5aed76-c4f7-487d-a846-3ea528cc8f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-2d9f7911-aaca-4b3e-99f1-12eacee19381,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-3f1fd2d2-8cf7-4392-912c-2d03de4579b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-8eef7db1-da29-4d16-937a-5770a865a37b,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a27f0bf2-c7f3-491d-870c-0a7f33a3d43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-c7c28eca-5912-48cb-ae6a-9879d2f9a52a,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-bdb9581a-af6e-468d-ad4a-b5f5335a81e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-82774eb6-1118-44e7-b307-71ce3b08b499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971049752-172.17.0.5-1596943457518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45975,DS-b12e06cb-8bf6-4728-a4ba-c4c135b91fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-4ed5bafc-b55a-4560-9e30-b850324f879a,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-f6426eee-1980-4723-9f74-982827ac8221,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-87dd03c5-f586-483d-8448-6b103eaf3300,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-e1cee9f1-4a34-49e0-918f-d96866243ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-b2c6ee84-99d6-4229-a099-df53381d4f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-e24fbe48-3fde-4a10-88c6-8c1ccf8fdca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-62c77712-f019-410a-a7e8-fba03a7999e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971049752-172.17.0.5-1596943457518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45975,DS-b12e06cb-8bf6-4728-a4ba-c4c135b91fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-4ed5bafc-b55a-4560-9e30-b850324f879a,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-f6426eee-1980-4723-9f74-982827ac8221,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-87dd03c5-f586-483d-8448-6b103eaf3300,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-e1cee9f1-4a34-49e0-918f-d96866243ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-b2c6ee84-99d6-4229-a099-df53381d4f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-e24fbe48-3fde-4a10-88c6-8c1ccf8fdca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-62c77712-f019-410a-a7e8-fba03a7999e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727973302-172.17.0.5-1596943636676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-5b082df5-4a44-489a-87ca-ab402cb7c250,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-e199797d-3cd8-49ca-a7c6-c59b8edefa16,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-311f15df-099a-4291-a74b-b48eb987c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-ded26a84-09b0-43ac-8c8f-752abc7c45e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-afba48a1-71b3-4cc3-a532-c2d8f2ef3429,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-782ce17e-a3ab-4434-9f61-5b26f0cd554c,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-c9dbbbd1-33d5-4a01-a414-ff5e8a88efc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-865e4d4f-0911-4f31-bb4d-876959918c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727973302-172.17.0.5-1596943636676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-5b082df5-4a44-489a-87ca-ab402cb7c250,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-e199797d-3cd8-49ca-a7c6-c59b8edefa16,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-311f15df-099a-4291-a74b-b48eb987c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-ded26a84-09b0-43ac-8c8f-752abc7c45e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-afba48a1-71b3-4cc3-a532-c2d8f2ef3429,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-782ce17e-a3ab-4434-9f61-5b26f0cd554c,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-c9dbbbd1-33d5-4a01-a414-ff5e8a88efc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-865e4d4f-0911-4f31-bb4d-876959918c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150587112-172.17.0.5-1596943888530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-039c191f-7492-4c0d-b0e5-f176cc22ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-447b9f05-69c2-4168-b646-72d53262c721,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-61277f49-34fd-4324-beba-3ae4ae40f941,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-50636a80-c318-4619-973f-44b395729dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-9aab2ddf-555b-44b0-b1a5-92e3b7302cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-a285be37-2984-425d-b4b7-b994f2bf96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-709adc41-23ec-43c6-9b62-15371b0ef7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-a15cf249-028b-4b12-b314-fd4b206f9590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150587112-172.17.0.5-1596943888530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-039c191f-7492-4c0d-b0e5-f176cc22ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-447b9f05-69c2-4168-b646-72d53262c721,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-61277f49-34fd-4324-beba-3ae4ae40f941,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-50636a80-c318-4619-973f-44b395729dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-9aab2ddf-555b-44b0-b1a5-92e3b7302cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-a285be37-2984-425d-b4b7-b994f2bf96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-709adc41-23ec-43c6-9b62-15371b0ef7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-a15cf249-028b-4b12-b314-fd4b206f9590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163442209-172.17.0.5-1596944788204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-4611f0a6-a766-4b11-aa4b-e58e64806b52,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-0b46e288-184d-4ec7-bd0c-95083ca8f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-9994748a-bb33-49a4-a789-07d5a282301a,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-09e53347-233d-401c-8a64-72ef5c5d19b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-d31c6749-8487-4715-bbb4-8bf62adbe1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-e6718bad-1bf8-4a95-b2ba-dbf086dbc56f,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-9ee862a4-8827-447d-987c-366ef14dd70b,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-0bbdb313-17f1-4a96-bec1-88d5b190788e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163442209-172.17.0.5-1596944788204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-4611f0a6-a766-4b11-aa4b-e58e64806b52,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-0b46e288-184d-4ec7-bd0c-95083ca8f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-9994748a-bb33-49a4-a789-07d5a282301a,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-09e53347-233d-401c-8a64-72ef5c5d19b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-d31c6749-8487-4715-bbb4-8bf62adbe1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-e6718bad-1bf8-4a95-b2ba-dbf086dbc56f,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-9ee862a4-8827-447d-987c-366ef14dd70b,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-0bbdb313-17f1-4a96-bec1-88d5b190788e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347790807-172.17.0.5-1596944967296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45680,DS-79efe8d6-ddcc-4309-b99d-aa1cb60d05a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-e7eae9d9-c9dc-4f26-8867-13aaf7a6f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-acb68b10-d66b-41e0-93aa-33e39f765112,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-7d5ef9cc-7cb4-4232-bcc7-2abf372b2ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-e3c8a541-e82c-4141-af5b-b68bc31995fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-105df6d3-4ed1-4a44-9635-0008b070d0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-2e802afb-9f03-4f97-8c76-0e2c423e1e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-430f8c15-c078-4fcb-b0b9-8ce9b112ab71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347790807-172.17.0.5-1596944967296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45680,DS-79efe8d6-ddcc-4309-b99d-aa1cb60d05a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-e7eae9d9-c9dc-4f26-8867-13aaf7a6f84c,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-acb68b10-d66b-41e0-93aa-33e39f765112,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-7d5ef9cc-7cb4-4232-bcc7-2abf372b2ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-e3c8a541-e82c-4141-af5b-b68bc31995fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-105df6d3-4ed1-4a44-9635-0008b070d0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-2e802afb-9f03-4f97-8c76-0e2c423e1e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-430f8c15-c078-4fcb-b0b9-8ce9b112ab71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646871978-172.17.0.5-1596945766483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37173,DS-2489c848-7872-47ba-ae9d-9a7be67999d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-f86e7694-e90a-405d-bbd4-8dcfcf80897f,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-dee6ebc2-cd46-4296-a129-aa9b1b04c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-2c38243c-6141-455f-9b04-0e0e68a5a63d,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-a38d6147-037a-4215-8712-7d106024e3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-ca6d7e3c-a323-4580-a8fa-be2d6b9cfdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-fc3ff847-5aeb-4120-8ab4-ca298ef43285,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-aaac1e0d-d018-4734-ac5d-10dca8bad7f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646871978-172.17.0.5-1596945766483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37173,DS-2489c848-7872-47ba-ae9d-9a7be67999d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-f86e7694-e90a-405d-bbd4-8dcfcf80897f,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-dee6ebc2-cd46-4296-a129-aa9b1b04c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-2c38243c-6141-455f-9b04-0e0e68a5a63d,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-a38d6147-037a-4215-8712-7d106024e3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-ca6d7e3c-a323-4580-a8fa-be2d6b9cfdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-fc3ff847-5aeb-4120-8ab4-ca298ef43285,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-aaac1e0d-d018-4734-ac5d-10dca8bad7f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576329922-172.17.0.5-1596945803819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38958,DS-6d21d4d4-c11f-4809-8904-586c031193c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-de5eb3c3-05c3-4b30-8f23-a7180da83771,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-6b9d0060-956f-4eac-96b4-1f129b6d3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-c25a579b-41db-4fd4-9268-48a730eefb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-462de265-e90a-4b73-876a-f00f098d593b,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-746e3817-f91b-48d0-8697-5edbf9a84ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-157b94c1-e0df-47af-9287-8bccad025346,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-f759c4ad-5f76-4ba4-8fd8-48c1461e0f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576329922-172.17.0.5-1596945803819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38958,DS-6d21d4d4-c11f-4809-8904-586c031193c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-de5eb3c3-05c3-4b30-8f23-a7180da83771,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-6b9d0060-956f-4eac-96b4-1f129b6d3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-c25a579b-41db-4fd4-9268-48a730eefb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-462de265-e90a-4b73-876a-f00f098d593b,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-746e3817-f91b-48d0-8697-5edbf9a84ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-157b94c1-e0df-47af-9287-8bccad025346,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-f759c4ad-5f76-4ba4-8fd8-48c1461e0f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378264459-172.17.0.5-1596945880382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45788,DS-ffc07ce8-602c-4946-b88a-d02c84b5ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-e3328abe-4ab5-4745-ab18-c38209b09c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-1dcb2447-fe9b-41d7-82c1-e1d756ae91ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-867ea627-0321-4249-9fd4-f4ca8502d2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-af02905c-c466-42ae-8902-4d7041b4945c,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-d70403a9-6385-4383-9acd-bc2c95024371,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-a646f269-c186-4b51-97bf-a655f0f44b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-ff7acf35-941c-464a-abcb-fd6f411d20f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378264459-172.17.0.5-1596945880382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45788,DS-ffc07ce8-602c-4946-b88a-d02c84b5ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-e3328abe-4ab5-4745-ab18-c38209b09c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-1dcb2447-fe9b-41d7-82c1-e1d756ae91ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-867ea627-0321-4249-9fd4-f4ca8502d2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-af02905c-c466-42ae-8902-4d7041b4945c,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-d70403a9-6385-4383-9acd-bc2c95024371,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-a646f269-c186-4b51-97bf-a655f0f44b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-ff7acf35-941c-464a-abcb-fd6f411d20f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328807317-172.17.0.5-1596945979117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-2fadae72-2f29-4170-ae47-49c161f63e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-bd7f7bc9-2d30-4b8f-a746-750b6c712c32,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-85712471-75ca-4ba4-885c-851c7ab76526,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-7b3d395e-8fd1-4c17-a176-2a1e90850632,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-f61b4b75-040e-4218-89a3-87ba68b91957,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-ac6c2c34-b9f3-48f3-bb74-2064cbdb93d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-57e97b6b-8358-4d3c-98ee-9ccefdc6095f,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-ce72c58d-0dd3-428d-93b7-e3f67700edff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328807317-172.17.0.5-1596945979117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-2fadae72-2f29-4170-ae47-49c161f63e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-bd7f7bc9-2d30-4b8f-a746-750b6c712c32,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-85712471-75ca-4ba4-885c-851c7ab76526,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-7b3d395e-8fd1-4c17-a176-2a1e90850632,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-f61b4b75-040e-4218-89a3-87ba68b91957,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-ac6c2c34-b9f3-48f3-bb74-2064cbdb93d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-57e97b6b-8358-4d3c-98ee-9ccefdc6095f,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-ce72c58d-0dd3-428d-93b7-e3f67700edff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311586585-172.17.0.5-1596946129641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33421,DS-3cedae75-c201-475b-8967-6651ce0cfb05,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-f34b9598-7da6-432c-bbb4-36cf655a6756,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-a8d63715-f9cd-448c-bb42-972ff7af21a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-ab9b2b6b-91a3-4d7c-8926-8b943d2c9214,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-b4ef17b4-254a-4376-b8e5-ad46f15b3914,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-46d02872-5bd7-436a-a943-2720ddd693db,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-4c11fbef-47a8-433d-b196-c2194b131022,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-2dabe824-48ea-46ae-91dd-963cd80637a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311586585-172.17.0.5-1596946129641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33421,DS-3cedae75-c201-475b-8967-6651ce0cfb05,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-f34b9598-7da6-432c-bbb4-36cf655a6756,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-a8d63715-f9cd-448c-bb42-972ff7af21a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-ab9b2b6b-91a3-4d7c-8926-8b943d2c9214,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-b4ef17b4-254a-4376-b8e5-ad46f15b3914,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-46d02872-5bd7-436a-a943-2720ddd693db,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-4c11fbef-47a8-433d-b196-c2194b131022,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-2dabe824-48ea-46ae-91dd-963cd80637a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5347
