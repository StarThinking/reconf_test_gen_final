reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142325641-172.17.0.16-1596904869623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-3c65575a-95c7-4028-a46a-74b72f23a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-e13b586d-3180-4c8b-b390-bc334607c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-0f0d97d2-cce2-4ddf-863e-4cf139cb6da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-1bdbe920-5f70-4ad0-83a1-e1163f497049,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-43d34cae-17fc-4703-a1e1-38ae69bc3ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-2469b404-02f7-4138-b6a7-c74669a3b4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-47bb32bc-b9cb-4829-aff9-ad1a356622b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-e2dff4b6-ef9a-446e-a88e-bbf5da3041a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142325641-172.17.0.16-1596904869623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-3c65575a-95c7-4028-a46a-74b72f23a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-e13b586d-3180-4c8b-b390-bc334607c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-0f0d97d2-cce2-4ddf-863e-4cf139cb6da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-1bdbe920-5f70-4ad0-83a1-e1163f497049,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-43d34cae-17fc-4703-a1e1-38ae69bc3ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-2469b404-02f7-4138-b6a7-c74669a3b4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-47bb32bc-b9cb-4829-aff9-ad1a356622b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-e2dff4b6-ef9a-446e-a88e-bbf5da3041a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313708281-172.17.0.16-1596905090856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44688,DS-d75b6991-a6fa-4d2c-aca9-be5bbf82417f,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-ca577ee3-ed1e-4ae2-8173-e10d4f20d320,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-95103e3c-d207-49bf-a14f-5350b944575a,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-da14d63f-9e91-4ba9-983b-dc835ec6b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-1cfa6c94-07ae-44ea-b2ac-4a4214ee9b48,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-1bbcac0f-6871-49a5-9e02-e63cd1e57d84,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-705944a9-a84c-43fd-9d28-23ac99a4fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-2d34376a-ddef-4b4e-950a-69167dcede91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313708281-172.17.0.16-1596905090856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44688,DS-d75b6991-a6fa-4d2c-aca9-be5bbf82417f,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-ca577ee3-ed1e-4ae2-8173-e10d4f20d320,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-95103e3c-d207-49bf-a14f-5350b944575a,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-da14d63f-9e91-4ba9-983b-dc835ec6b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-1cfa6c94-07ae-44ea-b2ac-4a4214ee9b48,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-1bbcac0f-6871-49a5-9e02-e63cd1e57d84,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-705944a9-a84c-43fd-9d28-23ac99a4fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-2d34376a-ddef-4b4e-950a-69167dcede91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046117602-172.17.0.16-1596905201539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44055,DS-656e66d5-91c1-4ae4-bf46-c706a5d20cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-c94bfa0f-e497-4e96-9b83-cf64b769d63b,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-326884df-8930-4dff-b9cf-3532dd97925b,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-240467a4-49bc-4ebe-a0ca-cdfdd964039f,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-540acde3-d315-4a0b-9974-c563508c4994,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-24cf76d4-f3d1-4ccb-87de-8510ae94fc22,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-3ff1fd0b-41a9-41cd-be5f-9870f5eeb0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-7337a73b-1b48-46d3-af59-2e52cf753102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046117602-172.17.0.16-1596905201539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44055,DS-656e66d5-91c1-4ae4-bf46-c706a5d20cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-c94bfa0f-e497-4e96-9b83-cf64b769d63b,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-326884df-8930-4dff-b9cf-3532dd97925b,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-240467a4-49bc-4ebe-a0ca-cdfdd964039f,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-540acde3-d315-4a0b-9974-c563508c4994,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-24cf76d4-f3d1-4ccb-87de-8510ae94fc22,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-3ff1fd0b-41a9-41cd-be5f-9870f5eeb0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-7337a73b-1b48-46d3-af59-2e52cf753102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474272915-172.17.0.16-1596905604741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41269,DS-a283f7a6-43d3-4c74-8bc6-21179697478d,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-e4e15cad-aa27-41f8-a36b-e57d4f00319e,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-364e1996-e040-465c-a0ae-a5bf28cdc3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-ef3528d5-b236-426a-97d5-40bab9dcaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-cb779317-f3c5-4c21-8439-a584689437a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-ca7ba7f6-5591-461f-8837-4961eefb05e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-1cddfafa-8559-48a6-a622-4ad8f1e9672c,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-ca52dc1b-20d4-42e3-88d3-bea56738c81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474272915-172.17.0.16-1596905604741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41269,DS-a283f7a6-43d3-4c74-8bc6-21179697478d,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-e4e15cad-aa27-41f8-a36b-e57d4f00319e,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-364e1996-e040-465c-a0ae-a5bf28cdc3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-ef3528d5-b236-426a-97d5-40bab9dcaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-cb779317-f3c5-4c21-8439-a584689437a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-ca7ba7f6-5591-461f-8837-4961eefb05e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-1cddfafa-8559-48a6-a622-4ad8f1e9672c,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-ca52dc1b-20d4-42e3-88d3-bea56738c81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210626066-172.17.0.16-1596905708617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-d5115f96-6821-4652-9d8b-c2b87d0962e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-f51448be-092c-4477-a618-b6848077a7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-e7ba444c-6667-4a5c-aac0-bec4223f47ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-d832e39a-8c1d-482a-a80a-8c47fb670875,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-859cfba5-671f-4f3a-8704-34bd765c5e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-350fbc13-375c-4980-a216-09fa6f201768,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-d4ab3c23-63df-40b6-80a0-2e1117ad2c32,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-d5280929-dde7-41fc-857a-dd2df880427b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210626066-172.17.0.16-1596905708617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-d5115f96-6821-4652-9d8b-c2b87d0962e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-f51448be-092c-4477-a618-b6848077a7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-e7ba444c-6667-4a5c-aac0-bec4223f47ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-d832e39a-8c1d-482a-a80a-8c47fb670875,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-859cfba5-671f-4f3a-8704-34bd765c5e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-350fbc13-375c-4980-a216-09fa6f201768,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-d4ab3c23-63df-40b6-80a0-2e1117ad2c32,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-d5280929-dde7-41fc-857a-dd2df880427b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941444539-172.17.0.16-1596905735033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-d4f17f77-c139-47c6-a3ac-ab710bd6f166,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c897314c-7c10-4711-b046-9658cf1fe2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-ff9ee796-0e13-430b-9a5c-2ad30c731096,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-378e959d-9c7e-41d6-b8c0-cf6c931e07fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-05c1de82-6447-4c16-8e6f-5cfec7aa9ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-dd144361-4510-4b8a-894c-0aaf3bbed027,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-f45a9ab8-0e87-4557-af4c-dc545f2424c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-8e5d6e1f-3527-4aa9-979e-d005bbbe7c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941444539-172.17.0.16-1596905735033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-d4f17f77-c139-47c6-a3ac-ab710bd6f166,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c897314c-7c10-4711-b046-9658cf1fe2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-ff9ee796-0e13-430b-9a5c-2ad30c731096,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-378e959d-9c7e-41d6-b8c0-cf6c931e07fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-05c1de82-6447-4c16-8e6f-5cfec7aa9ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-dd144361-4510-4b8a-894c-0aaf3bbed027,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-f45a9ab8-0e87-4557-af4c-dc545f2424c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-8e5d6e1f-3527-4aa9-979e-d005bbbe7c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121197826-172.17.0.16-1596906810618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40325,DS-b23621e0-c4d5-416b-a78c-59014a574c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-6de490ef-d739-4422-8619-e742180b08b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-44e4d2b6-b9c7-4d2e-b394-4361a7604ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-95f87196-8441-45f3-91dc-3b28df85fa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-b3ad68fd-01e5-467c-b6ef-ad483497f3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-3382ca42-88da-4702-a6ef-d118e774e574,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-bd68fcdc-26a0-4b67-8e19-df9b3db9455c,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-b8cdbf97-5a1a-4b96-beba-703f6086b233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121197826-172.17.0.16-1596906810618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40325,DS-b23621e0-c4d5-416b-a78c-59014a574c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-6de490ef-d739-4422-8619-e742180b08b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-44e4d2b6-b9c7-4d2e-b394-4361a7604ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-95f87196-8441-45f3-91dc-3b28df85fa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-b3ad68fd-01e5-467c-b6ef-ad483497f3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-3382ca42-88da-4702-a6ef-d118e774e574,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-bd68fcdc-26a0-4b67-8e19-df9b3db9455c,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-b8cdbf97-5a1a-4b96-beba-703f6086b233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115988193-172.17.0.16-1596907037350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44372,DS-e2db0f0c-193e-4c82-ba4a-ceda5a9a137c,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-7053a8fc-464b-45f1-b5c0-86400d9dfa99,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-347ed813-8bfd-49d7-8181-d99e09c8cb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-e11b9394-6c11-4bda-9998-358100e87021,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-59f2b270-23b7-436e-8a3f-30db823e2c08,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-7d4da8e2-635d-4b17-8b57-f5f71b15ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-c68e9003-cbdb-47c1-8d43-277e5737cfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-0b2e71ae-85e2-4890-b9f5-e3156c6c944f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115988193-172.17.0.16-1596907037350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44372,DS-e2db0f0c-193e-4c82-ba4a-ceda5a9a137c,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-7053a8fc-464b-45f1-b5c0-86400d9dfa99,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-347ed813-8bfd-49d7-8181-d99e09c8cb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-e11b9394-6c11-4bda-9998-358100e87021,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-59f2b270-23b7-436e-8a3f-30db823e2c08,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-7d4da8e2-635d-4b17-8b57-f5f71b15ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-c68e9003-cbdb-47c1-8d43-277e5737cfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-0b2e71ae-85e2-4890-b9f5-e3156c6c944f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089809179-172.17.0.16-1596907322745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-8eb0cd13-6351-4f65-bbb8-59bbfd8f81a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-bc3ae97b-f5ca-4d35-8d99-c3d752b874ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-547d6bd4-e329-4fe2-9b12-d58eb63c4139,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-c4c3fcc1-11d3-49ff-ab9a-01946e2eaae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-1ff5b24c-1c27-435b-afc3-b902f2ce5b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-a708bfb4-3103-4a25-abd2-0e6acfd36280,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-9f9968bb-a026-4f14-99fd-346c1a3b2df1,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-e250ae0c-7863-43a7-a7d3-f3a87f2808bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089809179-172.17.0.16-1596907322745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-8eb0cd13-6351-4f65-bbb8-59bbfd8f81a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-bc3ae97b-f5ca-4d35-8d99-c3d752b874ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-547d6bd4-e329-4fe2-9b12-d58eb63c4139,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-c4c3fcc1-11d3-49ff-ab9a-01946e2eaae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-1ff5b24c-1c27-435b-afc3-b902f2ce5b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-a708bfb4-3103-4a25-abd2-0e6acfd36280,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-9f9968bb-a026-4f14-99fd-346c1a3b2df1,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-e250ae0c-7863-43a7-a7d3-f3a87f2808bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955080143-172.17.0.16-1596907747963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-9b787772-63ab-4109-8119-5959ed55d562,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f3e09cdf-6dd3-482a-8f27-ce042847f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-5f4e9966-582d-4cec-8b97-55939575ca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-015c0658-60c1-4144-aebf-6382c6cca85a,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-ddfb4267-bc69-4e4e-a9ea-ddc6fba3b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4ddbd6a5-bd0a-45c1-9e95-01f98d3f1011,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-f674aa3e-840c-4505-9979-020016188119,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-66ba4da5-c4d3-4dff-a04d-9e2d54aa1ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955080143-172.17.0.16-1596907747963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-9b787772-63ab-4109-8119-5959ed55d562,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f3e09cdf-6dd3-482a-8f27-ce042847f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-5f4e9966-582d-4cec-8b97-55939575ca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-015c0658-60c1-4144-aebf-6382c6cca85a,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-ddfb4267-bc69-4e4e-a9ea-ddc6fba3b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4ddbd6a5-bd0a-45c1-9e95-01f98d3f1011,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-f674aa3e-840c-4505-9979-020016188119,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-66ba4da5-c4d3-4dff-a04d-9e2d54aa1ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122418200-172.17.0.16-1596908225016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40390,DS-00d2219f-a67b-4653-bc42-e5fc138d1f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-83af81dc-c42c-42cb-a8d0-f300f53d263b,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-c899aeb8-f2ec-4343-9060-c58c37619fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-e29cb35e-dd55-466b-893a-a8a73fd2e942,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-1f525720-eba9-42ad-80d8-948c9c1869a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-8e8be039-e723-42b5-8a44-27a7b8acd3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-9be15ff7-4890-485f-84c6-e1bb23a3b68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-39db8f4e-4fb5-4d1a-a269-5bf5e0759c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122418200-172.17.0.16-1596908225016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40390,DS-00d2219f-a67b-4653-bc42-e5fc138d1f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-83af81dc-c42c-42cb-a8d0-f300f53d263b,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-c899aeb8-f2ec-4343-9060-c58c37619fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-e29cb35e-dd55-466b-893a-a8a73fd2e942,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-1f525720-eba9-42ad-80d8-948c9c1869a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-8e8be039-e723-42b5-8a44-27a7b8acd3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-9be15ff7-4890-485f-84c6-e1bb23a3b68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-39db8f4e-4fb5-4d1a-a269-5bf5e0759c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281091638-172.17.0.16-1596908510517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34169,DS-1290fed6-b16c-4f05-99b2-ae7f69abee12,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-1546795e-2802-4e63-8676-e9186590c91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-8bab06ab-73d9-4e71-a1dd-de2de84a4ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-6c62bb4a-25a5-4d75-b154-054549d492a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-77e06870-ad09-4d6d-856b-525e639fd74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-67093af9-160e-4748-bd20-d13a90a77a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-c99d78e9-ea71-4d90-bffa-0dfd7b06c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-743f951c-e9f3-41a6-b824-ed30d19d804a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281091638-172.17.0.16-1596908510517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34169,DS-1290fed6-b16c-4f05-99b2-ae7f69abee12,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-1546795e-2802-4e63-8676-e9186590c91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-8bab06ab-73d9-4e71-a1dd-de2de84a4ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-6c62bb4a-25a5-4d75-b154-054549d492a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-77e06870-ad09-4d6d-856b-525e639fd74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-67093af9-160e-4748-bd20-d13a90a77a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-c99d78e9-ea71-4d90-bffa-0dfd7b06c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-743f951c-e9f3-41a6-b824-ed30d19d804a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627410704-172.17.0.16-1596908695364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-b4d84264-a833-45a2-b21d-2606c05c51d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-0da09f42-3f14-435e-b9c9-51b347270e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-caeb9e11-5150-4701-97fd-0cc2506acb33,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-0eb782a3-7c60-4aba-8ffd-72c445fe8538,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-7b9b7218-5ae8-4811-a8ae-26b893187622,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-96f9908e-5c3b-4c17-ac59-42cfc59bfbac,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-0a8d3880-cbe1-48a7-a405-30899e7a39e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-fa7590b1-0778-4038-8d6b-1505553dc1f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627410704-172.17.0.16-1596908695364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-b4d84264-a833-45a2-b21d-2606c05c51d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-0da09f42-3f14-435e-b9c9-51b347270e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-caeb9e11-5150-4701-97fd-0cc2506acb33,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-0eb782a3-7c60-4aba-8ffd-72c445fe8538,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-7b9b7218-5ae8-4811-a8ae-26b893187622,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-96f9908e-5c3b-4c17-ac59-42cfc59bfbac,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-0a8d3880-cbe1-48a7-a405-30899e7a39e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-fa7590b1-0778-4038-8d6b-1505553dc1f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286737089-172.17.0.16-1596908737030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40534,DS-057b1aaa-f85d-4f6a-9cf2-929b1c056086,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-9d340a50-2fd6-4cea-9a72-5331c507f31b,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-9779a0f0-4d05-4958-b7d4-175b5b80f009,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-f790475f-c691-430c-b584-ad165ec95e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-ba67b9f6-1890-4359-8679-9afc2ddfb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-70e38900-c160-4986-a576-095b7d8f171e,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-a1397b9c-eaf1-4f54-a359-4a930fca76e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-7ab23edf-4ca3-4a96-bc3d-e4176a09f782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286737089-172.17.0.16-1596908737030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40534,DS-057b1aaa-f85d-4f6a-9cf2-929b1c056086,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-9d340a50-2fd6-4cea-9a72-5331c507f31b,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-9779a0f0-4d05-4958-b7d4-175b5b80f009,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-f790475f-c691-430c-b584-ad165ec95e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-ba67b9f6-1890-4359-8679-9afc2ddfb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-70e38900-c160-4986-a576-095b7d8f171e,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-a1397b9c-eaf1-4f54-a359-4a930fca76e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-7ab23edf-4ca3-4a96-bc3d-e4176a09f782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469801563-172.17.0.16-1596908809449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46282,DS-6674a00d-7fe4-46b6-8000-754ba4590f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d714bd8b-5e7e-4dd2-b533-5165cee987f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-47910cfe-382e-419c-8793-f172b29c385e,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-7285de2c-93b0-468f-abdc-38a6b7443d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-24577f1b-22bb-454f-b31d-1d2a29b458a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-792f9ac6-6af0-4bc3-a2fd-62f0ac79c935,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-5e0bcebf-daa1-4437-86bf-10cc07793106,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-5426c575-ac93-4bc9-82e2-4ef7c7b69247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469801563-172.17.0.16-1596908809449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46282,DS-6674a00d-7fe4-46b6-8000-754ba4590f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d714bd8b-5e7e-4dd2-b533-5165cee987f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-47910cfe-382e-419c-8793-f172b29c385e,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-7285de2c-93b0-468f-abdc-38a6b7443d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-24577f1b-22bb-454f-b31d-1d2a29b458a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-792f9ac6-6af0-4bc3-a2fd-62f0ac79c935,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-5e0bcebf-daa1-4437-86bf-10cc07793106,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-5426c575-ac93-4bc9-82e2-4ef7c7b69247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182045277-172.17.0.16-1596909081760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33851,DS-be3f4e8f-0a4d-4429-856e-92a39d290c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-74fffcee-c0e0-429a-b4b1-d1469fb4f737,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-f18eec0c-939a-4237-9ad0-b79ce7825ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-4d829db7-7be0-4bf8-b661-2a2da80d2aec,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-b2e3c7e2-0806-44ae-805c-6c48fb22373e,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-16da74d9-3049-4ce8-bad1-1b5ae436ac49,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-8eb31851-4b15-48bf-90e2-bf8107a05240,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-e25e712f-09d1-405a-b346-27e398ebbff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182045277-172.17.0.16-1596909081760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33851,DS-be3f4e8f-0a4d-4429-856e-92a39d290c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-74fffcee-c0e0-429a-b4b1-d1469fb4f737,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-f18eec0c-939a-4237-9ad0-b79ce7825ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-4d829db7-7be0-4bf8-b661-2a2da80d2aec,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-b2e3c7e2-0806-44ae-805c-6c48fb22373e,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-16da74d9-3049-4ce8-bad1-1b5ae436ac49,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-8eb31851-4b15-48bf-90e2-bf8107a05240,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-e25e712f-09d1-405a-b346-27e398ebbff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011553147-172.17.0.16-1596909333965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44615,DS-60b9e396-cd4c-4c8c-a873-805fe0476110,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-8861c578-3491-41db-8d7e-a32be2c637b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-93580597-cff3-45b5-8d51-0d952479bb35,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-edfa0afb-4526-40f2-96e3-3a31d4700091,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-643068e4-95dd-4de8-a9f4-d91e0fb8033a,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-32e0a965-0fe4-4d4d-a61c-1037807ebc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-aee465d5-a65e-4214-8a41-90760f859ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-74f607a9-7a68-4d7d-9ee4-6ad8434ede28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011553147-172.17.0.16-1596909333965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44615,DS-60b9e396-cd4c-4c8c-a873-805fe0476110,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-8861c578-3491-41db-8d7e-a32be2c637b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-93580597-cff3-45b5-8d51-0d952479bb35,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-edfa0afb-4526-40f2-96e3-3a31d4700091,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-643068e4-95dd-4de8-a9f4-d91e0fb8033a,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-32e0a965-0fe4-4d4d-a61c-1037807ebc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-aee465d5-a65e-4214-8a41-90760f859ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-74f607a9-7a68-4d7d-9ee4-6ad8434ede28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8220103-172.17.0.16-1596909575049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-bd82eab7-9836-4f0c-bf8f-9121048cd538,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-9f336397-30a9-4cab-8aa6-2829c4a6fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-5c9cabad-b65e-4c31-b966-688111a78129,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-a05f7f55-388c-44a4-a41d-9453f82e9ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-744a6022-0465-41ad-9ac5-bf8a38023b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-5a327ae1-58fc-4238-844a-fade9280b755,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-ff0d1b2e-1ae7-4983-8724-ba27dd5dcdef,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-afd4e14c-7ff4-455a-9cb8-b66d340e18ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8220103-172.17.0.16-1596909575049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-bd82eab7-9836-4f0c-bf8f-9121048cd538,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-9f336397-30a9-4cab-8aa6-2829c4a6fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-5c9cabad-b65e-4c31-b966-688111a78129,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-a05f7f55-388c-44a4-a41d-9453f82e9ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-744a6022-0465-41ad-9ac5-bf8a38023b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-5a327ae1-58fc-4238-844a-fade9280b755,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-ff0d1b2e-1ae7-4983-8724-ba27dd5dcdef,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-afd4e14c-7ff4-455a-9cb8-b66d340e18ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481062386-172.17.0.16-1596909677539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-557615e3-7dc6-450c-9390-b15bbda4ace1,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-d4787764-e0a6-48e4-8d36-d773782e3899,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-89854f86-3b8e-4e18-aa46-20e11566c76e,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-af62f6ca-a294-45dc-a5f8-a75cd607ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-e3267885-68ce-4607-aa3d-4ab993ed7796,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-5e0d4aa1-f3ec-43b5-aad8-d753e8881c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-172eca13-ebff-4e67-87bf-dfb69f41245b,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-20b554f8-2cb8-42ef-a075-7b9b18bdf648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481062386-172.17.0.16-1596909677539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-557615e3-7dc6-450c-9390-b15bbda4ace1,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-d4787764-e0a6-48e4-8d36-d773782e3899,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-89854f86-3b8e-4e18-aa46-20e11566c76e,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-af62f6ca-a294-45dc-a5f8-a75cd607ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-e3267885-68ce-4607-aa3d-4ab993ed7796,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-5e0d4aa1-f3ec-43b5-aad8-d753e8881c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-172eca13-ebff-4e67-87bf-dfb69f41245b,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-20b554f8-2cb8-42ef-a075-7b9b18bdf648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585672377-172.17.0.16-1596909761476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41454,DS-df5587a0-9b17-4234-bb68-85d2115f93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-cc65b4d0-5140-45a5-8a37-fbedb5fdd49d,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-b8c8b68e-7b7e-45ae-bba5-e1301d29b648,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-40aefb3c-d69f-4a78-8bf7-932671602974,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-841f8bbf-59a8-49c1-b893-bcaa4825dcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-0ae896a4-34aa-498a-946c-1b0204af6b09,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-3f28b410-89ed-42de-bd59-9f61aa2e11ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-111adc2e-91c7-494c-9ae9-e770f16dc3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585672377-172.17.0.16-1596909761476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41454,DS-df5587a0-9b17-4234-bb68-85d2115f93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-cc65b4d0-5140-45a5-8a37-fbedb5fdd49d,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-b8c8b68e-7b7e-45ae-bba5-e1301d29b648,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-40aefb3c-d69f-4a78-8bf7-932671602974,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-841f8bbf-59a8-49c1-b893-bcaa4825dcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-0ae896a4-34aa-498a-946c-1b0204af6b09,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-3f28b410-89ed-42de-bd59-9f61aa2e11ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-111adc2e-91c7-494c-9ae9-e770f16dc3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376412107-172.17.0.16-1596909798785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44186,DS-e4c62819-565c-41ba-b1b2-5c8997004540,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-93e846cd-49c9-41aa-92d5-548f71be4555,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-95e89b3d-b12d-4db7-94c7-8095d9bc7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-1326698c-9260-4ac5-b4dc-313ca414fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-d2a2e53d-3d85-485e-a4ff-e0e9ca341e89,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-def356ce-b05f-4958-8ae8-3d363212612d,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-57446f5a-0ff5-42e9-b9a5-8eb2cbe821e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-67fe7956-4c8c-41af-a716-77b71b9f2f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376412107-172.17.0.16-1596909798785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44186,DS-e4c62819-565c-41ba-b1b2-5c8997004540,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-93e846cd-49c9-41aa-92d5-548f71be4555,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-95e89b3d-b12d-4db7-94c7-8095d9bc7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-1326698c-9260-4ac5-b4dc-313ca414fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-d2a2e53d-3d85-485e-a4ff-e0e9ca341e89,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-def356ce-b05f-4958-8ae8-3d363212612d,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-57446f5a-0ff5-42e9-b9a5-8eb2cbe821e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-67fe7956-4c8c-41af-a716-77b71b9f2f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823498244-172.17.0.16-1596909870638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-4a929933-341d-4e86-bfa0-e76f50d25c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-830959f2-0647-40ef-861f-a45c9ac0e917,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-81b8edee-e4fe-4d07-8fed-886e8a91f2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-c0fa38b6-11ff-46d0-8a4d-232841c637f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-742c6bf7-73a4-4409-8078-61cc3b3b0966,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-639c8ff4-748c-4900-b386-e236a0b71f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-2bd109fb-8b77-44b5-8aea-19c4b5ce720f,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-d0c7f39c-9933-44cc-b343-7703c3165373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823498244-172.17.0.16-1596909870638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-4a929933-341d-4e86-bfa0-e76f50d25c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-830959f2-0647-40ef-861f-a45c9ac0e917,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-81b8edee-e4fe-4d07-8fed-886e8a91f2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-c0fa38b6-11ff-46d0-8a4d-232841c637f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-742c6bf7-73a4-4409-8078-61cc3b3b0966,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-639c8ff4-748c-4900-b386-e236a0b71f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-2bd109fb-8b77-44b5-8aea-19c4b5ce720f,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-d0c7f39c-9933-44cc-b343-7703c3165373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310299411-172.17.0.16-1596909981725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-164273d2-8eda-404b-8503-0597cf452628,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-8d51b8ba-fc57-42e0-852e-7a421088885e,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-e32252bc-b75c-4258-876e-d20b7dbda3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-be96a797-0a23-482c-a685-03be3496fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-93687d70-c539-4e84-a566-788bef1fb01a,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-5577b39c-2e3a-4c32-938b-67f8fdae2310,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-d843c496-bdd1-4957-aa13-340cdec55333,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-32a349c4-fa95-4da8-b18d-86bf3f967c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310299411-172.17.0.16-1596909981725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-164273d2-8eda-404b-8503-0597cf452628,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-8d51b8ba-fc57-42e0-852e-7a421088885e,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-e32252bc-b75c-4258-876e-d20b7dbda3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-be96a797-0a23-482c-a685-03be3496fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-93687d70-c539-4e84-a566-788bef1fb01a,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-5577b39c-2e3a-4c32-938b-67f8fdae2310,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-d843c496-bdd1-4957-aa13-340cdec55333,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-32a349c4-fa95-4da8-b18d-86bf3f967c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209244607-172.17.0.16-1596910055157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-8f3c2d97-09ad-466b-8172-a62edd9998b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-1c2e7b39-8be3-4520-a4f5-00ee944125c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-3f069a74-5340-4a7f-9fec-585efa91be6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-9d05d08f-bdf8-41e2-b793-971516ce753d,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-13f06b19-cdbe-4fdb-8802-70f3367c2825,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-ae04d5f1-9b54-463d-8249-b0a7b3a46752,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-3ff7c5ac-6848-4edb-a4da-394f3d7b00a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-46cbc0bd-fde3-4249-a1ce-3e263512bfe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209244607-172.17.0.16-1596910055157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-8f3c2d97-09ad-466b-8172-a62edd9998b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-1c2e7b39-8be3-4520-a4f5-00ee944125c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-3f069a74-5340-4a7f-9fec-585efa91be6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-9d05d08f-bdf8-41e2-b793-971516ce753d,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-13f06b19-cdbe-4fdb-8802-70f3367c2825,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-ae04d5f1-9b54-463d-8249-b0a7b3a46752,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-3ff7c5ac-6848-4edb-a4da-394f3d7b00a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-46cbc0bd-fde3-4249-a1ce-3e263512bfe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278711938-172.17.0.16-1596910088623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-14cca8f7-ce0b-4832-92b6-b5e4fbc26788,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-5998c65f-90d7-4696-9271-67b552815518,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-fa117576-ed2a-4b76-b477-7c5d322b51ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-b970e860-3c6f-4975-9a6d-7a8e0b877fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-4e17cd00-2c29-4046-9810-8413c6d06f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-71c00f99-92ea-476f-b1a2-8e2fac9ea7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-ad55d4e0-c031-496f-a60f-c1e192ec2619,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-9e75cb6e-2bec-4453-be07-9d8be9a3be54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278711938-172.17.0.16-1596910088623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-14cca8f7-ce0b-4832-92b6-b5e4fbc26788,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-5998c65f-90d7-4696-9271-67b552815518,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-fa117576-ed2a-4b76-b477-7c5d322b51ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-b970e860-3c6f-4975-9a6d-7a8e0b877fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-4e17cd00-2c29-4046-9810-8413c6d06f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-71c00f99-92ea-476f-b1a2-8e2fac9ea7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-ad55d4e0-c031-496f-a60f-c1e192ec2619,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-9e75cb6e-2bec-4453-be07-9d8be9a3be54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251576872-172.17.0.16-1596910229016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-c74aedff-cd5d-4e0d-b4f6-1f1e986a1657,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-41db0955-26e8-45bb-b261-94b0784bdb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-3df7cd2b-3839-4466-8c65-be7d388af612,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-b13a7863-9801-48e4-bc4b-f1d4aab581b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-dfc343ff-3ebe-4081-b047-b744acb4e244,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-a7f4f9f5-dc93-4b7e-afd7-b685e3d0833e,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-f9d37846-6698-4357-8c00-1ed1b8180595,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-ac612fa1-c9ff-4c9b-98fb-c33ced4fe991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251576872-172.17.0.16-1596910229016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-c74aedff-cd5d-4e0d-b4f6-1f1e986a1657,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-41db0955-26e8-45bb-b261-94b0784bdb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-3df7cd2b-3839-4466-8c65-be7d388af612,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-b13a7863-9801-48e4-bc4b-f1d4aab581b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-dfc343ff-3ebe-4081-b047-b744acb4e244,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-a7f4f9f5-dc93-4b7e-afd7-b685e3d0833e,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-f9d37846-6698-4357-8c00-1ed1b8180595,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-ac612fa1-c9ff-4c9b-98fb-c33ced4fe991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5455
