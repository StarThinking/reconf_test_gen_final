reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275331562-172.17.0.4-1596886518141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38950,DS-a03e6706-f3d6-4528-8b09-f9c894ade6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-6065a468-e4d4-45ef-a3cc-0491fb73eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-3632d429-2c15-4d79-8a26-d599236f9419,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-a5b0bd37-fd61-4cc1-8dd3-70d584e762f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-7aca7f8c-a2de-4d0f-be85-3a32676aba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-d1fc0fd1-759b-4302-8768-64f442940bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-fd4e1953-51b1-4d2b-a48c-4de4155b03ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-15f7da4b-f624-4a12-a0ec-7d8381202a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275331562-172.17.0.4-1596886518141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38950,DS-a03e6706-f3d6-4528-8b09-f9c894ade6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-6065a468-e4d4-45ef-a3cc-0491fb73eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-3632d429-2c15-4d79-8a26-d599236f9419,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-a5b0bd37-fd61-4cc1-8dd3-70d584e762f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-7aca7f8c-a2de-4d0f-be85-3a32676aba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-d1fc0fd1-759b-4302-8768-64f442940bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-fd4e1953-51b1-4d2b-a48c-4de4155b03ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-15f7da4b-f624-4a12-a0ec-7d8381202a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009070890-172.17.0.4-1596886639351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-4aa65f5d-d925-4871-89b6-6c4f0b69dad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-fe3866b5-bf10-4820-853c-ab9c75da0569,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-c20c18d0-c17c-4ac1-a8dd-b0baa87cc9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-346bf24a-fb73-48ef-ac6b-acbd69dd7248,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-26a924c8-5cfb-4234-a39e-431a2e56a2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-de5e1be8-5000-460b-8255-04afd069a0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-dee66bf7-7fd0-47c2-be50-06ebc3aacee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-3f0aacde-c1d7-4668-b2c4-18996829ee12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009070890-172.17.0.4-1596886639351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-4aa65f5d-d925-4871-89b6-6c4f0b69dad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-fe3866b5-bf10-4820-853c-ab9c75da0569,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-c20c18d0-c17c-4ac1-a8dd-b0baa87cc9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-346bf24a-fb73-48ef-ac6b-acbd69dd7248,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-26a924c8-5cfb-4234-a39e-431a2e56a2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-de5e1be8-5000-460b-8255-04afd069a0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-dee66bf7-7fd0-47c2-be50-06ebc3aacee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-3f0aacde-c1d7-4668-b2c4-18996829ee12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002511690-172.17.0.4-1596886915230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33727,DS-b233a038-76f5-4dd7-9d59-d9046444a135,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-d9331c3a-c627-4207-bc5a-23e858ca17fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-37fd4a11-5ea3-44a4-818f-d5e444801f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-b892d664-728d-4890-ac70-b7ebaebb610f,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-c1dab385-2a35-40aa-93ea-3e6655b800f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-7fc223b7-08aa-4b01-ba4c-4fc4630973ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ed574384-b603-4b7b-8694-182b5937fa25,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-19dfc302-a0d7-463f-821a-248abd062e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002511690-172.17.0.4-1596886915230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33727,DS-b233a038-76f5-4dd7-9d59-d9046444a135,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-d9331c3a-c627-4207-bc5a-23e858ca17fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-37fd4a11-5ea3-44a4-818f-d5e444801f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-b892d664-728d-4890-ac70-b7ebaebb610f,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-c1dab385-2a35-40aa-93ea-3e6655b800f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-7fc223b7-08aa-4b01-ba4c-4fc4630973ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ed574384-b603-4b7b-8694-182b5937fa25,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-19dfc302-a0d7-463f-821a-248abd062e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391397799-172.17.0.4-1596887143199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39882,DS-55ae8e7e-1cfe-4877-9dd8-bc969c561e01,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-40e4a855-452b-4fde-843e-5b5882ece713,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-bb9c4e0c-02c3-4d9c-b765-277b82ee574a,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-02468720-764f-4036-a542-e720748451ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-5bbc009f-b67e-4103-a7e0-18d9735ae916,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-42512c55-ac72-4533-b4af-e742b1fa48ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-9c44cc03-6021-4a7f-a79e-6a6114c48993,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-754116f0-65f5-44e9-89f5-8facc90ece27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391397799-172.17.0.4-1596887143199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39882,DS-55ae8e7e-1cfe-4877-9dd8-bc969c561e01,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-40e4a855-452b-4fde-843e-5b5882ece713,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-bb9c4e0c-02c3-4d9c-b765-277b82ee574a,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-02468720-764f-4036-a542-e720748451ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-5bbc009f-b67e-4103-a7e0-18d9735ae916,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-42512c55-ac72-4533-b4af-e742b1fa48ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-9c44cc03-6021-4a7f-a79e-6a6114c48993,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-754116f0-65f5-44e9-89f5-8facc90ece27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146747561-172.17.0.4-1596887555792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34694,DS-78c0b853-14e5-4232-95d9-b17d83e79f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-ae565723-2d23-4f6a-9808-1b9b070ccfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-96a8448d-cc94-44fb-ae11-6dd546922978,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-776b9bbc-00ef-49e2-9e46-f75fbe16871e,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-07bdcaf4-426d-485e-98c8-ce64f24942af,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-fe0d6a13-cfc8-40ae-8f7c-2d6994c6a7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-2dd301bd-fe5b-4345-a60a-b7a38a95b1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-93af4828-8c83-4869-a6e7-96d6101df1f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146747561-172.17.0.4-1596887555792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34694,DS-78c0b853-14e5-4232-95d9-b17d83e79f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-ae565723-2d23-4f6a-9808-1b9b070ccfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-96a8448d-cc94-44fb-ae11-6dd546922978,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-776b9bbc-00ef-49e2-9e46-f75fbe16871e,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-07bdcaf4-426d-485e-98c8-ce64f24942af,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-fe0d6a13-cfc8-40ae-8f7c-2d6994c6a7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-2dd301bd-fe5b-4345-a60a-b7a38a95b1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-93af4828-8c83-4869-a6e7-96d6101df1f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578602132-172.17.0.4-1596887737795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43687,DS-57b6bf97-d302-4e2f-a201-519650eb712e,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-28b29aec-bbf0-4914-96ac-6b11fd031811,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-55e8a9c6-f9cf-426d-969b-ca2c5f775400,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-686600d7-d256-4baf-9a4d-bc4c21c5f2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-4f74c089-c1b3-4705-9a53-e3ed879c5b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-edf9733d-9bce-45dd-a490-07e3996c5207,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-eeffce74-7bb7-4c31-bdca-3d7d94846eff,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-988c1775-ea85-48c4-a4a7-a985b0e24241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578602132-172.17.0.4-1596887737795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43687,DS-57b6bf97-d302-4e2f-a201-519650eb712e,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-28b29aec-bbf0-4914-96ac-6b11fd031811,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-55e8a9c6-f9cf-426d-969b-ca2c5f775400,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-686600d7-d256-4baf-9a4d-bc4c21c5f2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-4f74c089-c1b3-4705-9a53-e3ed879c5b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-edf9733d-9bce-45dd-a490-07e3996c5207,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-eeffce74-7bb7-4c31-bdca-3d7d94846eff,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-988c1775-ea85-48c4-a4a7-a985b0e24241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508530397-172.17.0.4-1596887772671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-14ea86b1-d263-4ea1-902d-4ee722695a95,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-9210d0bc-c62e-4673-a2fd-962dfe89b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-db1009bc-0d49-4a28-825d-8710f88b34e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-684a6f78-4fe2-4cba-b2ac-52b99cc6dbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-b5b50bbb-7cb4-4e80-ad5f-4b18624318a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-3019cf8d-30c5-4bc9-a947-7874bc325aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-bf93aa36-eae4-4021-af7f-860557b00d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-e2cd4d74-50b6-4842-b5cd-983b4b2d4eb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508530397-172.17.0.4-1596887772671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-14ea86b1-d263-4ea1-902d-4ee722695a95,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-9210d0bc-c62e-4673-a2fd-962dfe89b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-db1009bc-0d49-4a28-825d-8710f88b34e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-684a6f78-4fe2-4cba-b2ac-52b99cc6dbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-b5b50bbb-7cb4-4e80-ad5f-4b18624318a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-3019cf8d-30c5-4bc9-a947-7874bc325aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-bf93aa36-eae4-4021-af7f-860557b00d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-e2cd4d74-50b6-4842-b5cd-983b4b2d4eb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025203163-172.17.0.4-1596888158456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-f21ea324-3b7f-4ab8-ba09-605d2d8997b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-e740104d-c5fc-4280-820c-81761e16feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-fedda145-25b9-497a-b327-ff805c1348ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-6de1c1f2-48bb-4ad5-ad33-ddcd1c66a508,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-faf2d231-bcf1-42d5-939a-73933cee5286,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b662ff29-b470-4c01-88e4-b4fe39245fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-d9a935e6-88c8-4bd3-8d41-ed08de7e4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-1e5ebd12-a3e9-4d2c-b904-68d0aceb9f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025203163-172.17.0.4-1596888158456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-f21ea324-3b7f-4ab8-ba09-605d2d8997b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-e740104d-c5fc-4280-820c-81761e16feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-fedda145-25b9-497a-b327-ff805c1348ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-6de1c1f2-48bb-4ad5-ad33-ddcd1c66a508,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-faf2d231-bcf1-42d5-939a-73933cee5286,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b662ff29-b470-4c01-88e4-b4fe39245fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-d9a935e6-88c8-4bd3-8d41-ed08de7e4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-1e5ebd12-a3e9-4d2c-b904-68d0aceb9f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119068358-172.17.0.4-1596888843055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40114,DS-2c932ffa-4cd5-459b-ba0f-6188d82a0185,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-1e7d4b97-cc85-4705-bf82-b6d594af976f,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-2a015dd9-1002-4c9a-b136-cfd1fe3293ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-59b5fdd8-c907-49b7-9c54-9b573dde07b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-ac5cefb3-be99-476a-9082-dfef55a671cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-62be6f89-1946-4cf2-8b24-6a8272a4ed53,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-5dd65ff6-7a83-4741-abc3-532d60cc7cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-28f245dc-1eb8-4903-b63c-b8ed9147235e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119068358-172.17.0.4-1596888843055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40114,DS-2c932ffa-4cd5-459b-ba0f-6188d82a0185,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-1e7d4b97-cc85-4705-bf82-b6d594af976f,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-2a015dd9-1002-4c9a-b136-cfd1fe3293ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-59b5fdd8-c907-49b7-9c54-9b573dde07b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-ac5cefb3-be99-476a-9082-dfef55a671cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-62be6f89-1946-4cf2-8b24-6a8272a4ed53,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-5dd65ff6-7a83-4741-abc3-532d60cc7cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-28f245dc-1eb8-4903-b63c-b8ed9147235e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025520964-172.17.0.4-1596889176629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36111,DS-04d9f37e-f2ac-490d-b25a-fca7a3b77d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-c933307a-ba8b-4b52-9ba4-4ed49f8e71e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-ec96e771-4017-48da-8d6c-7ae5f43df7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-5078ded9-506f-4672-856b-34d7ad46ad8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-09da97df-9ff4-47d1-8a78-1e19cc1c15eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-8fe871de-c06c-4440-9c39-74caa0525a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-a5fdf2c0-3b7a-4ea5-ab11-c09520b4a884,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-2f4d50da-11f8-4b68-b207-e40e6d515ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025520964-172.17.0.4-1596889176629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36111,DS-04d9f37e-f2ac-490d-b25a-fca7a3b77d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-c933307a-ba8b-4b52-9ba4-4ed49f8e71e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-ec96e771-4017-48da-8d6c-7ae5f43df7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-5078ded9-506f-4672-856b-34d7ad46ad8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-09da97df-9ff4-47d1-8a78-1e19cc1c15eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-8fe871de-c06c-4440-9c39-74caa0525a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-a5fdf2c0-3b7a-4ea5-ab11-c09520b4a884,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-2f4d50da-11f8-4b68-b207-e40e6d515ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75406319-172.17.0.4-1596889432596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-5cfe19e5-5e6e-4e55-a04d-59b622508cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-51470b6e-949c-4076-8b5e-d001fcb2007f,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-1bda3fb8-512a-4352-a22a-ba85147fc5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-52b907ab-2ed2-4f64-bded-9009a1cbe576,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-e6c87cdb-f478-4562-b7df-2d9499e3e987,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-bcd30263-5e01-4b7d-8484-cfb36ac86cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-93a8a371-370e-46f6-a64b-5620b488fae6,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-9fd07209-329c-46f3-a0d9-9fde4fed7c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75406319-172.17.0.4-1596889432596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-5cfe19e5-5e6e-4e55-a04d-59b622508cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-51470b6e-949c-4076-8b5e-d001fcb2007f,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-1bda3fb8-512a-4352-a22a-ba85147fc5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-52b907ab-2ed2-4f64-bded-9009a1cbe576,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-e6c87cdb-f478-4562-b7df-2d9499e3e987,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-bcd30263-5e01-4b7d-8484-cfb36ac86cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-93a8a371-370e-46f6-a64b-5620b488fae6,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-9fd07209-329c-46f3-a0d9-9fde4fed7c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283578082-172.17.0.4-1596889536108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-6f078f61-6a45-44c2-a981-a9b7aba1a6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-20d65db3-202b-419b-bace-aadb3bad5039,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-24a7f7b2-ec44-4027-a45c-dddec5d89ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-920efdb6-e96a-47a3-ae66-44b71eb5a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-6e5699e1-ed57-4ea9-bb5b-057890c55b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-72ef6fde-e1d9-4253-a1e4-960178ee8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-a896215e-1797-4a93-876c-34b899cf7178,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-d64e22f7-6536-4962-ae67-e46aa7375e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283578082-172.17.0.4-1596889536108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-6f078f61-6a45-44c2-a981-a9b7aba1a6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-20d65db3-202b-419b-bace-aadb3bad5039,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-24a7f7b2-ec44-4027-a45c-dddec5d89ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-920efdb6-e96a-47a3-ae66-44b71eb5a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-6e5699e1-ed57-4ea9-bb5b-057890c55b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-72ef6fde-e1d9-4253-a1e4-960178ee8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-a896215e-1797-4a93-876c-34b899cf7178,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-d64e22f7-6536-4962-ae67-e46aa7375e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624825825-172.17.0.4-1596889985151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45681,DS-79c8875a-dcb0-47aa-bf5c-614d44c239ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-13221955-61f7-4df4-bfb8-dc110801a17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-6771b1b0-feec-42c0-bbc9-901a6e3568ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-baa1dad1-414f-4c60-b98b-45c791a838f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-63becaed-f5b1-47d8-a996-549466968e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1c96fdb6-100d-456c-9336-bf45b6e34df7,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-e4ff747e-2937-430e-9907-f9a9b4a12a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-785086a5-ac97-4151-9672-896da67c0ad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624825825-172.17.0.4-1596889985151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45681,DS-79c8875a-dcb0-47aa-bf5c-614d44c239ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-13221955-61f7-4df4-bfb8-dc110801a17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-6771b1b0-feec-42c0-bbc9-901a6e3568ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-baa1dad1-414f-4c60-b98b-45c791a838f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-63becaed-f5b1-47d8-a996-549466968e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1c96fdb6-100d-456c-9336-bf45b6e34df7,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-e4ff747e-2937-430e-9907-f9a9b4a12a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-785086a5-ac97-4151-9672-896da67c0ad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267925513-172.17.0.4-1596890158620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43378,DS-807f0bf7-1967-4871-8367-5907305459a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-7b05d3f3-9d5d-4246-994d-d001797503d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-a3f64b78-7cd9-4e33-a2be-54f33b7d2a68,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-ff663066-2a2d-40ba-8bfe-dd333b2ce067,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-67a4f54a-cf79-44d7-a1bc-093cda91732e,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-d01dcf20-72c9-4f9c-96e1-57cc9e6483e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-e1180981-fb51-4f56-a42a-13dacb5dc205,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-41c1caa0-2867-41ec-8849-b1f80add1601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267925513-172.17.0.4-1596890158620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43378,DS-807f0bf7-1967-4871-8367-5907305459a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-7b05d3f3-9d5d-4246-994d-d001797503d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-a3f64b78-7cd9-4e33-a2be-54f33b7d2a68,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-ff663066-2a2d-40ba-8bfe-dd333b2ce067,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-67a4f54a-cf79-44d7-a1bc-093cda91732e,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-d01dcf20-72c9-4f9c-96e1-57cc9e6483e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-e1180981-fb51-4f56-a42a-13dacb5dc205,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-41c1caa0-2867-41ec-8849-b1f80add1601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326928256-172.17.0.4-1596890196727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-6b9a25b9-7777-4f8a-9e23-2ff10f49b13e,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-91384371-4a7b-4d1d-98a9-041345a76820,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-45418ac0-3c97-4647-95f6-f7192ac961d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-c53b3d4d-af35-42ce-8222-8fd85641244e,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-71d32f02-973a-4ec8-889f-7feefaa55028,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-d6089310-12b0-460b-80ca-9f9eb7ccbc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-7c3eaade-5bdc-4854-8f73-5a1a40722c40,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-43efc94d-886f-4805-8f1a-eb78972cde37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326928256-172.17.0.4-1596890196727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-6b9a25b9-7777-4f8a-9e23-2ff10f49b13e,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-91384371-4a7b-4d1d-98a9-041345a76820,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-45418ac0-3c97-4647-95f6-f7192ac961d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-c53b3d4d-af35-42ce-8222-8fd85641244e,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-71d32f02-973a-4ec8-889f-7feefaa55028,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-d6089310-12b0-460b-80ca-9f9eb7ccbc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-7c3eaade-5bdc-4854-8f73-5a1a40722c40,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-43efc94d-886f-4805-8f1a-eb78972cde37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758596305-172.17.0.4-1596890392156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-8022b3c3-6491-47be-be99-2827137cc5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-6d1c1fa3-7882-4e45-a4f1-234883147469,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-427c3626-43ab-44dc-a34f-c8502e2ed772,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-ff7a0083-76f7-4d83-a807-b0acf8ec95d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-8ad7c7f2-86d3-43f5-9311-6320839c59a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-84e0a796-9a79-4321-a77c-0dbc54664cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-099abd8b-5e27-4fa3-b1a1-e8d91be7129f,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-485919c3-05a7-426f-8c38-d95f4bf1f84b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758596305-172.17.0.4-1596890392156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-8022b3c3-6491-47be-be99-2827137cc5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-6d1c1fa3-7882-4e45-a4f1-234883147469,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-427c3626-43ab-44dc-a34f-c8502e2ed772,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-ff7a0083-76f7-4d83-a807-b0acf8ec95d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-8ad7c7f2-86d3-43f5-9311-6320839c59a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-84e0a796-9a79-4321-a77c-0dbc54664cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-099abd8b-5e27-4fa3-b1a1-e8d91be7129f,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-485919c3-05a7-426f-8c38-d95f4bf1f84b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792595172-172.17.0.4-1596890629637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-11a4b0ab-760f-4fed-8c0b-3eadcd30192b,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-3a784f25-29a3-4315-9f8c-9eedf120ad03,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-38d2f45a-d8b0-4464-b576-59b2210290da,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-5be4ff65-1894-489f-b318-1ff09c8b1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-6965e50b-a1f8-4211-9ab2-d12d513ed478,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-9c11e3eb-fadb-4264-bac3-a3cad4d2dbab,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-fee51b82-f39b-4b95-9428-0bafce490821,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-cab7afff-48f2-45a3-a906-ddfcc6a3a27e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792595172-172.17.0.4-1596890629637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-11a4b0ab-760f-4fed-8c0b-3eadcd30192b,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-3a784f25-29a3-4315-9f8c-9eedf120ad03,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-38d2f45a-d8b0-4464-b576-59b2210290da,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-5be4ff65-1894-489f-b318-1ff09c8b1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-6965e50b-a1f8-4211-9ab2-d12d513ed478,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-9c11e3eb-fadb-4264-bac3-a3cad4d2dbab,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-fee51b82-f39b-4b95-9428-0bafce490821,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-cab7afff-48f2-45a3-a906-ddfcc6a3a27e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001406866-172.17.0.4-1596891234820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-81da0d79-1e31-425f-b21c-1921999c0cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-d78e4d6b-2f0a-4d5f-8305-a2ecc77767fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-96309d3e-60dc-483e-b487-f930efdaec19,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-8302cfb5-481f-4c14-947d-bd75713d2e84,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-f408bc8f-576f-4802-88ef-e7c93009e9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-d2737240-4ac5-4712-b52b-5920b6bb1671,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-e5cb6d43-6525-416e-bee8-c055d73b1130,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-05b904af-2561-421b-b874-03e7165c0731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001406866-172.17.0.4-1596891234820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38748,DS-81da0d79-1e31-425f-b21c-1921999c0cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-d78e4d6b-2f0a-4d5f-8305-a2ecc77767fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-96309d3e-60dc-483e-b487-f930efdaec19,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-8302cfb5-481f-4c14-947d-bd75713d2e84,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-f408bc8f-576f-4802-88ef-e7c93009e9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-d2737240-4ac5-4712-b52b-5920b6bb1671,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-e5cb6d43-6525-416e-bee8-c055d73b1130,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-05b904af-2561-421b-b874-03e7165c0731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150042116-172.17.0.4-1596891306859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43729,DS-51e7c9a3-086c-493c-9a2b-ea2d65845fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-94aaaf5c-11e1-42fd-b557-a9e535a41280,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-d29d758d-3b71-44f3-bbd8-64e496966678,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-b53e33cd-c213-438b-ae03-90e1bbf5937c,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-001edbb5-de40-4e26-8f1b-fae702b31e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-5a2ba723-8252-4e21-b10c-a798eb7a3534,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-e05b085a-620c-499c-ae65-4d67b1ace5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-791f642c-5aae-4a87-866e-d51f395ff127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150042116-172.17.0.4-1596891306859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43729,DS-51e7c9a3-086c-493c-9a2b-ea2d65845fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-94aaaf5c-11e1-42fd-b557-a9e535a41280,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-d29d758d-3b71-44f3-bbd8-64e496966678,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-b53e33cd-c213-438b-ae03-90e1bbf5937c,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-001edbb5-de40-4e26-8f1b-fae702b31e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-5a2ba723-8252-4e21-b10c-a798eb7a3534,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-e05b085a-620c-499c-ae65-4d67b1ace5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-791f642c-5aae-4a87-866e-d51f395ff127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987396556-172.17.0.4-1596891571328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-57550a01-6635-4c70-976c-2e76c0b8d995,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-ff80aa2b-1e70-4428-a99b-f0eddbcfc3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-53269a46-ad80-47eb-9e5f-c0753caf49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-4092a449-7fd5-48b0-bd36-437abea80604,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-60b05ed1-e2aa-43d8-b3e3-5a659bc78016,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-5124746b-be72-4507-86f4-ece47fd42a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-76de669f-9675-4fb8-8a2c-2a0925aea6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-3c4717f0-8f03-4ca7-97f6-217fb5e5d265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987396556-172.17.0.4-1596891571328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-57550a01-6635-4c70-976c-2e76c0b8d995,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-ff80aa2b-1e70-4428-a99b-f0eddbcfc3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-53269a46-ad80-47eb-9e5f-c0753caf49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-4092a449-7fd5-48b0-bd36-437abea80604,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-60b05ed1-e2aa-43d8-b3e3-5a659bc78016,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-5124746b-be72-4507-86f4-ece47fd42a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-76de669f-9675-4fb8-8a2c-2a0925aea6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-3c4717f0-8f03-4ca7-97f6-217fb5e5d265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765431351-172.17.0.4-1596891823699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-f438b8f7-c062-4adc-9ecd-d6d420b6b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-dd088b7c-16cb-4b0c-b420-4ff26b80498c,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-79c87643-f3d6-4740-9e19-30103af26c15,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-882764ce-1e7d-4f19-8990-fbaf44573306,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-894fc26a-0787-4181-b37d-596bb1c74e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-3695697f-1e90-4941-9fdb-fdb715e40720,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-fc2b061d-e4f2-4193-b18e-34ebc447336a,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-11f8cda0-8434-4356-bf5b-7fd54cfc225e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765431351-172.17.0.4-1596891823699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-f438b8f7-c062-4adc-9ecd-d6d420b6b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-dd088b7c-16cb-4b0c-b420-4ff26b80498c,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-79c87643-f3d6-4740-9e19-30103af26c15,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-882764ce-1e7d-4f19-8990-fbaf44573306,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-894fc26a-0787-4181-b37d-596bb1c74e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-3695697f-1e90-4941-9fdb-fdb715e40720,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-fc2b061d-e4f2-4193-b18e-34ebc447336a,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-11f8cda0-8434-4356-bf5b-7fd54cfc225e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5521
