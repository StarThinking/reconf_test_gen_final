reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552782334-172.17.0.13-1596913894609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35047,DS-d3f92de0-3104-4171-8a9e-6b820486f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-77a507e2-b59d-4694-b982-6c2ee0f46b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-312bf125-8525-4f06-9f85-9169de258fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-85eb6311-b4bc-45bc-9a75-33ef6b89c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-2098da1c-cbb1-428f-b8d8-8b1b8e300ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-1b6a5083-be10-4628-be69-d65e3479d364,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-058d2caf-e5a1-43e9-b658-5dd7f110278a,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-f0f60139-634e-41be-a923-dc4b37d2fe0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552782334-172.17.0.13-1596913894609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35047,DS-d3f92de0-3104-4171-8a9e-6b820486f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-77a507e2-b59d-4694-b982-6c2ee0f46b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-312bf125-8525-4f06-9f85-9169de258fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-85eb6311-b4bc-45bc-9a75-33ef6b89c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-2098da1c-cbb1-428f-b8d8-8b1b8e300ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-1b6a5083-be10-4628-be69-d65e3479d364,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-058d2caf-e5a1-43e9-b658-5dd7f110278a,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-f0f60139-634e-41be-a923-dc4b37d2fe0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558616046-172.17.0.13-1596914516431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-17886608-245d-4706-ac81-1c83011eb23c,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-a282f2f9-4b93-438d-a785-30dc64291f07,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-2926d0ea-164e-4bac-bc32-97bdb4e86716,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-21a6239e-7775-489e-a1ca-6b144c181c72,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-486173d7-b79a-49cb-88ba-4c6d906ea2da,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-84a804bc-75f5-4397-9765-c1ba3660c22b,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-5f602dd3-f883-4282-a7a3-a3380fe0da2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-f4173495-12ee-4a75-9ea2-0c1925ad26ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558616046-172.17.0.13-1596914516431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-17886608-245d-4706-ac81-1c83011eb23c,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-a282f2f9-4b93-438d-a785-30dc64291f07,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-2926d0ea-164e-4bac-bc32-97bdb4e86716,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-21a6239e-7775-489e-a1ca-6b144c181c72,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-486173d7-b79a-49cb-88ba-4c6d906ea2da,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-84a804bc-75f5-4397-9765-c1ba3660c22b,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-5f602dd3-f883-4282-a7a3-a3380fe0da2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-f4173495-12ee-4a75-9ea2-0c1925ad26ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527919130-172.17.0.13-1596914662448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46119,DS-77cef358-83be-452b-8410-01fc9c4bebac,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-08236837-62ce-42f2-8fbd-b03319f216a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-8445aa53-9395-43d2-8f1c-08fc3507034b,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-6896adf3-395d-49d5-9333-b889dc202190,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-581b789c-2148-4330-abae-aa998193a635,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-229021cd-938a-490d-b641-7a5afdd3910f,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-1fa028c9-1036-4c95-b6eb-d296dcc6e367,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-f604071f-af3b-48e7-a60f-bacfc3d3f207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527919130-172.17.0.13-1596914662448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46119,DS-77cef358-83be-452b-8410-01fc9c4bebac,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-08236837-62ce-42f2-8fbd-b03319f216a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-8445aa53-9395-43d2-8f1c-08fc3507034b,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-6896adf3-395d-49d5-9333-b889dc202190,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-581b789c-2148-4330-abae-aa998193a635,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-229021cd-938a-490d-b641-7a5afdd3910f,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-1fa028c9-1036-4c95-b6eb-d296dcc6e367,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-f604071f-af3b-48e7-a60f-bacfc3d3f207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006054051-172.17.0.13-1596914698289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-be1fc05f-a288-49ff-a1c4-69dbfd67b918,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-eb9e5064-1443-46a7-8af5-73ff06325bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-6105cacb-cb69-4110-b904-d852e9b8939c,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-f857884d-018a-4762-b39a-6f2b0be6d7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-47f29e8a-88a3-4d64-84a9-7e6a6384227c,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-7563d4f8-00a0-4838-be6c-475be7048267,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-a4ab0d5b-006f-49e4-856a-77bfd8241e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-6a593b84-9a43-4eb7-98be-e3d449604519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006054051-172.17.0.13-1596914698289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35056,DS-be1fc05f-a288-49ff-a1c4-69dbfd67b918,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-eb9e5064-1443-46a7-8af5-73ff06325bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-6105cacb-cb69-4110-b904-d852e9b8939c,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-f857884d-018a-4762-b39a-6f2b0be6d7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-47f29e8a-88a3-4d64-84a9-7e6a6384227c,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-7563d4f8-00a0-4838-be6c-475be7048267,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-a4ab0d5b-006f-49e4-856a-77bfd8241e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-6a593b84-9a43-4eb7-98be-e3d449604519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140971525-172.17.0.13-1596915387241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-6e601588-fd63-4ba0-85be-30c3fbe34357,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-d67c49ac-e414-457f-bb91-92b0013e961d,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-486ade70-aed3-4196-9778-359ec776ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-216e6568-292d-48f6-b426-f688fa7d0a76,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-21bc9279-5b64-40e1-9dc5-2cf94561f5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-afc3c4b3-adae-4657-890b-b4c7cc971a28,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-2f1d135a-c0aa-4585-a341-43a532cc540a,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-0ad43f14-1635-49bf-b605-b4d43afab3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140971525-172.17.0.13-1596915387241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-6e601588-fd63-4ba0-85be-30c3fbe34357,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-d67c49ac-e414-457f-bb91-92b0013e961d,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-486ade70-aed3-4196-9778-359ec776ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-216e6568-292d-48f6-b426-f688fa7d0a76,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-21bc9279-5b64-40e1-9dc5-2cf94561f5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-afc3c4b3-adae-4657-890b-b4c7cc971a28,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-2f1d135a-c0aa-4585-a341-43a532cc540a,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-0ad43f14-1635-49bf-b605-b4d43afab3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383577630-172.17.0.13-1596915461951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38761,DS-17c5742a-9628-45e7-b079-03556cd7e9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-bfc5964f-7d79-4315-85da-6659795d72f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-cf51a7de-bbf4-40da-9637-89d56067f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-85098390-33b7-4922-bebb-f160084db9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-ba275e73-0e1d-46ec-bc2e-cd6828151db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-8a57a75d-16fc-46a6-ba99-1417427e8927,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-5a019993-83b6-41f0-89c1-928371a12779,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-be30097f-f5eb-424f-95f2-7b667fd75845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383577630-172.17.0.13-1596915461951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38761,DS-17c5742a-9628-45e7-b079-03556cd7e9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-bfc5964f-7d79-4315-85da-6659795d72f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-cf51a7de-bbf4-40da-9637-89d56067f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-85098390-33b7-4922-bebb-f160084db9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-ba275e73-0e1d-46ec-bc2e-cd6828151db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-8a57a75d-16fc-46a6-ba99-1417427e8927,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-5a019993-83b6-41f0-89c1-928371a12779,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-be30097f-f5eb-424f-95f2-7b667fd75845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300638925-172.17.0.13-1596915896097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40786,DS-7ca7522c-4183-4de0-8ee5-2b5a98204112,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-34ba94ab-eb18-4709-9b89-133391e887da,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-04f95a62-5c55-48a1-8ea6-4852466373ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-851f7ad8-32e4-4b2a-87b8-3f45bbb9d382,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-e509d2f0-6c6a-471f-9319-e2d056d0fb16,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-da18efe5-ac9c-4191-a497-67b6718211e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-f1ba72a2-e6b6-4753-a88a-ce8d875253b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-b96e4af9-db5c-4fe5-9134-e14fddb88c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300638925-172.17.0.13-1596915896097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40786,DS-7ca7522c-4183-4de0-8ee5-2b5a98204112,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-34ba94ab-eb18-4709-9b89-133391e887da,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-04f95a62-5c55-48a1-8ea6-4852466373ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-851f7ad8-32e4-4b2a-87b8-3f45bbb9d382,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-e509d2f0-6c6a-471f-9319-e2d056d0fb16,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-da18efe5-ac9c-4191-a497-67b6718211e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-f1ba72a2-e6b6-4753-a88a-ce8d875253b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-b96e4af9-db5c-4fe5-9134-e14fddb88c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698169726-172.17.0.13-1596916153441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-b4a83e77-e779-4bac-998e-af0df45cf04b,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-d67c479b-50a6-4f41-9390-092aeeaaa747,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-68218455-1957-4538-9167-7e1188bf615a,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-b4588b0f-4a9f-4645-9752-2a5e0deb7df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-68563a2f-cc0f-444d-96cc-cadf1a78b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-dca1d3f7-115d-437c-8596-f3e8fd3eaf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-f761bc55-9d8c-4d95-9650-bb05d89c95c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-06500ce2-45c6-4f07-89e4-4018d2500c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698169726-172.17.0.13-1596916153441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-b4a83e77-e779-4bac-998e-af0df45cf04b,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-d67c479b-50a6-4f41-9390-092aeeaaa747,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-68218455-1957-4538-9167-7e1188bf615a,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-b4588b0f-4a9f-4645-9752-2a5e0deb7df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-68563a2f-cc0f-444d-96cc-cadf1a78b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-dca1d3f7-115d-437c-8596-f3e8fd3eaf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-f761bc55-9d8c-4d95-9650-bb05d89c95c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-06500ce2-45c6-4f07-89e4-4018d2500c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127927926-172.17.0.13-1596916319189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32887,DS-42bf5aaf-46da-48f0-83b4-6551352edcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-8aae9e08-cae2-40c5-aefe-e6fc1017bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-7507f404-135e-4aa4-9a0b-1d6d4774b67c,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-b7d5312c-6d80-43d6-9635-591550aa7cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-d382c8ca-5ddf-4f07-b41b-9377e89b89ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-50ff920a-955a-4e6d-8186-293b46ae1588,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-90437d09-ef08-4c13-974c-d4a4615238a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-96ea3cb1-807b-44f3-b72d-aecd05ccf6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127927926-172.17.0.13-1596916319189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32887,DS-42bf5aaf-46da-48f0-83b4-6551352edcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-8aae9e08-cae2-40c5-aefe-e6fc1017bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-7507f404-135e-4aa4-9a0b-1d6d4774b67c,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-b7d5312c-6d80-43d6-9635-591550aa7cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-d382c8ca-5ddf-4f07-b41b-9377e89b89ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-50ff920a-955a-4e6d-8186-293b46ae1588,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-90437d09-ef08-4c13-974c-d4a4615238a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-96ea3cb1-807b-44f3-b72d-aecd05ccf6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911418997-172.17.0.13-1596916899075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41444,DS-0fbee23b-38a2-4a21-928e-1628fa2d40fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-8fca9da5-901e-4034-81ea-e31102b57b97,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-788f6def-fbfd-475d-9514-f2b3402c17aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-ba1d488e-23a2-46eb-a277-ef2512ea10bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-203c9dc2-6bc8-46f2-b022-b39e9834f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-55f926eb-7351-42c8-849e-eac25f819f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-beed3e7d-1d22-4fa7-b3f6-e31bdee877c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-e4c761a1-c635-4565-b06c-a30470d58fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911418997-172.17.0.13-1596916899075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41444,DS-0fbee23b-38a2-4a21-928e-1628fa2d40fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-8fca9da5-901e-4034-81ea-e31102b57b97,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-788f6def-fbfd-475d-9514-f2b3402c17aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-ba1d488e-23a2-46eb-a277-ef2512ea10bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-203c9dc2-6bc8-46f2-b022-b39e9834f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-55f926eb-7351-42c8-849e-eac25f819f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-beed3e7d-1d22-4fa7-b3f6-e31bdee877c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-e4c761a1-c635-4565-b06c-a30470d58fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524828991-172.17.0.13-1596916934749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-0272ff31-23ea-4a5f-99b6-3b8ac4e73318,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-1b1ac6b4-713c-4ea8-8ada-e2662bb396a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-765e874f-a08c-4132-a3b2-963ae69f8041,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-cce42416-dcde-4fd4-91b5-f602711d6e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-278ec6a2-3017-47e4-8097-37f1ee800719,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-ef36bb8d-7c7e-4f7e-9f4b-c3fe46f4f6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-8fe8e3b9-12bd-4e8c-87e8-f77811b6c4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-285e25b2-65d1-4a29-b0cd-05543971685c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524828991-172.17.0.13-1596916934749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-0272ff31-23ea-4a5f-99b6-3b8ac4e73318,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-1b1ac6b4-713c-4ea8-8ada-e2662bb396a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-765e874f-a08c-4132-a3b2-963ae69f8041,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-cce42416-dcde-4fd4-91b5-f602711d6e32,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-278ec6a2-3017-47e4-8097-37f1ee800719,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-ef36bb8d-7c7e-4f7e-9f4b-c3fe46f4f6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-8fe8e3b9-12bd-4e8c-87e8-f77811b6c4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-285e25b2-65d1-4a29-b0cd-05543971685c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815025533-172.17.0.13-1596917872004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45586,DS-c57cfc48-03ad-4481-a1b3-490ee9048081,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-9a047608-df3c-4d4d-96f6-c52c98c2aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-1ea2f715-4209-4612-bfa5-056ac3012366,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-361157a1-f9c4-478e-a887-93d9fa5515c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-23ea2dcc-f3b7-4d1b-8923-cca7ab99fc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-09f6d495-923c-4557-9455-a4a92fea432b,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-64306905-7982-4edb-b0bf-dcd2f851e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-844bd6b7-30d5-450f-bee2-cb1f8d4aa759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815025533-172.17.0.13-1596917872004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45586,DS-c57cfc48-03ad-4481-a1b3-490ee9048081,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-9a047608-df3c-4d4d-96f6-c52c98c2aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-1ea2f715-4209-4612-bfa5-056ac3012366,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-361157a1-f9c4-478e-a887-93d9fa5515c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-23ea2dcc-f3b7-4d1b-8923-cca7ab99fc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-09f6d495-923c-4557-9455-a4a92fea432b,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-64306905-7982-4edb-b0bf-dcd2f851e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-844bd6b7-30d5-450f-bee2-cb1f8d4aa759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322272851-172.17.0.13-1596917909435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-16e8d2c8-7a86-4425-89ca-744c08f3680e,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-85f1c241-e708-4a93-b8cf-0062e23fee9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-556fdf1f-2321-4ee7-a7d6-f16e19c85bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-2506cd05-f4e5-41c3-9552-b194a10f0228,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-997d0756-90d8-4389-9218-c1bce77ea21e,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-79e6407d-aaa7-4e04-b34e-8022ac085484,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-f8cbe6ec-1836-4731-9449-316cc2fba028,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-0880be2f-f465-4472-be36-80a2b54a53f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322272851-172.17.0.13-1596917909435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-16e8d2c8-7a86-4425-89ca-744c08f3680e,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-85f1c241-e708-4a93-b8cf-0062e23fee9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-556fdf1f-2321-4ee7-a7d6-f16e19c85bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-2506cd05-f4e5-41c3-9552-b194a10f0228,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-997d0756-90d8-4389-9218-c1bce77ea21e,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-79e6407d-aaa7-4e04-b34e-8022ac085484,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-f8cbe6ec-1836-4731-9449-316cc2fba028,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-0880be2f-f465-4472-be36-80a2b54a53f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016468561-172.17.0.13-1596918051430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-1fb41132-cc40-4c86-8d5b-180f54334941,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-4b45dda4-037a-4baf-b5ef-5697ee65fa73,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-83bf0cb5-6169-414f-a784-991f635bc806,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-a79ab5bd-c815-47f8-8c62-5292932c4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-354cd2ca-ab45-4ba7-b429-51d3ecb81a69,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-c7bdb3f8-e371-4a4d-ac87-c6783c022273,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-209f8f4f-b2a6-4962-9647-c13cae1e346b,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-682ebe44-8725-41da-8e7a-fdaded1434ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016468561-172.17.0.13-1596918051430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-1fb41132-cc40-4c86-8d5b-180f54334941,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-4b45dda4-037a-4baf-b5ef-5697ee65fa73,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-83bf0cb5-6169-414f-a784-991f635bc806,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-a79ab5bd-c815-47f8-8c62-5292932c4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-354cd2ca-ab45-4ba7-b429-51d3ecb81a69,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-c7bdb3f8-e371-4a4d-ac87-c6783c022273,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-209f8f4f-b2a6-4962-9647-c13cae1e346b,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-682ebe44-8725-41da-8e7a-fdaded1434ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280423562-172.17.0.13-1596918446877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44723,DS-b66f18be-f543-4b47-83b4-3f77f06aba33,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-d39be0bb-736e-4f4f-94f7-a88566bea2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-9884e8ce-1c95-4da4-9d1f-594165667f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-c5aaf8ad-0e63-4a58-a62b-dc1d557ca72e,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-4318e456-a0b1-4dbf-bb68-cd0728054e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-e38a3b4f-748b-494c-8d5a-9c956ba29474,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-ad5e4cef-62d3-4d66-b3ba-fdaab147a550,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-a6a327f1-b0bc-4d1e-b349-0c339c5e6327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280423562-172.17.0.13-1596918446877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44723,DS-b66f18be-f543-4b47-83b4-3f77f06aba33,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-d39be0bb-736e-4f4f-94f7-a88566bea2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-9884e8ce-1c95-4da4-9d1f-594165667f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-c5aaf8ad-0e63-4a58-a62b-dc1d557ca72e,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-4318e456-a0b1-4dbf-bb68-cd0728054e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-e38a3b4f-748b-494c-8d5a-9c956ba29474,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-ad5e4cef-62d3-4d66-b3ba-fdaab147a550,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-a6a327f1-b0bc-4d1e-b349-0c339c5e6327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754262416-172.17.0.13-1596918481225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-2832a91d-8084-4406-901f-5466e5c60d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-92df50f4-6ec0-43b4-9d7b-1b307e4d4ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-33aedf05-7a00-4d1d-a9a8-6f8a4669f439,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-e66fb42d-b945-4d76-8b29-9b07b4d09bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-f5dcdc2e-ec2e-4cb0-b2b4-e085d0a054ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-4afe74e3-aec4-4077-b3b9-ef2254614ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-ade2875e-8081-429b-aaca-7a87e212d184,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-8d42d089-397c-486a-8c9e-a37328a8f07f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754262416-172.17.0.13-1596918481225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-2832a91d-8084-4406-901f-5466e5c60d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-92df50f4-6ec0-43b4-9d7b-1b307e4d4ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-33aedf05-7a00-4d1d-a9a8-6f8a4669f439,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-e66fb42d-b945-4d76-8b29-9b07b4d09bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-f5dcdc2e-ec2e-4cb0-b2b4-e085d0a054ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-4afe74e3-aec4-4077-b3b9-ef2254614ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-ade2875e-8081-429b-aaca-7a87e212d184,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-8d42d089-397c-486a-8c9e-a37328a8f07f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964636077-172.17.0.13-1596919205055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43643,DS-40398be6-c5ea-4e3f-8641-a68a70df4218,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-bcba64ce-c085-4e1e-9b9e-177a0c8ae5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-6a153d40-ca2b-4c3e-82f4-7667339030ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-1bd776e4-def1-4ff7-99f5-93645a2b1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-72c63e6d-7c63-43f9-ad28-040d6f2e61c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-23a850f7-0633-4fa8-a22a-65d5bfc184b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-c960d640-0d3f-4554-8f2d-d2a2f6130d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-4f89f542-0b5f-4b59-a94c-37606e2b6b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964636077-172.17.0.13-1596919205055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43643,DS-40398be6-c5ea-4e3f-8641-a68a70df4218,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-bcba64ce-c085-4e1e-9b9e-177a0c8ae5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-6a153d40-ca2b-4c3e-82f4-7667339030ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-1bd776e4-def1-4ff7-99f5-93645a2b1b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-72c63e6d-7c63-43f9-ad28-040d6f2e61c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-23a850f7-0633-4fa8-a22a-65d5bfc184b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-c960d640-0d3f-4554-8f2d-d2a2f6130d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-4f89f542-0b5f-4b59-a94c-37606e2b6b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-829775023-172.17.0.13-1596919235195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34790,DS-8c7e7968-0ae8-4f2d-8739-3a64bbdade2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-91fca474-484e-4e37-8949-655244411408,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-dd6bd7f8-6ece-45e2-8f4f-1f2e42fc0c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-71dad869-185f-463b-a400-c61423b1090a,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-ec22528c-2b3a-44f2-b27b-a6766da721df,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-5f746920-68c6-4f99-8d04-de5f2c80dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-0a4e4bb8-8377-4d59-bf2b-4e09ceb8e0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-e276c707-f79d-451d-abd2-b815dbcb370b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-829775023-172.17.0.13-1596919235195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34790,DS-8c7e7968-0ae8-4f2d-8739-3a64bbdade2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-91fca474-484e-4e37-8949-655244411408,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-dd6bd7f8-6ece-45e2-8f4f-1f2e42fc0c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-71dad869-185f-463b-a400-c61423b1090a,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-ec22528c-2b3a-44f2-b27b-a6766da721df,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-5f746920-68c6-4f99-8d04-de5f2c80dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-0a4e4bb8-8377-4d59-bf2b-4e09ceb8e0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-e276c707-f79d-451d-abd2-b815dbcb370b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5441
