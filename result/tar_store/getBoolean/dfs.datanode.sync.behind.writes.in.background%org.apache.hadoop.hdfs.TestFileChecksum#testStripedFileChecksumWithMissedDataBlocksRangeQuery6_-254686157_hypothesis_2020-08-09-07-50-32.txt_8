reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761114754-172.17.0.7-1596959544796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-adb3b8cb-de08-4b10-94ed-e09a0a40231e,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-6fab1fee-cc9d-47ff-a9db-6ed503bf77f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-99501ee6-ea81-4899-a294-40eba6c7d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-fe299345-1874-4f39-b4e0-613520625464,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-0b43df7e-cc22-4478-aeef-00a8483f9084,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-648481a1-04f3-4e62-881c-7fa4ba3304f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-970cb12e-89f4-4d5e-89a1-24d18d29bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-65a8b419-1974-4830-85f6-42938e13cbe5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761114754-172.17.0.7-1596959544796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-adb3b8cb-de08-4b10-94ed-e09a0a40231e,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-6fab1fee-cc9d-47ff-a9db-6ed503bf77f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-99501ee6-ea81-4899-a294-40eba6c7d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-fe299345-1874-4f39-b4e0-613520625464,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-0b43df7e-cc22-4478-aeef-00a8483f9084,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-648481a1-04f3-4e62-881c-7fa4ba3304f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-970cb12e-89f4-4d5e-89a1-24d18d29bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-65a8b419-1974-4830-85f6-42938e13cbe5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371605773-172.17.0.7-1596959688411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39384,DS-c16ac45a-a5dd-4259-bec7-d09a7aebbdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-fc5b6687-9429-412c-8413-e1cf80034460,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-f5eb1bc0-ff65-400d-b0ec-43563351b5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-6ffde54f-f7c9-4f4c-86fc-1a3d47d121e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-fbafabc9-715d-405b-a018-017d8f928d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-76d25348-a3a2-4bc4-b62d-ebd41737d180,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-090e10d7-7779-4d82-912a-a7c9d040845c,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-962d9fb2-3a3e-4877-bfe9-5103c1e8790e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371605773-172.17.0.7-1596959688411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39384,DS-c16ac45a-a5dd-4259-bec7-d09a7aebbdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-fc5b6687-9429-412c-8413-e1cf80034460,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-f5eb1bc0-ff65-400d-b0ec-43563351b5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-6ffde54f-f7c9-4f4c-86fc-1a3d47d121e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-fbafabc9-715d-405b-a018-017d8f928d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-76d25348-a3a2-4bc4-b62d-ebd41737d180,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-090e10d7-7779-4d82-912a-a7c9d040845c,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-962d9fb2-3a3e-4877-bfe9-5103c1e8790e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647194152-172.17.0.7-1596959759462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32890,DS-4d9d2904-4975-4d54-81ac-cbd752c9a473,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-dd0605b5-9346-4898-a738-cdfc67bf0a19,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-7ec94bdc-1971-44d6-b10b-02c23c55e854,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-3f7438dd-da61-4398-a75a-c472283dbcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-3162f8f2-c87f-43ca-8dc9-089e4e040e93,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-09f2b8cc-4032-4cbf-8f43-5701a4671833,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-a5f95556-ee18-433a-a7bc-b26099f53663,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-89ca0302-6281-468b-848a-b931c6180555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647194152-172.17.0.7-1596959759462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32890,DS-4d9d2904-4975-4d54-81ac-cbd752c9a473,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-dd0605b5-9346-4898-a738-cdfc67bf0a19,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-7ec94bdc-1971-44d6-b10b-02c23c55e854,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-3f7438dd-da61-4398-a75a-c472283dbcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-3162f8f2-c87f-43ca-8dc9-089e4e040e93,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-09f2b8cc-4032-4cbf-8f43-5701a4671833,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-a5f95556-ee18-433a-a7bc-b26099f53663,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-89ca0302-6281-468b-848a-b931c6180555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779435846-172.17.0.7-1596959859353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43322,DS-3fb8edcf-445e-4f60-8653-42fd20af59ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-0ef77f6d-e8dd-4595-9590-8cdc6968f3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-505fcd30-118b-47c0-a4e0-b62a9301f47a,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-65dbaa16-0f72-47a8-a3d4-361be54ee44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-88665a34-a80d-4674-af02-d53a78f302cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-9495e035-5b3c-4f27-8c4d-bb09f2caab72,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-6faf677d-e55a-4cf9-aaa7-2ac422dbb1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-a63e87ae-af5b-4c20-b6ff-dc55450bcdf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779435846-172.17.0.7-1596959859353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43322,DS-3fb8edcf-445e-4f60-8653-42fd20af59ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-0ef77f6d-e8dd-4595-9590-8cdc6968f3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-505fcd30-118b-47c0-a4e0-b62a9301f47a,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-65dbaa16-0f72-47a8-a3d4-361be54ee44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-88665a34-a80d-4674-af02-d53a78f302cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-9495e035-5b3c-4f27-8c4d-bb09f2caab72,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-6faf677d-e55a-4cf9-aaa7-2ac422dbb1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-a63e87ae-af5b-4c20-b6ff-dc55450bcdf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763785894-172.17.0.7-1596959896578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-7c867ca0-348b-4768-b5c7-24cded26b424,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-e1806cb3-1169-472e-8f0c-965620130ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-67cd4c27-3bdf-4858-a56f-d633a756a130,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-2e649e61-90b8-4bd4-845c-14864ea92216,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-91650088-18d3-4646-92e7-67592566d703,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-168e0137-44ec-4978-8856-606de9c0a747,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-c34a2342-47dc-4d34-94fe-6d3da4fa6832,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-c4847048-a2a7-4a78-a1f2-9d64f2fad922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763785894-172.17.0.7-1596959896578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-7c867ca0-348b-4768-b5c7-24cded26b424,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-e1806cb3-1169-472e-8f0c-965620130ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-67cd4c27-3bdf-4858-a56f-d633a756a130,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-2e649e61-90b8-4bd4-845c-14864ea92216,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-91650088-18d3-4646-92e7-67592566d703,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-168e0137-44ec-4978-8856-606de9c0a747,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-c34a2342-47dc-4d34-94fe-6d3da4fa6832,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-c4847048-a2a7-4a78-a1f2-9d64f2fad922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322018216-172.17.0.7-1596959934594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36243,DS-62aff831-7035-47a5-8d7a-a2d02f67d47f,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-9ebe2db1-ee6a-4b7a-a060-14110656d31d,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-5cf1c8eb-48c0-4be6-b6e7-8aea2e74f491,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-89d76a99-2b91-4320-8ba8-f8176356dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-5aaba021-9130-450d-8a7f-2636aa86fa79,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-5d63abdd-14f8-4234-9e31-3aebe2ff0b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-940bea34-f162-4a39-a4f2-6df9cbf8d2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-72c2f503-c126-432a-a55d-a1ce6d696d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322018216-172.17.0.7-1596959934594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36243,DS-62aff831-7035-47a5-8d7a-a2d02f67d47f,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-9ebe2db1-ee6a-4b7a-a060-14110656d31d,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-5cf1c8eb-48c0-4be6-b6e7-8aea2e74f491,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-89d76a99-2b91-4320-8ba8-f8176356dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-5aaba021-9130-450d-8a7f-2636aa86fa79,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-5d63abdd-14f8-4234-9e31-3aebe2ff0b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-940bea34-f162-4a39-a4f2-6df9cbf8d2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-72c2f503-c126-432a-a55d-a1ce6d696d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081494693-172.17.0.7-1596960039129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45719,DS-88e7a0b8-71d4-4a77-a3c4-d6e0e816300d,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-2a8c3ab9-5d0d-48cf-bf6c-18b13f1cdfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-918741b3-7ec8-42df-a810-eab8bff876d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-a0341cd5-7687-4656-bdbf-d296a4408564,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-c52a2ff7-3add-40d9-8823-1370ded896ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-273b027b-2ade-4e24-9af2-75a7fbfc8ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-b5709a9d-a4d8-4b67-ae35-82a393991d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-137a4d7d-5856-4763-a54c-b6008078e4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081494693-172.17.0.7-1596960039129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45719,DS-88e7a0b8-71d4-4a77-a3c4-d6e0e816300d,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-2a8c3ab9-5d0d-48cf-bf6c-18b13f1cdfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-918741b3-7ec8-42df-a810-eab8bff876d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-a0341cd5-7687-4656-bdbf-d296a4408564,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-c52a2ff7-3add-40d9-8823-1370ded896ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-273b027b-2ade-4e24-9af2-75a7fbfc8ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-b5709a9d-a4d8-4b67-ae35-82a393991d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-137a4d7d-5856-4763-a54c-b6008078e4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805799287-172.17.0.7-1596960416761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-2a3630bb-29f1-4685-a941-925dae16d762,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-6cf3827c-ae5b-4e30-b690-23fd8d0febd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-876beecd-0762-469a-b018-7967b950e590,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-06a5aa2c-5e19-4dca-a32d-3044d726169e,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-cf82b7c4-635c-4b8f-a7bc-f150de185832,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-9b39ff47-c0b5-4a68-aa1b-c158bd7f11b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-2aa63aad-8a62-409b-8aed-a04cd283b417,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-24627f74-ef3f-410d-a5de-7c35b3f707cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805799287-172.17.0.7-1596960416761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-2a3630bb-29f1-4685-a941-925dae16d762,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-6cf3827c-ae5b-4e30-b690-23fd8d0febd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-876beecd-0762-469a-b018-7967b950e590,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-06a5aa2c-5e19-4dca-a32d-3044d726169e,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-cf82b7c4-635c-4b8f-a7bc-f150de185832,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-9b39ff47-c0b5-4a68-aa1b-c158bd7f11b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-2aa63aad-8a62-409b-8aed-a04cd283b417,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-24627f74-ef3f-410d-a5de-7c35b3f707cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231355768-172.17.0.7-1596960449356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-552cee89-543c-4263-817b-667308313495,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-ef6cfa97-d74a-4b2c-870a-522c35c8a5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-42456c43-0c15-4df8-884c-be9965b713bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-bb270691-89a6-4654-944f-99533ab64df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-27041626-bc70-4abd-a5e9-ef3a1cc1dbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-e95ea60c-9ffb-41ac-9315-434f946d2e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-ddcf3c05-1d7f-4fb6-92ef-382bff448d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-69e481fe-0b9a-4a13-904f-8d1d355026cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231355768-172.17.0.7-1596960449356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-552cee89-543c-4263-817b-667308313495,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-ef6cfa97-d74a-4b2c-870a-522c35c8a5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-42456c43-0c15-4df8-884c-be9965b713bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-bb270691-89a6-4654-944f-99533ab64df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-27041626-bc70-4abd-a5e9-ef3a1cc1dbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-e95ea60c-9ffb-41ac-9315-434f946d2e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-ddcf3c05-1d7f-4fb6-92ef-382bff448d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-69e481fe-0b9a-4a13-904f-8d1d355026cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974530964-172.17.0.7-1596960522468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43664,DS-8dd77e90-fdcc-40da-bf30-ba0236c42675,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-5a277613-3428-46f7-8b91-ac01669e0c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-ba6fd7e4-463e-492f-80cd-0d23fbd1a467,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-7b0be581-4585-4ec9-9e9d-02958c09d3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-d009d7f5-f09d-434e-9c65-8a9b744183a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-caa76e1e-0580-4567-9c9c-abeeb803aab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-124cb27e-8a8c-404f-a3f8-13fd808394d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-c276cce4-e3c1-4163-b9d9-a2bccc0944d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974530964-172.17.0.7-1596960522468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43664,DS-8dd77e90-fdcc-40da-bf30-ba0236c42675,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-5a277613-3428-46f7-8b91-ac01669e0c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-ba6fd7e4-463e-492f-80cd-0d23fbd1a467,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-7b0be581-4585-4ec9-9e9d-02958c09d3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-d009d7f5-f09d-434e-9c65-8a9b744183a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-caa76e1e-0580-4567-9c9c-abeeb803aab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-124cb27e-8a8c-404f-a3f8-13fd808394d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-c276cce4-e3c1-4163-b9d9-a2bccc0944d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132493193-172.17.0.7-1596960548020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-2b46633c-c3ea-4ad2-96ca-b973dcb7504f,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-9ec4f240-9c55-494b-a00b-9e9f1092bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-189437cb-ad8f-47e3-a8dc-65da73cf4136,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-757ddc65-738b-4d9c-9af4-a460d1b9e11c,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-3271b0f6-19b0-46d7-a83f-e436154d90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-3db8452a-0ed8-4702-b856-2e7a982bbb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-b3677ba2-eadb-4e7b-96e2-bb2560949b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-343f30ec-0e07-4dbe-9973-bb6f1550568c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132493193-172.17.0.7-1596960548020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-2b46633c-c3ea-4ad2-96ca-b973dcb7504f,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-9ec4f240-9c55-494b-a00b-9e9f1092bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-189437cb-ad8f-47e3-a8dc-65da73cf4136,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-757ddc65-738b-4d9c-9af4-a460d1b9e11c,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-3271b0f6-19b0-46d7-a83f-e436154d90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-3db8452a-0ed8-4702-b856-2e7a982bbb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-b3677ba2-eadb-4e7b-96e2-bb2560949b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-343f30ec-0e07-4dbe-9973-bb6f1550568c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013210772-172.17.0.7-1596960803809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-6e98c570-abc8-4784-bc3b-715fd782f958,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-77c6ffa0-0715-4aa7-b047-6b6754b456d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-471f166f-8ec8-44a4-b63c-3e43f2344c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-a5151e7d-b512-49bc-8173-61e77b9c6be6,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-15fd381c-c86c-4888-84b4-398e05ae2368,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-e74ed1bf-aa01-4860-8745-0f92867088d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-5924d7b6-7c9d-4dd2-abbe-60117d90da9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-b242628a-4952-4d7e-8138-80a294c7d493,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013210772-172.17.0.7-1596960803809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-6e98c570-abc8-4784-bc3b-715fd782f958,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-77c6ffa0-0715-4aa7-b047-6b6754b456d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-471f166f-8ec8-44a4-b63c-3e43f2344c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-a5151e7d-b512-49bc-8173-61e77b9c6be6,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-15fd381c-c86c-4888-84b4-398e05ae2368,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-e74ed1bf-aa01-4860-8745-0f92867088d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-5924d7b6-7c9d-4dd2-abbe-60117d90da9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-b242628a-4952-4d7e-8138-80a294c7d493,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139554701-172.17.0.7-1596960900493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-34981cf8-c618-46f5-9f4d-20e1610ecaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-cec68bad-aa91-4776-b74d-97c1a94a9c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-1b39beab-8432-4150-b6fa-c6e187a789e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-0b2795ca-a778-4a80-9440-321ee6823f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-e3da120c-943a-4b0b-9ad6-5986958f6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-9151ba78-5fa0-4d15-908d-6f6baf1fd818,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-76fef958-72d3-44cb-9ab1-47996768da36,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-4abf14e9-b609-408a-a530-b518d04dd896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139554701-172.17.0.7-1596960900493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-34981cf8-c618-46f5-9f4d-20e1610ecaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-cec68bad-aa91-4776-b74d-97c1a94a9c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-1b39beab-8432-4150-b6fa-c6e187a789e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-0b2795ca-a778-4a80-9440-321ee6823f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-e3da120c-943a-4b0b-9ad6-5986958f6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-9151ba78-5fa0-4d15-908d-6f6baf1fd818,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-76fef958-72d3-44cb-9ab1-47996768da36,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-4abf14e9-b609-408a-a530-b518d04dd896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205444763-172.17.0.7-1596960953415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42791,DS-6b6f2c2d-fa5d-4ab3-b2d5-9c2e1e4ce461,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-7c3e2dd5-3203-430c-859e-7e65929bba97,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-11aad6be-276c-4900-8382-df7ef39c3333,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-f8a177b7-d648-45dd-a9f9-45397e5dbacd,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-792e9da6-da94-4308-b363-c6a1d035a539,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-685230ac-9579-45ad-902e-82f36fa7d249,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-3514bd67-4af0-4b30-82f5-8a9c14b38b87,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-7ac2f3f2-49a4-47e0-898e-8d44281eae46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205444763-172.17.0.7-1596960953415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42791,DS-6b6f2c2d-fa5d-4ab3-b2d5-9c2e1e4ce461,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-7c3e2dd5-3203-430c-859e-7e65929bba97,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-11aad6be-276c-4900-8382-df7ef39c3333,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-f8a177b7-d648-45dd-a9f9-45397e5dbacd,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-792e9da6-da94-4308-b363-c6a1d035a539,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-685230ac-9579-45ad-902e-82f36fa7d249,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-3514bd67-4af0-4b30-82f5-8a9c14b38b87,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-7ac2f3f2-49a4-47e0-898e-8d44281eae46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039965751-172.17.0.7-1596961013477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-9d520a87-b060-49ed-b923-6ab4f08599e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-6b4b64c8-f690-49d4-9e38-d6bd8e0e28f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-b9faf769-3327-46dd-a9db-4695972b5056,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-a0be7dc6-b140-4575-9041-f1902b4711e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-c53fa630-8a9a-46e6-9c8c-3f462bf6450a,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-a75ace27-fd37-4429-ba2b-3b5e1816aad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-9f97afbb-7c4a-4465-bcd3-e8e36d69f17e,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-e6ed38a6-31f9-4473-8834-d5fbac8d60d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039965751-172.17.0.7-1596961013477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34711,DS-9d520a87-b060-49ed-b923-6ab4f08599e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-6b4b64c8-f690-49d4-9e38-d6bd8e0e28f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-b9faf769-3327-46dd-a9db-4695972b5056,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-a0be7dc6-b140-4575-9041-f1902b4711e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-c53fa630-8a9a-46e6-9c8c-3f462bf6450a,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-a75ace27-fd37-4429-ba2b-3b5e1816aad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-9f97afbb-7c4a-4465-bcd3-e8e36d69f17e,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-e6ed38a6-31f9-4473-8834-d5fbac8d60d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380807525-172.17.0.7-1596961117321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-ce30c5d0-0da0-4454-8663-2fb3ffb50ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-a12c2a0c-2990-4762-9a30-003aa9f3b301,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-be0dcde9-ebcc-43b7-916d-f928e57a078c,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-5d83b4df-5ed8-4888-beec-5089f713636b,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-5dc4e3c5-e308-4325-bad0-81c4858bf826,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-a7b1d6fd-c66f-4fca-b7b8-7c1749f10e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-29b3becd-3f96-4953-8a6d-31558269d448,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-920e9fea-a8f6-4935-996d-d12dfb5398b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380807525-172.17.0.7-1596961117321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-ce30c5d0-0da0-4454-8663-2fb3ffb50ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-a12c2a0c-2990-4762-9a30-003aa9f3b301,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-be0dcde9-ebcc-43b7-916d-f928e57a078c,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-5d83b4df-5ed8-4888-beec-5089f713636b,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-5dc4e3c5-e308-4325-bad0-81c4858bf826,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-a7b1d6fd-c66f-4fca-b7b8-7c1749f10e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-29b3becd-3f96-4953-8a6d-31558269d448,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-920e9fea-a8f6-4935-996d-d12dfb5398b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019643921-172.17.0.7-1596961306741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46441,DS-0e360b77-4f8e-4729-99c0-b154f5c35258,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-2df49083-0278-4b82-af2c-72800b383b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-b00bc676-e821-49d4-a81e-a87d23e716ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-f6e63960-e1c9-437a-93b9-265d9fede9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-163b2d12-7d65-45f6-b835-5b93b5240545,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-7bee54bb-a5c0-4488-a421-ddecdebe03b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-b97c248a-9c24-4118-aff9-7ea06c04a540,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-a2ec264d-bcb4-410f-a0ab-518bf63d8811,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019643921-172.17.0.7-1596961306741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46441,DS-0e360b77-4f8e-4729-99c0-b154f5c35258,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-2df49083-0278-4b82-af2c-72800b383b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-b00bc676-e821-49d4-a81e-a87d23e716ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-f6e63960-e1c9-437a-93b9-265d9fede9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-163b2d12-7d65-45f6-b835-5b93b5240545,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-7bee54bb-a5c0-4488-a421-ddecdebe03b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-b97c248a-9c24-4118-aff9-7ea06c04a540,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-a2ec264d-bcb4-410f-a0ab-518bf63d8811,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200314536-172.17.0.7-1596961337088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-aaf0fab5-5c60-496e-85a7-e7d556560d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-cd7b4266-8600-4f92-a2bb-cdefd74aff99,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-e196a8ca-543e-408a-aba6-27c85a4eefee,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-acdb0c42-0dfa-4e31-9e14-5edc1eb5278a,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-9292717e-8ffc-49f0-9ca4-4b179068f3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-6d964369-c6a7-4a9a-9549-0a41a3140649,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-8b18ffaa-8a12-463e-aa4f-05a577d718cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-08373502-f118-4173-9026-8bbd6dad6e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200314536-172.17.0.7-1596961337088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-aaf0fab5-5c60-496e-85a7-e7d556560d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-cd7b4266-8600-4f92-a2bb-cdefd74aff99,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-e196a8ca-543e-408a-aba6-27c85a4eefee,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-acdb0c42-0dfa-4e31-9e14-5edc1eb5278a,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-9292717e-8ffc-49f0-9ca4-4b179068f3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-6d964369-c6a7-4a9a-9549-0a41a3140649,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-8b18ffaa-8a12-463e-aa4f-05a577d718cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-08373502-f118-4173-9026-8bbd6dad6e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047668454-172.17.0.7-1596961400743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-071ff558-7c59-41e4-a308-f0e9712bfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-ac82a6cc-0f95-4e6c-b19f-c273ffb8c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-ef1a160f-5a21-4d99-8bbe-da5c73aac5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-c59b3730-ee22-427f-bc5e-d2590bd6f2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-fc53dd30-3b40-428b-98cb-4ab49b01d887,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-783b3957-86b7-49a7-aded-dedad78d8582,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-afa306d6-d00a-492a-af75-381613f52a99,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-db1c27d7-c370-4154-81ed-756ff74474e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047668454-172.17.0.7-1596961400743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-071ff558-7c59-41e4-a308-f0e9712bfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-ac82a6cc-0f95-4e6c-b19f-c273ffb8c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-ef1a160f-5a21-4d99-8bbe-da5c73aac5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-c59b3730-ee22-427f-bc5e-d2590bd6f2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-fc53dd30-3b40-428b-98cb-4ab49b01d887,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-783b3957-86b7-49a7-aded-dedad78d8582,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-afa306d6-d00a-492a-af75-381613f52a99,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-db1c27d7-c370-4154-81ed-756ff74474e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272327072-172.17.0.7-1596961464282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44346,DS-200eb619-4c53-4413-a486-e84a09db2ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-3d7072d8-8089-4140-8bf5-b288c4b9fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-214ba45e-58d5-47d1-b816-1e02041219f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-b4f4d8df-ef2c-498f-8aa7-71c832af0dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-4263c17e-40de-4982-bf3b-0f80d78dae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-822e4d65-9949-4108-a347-f6eeeae91126,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-ba012e5e-7355-4402-9b50-88669c61c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-89b6f28b-d39a-4ddf-8764-b80fe8bad310,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272327072-172.17.0.7-1596961464282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44346,DS-200eb619-4c53-4413-a486-e84a09db2ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-3d7072d8-8089-4140-8bf5-b288c4b9fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-214ba45e-58d5-47d1-b816-1e02041219f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-b4f4d8df-ef2c-498f-8aa7-71c832af0dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-4263c17e-40de-4982-bf3b-0f80d78dae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-822e4d65-9949-4108-a347-f6eeeae91126,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-ba012e5e-7355-4402-9b50-88669c61c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-89b6f28b-d39a-4ddf-8764-b80fe8bad310,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358453873-172.17.0.7-1596961500884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-c6485794-5a6d-4462-a69a-86adcde5650a,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-ef7b80b7-e291-4b42-83e1-b58960c4a401,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-23f25b0b-e2e3-45be-a1e9-e171daf5d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-ebef2c38-2229-41a8-ab77-d43813536b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-ea634984-5639-4b5c-b574-39a4d4bd781b,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-52be8b18-7572-48ca-92d0-7449e3334231,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-05ef9ffd-f10e-4e66-ac48-f50f4a1a4891,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-2ca3fdb1-8bfe-4b75-afff-3d66efb101fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358453873-172.17.0.7-1596961500884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-c6485794-5a6d-4462-a69a-86adcde5650a,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-ef7b80b7-e291-4b42-83e1-b58960c4a401,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-23f25b0b-e2e3-45be-a1e9-e171daf5d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-ebef2c38-2229-41a8-ab77-d43813536b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-ea634984-5639-4b5c-b574-39a4d4bd781b,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-52be8b18-7572-48ca-92d0-7449e3334231,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-05ef9ffd-f10e-4e66-ac48-f50f4a1a4891,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-2ca3fdb1-8bfe-4b75-afff-3d66efb101fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488398656-172.17.0.7-1596961767241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-a9406e11-abdb-4423-95e7-512a5124850d,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-c54e00a0-0795-406b-adb0-a805de1c9303,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-979d8729-a23d-4bec-a91d-69078377379c,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-853929bc-8330-494f-b81e-88dcb1ea372b,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-b0138d3b-5c72-447b-96ae-fe9d38f6cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-9613d923-f7d4-42d5-a25d-11a51bcba212,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-d5ea9c32-1510-4226-8c57-ff1e7d56ae99,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-19e41199-dc24-4cbb-84ca-71589d4351ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488398656-172.17.0.7-1596961767241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-a9406e11-abdb-4423-95e7-512a5124850d,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-c54e00a0-0795-406b-adb0-a805de1c9303,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-979d8729-a23d-4bec-a91d-69078377379c,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-853929bc-8330-494f-b81e-88dcb1ea372b,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-b0138d3b-5c72-447b-96ae-fe9d38f6cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-9613d923-f7d4-42d5-a25d-11a51bcba212,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-d5ea9c32-1510-4226-8c57-ff1e7d56ae99,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-19e41199-dc24-4cbb-84ca-71589d4351ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681685429-172.17.0.7-1596961799608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-26855ca0-7c44-4ecf-accd-d2355b6212de,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-5e92c83e-6cf4-4f82-8e21-b70ebc444c23,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-e1e482d5-9b99-49c0-ac9b-6881d933e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-92ad6ca0-ffa3-4f9f-b0b7-2edec6508cba,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-ae68708b-1c44-4d3b-b346-3c7f6cef9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-96f6b14b-90fc-4163-919c-40b44e0dfbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-d359bc26-6825-4448-bc50-afaeb8516dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-e4995db1-491e-433b-a6cf-58b8c97b569a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681685429-172.17.0.7-1596961799608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-26855ca0-7c44-4ecf-accd-d2355b6212de,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-5e92c83e-6cf4-4f82-8e21-b70ebc444c23,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-e1e482d5-9b99-49c0-ac9b-6881d933e38b,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-92ad6ca0-ffa3-4f9f-b0b7-2edec6508cba,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-ae68708b-1c44-4d3b-b346-3c7f6cef9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-96f6b14b-90fc-4163-919c-40b44e0dfbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-d359bc26-6825-4448-bc50-afaeb8516dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-e4995db1-491e-433b-a6cf-58b8c97b569a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165818209-172.17.0.7-1596961941889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41934,DS-ae48810f-5580-445f-a95c-e55bb191d197,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-1a8f13a3-8d3f-402a-adee-6e70ec95fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-1f7d5f2f-cd08-4016-9303-2c7d3ba5bb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-c2160f6f-a991-4566-83bf-132c5650c3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-d2268852-95b9-4a3e-baea-d678ff537950,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-faf6e99f-296a-40d6-8d2b-516c08ca1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-ac95bcef-e92d-4f56-9ffc-78cfa494f09e,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-d4dd51e8-50b8-4b59-abe0-02948cfa8ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165818209-172.17.0.7-1596961941889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41934,DS-ae48810f-5580-445f-a95c-e55bb191d197,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-1a8f13a3-8d3f-402a-adee-6e70ec95fdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-1f7d5f2f-cd08-4016-9303-2c7d3ba5bb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-c2160f6f-a991-4566-83bf-132c5650c3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-d2268852-95b9-4a3e-baea-d678ff537950,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-faf6e99f-296a-40d6-8d2b-516c08ca1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-ac95bcef-e92d-4f56-9ffc-78cfa494f09e,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-d4dd51e8-50b8-4b59-abe0-02948cfa8ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004929440-172.17.0.7-1596962447522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35307,DS-15a67248-72a5-44a3-9c3a-54b6f73e0cba,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-96cdcca4-f844-4cb0-a33e-60e4e4d94d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-05e0cb0e-b74e-49ee-8fee-a753c7f99bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-6dfc1070-0a9e-44dd-bdf3-226481dfed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-f143c848-f87f-4f97-973e-d58823079305,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-3a0514d8-242a-4f34-872e-5b1298eac59b,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-628698dc-3b0a-41ea-bdbb-ecf1e073188b,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-914683eb-c611-4dfe-8702-dca9833a0b29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004929440-172.17.0.7-1596962447522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35307,DS-15a67248-72a5-44a3-9c3a-54b6f73e0cba,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-96cdcca4-f844-4cb0-a33e-60e4e4d94d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-05e0cb0e-b74e-49ee-8fee-a753c7f99bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-6dfc1070-0a9e-44dd-bdf3-226481dfed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-f143c848-f87f-4f97-973e-d58823079305,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-3a0514d8-242a-4f34-872e-5b1298eac59b,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-628698dc-3b0a-41ea-bdbb-ecf1e073188b,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-914683eb-c611-4dfe-8702-dca9833a0b29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041778511-172.17.0.7-1596962702529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-de2c5ef6-77a3-4510-8d75-e257110732da,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-26819d95-2747-433d-a973-810d9a0f6dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-2c0ca32b-5845-4ddb-a6b8-a62fa817c0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-de164eee-ed40-420a-85f8-cf8ff713289f,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-ce4500d1-02d9-4ac0-90f5-2ddd10a2bd37,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-3abbce01-add0-46df-9bad-7a2fcb1bb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-5ad6ee23-c8b4-4d9e-9073-7475aea12e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-907c2961-4753-4e22-b131-5c43b34f7965,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041778511-172.17.0.7-1596962702529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-de2c5ef6-77a3-4510-8d75-e257110732da,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-26819d95-2747-433d-a973-810d9a0f6dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-2c0ca32b-5845-4ddb-a6b8-a62fa817c0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-de164eee-ed40-420a-85f8-cf8ff713289f,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-ce4500d1-02d9-4ac0-90f5-2ddd10a2bd37,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-3abbce01-add0-46df-9bad-7a2fcb1bb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-5ad6ee23-c8b4-4d9e-9073-7475aea12e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-907c2961-4753-4e22-b131-5c43b34f7965,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968693579-172.17.0.7-1596962765636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39501,DS-e55acf52-03fc-4bc9-9b7c-d1dc6928bb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-c7ad9153-4673-435f-a898-6417da3f5c33,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-43c1fe79-591e-476e-8376-7ec8e824b097,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-416cffbf-7d70-4469-a840-0a72927ca130,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-c208f82e-db48-43c6-8a2b-589aa3be7773,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-328b0237-694f-400e-a9af-88a0ea568215,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-ace9c884-c8ea-4f06-85d5-037995935d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-7b34d918-1b6b-4e82-9165-31b1377960c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968693579-172.17.0.7-1596962765636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39501,DS-e55acf52-03fc-4bc9-9b7c-d1dc6928bb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-c7ad9153-4673-435f-a898-6417da3f5c33,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-43c1fe79-591e-476e-8376-7ec8e824b097,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-416cffbf-7d70-4469-a840-0a72927ca130,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-c208f82e-db48-43c6-8a2b-589aa3be7773,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-328b0237-694f-400e-a9af-88a0ea568215,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-ace9c884-c8ea-4f06-85d5-037995935d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-7b34d918-1b6b-4e82-9165-31b1377960c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53171981-172.17.0.7-1596962797181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-4a792325-3fac-4c68-bbb0-f6dfab52b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-a6c88de0-95a9-46d5-bd09-45e5960ca39c,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-ddedfccf-c0fb-44b6-bd33-ae148e076941,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-eef8cac2-6c9e-4ce7-b561-3f7490367cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-bb9a55e5-8dcb-49b5-82eb-aa14f6d8c232,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-b6419f77-de36-4d8a-a678-07a7b4438236,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-8c926829-b268-4b55-a954-efc9429f1649,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-e4de8087-e58d-481f-92dc-ef413d6a18cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53171981-172.17.0.7-1596962797181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-4a792325-3fac-4c68-bbb0-f6dfab52b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-a6c88de0-95a9-46d5-bd09-45e5960ca39c,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-ddedfccf-c0fb-44b6-bd33-ae148e076941,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-eef8cac2-6c9e-4ce7-b561-3f7490367cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-bb9a55e5-8dcb-49b5-82eb-aa14f6d8c232,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-b6419f77-de36-4d8a-a678-07a7b4438236,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-8c926829-b268-4b55-a954-efc9429f1649,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-e4de8087-e58d-481f-92dc-ef413d6a18cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975281122-172.17.0.7-1596962897877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-20738d00-ccf7-4b15-976a-32685b59015b,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-8919a8c3-77b6-4dc4-a085-521f8f2da2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-d4b983e3-e955-4f9c-a4ce-de2b04dcb24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-ff48ee55-76e8-4f51-a92f-5dfb4cc8575d,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-3c8b3eb1-ddd1-4566-bb4e-eb1c72b041cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-41a75cf2-921f-461a-a25d-9dc1bec76bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-f8882c59-1d7b-4ea9-8019-8e46cb469460,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-2d1bbeb5-8fea-43ad-96bc-030bf02651b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975281122-172.17.0.7-1596962897877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-20738d00-ccf7-4b15-976a-32685b59015b,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-8919a8c3-77b6-4dc4-a085-521f8f2da2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-d4b983e3-e955-4f9c-a4ce-de2b04dcb24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-ff48ee55-76e8-4f51-a92f-5dfb4cc8575d,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-3c8b3eb1-ddd1-4566-bb4e-eb1c72b041cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-41a75cf2-921f-461a-a25d-9dc1bec76bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-f8882c59-1d7b-4ea9-8019-8e46cb469460,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-2d1bbeb5-8fea-43ad-96bc-030bf02651b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765402168-172.17.0.7-1596963099382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46732,DS-f38e7b28-cccf-4ce8-8352-70f18d815bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-e9ad94c9-239c-4fe2-8202-6111c9048f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-161d4e69-a2ee-4976-943e-60b79aa74273,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-18dcdbbe-f3c4-4a78-8483-cdc6e1e16a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-2cc5b48e-6015-4903-8e8d-23647ed0bf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-0a58eeac-e393-477b-aa4b-30443ea8b14e,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-575798c2-5dbb-4a20-9ff1-0c1429d33968,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-e1067c00-4ea5-46cb-9d95-f5a486323583,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765402168-172.17.0.7-1596963099382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46732,DS-f38e7b28-cccf-4ce8-8352-70f18d815bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-e9ad94c9-239c-4fe2-8202-6111c9048f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-161d4e69-a2ee-4976-943e-60b79aa74273,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-18dcdbbe-f3c4-4a78-8483-cdc6e1e16a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-2cc5b48e-6015-4903-8e8d-23647ed0bf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-0a58eeac-e393-477b-aa4b-30443ea8b14e,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-575798c2-5dbb-4a20-9ff1-0c1429d33968,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-e1067c00-4ea5-46cb-9d95-f5a486323583,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413782789-172.17.0.7-1596963214242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36876,DS-a05d9824-33be-4bf6-88c7-ab54db9a5a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-e7bf2f90-ba81-48d3-bfc2-75d6f179e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-3bbdd184-4880-46b8-9859-cbb4fc7febf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-67d79316-774d-45ea-a80e-496e7c2b777c,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-3186c16a-a2fc-4bcf-83f5-03408fb6ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-af4c8063-f05a-4cc9-b02c-54dc5f9ea134,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-ed03c7fc-915e-4ceb-887f-be575b04edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-463beced-99ad-4ff9-ba0f-16809af2f56a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413782789-172.17.0.7-1596963214242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36876,DS-a05d9824-33be-4bf6-88c7-ab54db9a5a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-e7bf2f90-ba81-48d3-bfc2-75d6f179e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-3bbdd184-4880-46b8-9859-cbb4fc7febf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-67d79316-774d-45ea-a80e-496e7c2b777c,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-3186c16a-a2fc-4bcf-83f5-03408fb6ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-af4c8063-f05a-4cc9-b02c-54dc5f9ea134,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-ed03c7fc-915e-4ceb-887f-be575b04edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-463beced-99ad-4ff9-ba0f-16809af2f56a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474818757-172.17.0.7-1596963337897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-e83167c5-5e79-44d6-9ea8-8df0c78decf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-be73b346-84c9-487a-a3c9-9c41054e8218,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-5193e7fc-9a10-4b6d-82af-fb842f5d0ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-1f7e06d8-62dc-4699-9deb-185ba5a351ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-a401e3ad-6809-465b-98b3-0de1041d0c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-42b233f7-077d-4aff-bb4e-0057acd6ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-c6c86819-ee96-44dd-9209-4950cb5b7883,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-1fe67dbc-e796-471e-8c57-df7b5b17ce1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474818757-172.17.0.7-1596963337897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-e83167c5-5e79-44d6-9ea8-8df0c78decf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-be73b346-84c9-487a-a3c9-9c41054e8218,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-5193e7fc-9a10-4b6d-82af-fb842f5d0ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-1f7e06d8-62dc-4699-9deb-185ba5a351ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-a401e3ad-6809-465b-98b3-0de1041d0c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-42b233f7-077d-4aff-bb4e-0057acd6ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-c6c86819-ee96-44dd-9209-4950cb5b7883,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-1fe67dbc-e796-471e-8c57-df7b5b17ce1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845712000-172.17.0.7-1596963682582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40601,DS-fd416777-fcda-4268-97df-0943e0db373c,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-508feff9-7f36-47cf-8977-a8aeb16b80e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-73289fdd-7025-45df-baf0-f89897a550b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-844453dc-62dd-4e0c-b212-008c8670a084,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-1609116f-3cfa-4f95-9f92-aae3aa5d3bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-91243dd6-1e2d-4e83-b5c1-a931187dfb02,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-224b32fc-86bd-4f9a-a8fd-1ce4329ebf36,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-ce11e290-9258-4c74-be78-327e783dc8ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845712000-172.17.0.7-1596963682582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40601,DS-fd416777-fcda-4268-97df-0943e0db373c,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-508feff9-7f36-47cf-8977-a8aeb16b80e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-73289fdd-7025-45df-baf0-f89897a550b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-844453dc-62dd-4e0c-b212-008c8670a084,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-1609116f-3cfa-4f95-9f92-aae3aa5d3bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-91243dd6-1e2d-4e83-b5c1-a931187dfb02,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-224b32fc-86bd-4f9a-a8fd-1ce4329ebf36,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-ce11e290-9258-4c74-be78-327e783dc8ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594544071-172.17.0.7-1596963815730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-388d82d3-4669-4150-8320-30f014b4b8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-9c078761-716d-45e2-a0e7-b54c8a33891b,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-2912043a-d871-484e-b0c1-82b803579784,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-6559ad72-b9ee-49f6-af6e-36cf5b345c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-bf39b809-5139-49ca-88fc-7bff318b0d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-0941471b-7b2e-47c2-a764-6d4739b19f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-1809aed2-9586-4e83-a4ae-85917998128b,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-1c7a763a-167b-4e82-aaf1-fbab715f4311,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594544071-172.17.0.7-1596963815730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-388d82d3-4669-4150-8320-30f014b4b8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-9c078761-716d-45e2-a0e7-b54c8a33891b,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-2912043a-d871-484e-b0c1-82b803579784,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-6559ad72-b9ee-49f6-af6e-36cf5b345c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-bf39b809-5139-49ca-88fc-7bff318b0d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-0941471b-7b2e-47c2-a764-6d4739b19f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-1809aed2-9586-4e83-a4ae-85917998128b,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-1c7a763a-167b-4e82-aaf1-fbab715f4311,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299623941-172.17.0.7-1596964014193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41178,DS-cf0c2c0c-335a-4354-963e-742cf510e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-d2baf572-be35-4099-a4f3-e032a80dc639,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-73a58c4f-80ed-4bd1-8acc-49bbd8ed2e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-c2566f58-49b4-43aa-ab5d-0139b1f56089,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-0af092cd-b388-425b-ab5f-5d5de22337fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-c293e367-631f-4ca4-8ef0-f133d69fcb09,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-82c4307f-7a00-4a10-876e-b3a83868e2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-4e8a916d-a661-43f4-9740-2ae8bcebdf6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299623941-172.17.0.7-1596964014193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41178,DS-cf0c2c0c-335a-4354-963e-742cf510e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-d2baf572-be35-4099-a4f3-e032a80dc639,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-73a58c4f-80ed-4bd1-8acc-49bbd8ed2e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-c2566f58-49b4-43aa-ab5d-0139b1f56089,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-0af092cd-b388-425b-ab5f-5d5de22337fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-c293e367-631f-4ca4-8ef0-f133d69fcb09,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-82c4307f-7a00-4a10-876e-b3a83868e2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-4e8a916d-a661-43f4-9740-2ae8bcebdf6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138288573-172.17.0.7-1596964055398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46805,DS-84e21a20-62ea-4d84-85b3-e474fb463dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-27f260fa-a26e-4368-8802-8bef72f26454,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-76403c96-cc67-46ac-b46e-670c1bba2219,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-222ed4ff-86fa-48e8-8e73-37e4b34deed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-91edffff-7913-430e-965c-91cbd8cb4720,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-2bd5927c-b707-4f74-afb2-7c6b2d63ff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-5930d7a0-30a0-41c8-8d21-118882e6d077,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-1ff00bb8-db90-4970-89a7-f8d145108a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138288573-172.17.0.7-1596964055398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46805,DS-84e21a20-62ea-4d84-85b3-e474fb463dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-27f260fa-a26e-4368-8802-8bef72f26454,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-76403c96-cc67-46ac-b46e-670c1bba2219,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-222ed4ff-86fa-48e8-8e73-37e4b34deed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-91edffff-7913-430e-965c-91cbd8cb4720,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-2bd5927c-b707-4f74-afb2-7c6b2d63ff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-5930d7a0-30a0-41c8-8d21-118882e6d077,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-1ff00bb8-db90-4970-89a7-f8d145108a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 4909
