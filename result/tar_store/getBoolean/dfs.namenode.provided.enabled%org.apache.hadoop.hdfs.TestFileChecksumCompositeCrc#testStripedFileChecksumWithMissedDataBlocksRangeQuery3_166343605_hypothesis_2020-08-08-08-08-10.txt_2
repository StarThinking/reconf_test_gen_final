reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121582278-172.17.0.21-1596875270703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45183,DS-7f8e8904-a9a5-44b4-a03c-28280ca81a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-4abc999d-e06f-4bde-b9e6-11150754e8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-837fcc34-93ee-4220-bf6b-4defb47ff750,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-32b1c61a-b7dc-46ea-80f8-ffac438a3d22,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-82cde7fc-069f-4235-b8e8-cb193b3a7ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-aeb79194-b850-4592-9a0d-574a033d4614,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-2e3f9d9f-bd52-42ec-8445-91e928eebf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-9b7360eb-c6fe-4982-903f-75c0a88a8215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121582278-172.17.0.21-1596875270703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45183,DS-7f8e8904-a9a5-44b4-a03c-28280ca81a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-4abc999d-e06f-4bde-b9e6-11150754e8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-837fcc34-93ee-4220-bf6b-4defb47ff750,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-32b1c61a-b7dc-46ea-80f8-ffac438a3d22,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-82cde7fc-069f-4235-b8e8-cb193b3a7ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-aeb79194-b850-4592-9a0d-574a033d4614,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-2e3f9d9f-bd52-42ec-8445-91e928eebf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-9b7360eb-c6fe-4982-903f-75c0a88a8215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620990318-172.17.0.21-1596875676196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37123,DS-34e2b6c5-b8f2-4568-873f-64c7198da3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-9bf38a01-761b-4825-9b76-b1ea4c92f12e,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-29c12b3f-a740-4da5-b172-d9139fe0df99,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-ce815ddd-4133-4e27-9281-963840e88a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-910cdcda-e848-4cd8-9d73-c904e598a60c,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-76a35a2e-beda-4694-8085-f90ef5ea8d20,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-2a70045b-40e2-408e-91e0-f6dce5b02cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-e9df8fb8-7239-4533-8d08-5107de39ee67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620990318-172.17.0.21-1596875676196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37123,DS-34e2b6c5-b8f2-4568-873f-64c7198da3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-9bf38a01-761b-4825-9b76-b1ea4c92f12e,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-29c12b3f-a740-4da5-b172-d9139fe0df99,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-ce815ddd-4133-4e27-9281-963840e88a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-910cdcda-e848-4cd8-9d73-c904e598a60c,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-76a35a2e-beda-4694-8085-f90ef5ea8d20,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-2a70045b-40e2-408e-91e0-f6dce5b02cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-e9df8fb8-7239-4533-8d08-5107de39ee67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155564618-172.17.0.21-1596875716091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-355d047e-0cba-4249-a18a-fecf1cc72fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-6e49e417-597b-4048-87ee-aef1764cab56,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-61f27130-c3f5-4b8d-961e-e5940cc698b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-171691f0-8587-4ed3-8686-8a35ba110823,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-32baccc8-d783-4bf7-a9f7-ed43d5cb19b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-01354be0-af9a-44cd-9df2-7ba8af024801,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-9738e34c-26ea-4f48-b5ca-20060d2169d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-71bc85bc-c7ab-41a5-b5b3-460b69329d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155564618-172.17.0.21-1596875716091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-355d047e-0cba-4249-a18a-fecf1cc72fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-6e49e417-597b-4048-87ee-aef1764cab56,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-61f27130-c3f5-4b8d-961e-e5940cc698b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-171691f0-8587-4ed3-8686-8a35ba110823,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-32baccc8-d783-4bf7-a9f7-ed43d5cb19b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-01354be0-af9a-44cd-9df2-7ba8af024801,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-9738e34c-26ea-4f48-b5ca-20060d2169d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-71bc85bc-c7ab-41a5-b5b3-460b69329d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092327613-172.17.0.21-1596876114368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-e832f43b-2ac5-4a36-8912-38513647a1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-e57ab4f7-8678-4936-a648-0e571ae67782,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-b9c49f54-53aa-458c-bcc4-1df6264c501a,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-946d3937-b6a0-4669-ac58-e249dcd2f9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-388ddb12-873d-4d0e-b43a-1f0b6ce33d63,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-09d0a88a-edba-45d9-b97b-97f75ebea062,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-39200c4c-ec36-4462-82f8-918481bae335,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-07ea8c5b-6e62-4ac5-a781-7d5797b22c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092327613-172.17.0.21-1596876114368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-e832f43b-2ac5-4a36-8912-38513647a1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-e57ab4f7-8678-4936-a648-0e571ae67782,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-b9c49f54-53aa-458c-bcc4-1df6264c501a,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-946d3937-b6a0-4669-ac58-e249dcd2f9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-388ddb12-873d-4d0e-b43a-1f0b6ce33d63,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-09d0a88a-edba-45d9-b97b-97f75ebea062,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-39200c4c-ec36-4462-82f8-918481bae335,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-07ea8c5b-6e62-4ac5-a781-7d5797b22c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107949699-172.17.0.21-1596876186278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-85fc17e2-84fe-4475-9256-e9b224df114c,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-bf60c4a1-46b8-4e35-82d1-80c86155b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-28c05c0e-e9a3-4972-b6c4-cf5b484818d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-2d11175b-cc36-4b73-b655-0b3d8b437fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-a3677dfb-aa16-46ff-8a8a-e071093d2dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-a1e098df-7e7e-45a2-a4a8-8921464f9797,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-c08f1fac-0d62-4631-8018-ce7b34f83b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-73f0c881-584c-4486-bde8-fcca73274aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107949699-172.17.0.21-1596876186278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-85fc17e2-84fe-4475-9256-e9b224df114c,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-bf60c4a1-46b8-4e35-82d1-80c86155b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-28c05c0e-e9a3-4972-b6c4-cf5b484818d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-2d11175b-cc36-4b73-b655-0b3d8b437fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-a3677dfb-aa16-46ff-8a8a-e071093d2dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-a1e098df-7e7e-45a2-a4a8-8921464f9797,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-c08f1fac-0d62-4631-8018-ce7b34f83b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-73f0c881-584c-4486-bde8-fcca73274aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307099901-172.17.0.21-1596876767066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-f204453f-7c12-4014-aaf5-d3d235df4cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-caa4645d-beff-460d-b9d9-ccf365024887,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-1ac6c7a2-4b66-4b32-8d2c-b31a323b1ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-8400faab-efc8-4e02-b9d7-153d0e5b0387,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-48113d71-39a7-4105-b471-bd7fd8e4602d,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-c13d53d2-a7ec-4c56-90df-a545af6b4767,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-a80fbd80-6c62-43e1-82e5-ddafdca09cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-8839ed38-d86a-4d92-ba4b-fd23f144fc3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307099901-172.17.0.21-1596876767066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-f204453f-7c12-4014-aaf5-d3d235df4cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-caa4645d-beff-460d-b9d9-ccf365024887,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-1ac6c7a2-4b66-4b32-8d2c-b31a323b1ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-8400faab-efc8-4e02-b9d7-153d0e5b0387,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-48113d71-39a7-4105-b471-bd7fd8e4602d,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-c13d53d2-a7ec-4c56-90df-a545af6b4767,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-a80fbd80-6c62-43e1-82e5-ddafdca09cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-8839ed38-d86a-4d92-ba4b-fd23f144fc3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680660399-172.17.0.21-1596877098086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-8b99f4d1-9cf5-426c-9bb7-c42723efdf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-168f88f0-2cfe-4b38-be00-42c371423a90,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-edc30599-469a-4811-a596-cf61dd66af15,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-173b17e9-ee12-4e1a-8a48-2b33f2164b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-865fd6c8-d786-44ae-9322-ea6aa0447c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-481cd383-10b4-4660-b04d-4ad3d49ec81e,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-327f5423-e263-4703-af44-d63d73d39351,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-9f6857cc-f4ae-4f5a-a284-536d0e890471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680660399-172.17.0.21-1596877098086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-8b99f4d1-9cf5-426c-9bb7-c42723efdf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-168f88f0-2cfe-4b38-be00-42c371423a90,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-edc30599-469a-4811-a596-cf61dd66af15,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-173b17e9-ee12-4e1a-8a48-2b33f2164b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-865fd6c8-d786-44ae-9322-ea6aa0447c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-481cd383-10b4-4660-b04d-4ad3d49ec81e,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-327f5423-e263-4703-af44-d63d73d39351,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-9f6857cc-f4ae-4f5a-a284-536d0e890471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91739589-172.17.0.21-1596877429567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39346,DS-148cc199-7195-4fe5-a0bb-012b53d18f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-37f7dfcf-1b4f-4063-a382-4343be5867d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-a7633f6e-53d0-4585-bddc-f404020fdbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-0c1894fd-2de3-411b-b3fd-3cbc39d82281,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-fce52d45-7557-43fe-b452-0f98b4bc2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-6b8e7445-93b8-4e3f-9ef9-e82a170877aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-39d1da9f-e485-466c-b83b-a8cd380fcc11,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-d9c05955-f17f-4f8f-b621-0beb0ca71da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91739589-172.17.0.21-1596877429567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39346,DS-148cc199-7195-4fe5-a0bb-012b53d18f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-37f7dfcf-1b4f-4063-a382-4343be5867d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-a7633f6e-53d0-4585-bddc-f404020fdbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-0c1894fd-2de3-411b-b3fd-3cbc39d82281,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-fce52d45-7557-43fe-b452-0f98b4bc2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-6b8e7445-93b8-4e3f-9ef9-e82a170877aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-39d1da9f-e485-466c-b83b-a8cd380fcc11,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-d9c05955-f17f-4f8f-b621-0beb0ca71da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853589865-172.17.0.21-1596878092790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40037,DS-3c8c3a0a-e4d6-421d-a4ab-ad7d9fd03db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-ae2de5cd-6aa7-4fce-b5c9-ed06a2913c93,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-fe00ea6a-2b6a-4a65-b72c-8b385d8ea978,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-8c77e11c-804c-4a20-ab12-76a9c387380d,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-4a61244e-baaf-406a-8b24-52496249f9db,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-e3a84d4a-b5be-42e2-a5fc-691e86f8fee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-3506a2d5-0a5e-4674-a609-2d34796c154e,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-604cdb3c-bf52-4c48-9d9d-092234c80f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853589865-172.17.0.21-1596878092790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40037,DS-3c8c3a0a-e4d6-421d-a4ab-ad7d9fd03db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-ae2de5cd-6aa7-4fce-b5c9-ed06a2913c93,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-fe00ea6a-2b6a-4a65-b72c-8b385d8ea978,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-8c77e11c-804c-4a20-ab12-76a9c387380d,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-4a61244e-baaf-406a-8b24-52496249f9db,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-e3a84d4a-b5be-42e2-a5fc-691e86f8fee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-3506a2d5-0a5e-4674-a609-2d34796c154e,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-604cdb3c-bf52-4c48-9d9d-092234c80f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15407963-172.17.0.21-1596878222022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-4379c42b-395a-4936-9478-d4a178cd92c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-2e6d289a-975b-4ab3-9f85-27b303d852df,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-bf00d85f-90c8-4d30-a8e2-6f89cefeb8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-e0be1f3b-d70c-4fa3-a2fe-4908934dde88,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-0954c3f4-64a9-43fd-8a77-0da2efad7541,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-43ce0e69-7c01-4c6c-b6f5-913aee28eccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-6ce24590-7ec4-4594-98e4-0d12ca0cc4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-a58e61e2-f6b6-4fc5-9108-cf30f282b5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15407963-172.17.0.21-1596878222022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-4379c42b-395a-4936-9478-d4a178cd92c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-2e6d289a-975b-4ab3-9f85-27b303d852df,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-bf00d85f-90c8-4d30-a8e2-6f89cefeb8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-e0be1f3b-d70c-4fa3-a2fe-4908934dde88,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-0954c3f4-64a9-43fd-8a77-0da2efad7541,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-43ce0e69-7c01-4c6c-b6f5-913aee28eccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-6ce24590-7ec4-4594-98e4-0d12ca0cc4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-a58e61e2-f6b6-4fc5-9108-cf30f282b5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996514125-172.17.0.21-1596878449088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46580,DS-90bfa75a-4775-44f7-a862-bc6b2f905087,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-5a040529-ef5e-4dd1-a3f6-975a755d4107,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-a7524f31-237c-437d-8cb7-aac252542994,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-53ffe203-0f40-494c-ae8e-75ad98b0afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-daf7aaee-ad54-4408-8b57-03b48f20398c,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-3b346f18-316a-4266-ab82-93f3aa7d8efe,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-9e77edee-6860-4cf9-8c96-e477db2c187d,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-a9788ed9-c387-4ca5-98f6-528cc0eaf507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996514125-172.17.0.21-1596878449088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46580,DS-90bfa75a-4775-44f7-a862-bc6b2f905087,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-5a040529-ef5e-4dd1-a3f6-975a755d4107,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-a7524f31-237c-437d-8cb7-aac252542994,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-53ffe203-0f40-494c-ae8e-75ad98b0afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-daf7aaee-ad54-4408-8b57-03b48f20398c,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-3b346f18-316a-4266-ab82-93f3aa7d8efe,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-9e77edee-6860-4cf9-8c96-e477db2c187d,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-a9788ed9-c387-4ca5-98f6-528cc0eaf507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535019213-172.17.0.21-1596878520863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-0e9492ed-67d7-4ddc-a0c2-b90fb42af67c,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-3165df78-6d60-4353-90cc-7c809dadaebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-df7c3403-62bd-4374-96da-44066585e9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-9336b32b-3c77-4c2f-bd8e-8f1b062a40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-6c6367f8-6532-4a94-b167-eee73dd49d62,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-cdee1f96-0cf8-4f4c-b428-bc36beb204df,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-c69ca873-b0a2-4a52-bfbb-cabd09c13340,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-1a6dda72-b236-44be-800b-33a1122dfa49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535019213-172.17.0.21-1596878520863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-0e9492ed-67d7-4ddc-a0c2-b90fb42af67c,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-3165df78-6d60-4353-90cc-7c809dadaebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-df7c3403-62bd-4374-96da-44066585e9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-9336b32b-3c77-4c2f-bd8e-8f1b062a40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-6c6367f8-6532-4a94-b167-eee73dd49d62,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-cdee1f96-0cf8-4f4c-b428-bc36beb204df,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-c69ca873-b0a2-4a52-bfbb-cabd09c13340,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-1a6dda72-b236-44be-800b-33a1122dfa49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015695220-172.17.0.21-1596878631837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-43fb6e5e-c2cf-4d03-85c5-c0cf1b9c43b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-e6fafd99-c6da-4eba-9bb8-036a06b85df8,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-5d2386c8-ca3a-4928-8b73-bfcd26e720f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-5bb33626-2f8c-4ac4-be3c-6e5afde06fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-ec15e55d-ec53-4f1c-af18-5e2acbbf5254,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-7eeff7e9-76ea-4e3f-9449-92640b263b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-efde65ff-f64c-4627-b36a-27185d262454,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-701a3b1a-b8f8-43be-addc-c2a1363ba4f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015695220-172.17.0.21-1596878631837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-43fb6e5e-c2cf-4d03-85c5-c0cf1b9c43b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-e6fafd99-c6da-4eba-9bb8-036a06b85df8,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-5d2386c8-ca3a-4928-8b73-bfcd26e720f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-5bb33626-2f8c-4ac4-be3c-6e5afde06fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-ec15e55d-ec53-4f1c-af18-5e2acbbf5254,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-7eeff7e9-76ea-4e3f-9449-92640b263b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-efde65ff-f64c-4627-b36a-27185d262454,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-701a3b1a-b8f8-43be-addc-c2a1363ba4f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908204217-172.17.0.21-1596879155218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-68701342-e73d-4c65-9f14-26552c5bc0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-c8837278-835d-4a12-82c1-d828aad34443,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-de78d3b6-a0df-4b8d-bb81-434130d99b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-8f2993d5-9d69-4b76-87b5-ddc20531926f,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-e8552390-1992-49ce-b3f0-3931a2e81eda,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-925becb0-b907-4662-b677-29342f479c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-d8392414-a732-40ab-adbc-061fbf9f6238,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-2e3ec46c-abb6-4225-9271-dfc1c192236e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908204217-172.17.0.21-1596879155218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-68701342-e73d-4c65-9f14-26552c5bc0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-c8837278-835d-4a12-82c1-d828aad34443,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-de78d3b6-a0df-4b8d-bb81-434130d99b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-8f2993d5-9d69-4b76-87b5-ddc20531926f,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-e8552390-1992-49ce-b3f0-3931a2e81eda,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-925becb0-b907-4662-b677-29342f479c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-d8392414-a732-40ab-adbc-061fbf9f6238,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-2e3ec46c-abb6-4225-9271-dfc1c192236e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5403
