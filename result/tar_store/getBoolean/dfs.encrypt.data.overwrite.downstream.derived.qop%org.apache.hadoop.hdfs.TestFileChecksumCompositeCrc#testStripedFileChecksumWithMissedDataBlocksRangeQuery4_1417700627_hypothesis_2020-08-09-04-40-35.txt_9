reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885435193-172.17.0.19-1596948124883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-49e15696-c017-4ac0-8bf4-05729d16a69a,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-d628a416-56a3-4011-9718-3f20db2ef7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-bfa2b58d-33c4-486c-84df-28622fb0c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-899368cf-2acf-4309-9051-f441cae5724e,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-e08bbc7f-476f-4374-abe4-0c6aae86ea44,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-c233d19e-3061-43b3-86b0-96ff5a026290,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-caad0389-0eb8-49dd-85f7-7a449b919205,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-7025a5ae-a271-46a2-87bc-135efdbfad53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885435193-172.17.0.19-1596948124883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-49e15696-c017-4ac0-8bf4-05729d16a69a,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-d628a416-56a3-4011-9718-3f20db2ef7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-bfa2b58d-33c4-486c-84df-28622fb0c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-899368cf-2acf-4309-9051-f441cae5724e,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-e08bbc7f-476f-4374-abe4-0c6aae86ea44,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-c233d19e-3061-43b3-86b0-96ff5a026290,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-caad0389-0eb8-49dd-85f7-7a449b919205,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-7025a5ae-a271-46a2-87bc-135efdbfad53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024430446-172.17.0.19-1596948819089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42877,DS-e2207996-b1e8-47d1-b9b2-36da80bcc4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-9e05704f-e6ab-4070-8251-87805ef411f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-8e335638-95ca-4a31-9d54-1b2f9cd7b0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-2903d6d6-15f4-4ce4-8b8e-a686be109cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-73682b32-38d4-4456-aaec-74aa3c6a2bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-a7bd0726-bad5-4698-b054-815bff9e1d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-0e907012-049c-4c1c-aae3-a5825a563b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-eb87a09e-cb78-4620-a330-339b1ecffe26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024430446-172.17.0.19-1596948819089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42877,DS-e2207996-b1e8-47d1-b9b2-36da80bcc4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-9e05704f-e6ab-4070-8251-87805ef411f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-8e335638-95ca-4a31-9d54-1b2f9cd7b0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-2903d6d6-15f4-4ce4-8b8e-a686be109cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-73682b32-38d4-4456-aaec-74aa3c6a2bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-a7bd0726-bad5-4698-b054-815bff9e1d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-0e907012-049c-4c1c-aae3-a5825a563b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-eb87a09e-cb78-4620-a330-339b1ecffe26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096546029-172.17.0.19-1596949407168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42904,DS-f0cebb00-fae9-4c98-98ba-012e2d778bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-735013e5-da7c-4544-a8a5-b176fb1da8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-e828adc4-b35d-49e6-a376-74e1e71e6928,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-0dfe9226-0cca-4c25-9d3f-79820ef5874d,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-effac94a-e328-4b33-beeb-6b9b878a3cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-e7cfd674-e465-4788-8277-d31cfafbd6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-ebedb892-1994-4716-b7a5-2b59861eb86b,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-1371d18c-a90f-470b-b253-a3d4e6f69a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096546029-172.17.0.19-1596949407168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42904,DS-f0cebb00-fae9-4c98-98ba-012e2d778bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-735013e5-da7c-4544-a8a5-b176fb1da8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-e828adc4-b35d-49e6-a376-74e1e71e6928,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-0dfe9226-0cca-4c25-9d3f-79820ef5874d,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-effac94a-e328-4b33-beeb-6b9b878a3cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-e7cfd674-e465-4788-8277-d31cfafbd6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-ebedb892-1994-4716-b7a5-2b59861eb86b,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-1371d18c-a90f-470b-b253-a3d4e6f69a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980770964-172.17.0.19-1596949738033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-b9852f87-f369-49a9-8025-f2f370e90ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-385629b8-f7c1-4950-a96f-d7f5d883711c,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-c78e777b-8929-453f-bda0-11b30808fc93,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-971fbff7-0cba-4824-9714-a626ed72d07a,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-16b42ab3-61fd-4961-8c92-48b81c430bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-60087380-53e1-4a64-a5dc-860b1d209539,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-6284527f-3af1-4d6b-a2d5-f161c3492c99,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-5ceefb5b-b690-414c-811c-99d37f7e722e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980770964-172.17.0.19-1596949738033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-b9852f87-f369-49a9-8025-f2f370e90ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-385629b8-f7c1-4950-a96f-d7f5d883711c,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-c78e777b-8929-453f-bda0-11b30808fc93,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-971fbff7-0cba-4824-9714-a626ed72d07a,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-16b42ab3-61fd-4961-8c92-48b81c430bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-60087380-53e1-4a64-a5dc-860b1d209539,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-6284527f-3af1-4d6b-a2d5-f161c3492c99,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-5ceefb5b-b690-414c-811c-99d37f7e722e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942310716-172.17.0.19-1596950117152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39387,DS-5ee5a517-172b-4e53-ac93-36299a61d562,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a6407935-e810-479c-b08c-56e800171523,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-2c77f070-afa5-4992-8491-802f410bf35d,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-13451647-d786-43dd-8915-16f0bf0378ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-f2687c59-3ca8-45e0-a9ce-0d705678b881,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-f82a5953-34f4-4d99-bb11-b3a53ca474ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-a873d87d-3c20-404b-8cf1-ecaaf718fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-01ddd6ff-b47d-470f-a914-cd13f27f6c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942310716-172.17.0.19-1596950117152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39387,DS-5ee5a517-172b-4e53-ac93-36299a61d562,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a6407935-e810-479c-b08c-56e800171523,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-2c77f070-afa5-4992-8491-802f410bf35d,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-13451647-d786-43dd-8915-16f0bf0378ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-f2687c59-3ca8-45e0-a9ce-0d705678b881,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-f82a5953-34f4-4d99-bb11-b3a53ca474ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-a873d87d-3c20-404b-8cf1-ecaaf718fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-01ddd6ff-b47d-470f-a914-cd13f27f6c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335190018-172.17.0.19-1596950286981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41950,DS-ec823ce1-1eed-4d16-90e4-539367d8526f,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-ed2a7b14-0da1-4b42-8d5f-76a08b65d6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-5936a2b2-65cf-45b8-935f-d7252a59bae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-a76f9394-c742-47b3-9906-efc9c2bf247e,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-c6a50472-1faa-4c58-adee-3455eda6cf59,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-208cf41b-83ff-44be-8d0e-ed16ba20da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-58cc1397-657c-4fd4-a7ec-62c8e7ea2dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-5e14e54b-d154-4af6-ad4e-6b52a6098a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335190018-172.17.0.19-1596950286981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41950,DS-ec823ce1-1eed-4d16-90e4-539367d8526f,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-ed2a7b14-0da1-4b42-8d5f-76a08b65d6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-5936a2b2-65cf-45b8-935f-d7252a59bae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-a76f9394-c742-47b3-9906-efc9c2bf247e,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-c6a50472-1faa-4c58-adee-3455eda6cf59,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-208cf41b-83ff-44be-8d0e-ed16ba20da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-58cc1397-657c-4fd4-a7ec-62c8e7ea2dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-5e14e54b-d154-4af6-ad4e-6b52a6098a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225582960-172.17.0.19-1596950437918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40590,DS-5dc7ed37-1505-469e-9d39-8744dd9b8238,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-78a6c6c2-2c99-481b-904e-4654e432611a,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-29492e69-d82c-4635-b5a2-e3d778eac55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-cafdb2f4-8ea7-4ec3-981c-6b8198be4590,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-bf6b5edc-6fc6-44d2-8fd7-b61408efc296,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-2d4129e0-9edd-442a-a026-e1a57bda3360,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-580eca43-1014-41b5-a64f-e4a587da6332,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-ae0b6533-fa9a-4f35-b42f-20573aaaac40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225582960-172.17.0.19-1596950437918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40590,DS-5dc7ed37-1505-469e-9d39-8744dd9b8238,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-78a6c6c2-2c99-481b-904e-4654e432611a,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-29492e69-d82c-4635-b5a2-e3d778eac55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-cafdb2f4-8ea7-4ec3-981c-6b8198be4590,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-bf6b5edc-6fc6-44d2-8fd7-b61408efc296,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-2d4129e0-9edd-442a-a026-e1a57bda3360,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-580eca43-1014-41b5-a64f-e4a587da6332,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-ae0b6533-fa9a-4f35-b42f-20573aaaac40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449127362-172.17.0.19-1596950628634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35100,DS-a2b731ab-aff3-4ef3-9b49-98714b904eda,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-99135e12-c3e4-482b-afd4-0500b4c869a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-0a107a4f-c820-480d-873f-5c7351294865,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-fe4c1415-4b34-48c3-9da0-671fc1bc1ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-a68672e0-3f16-4417-90d7-cee141768be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-2e7b40f5-09dc-4295-b237-2b1763207f06,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-a2551a43-988b-4402-a133-407665f55863,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-6a1dfd19-0ecf-4a63-aed0-e9ad774dde90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449127362-172.17.0.19-1596950628634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35100,DS-a2b731ab-aff3-4ef3-9b49-98714b904eda,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-99135e12-c3e4-482b-afd4-0500b4c869a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-0a107a4f-c820-480d-873f-5c7351294865,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-fe4c1415-4b34-48c3-9da0-671fc1bc1ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-a68672e0-3f16-4417-90d7-cee141768be2,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-2e7b40f5-09dc-4295-b237-2b1763207f06,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-a2551a43-988b-4402-a133-407665f55863,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-6a1dfd19-0ecf-4a63-aed0-e9ad774dde90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434722994-172.17.0.19-1596950740704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42971,DS-3da54c7f-aa91-4d85-b828-aff5bce90dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-7d9de4d2-d22f-4e24-9979-00f41f6d7799,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-c84c07ab-2574-4709-833b-1f0fbee68033,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-f287ac49-0214-4be9-8823-a77fdc0bad18,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-d21cc427-b91f-4e85-91ec-c6574c43ebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-e589c203-68d8-4e72-ae6b-200d87143230,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-84ac0d47-e78f-48cc-9741-256330b1471f,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-c6f8ad83-db43-4ff9-8109-ed27de91af6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434722994-172.17.0.19-1596950740704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42971,DS-3da54c7f-aa91-4d85-b828-aff5bce90dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-7d9de4d2-d22f-4e24-9979-00f41f6d7799,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-c84c07ab-2574-4709-833b-1f0fbee68033,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-f287ac49-0214-4be9-8823-a77fdc0bad18,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-d21cc427-b91f-4e85-91ec-c6574c43ebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-e589c203-68d8-4e72-ae6b-200d87143230,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-84ac0d47-e78f-48cc-9741-256330b1471f,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-c6f8ad83-db43-4ff9-8109-ed27de91af6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642733176-172.17.0.19-1596950893173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39679,DS-a87301fb-485e-4683-aef7-af3de516dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-135d895b-24ec-44ce-b6a6-55d17a0c1e77,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-59dc472f-6db9-43c9-9926-cdb9f822e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-faa66566-108f-4ff4-8110-440dfd234b74,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-440bb2d9-9b8d-4f6a-8506-870126260e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-f802c20b-d10d-42bf-8327-b9dddb12bb16,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-bd23ea79-1e6d-44e0-a2da-612c545b4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-99284894-ea34-428b-a8bc-0d2f574c17c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642733176-172.17.0.19-1596950893173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39679,DS-a87301fb-485e-4683-aef7-af3de516dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-135d895b-24ec-44ce-b6a6-55d17a0c1e77,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-59dc472f-6db9-43c9-9926-cdb9f822e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-faa66566-108f-4ff4-8110-440dfd234b74,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-440bb2d9-9b8d-4f6a-8506-870126260e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-f802c20b-d10d-42bf-8327-b9dddb12bb16,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-bd23ea79-1e6d-44e0-a2da-612c545b4d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-99284894-ea34-428b-a8bc-0d2f574c17c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093268961-172.17.0.19-1596951327705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39657,DS-9b44e238-c3d2-4078-9fca-12f2c2fc3b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-db2343a9-e689-44d3-a3e1-0a078445495f,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-b92f9239-0772-46f1-b7f0-d3d9bf56844f,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-a676dd8b-265c-4d8c-ac94-81cc33ce748d,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-c58d26fb-4e1f-4af4-b1ee-5c8974914cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-57e5cc93-b868-467e-b85d-bac69562ef42,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-b38cf514-305e-420f-a737-d3370c495f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-6a7b48fc-8ff9-4205-be5a-a30528128687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093268961-172.17.0.19-1596951327705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39657,DS-9b44e238-c3d2-4078-9fca-12f2c2fc3b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-db2343a9-e689-44d3-a3e1-0a078445495f,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-b92f9239-0772-46f1-b7f0-d3d9bf56844f,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-a676dd8b-265c-4d8c-ac94-81cc33ce748d,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-c58d26fb-4e1f-4af4-b1ee-5c8974914cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-57e5cc93-b868-467e-b85d-bac69562ef42,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-b38cf514-305e-420f-a737-d3370c495f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-6a7b48fc-8ff9-4205-be5a-a30528128687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188285377-172.17.0.19-1596951433529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-f9d52897-e3ed-4c20-801f-651a9940e160,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-abf2137b-9e97-411a-9326-da181bffdc64,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-ec108c7e-2b8e-4487-b001-242c810654fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-8292455d-2e7a-4a56-9933-c9b775edea60,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-1d0308b7-a5bd-4616-bf79-18b3ab550052,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-659eff13-17e6-43bf-9c30-c5c25da99af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-27f86c0b-2415-4960-9bc3-419031998706,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-4633d51b-910d-47db-bf7f-fe0bff679da5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188285377-172.17.0.19-1596951433529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-f9d52897-e3ed-4c20-801f-651a9940e160,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-abf2137b-9e97-411a-9326-da181bffdc64,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-ec108c7e-2b8e-4487-b001-242c810654fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-8292455d-2e7a-4a56-9933-c9b775edea60,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-1d0308b7-a5bd-4616-bf79-18b3ab550052,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-659eff13-17e6-43bf-9c30-c5c25da99af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-27f86c0b-2415-4960-9bc3-419031998706,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-4633d51b-910d-47db-bf7f-fe0bff679da5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416547591-172.17.0.19-1596951472039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38259,DS-5ed16810-6eed-4318-bbe1-7d200824ee82,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-1c8ecf16-ca17-46b2-8349-69c852122b67,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-b7b00887-0537-45cc-a7ae-2ac21f73541a,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-797a20a2-f983-4571-aa66-77ba9e20e174,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-8b43e088-f91e-4696-a040-f2a98bef4fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-56b2ae37-b563-4df5-bdcd-b68457df16b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-7ff3a72d-1832-4885-a062-7fbba5313c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-5169bc28-26af-4095-9799-cdb2fc30b8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416547591-172.17.0.19-1596951472039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38259,DS-5ed16810-6eed-4318-bbe1-7d200824ee82,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-1c8ecf16-ca17-46b2-8349-69c852122b67,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-b7b00887-0537-45cc-a7ae-2ac21f73541a,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-797a20a2-f983-4571-aa66-77ba9e20e174,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-8b43e088-f91e-4696-a040-f2a98bef4fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-56b2ae37-b563-4df5-bdcd-b68457df16b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-7ff3a72d-1832-4885-a062-7fbba5313c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-5169bc28-26af-4095-9799-cdb2fc30b8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105286552-172.17.0.19-1596951696784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42975,DS-6defe092-eb8e-4b31-837a-32382c5b0611,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-cc5215d4-cdf9-4856-bc63-d252bbdf15f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-588697f8-8aed-4863-9e7e-89d5a6b5450d,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-10a382b3-7c98-42fa-a232-8c0b37d41f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-067209f2-01a3-4213-98c0-cd96fbccaf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-430427f7-bd50-4c4b-8d45-45af8247d40f,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-ba513870-df41-4d7b-a6e6-f3ba3cc577a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-da4eee58-6f8f-4dd0-ae3b-64ae7ac89eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105286552-172.17.0.19-1596951696784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42975,DS-6defe092-eb8e-4b31-837a-32382c5b0611,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-cc5215d4-cdf9-4856-bc63-d252bbdf15f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-588697f8-8aed-4863-9e7e-89d5a6b5450d,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-10a382b3-7c98-42fa-a232-8c0b37d41f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-067209f2-01a3-4213-98c0-cd96fbccaf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-430427f7-bd50-4c4b-8d45-45af8247d40f,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-ba513870-df41-4d7b-a6e6-f3ba3cc577a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-da4eee58-6f8f-4dd0-ae3b-64ae7ac89eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242965737-172.17.0.19-1596952334735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-326c1063-fed0-4efd-a485-8a12df5c6f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-a118bd70-1c16-4b38-844e-5cacbd5cd6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-6d0009db-ebe5-4c06-9a3b-c4c1913b1555,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-900d5f2c-c832-4df1-b0d2-7e906c21e457,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-f61e90b8-7d56-4041-84b7-d63eef0090b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-2d472819-8e32-4cc2-954b-ac32a6b39073,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-1480af87-b99b-468d-96b8-c91dbea199d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-fc1beecb-6d63-4a5a-8cc8-75ae59b34033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242965737-172.17.0.19-1596952334735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-326c1063-fed0-4efd-a485-8a12df5c6f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-a118bd70-1c16-4b38-844e-5cacbd5cd6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-6d0009db-ebe5-4c06-9a3b-c4c1913b1555,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-900d5f2c-c832-4df1-b0d2-7e906c21e457,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-f61e90b8-7d56-4041-84b7-d63eef0090b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-2d472819-8e32-4cc2-954b-ac32a6b39073,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-1480af87-b99b-468d-96b8-c91dbea199d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-fc1beecb-6d63-4a5a-8cc8-75ae59b34033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107923317-172.17.0.19-1596952407154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-b35c0dc0-004a-473a-a6dd-39318b791ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-8dc9d667-0966-4e75-9d3f-0f57f0079da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-7f01b7b2-ad63-48e0-a568-0811e7b2c207,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-ec715135-3eb9-4e12-a770-2063d8219003,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-b602a2e8-53d7-4ea0-ad7b-da9a7d3d890b,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-f139760c-9696-4e2f-b0e7-02b65970a746,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-f900de46-c654-425e-8f07-df5aeb6abab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-bfb83f3e-555d-4b2d-820c-d42efdd1c4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107923317-172.17.0.19-1596952407154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-b35c0dc0-004a-473a-a6dd-39318b791ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-8dc9d667-0966-4e75-9d3f-0f57f0079da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-7f01b7b2-ad63-48e0-a568-0811e7b2c207,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-ec715135-3eb9-4e12-a770-2063d8219003,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-b602a2e8-53d7-4ea0-ad7b-da9a7d3d890b,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-f139760c-9696-4e2f-b0e7-02b65970a746,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-f900de46-c654-425e-8f07-df5aeb6abab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-bfb83f3e-555d-4b2d-820c-d42efdd1c4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222591442-172.17.0.19-1596952820415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34084,DS-c18a2ee1-73c8-4296-b14d-a228b93c6f80,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-ab4cbc5b-6601-4f59-85e7-8127f4375db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-5b3e8f5a-8338-4621-b88b-3db444edfec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-76467338-33de-488f-915e-7250d1af4844,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-82c90a6e-ed77-4410-9e84-2fcecf363e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-b6523705-349d-4fff-81bc-b2142924159d,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-328b5594-fb4c-4c36-ae78-41c7f83fa10f,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-4ec88384-8cb0-4c0c-90d5-dfeb03c2daf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222591442-172.17.0.19-1596952820415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34084,DS-c18a2ee1-73c8-4296-b14d-a228b93c6f80,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-ab4cbc5b-6601-4f59-85e7-8127f4375db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-5b3e8f5a-8338-4621-b88b-3db444edfec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-76467338-33de-488f-915e-7250d1af4844,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-82c90a6e-ed77-4410-9e84-2fcecf363e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-b6523705-349d-4fff-81bc-b2142924159d,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-328b5594-fb4c-4c36-ae78-41c7f83fa10f,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-4ec88384-8cb0-4c0c-90d5-dfeb03c2daf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459691916-172.17.0.19-1596952886861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-8d68e2d2-2f69-4e21-9c26-5f5c674956f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-9661c5c1-498d-4d34-a099-e3015f8e2606,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-3252a646-7232-4cdc-83cc-10da01ea5d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-825ba706-8149-425b-b70a-bf28cc8932f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-e7cbcac8-4e20-4f9e-929b-1e75867cba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-fa5bf3be-6118-4bb6-9fae-8d1149ec5d24,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-370c1f60-a6bc-4096-bbd2-a13b032c2c66,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-1cb6a701-8cec-4edb-949a-b3828ba1a0e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459691916-172.17.0.19-1596952886861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-8d68e2d2-2f69-4e21-9c26-5f5c674956f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-9661c5c1-498d-4d34-a099-e3015f8e2606,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-3252a646-7232-4cdc-83cc-10da01ea5d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-825ba706-8149-425b-b70a-bf28cc8932f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-e7cbcac8-4e20-4f9e-929b-1e75867cba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-fa5bf3be-6118-4bb6-9fae-8d1149ec5d24,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-370c1f60-a6bc-4096-bbd2-a13b032c2c66,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-1cb6a701-8cec-4edb-949a-b3828ba1a0e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464797827-172.17.0.19-1596953154021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-de4cbf58-fd9c-43a9-8baf-b3303e71d7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a76d3fde-d219-4156-9307-1fd7f77f3a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-6902da4f-3efa-4d4e-878b-40fff75d0ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-def76baa-df06-43c8-8b4a-98fcd0b3d465,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-244eaede-99e3-4417-9403-76e858481969,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-682bd806-a279-42ee-a4e6-a17e24c2fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-3fa8eaf2-529a-4e48-a5cf-88aea4333dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-d5e247a2-b9d3-4dfb-9bbb-67e4ea0872a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464797827-172.17.0.19-1596953154021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-de4cbf58-fd9c-43a9-8baf-b3303e71d7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a76d3fde-d219-4156-9307-1fd7f77f3a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-6902da4f-3efa-4d4e-878b-40fff75d0ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-def76baa-df06-43c8-8b4a-98fcd0b3d465,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-244eaede-99e3-4417-9403-76e858481969,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-682bd806-a279-42ee-a4e6-a17e24c2fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-3fa8eaf2-529a-4e48-a5cf-88aea4333dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-d5e247a2-b9d3-4dfb-9bbb-67e4ea0872a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093813000-172.17.0.19-1596953226301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-67988489-06a7-42d4-a17c-a5437db64a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-6a333565-6625-43f6-bea8-ab1d932e8758,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-c1ad3b0a-957f-41ac-aac1-ef0336524e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-ec51765a-1313-49d9-ae9d-1d9717028be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-f7c10337-326a-40b4-b314-1fce30a9d214,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-021e614e-f44b-4541-8be0-720aaae85190,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-b48aa553-f89a-45bc-87bd-e1acfd703c31,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-c0e3bc7e-dc5f-4171-be95-01e8d30e1bea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093813000-172.17.0.19-1596953226301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-67988489-06a7-42d4-a17c-a5437db64a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-6a333565-6625-43f6-bea8-ab1d932e8758,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-c1ad3b0a-957f-41ac-aac1-ef0336524e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-ec51765a-1313-49d9-ae9d-1d9717028be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-f7c10337-326a-40b4-b314-1fce30a9d214,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-021e614e-f44b-4541-8be0-720aaae85190,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-b48aa553-f89a-45bc-87bd-e1acfd703c31,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-c0e3bc7e-dc5f-4171-be95-01e8d30e1bea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5488
