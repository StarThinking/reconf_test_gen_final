reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32091836-172.17.0.6-1596866604019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46204,DS-9ca61bad-e74a-4038-9436-def0eaeab58d,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-16b8c6ab-c0a7-4480-86b2-80178c707fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-4ff303a9-a4f7-418c-8e7a-99dcc8b5aad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-d9b71d4b-f2e6-43f3-8a1e-9206d821cf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-e1581864-67d0-4d39-8335-2d22dd203db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-30b0855c-647b-4cb5-a77c-835b8ac0dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-0ed0c510-e62f-4e42-98f9-d78155160e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-f855cb3e-bdd6-4e21-813f-ffd28146c72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32091836-172.17.0.6-1596866604019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46204,DS-9ca61bad-e74a-4038-9436-def0eaeab58d,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-16b8c6ab-c0a7-4480-86b2-80178c707fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-4ff303a9-a4f7-418c-8e7a-99dcc8b5aad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-d9b71d4b-f2e6-43f3-8a1e-9206d821cf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-e1581864-67d0-4d39-8335-2d22dd203db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-30b0855c-647b-4cb5-a77c-835b8ac0dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-0ed0c510-e62f-4e42-98f9-d78155160e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-f855cb3e-bdd6-4e21-813f-ffd28146c72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709555138-172.17.0.6-1596866753513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-8f76ca49-28c8-4e55-bf35-5e1e2fd754b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-36b5a988-8667-420d-a5bc-810acab28d81,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-fd267ef7-a84a-4a99-9640-655a7b17c1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-c9464d9e-332c-45b0-830f-a2613e1d05af,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-db967ee9-57f8-4c50-b92a-b4d1c2a0a24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-7e94677e-0870-4d65-b7db-2c92c140c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-8eab96f3-4431-4ab9-b076-830c5cc98ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-81c5e1fb-d7c3-4259-8474-5d2b2d53b45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709555138-172.17.0.6-1596866753513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-8f76ca49-28c8-4e55-bf35-5e1e2fd754b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-36b5a988-8667-420d-a5bc-810acab28d81,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-fd267ef7-a84a-4a99-9640-655a7b17c1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-c9464d9e-332c-45b0-830f-a2613e1d05af,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-db967ee9-57f8-4c50-b92a-b4d1c2a0a24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-7e94677e-0870-4d65-b7db-2c92c140c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-8eab96f3-4431-4ab9-b076-830c5cc98ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-81c5e1fb-d7c3-4259-8474-5d2b2d53b45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580275598-172.17.0.6-1596867107467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-e687f2f1-0d80-4cb8-9e3b-2f9fef3e33e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-214a7d2b-3f9c-49a3-a906-0e8f0d8af8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-6e2ddeaa-f0d6-4f35-ba73-5bfe07ac41ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-4601dd87-2263-42ba-8c19-4c2c01aabada,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-bf0f1012-3553-4109-9789-f71b17ed9395,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-be82b222-b9a7-41a9-b6b7-27f9748458d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-7d034180-7a7b-46cb-859f-2bc4dd8c6698,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-0ef030e1-489c-4d43-b780-67efab1fbfce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580275598-172.17.0.6-1596867107467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-e687f2f1-0d80-4cb8-9e3b-2f9fef3e33e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-214a7d2b-3f9c-49a3-a906-0e8f0d8af8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-6e2ddeaa-f0d6-4f35-ba73-5bfe07ac41ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-4601dd87-2263-42ba-8c19-4c2c01aabada,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-bf0f1012-3553-4109-9789-f71b17ed9395,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-be82b222-b9a7-41a9-b6b7-27f9748458d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-7d034180-7a7b-46cb-859f-2bc4dd8c6698,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-0ef030e1-489c-4d43-b780-67efab1fbfce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185139970-172.17.0.6-1596867263273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-f545c6da-9744-4e84-8618-65ae3e8126bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-b09e52f0-fa59-45c9-8794-a2d2be10293d,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-8026460c-a234-4a13-8cd3-f0d172689a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-41286757-c8c1-4d68-b147-81ae89584498,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-a5d7e788-844d-4a54-b659-55742952ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-ca379dc4-5bc4-4060-a1cb-7825f1d8d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-08f090bd-a8ae-443c-b05c-c51a7460685e,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-d19c3fd0-1649-466d-a37c-ba0dd95dd46b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185139970-172.17.0.6-1596867263273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-f545c6da-9744-4e84-8618-65ae3e8126bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-b09e52f0-fa59-45c9-8794-a2d2be10293d,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-8026460c-a234-4a13-8cd3-f0d172689a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-41286757-c8c1-4d68-b147-81ae89584498,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-a5d7e788-844d-4a54-b659-55742952ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-ca379dc4-5bc4-4060-a1cb-7825f1d8d9df,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-08f090bd-a8ae-443c-b05c-c51a7460685e,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-d19c3fd0-1649-466d-a37c-ba0dd95dd46b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648550336-172.17.0.6-1596867454004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-a1a7519c-464f-4702-9d11-17da27f17232,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-4a2da120-da7c-4575-97b2-3091f400adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-43784dcb-b2f5-4ca3-88aa-fc8f2220bff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-0dde0ca8-6250-41e8-8650-40060ca1587c,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-90a5cd9a-3ca2-4087-8a67-cdb0fb856bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-94c2f6b7-26d9-421e-bf85-bcafb3a6b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-114bfb2f-f82b-42eb-aaf9-1f51aede8b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-7db66b45-3f30-4fdc-9735-ffea85aec5bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648550336-172.17.0.6-1596867454004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-a1a7519c-464f-4702-9d11-17da27f17232,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-4a2da120-da7c-4575-97b2-3091f400adb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-43784dcb-b2f5-4ca3-88aa-fc8f2220bff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-0dde0ca8-6250-41e8-8650-40060ca1587c,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-90a5cd9a-3ca2-4087-8a67-cdb0fb856bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-94c2f6b7-26d9-421e-bf85-bcafb3a6b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-114bfb2f-f82b-42eb-aaf9-1f51aede8b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-7db66b45-3f30-4fdc-9735-ffea85aec5bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281100550-172.17.0.6-1596867524191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45895,DS-7e4ed0e8-824e-435a-950e-7da1a4d8d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-5c052e17-66b2-4d72-acdd-c84461039405,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-620f22ed-9bfb-4b71-a74c-2d2f758535fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-09bf9a28-50a4-48f8-8f37-0c26b7ccaf11,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-5611725f-0253-479d-8326-a9c153e41d14,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-b55c4fbf-7d72-4cc0-a22f-9997e8c57770,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-bf357999-6bbe-4461-9d00-c20410e16784,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-3922a897-2dea-4511-9990-2141cc71a603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281100550-172.17.0.6-1596867524191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45895,DS-7e4ed0e8-824e-435a-950e-7da1a4d8d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-5c052e17-66b2-4d72-acdd-c84461039405,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-620f22ed-9bfb-4b71-a74c-2d2f758535fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-09bf9a28-50a4-48f8-8f37-0c26b7ccaf11,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-5611725f-0253-479d-8326-a9c153e41d14,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-b55c4fbf-7d72-4cc0-a22f-9997e8c57770,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-bf357999-6bbe-4461-9d00-c20410e16784,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-3922a897-2dea-4511-9990-2141cc71a603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031741085-172.17.0.6-1596867670412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-38c5e341-59c3-43a5-a0ee-714a0e87c03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-bf4b2f7d-b5e1-4628-84fc-5182997e81e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-299e8803-a41b-49f0-915e-9d67c3f4e00b,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-cdebcce2-a6ef-4742-a233-821261485914,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-c6492707-23a1-4d8f-b5ad-8a38dec2b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-812c78ba-0971-44b7-b3b5-663e13f3677f,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-e0302494-a8eb-4619-a779-0ba639757e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-db4570e8-9511-4be6-8391-a49b1bd2bcc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031741085-172.17.0.6-1596867670412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-38c5e341-59c3-43a5-a0ee-714a0e87c03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-bf4b2f7d-b5e1-4628-84fc-5182997e81e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-299e8803-a41b-49f0-915e-9d67c3f4e00b,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-cdebcce2-a6ef-4742-a233-821261485914,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-c6492707-23a1-4d8f-b5ad-8a38dec2b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-812c78ba-0971-44b7-b3b5-663e13f3677f,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-e0302494-a8eb-4619-a779-0ba639757e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-db4570e8-9511-4be6-8391-a49b1bd2bcc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619762679-172.17.0.6-1596867713386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45343,DS-f8889ba8-e2da-4bb0-9063-8277f2b5af9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-6d3fec47-021a-4134-82d0-a223ff47149c,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-0ef92440-ee4d-4b4e-899c-b5cc1152a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-e79d6471-1a3d-4964-8c5c-4cc655502c66,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-2b329d09-8a20-4a64-a804-54aac4b4582a,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-e207d2d1-bbda-41a2-857b-3a7d30ae3992,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-dd35d20c-1549-4a3a-9483-ff4081735c36,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-c5556adc-a9d7-4608-a0c0-07c5677c2a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619762679-172.17.0.6-1596867713386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45343,DS-f8889ba8-e2da-4bb0-9063-8277f2b5af9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-6d3fec47-021a-4134-82d0-a223ff47149c,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-0ef92440-ee4d-4b4e-899c-b5cc1152a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-e79d6471-1a3d-4964-8c5c-4cc655502c66,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-2b329d09-8a20-4a64-a804-54aac4b4582a,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-e207d2d1-bbda-41a2-857b-3a7d30ae3992,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-dd35d20c-1549-4a3a-9483-ff4081735c36,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-c5556adc-a9d7-4608-a0c0-07c5677c2a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68513659-172.17.0.6-1596867867492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36206,DS-901b4f3a-3a30-43fa-9f95-8efbe7f3db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-09a24238-a5ff-436b-83ca-6130d17664eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-dcfd355b-78b0-401a-824a-2b387c7115a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-ebf52c5c-b541-4bfa-8f53-177700fc15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-c307458b-993d-46ec-88b5-28be0e80f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-08942c05-8abd-44e8-bbcc-ba3ab533998f,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-f1ada3e8-2e73-435c-991d-2928c9d939cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-776ac899-d22f-461b-9fbc-817f96238311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68513659-172.17.0.6-1596867867492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36206,DS-901b4f3a-3a30-43fa-9f95-8efbe7f3db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-09a24238-a5ff-436b-83ca-6130d17664eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-dcfd355b-78b0-401a-824a-2b387c7115a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-ebf52c5c-b541-4bfa-8f53-177700fc15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-c307458b-993d-46ec-88b5-28be0e80f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-08942c05-8abd-44e8-bbcc-ba3ab533998f,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-f1ada3e8-2e73-435c-991d-2928c9d939cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-776ac899-d22f-461b-9fbc-817f96238311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144412848-172.17.0.6-1596867947218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-5d209f7c-d787-4e9a-ba6b-b6588268582b,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-436a6fb9-8742-4867-911d-aeb189404d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-9762617d-c12d-4c2c-8354-84d60c5068a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-77493097-435f-4826-b138-f50956a2697b,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-45b2847c-82c6-4912-87e3-c8f58466a720,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-01ba5196-f3b3-43bd-8303-6a3d42e51edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-4fff14c8-aded-462c-9da7-75c49939ade1,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-138e9a22-2af4-46ac-971f-c74f2512ced6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144412848-172.17.0.6-1596867947218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-5d209f7c-d787-4e9a-ba6b-b6588268582b,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-436a6fb9-8742-4867-911d-aeb189404d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-9762617d-c12d-4c2c-8354-84d60c5068a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-77493097-435f-4826-b138-f50956a2697b,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-45b2847c-82c6-4912-87e3-c8f58466a720,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-01ba5196-f3b3-43bd-8303-6a3d42e51edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-4fff14c8-aded-462c-9da7-75c49939ade1,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-138e9a22-2af4-46ac-971f-c74f2512ced6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738862321-172.17.0.6-1596868390051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39403,DS-7bdb1e5a-25e6-4382-a9c8-cb0ef0c2edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-53256be2-6f5d-402a-b4ca-b24ff0d07840,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-d6738b39-56c1-4bd8-9507-0f96cd28fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-350fb7ab-aea3-4ab1-9427-5b33511fb23f,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-6e8d70cc-8aa6-4d24-8b20-d77bc24c176f,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-bd9a159c-f6b6-41ff-8e9b-ce87583330be,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-548f88c0-a0cc-4fef-b94e-e5494b6c26c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-679a53bb-c244-4f02-8959-9677b157dc9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738862321-172.17.0.6-1596868390051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39403,DS-7bdb1e5a-25e6-4382-a9c8-cb0ef0c2edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-53256be2-6f5d-402a-b4ca-b24ff0d07840,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-d6738b39-56c1-4bd8-9507-0f96cd28fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-350fb7ab-aea3-4ab1-9427-5b33511fb23f,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-6e8d70cc-8aa6-4d24-8b20-d77bc24c176f,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-bd9a159c-f6b6-41ff-8e9b-ce87583330be,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-548f88c0-a0cc-4fef-b94e-e5494b6c26c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-679a53bb-c244-4f02-8959-9677b157dc9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665561485-172.17.0.6-1596868433135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-c26732ab-5c9e-4560-8578-261e2d12b385,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-3233a933-b14e-4644-b400-5a1297492654,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-7db5de20-2dde-439c-b751-8c1b5d7b45a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-78ec7926-f85f-4a22-9fe1-610a6d040a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-18c2e066-a366-4991-99f7-7476e1bed536,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-b2812b7d-c479-461d-9194-2426ff6c1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-13b54c45-f753-41a7-86e0-6a0bd377f38e,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-a2da49c6-7ca7-4f75-8a26-54cab9468adc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665561485-172.17.0.6-1596868433135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-c26732ab-5c9e-4560-8578-261e2d12b385,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-3233a933-b14e-4644-b400-5a1297492654,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-7db5de20-2dde-439c-b751-8c1b5d7b45a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-78ec7926-f85f-4a22-9fe1-610a6d040a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-18c2e066-a366-4991-99f7-7476e1bed536,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-b2812b7d-c479-461d-9194-2426ff6c1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-13b54c45-f753-41a7-86e0-6a0bd377f38e,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-a2da49c6-7ca7-4f75-8a26-54cab9468adc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170835983-172.17.0.6-1596868626223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-d31ef984-2078-455b-96cd-004aab1e2a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-cdc6d401-5d45-42f9-a892-4ab142ddacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-82eb9d44-9428-4ad6-91b4-e1548bc5ba16,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-5cb2fdd7-eee2-4f06-8230-9786c4a0dc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-85d02d78-a996-4257-b352-a23d191a6c07,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-15044267-e83e-4f2d-bcb1-95b168b2c448,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-cdbfb749-4b8b-43c5-b6ed-ce35cfffcb44,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-26ca40c3-15f8-4097-8851-a834445e21a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170835983-172.17.0.6-1596868626223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-d31ef984-2078-455b-96cd-004aab1e2a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-cdc6d401-5d45-42f9-a892-4ab142ddacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-82eb9d44-9428-4ad6-91b4-e1548bc5ba16,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-5cb2fdd7-eee2-4f06-8230-9786c4a0dc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-85d02d78-a996-4257-b352-a23d191a6c07,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-15044267-e83e-4f2d-bcb1-95b168b2c448,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-cdbfb749-4b8b-43c5-b6ed-ce35cfffcb44,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-26ca40c3-15f8-4097-8851-a834445e21a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108662694-172.17.0.6-1596868697677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-544bb783-124f-4e76-801d-7af736817f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-129e4474-9654-438b-a4f2-f154c558d4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-a7c96533-7df0-4b8f-a551-a22b7e07bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-1f6d28db-d2eb-48b5-adc1-de48faafa724,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-7e95f5fd-dbd3-43b1-93c6-c3d3e19b7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-f1da1a83-b3e1-4864-b5c1-9afcb8f92f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-90cea068-f894-4e38-84d4-04172861e30e,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-42645e3b-26ae-4086-bd32-7b0502773d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108662694-172.17.0.6-1596868697677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-544bb783-124f-4e76-801d-7af736817f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-129e4474-9654-438b-a4f2-f154c558d4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-a7c96533-7df0-4b8f-a551-a22b7e07bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-1f6d28db-d2eb-48b5-adc1-de48faafa724,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-7e95f5fd-dbd3-43b1-93c6-c3d3e19b7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-f1da1a83-b3e1-4864-b5c1-9afcb8f92f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-90cea068-f894-4e38-84d4-04172861e30e,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-42645e3b-26ae-4086-bd32-7b0502773d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424593769-172.17.0.6-1596868780277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32939,DS-2855f8e7-70ae-4fa0-893f-f51c435969a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-65acaa76-e1be-4b0d-ba36-13bc5a3aafe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-916c37e7-c5fc-4b00-a06f-5a36b832ae3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-b7b14f04-1182-4cd3-82cf-e8ba8525b885,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-c82c2a6e-d1db-4612-894b-c77d7683f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-8c685afe-1152-49be-afa4-90dd0d041bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-e544f32e-9bca-4b3a-bc8e-f28c7d4dbc11,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-61ebabd3-5c7f-4780-9293-52ec0ae1c453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424593769-172.17.0.6-1596868780277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32939,DS-2855f8e7-70ae-4fa0-893f-f51c435969a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-65acaa76-e1be-4b0d-ba36-13bc5a3aafe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-916c37e7-c5fc-4b00-a06f-5a36b832ae3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-b7b14f04-1182-4cd3-82cf-e8ba8525b885,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-c82c2a6e-d1db-4612-894b-c77d7683f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-8c685afe-1152-49be-afa4-90dd0d041bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-e544f32e-9bca-4b3a-bc8e-f28c7d4dbc11,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-61ebabd3-5c7f-4780-9293-52ec0ae1c453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526548463-172.17.0.6-1596869153196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43132,DS-68ac6a3b-c15e-40a6-aaea-59c8eac4d2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-e4b106ff-f9ea-4733-b1ba-684501910552,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-832fd894-ac83-40e5-ae4d-03b3fd145d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-a267751e-baff-40bc-a77b-a492af36fd83,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-bf246552-e777-4ca4-828f-1d59cd720855,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-7b0c6655-4bbe-4c3b-bb36-01238021ab99,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-4098b8b1-35cb-403e-b491-709173e5dc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-5c6e2c01-779a-4869-a2f0-f239b09b2fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526548463-172.17.0.6-1596869153196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43132,DS-68ac6a3b-c15e-40a6-aaea-59c8eac4d2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-e4b106ff-f9ea-4733-b1ba-684501910552,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-832fd894-ac83-40e5-ae4d-03b3fd145d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-a267751e-baff-40bc-a77b-a492af36fd83,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-bf246552-e777-4ca4-828f-1d59cd720855,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-7b0c6655-4bbe-4c3b-bb36-01238021ab99,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-4098b8b1-35cb-403e-b491-709173e5dc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-5c6e2c01-779a-4869-a2f0-f239b09b2fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668598921-172.17.0.6-1596869324514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42838,DS-7fc5f5ff-b6a5-4ab5-806a-a7f7ac32ba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-8117f439-bd4c-49e3-a41c-92f4beeef68a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-73a0b468-c886-48ec-90ee-6a66aff93bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-8976abe5-5049-4a55-b390-8caa8e4e7ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-1472b15d-b632-4492-8ba2-44012f9bf211,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-63ba046c-50f3-4523-baae-d3407f9b548e,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b287f503-7cfe-4715-898f-51cb565f590d,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-b42e8334-f014-4142-9a7d-caedeb661d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668598921-172.17.0.6-1596869324514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42838,DS-7fc5f5ff-b6a5-4ab5-806a-a7f7ac32ba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-8117f439-bd4c-49e3-a41c-92f4beeef68a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-73a0b468-c886-48ec-90ee-6a66aff93bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-8976abe5-5049-4a55-b390-8caa8e4e7ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-1472b15d-b632-4492-8ba2-44012f9bf211,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-63ba046c-50f3-4523-baae-d3407f9b548e,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b287f503-7cfe-4715-898f-51cb565f590d,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-b42e8334-f014-4142-9a7d-caedeb661d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076871932-172.17.0.6-1596869597799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-94b7439d-6b0b-4cf3-a518-a60ccb579018,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-876d56df-fbb5-4f27-b5d9-ec8b6ce26294,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-d2fd44e8-0a93-4fd1-b7e8-17b683fd566e,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-b90594e8-8f11-4518-8789-8f6279018658,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-d47e2ef1-2310-4571-b89d-f22a99958592,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-384c1fbf-5cad-4f4b-9e8e-91141c8d2e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-4c9e334d-5151-4da4-b9ec-f3c501594476,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-932bd9d8-59fe-4c7e-b809-593654eb9ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076871932-172.17.0.6-1596869597799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-94b7439d-6b0b-4cf3-a518-a60ccb579018,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-876d56df-fbb5-4f27-b5d9-ec8b6ce26294,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-d2fd44e8-0a93-4fd1-b7e8-17b683fd566e,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-b90594e8-8f11-4518-8789-8f6279018658,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-d47e2ef1-2310-4571-b89d-f22a99958592,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-384c1fbf-5cad-4f4b-9e8e-91141c8d2e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-4c9e334d-5151-4da4-b9ec-f3c501594476,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-932bd9d8-59fe-4c7e-b809-593654eb9ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133360441-172.17.0.6-1596869725011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34431,DS-e2715dda-14f8-45bd-a665-6f776cc77db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-89701bf0-9c25-4332-a4c5-b31358f6f6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-0edae97e-49c8-4a39-befe-2637f79a5426,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-eea3a34e-86cf-4a8c-a150-ed691216af11,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-290daf66-03e7-43d0-8373-6c041073a234,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-9e028725-b141-47c2-9d8d-7cb643862099,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-c478d8d2-2041-4a21-abb2-9aca9e286a56,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-2922650e-7a2f-4fbd-8d73-4ec91bd17012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133360441-172.17.0.6-1596869725011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34431,DS-e2715dda-14f8-45bd-a665-6f776cc77db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-89701bf0-9c25-4332-a4c5-b31358f6f6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-0edae97e-49c8-4a39-befe-2637f79a5426,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-eea3a34e-86cf-4a8c-a150-ed691216af11,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-290daf66-03e7-43d0-8373-6c041073a234,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-9e028725-b141-47c2-9d8d-7cb643862099,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-c478d8d2-2041-4a21-abb2-9aca9e286a56,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-2922650e-7a2f-4fbd-8d73-4ec91bd17012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969746267-172.17.0.6-1596870004219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34502,DS-7e979c75-1bc4-479a-8d49-8ca563f11706,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-e4af8d0a-956a-4846-9e24-c4879572e504,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-c8c3490a-0edf-4f67-8a05-09b83707bbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-ac422a02-38c0-4337-bab7-fdeef84cc930,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-a8d66348-0630-49f8-842b-5bb07a48cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-db0ab497-5124-4895-9fc4-de193910f785,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-d251db4a-fc8d-494f-b2cd-8813ce9e0db3,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-726025b5-85ae-49fb-a58f-c9900e97fd21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969746267-172.17.0.6-1596870004219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34502,DS-7e979c75-1bc4-479a-8d49-8ca563f11706,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-e4af8d0a-956a-4846-9e24-c4879572e504,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-c8c3490a-0edf-4f67-8a05-09b83707bbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-ac422a02-38c0-4337-bab7-fdeef84cc930,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-a8d66348-0630-49f8-842b-5bb07a48cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-db0ab497-5124-4895-9fc4-de193910f785,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-d251db4a-fc8d-494f-b2cd-8813ce9e0db3,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-726025b5-85ae-49fb-a58f-c9900e97fd21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861104187-172.17.0.6-1596870151698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34452,DS-f72a7638-10e8-4fc9-aa1d-7efecb55c981,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-69579d54-cf3f-4c05-881c-5019af697662,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-ebd176ee-5a77-4224-a16a-bf539994da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-4141706f-02a4-4e50-ac79-abd09f054398,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-c15d2fac-a552-42e8-8f83-74e40e5be5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-660ef7bb-8140-4b5f-a829-551344e10819,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-1bc47671-aa89-4b86-980c-9b030420ed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-c8eda98a-5c72-4376-9662-37df883191fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861104187-172.17.0.6-1596870151698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34452,DS-f72a7638-10e8-4fc9-aa1d-7efecb55c981,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-69579d54-cf3f-4c05-881c-5019af697662,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-ebd176ee-5a77-4224-a16a-bf539994da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-4141706f-02a4-4e50-ac79-abd09f054398,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-c15d2fac-a552-42e8-8f83-74e40e5be5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-660ef7bb-8140-4b5f-a829-551344e10819,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-1bc47671-aa89-4b86-980c-9b030420ed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-c8eda98a-5c72-4376-9662-37df883191fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887387557-172.17.0.6-1596870667970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34173,DS-a7f4cf3f-bf48-436a-95df-4e71fcd9d8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-f2553b3f-e08f-4554-8ad8-3862bfb483bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-96d1fd6f-22d3-4f02-b2f1-ce25b1fa4a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-ad3045a2-fbbb-4000-80fd-e5aa87437b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-fbe3db29-5c9c-4525-8766-e741360079ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-19ecb267-7615-448b-95b9-8a7a8a5c8ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-04f7fec5-4120-48cf-962e-a8a7a02ee1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-1889ef2f-d46d-4b32-9a2b-57dffccbb441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887387557-172.17.0.6-1596870667970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34173,DS-a7f4cf3f-bf48-436a-95df-4e71fcd9d8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-f2553b3f-e08f-4554-8ad8-3862bfb483bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-96d1fd6f-22d3-4f02-b2f1-ce25b1fa4a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-ad3045a2-fbbb-4000-80fd-e5aa87437b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-fbe3db29-5c9c-4525-8766-e741360079ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-19ecb267-7615-448b-95b9-8a7a8a5c8ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-04f7fec5-4120-48cf-962e-a8a7a02ee1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-1889ef2f-d46d-4b32-9a2b-57dffccbb441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375979026-172.17.0.6-1596870865048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-13e7c02b-c3bf-4480-8898-658a60838d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-d144212f-dcdb-4618-b112-ff66bcc149a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-f7c738c3-5055-4fa7-9c28-c13e1f8c85e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-03dcf3ec-63df-4e9b-9ac2-be73a083d968,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-123be975-221d-411e-be24-ff203948bf92,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-dbca4a4a-c293-4334-91ff-05651dc29302,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-46c1a646-5db3-4774-88bc-fb0a09aa78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-ccb1d125-0c1c-4bc0-ac20-5c95ea6ec00a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375979026-172.17.0.6-1596870865048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-13e7c02b-c3bf-4480-8898-658a60838d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-d144212f-dcdb-4618-b112-ff66bcc149a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-f7c738c3-5055-4fa7-9c28-c13e1f8c85e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-03dcf3ec-63df-4e9b-9ac2-be73a083d968,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-123be975-221d-411e-be24-ff203948bf92,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-dbca4a4a-c293-4334-91ff-05651dc29302,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-46c1a646-5db3-4774-88bc-fb0a09aa78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-ccb1d125-0c1c-4bc0-ac20-5c95ea6ec00a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515948245-172.17.0.6-1596870985877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-a5915dfa-ee91-4f69-89eb-90cec9723ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-c0202375-1345-411a-ae1e-fa58f5fec242,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-73555ac8-2786-45a6-ace1-76a63141abd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-45b797c0-9770-486f-ae75-420f8defa3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-a12c0281-9cd4-4f4c-af49-fd2d3db4df47,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-edcf1899-8c01-4751-bfd1-c2c9ea291391,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-015700eb-d4b9-484e-b8a2-03c2a8201101,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-78e2f5f0-3ae1-4521-b030-4ec7bd94ad7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515948245-172.17.0.6-1596870985877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-a5915dfa-ee91-4f69-89eb-90cec9723ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-c0202375-1345-411a-ae1e-fa58f5fec242,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-73555ac8-2786-45a6-ace1-76a63141abd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-45b797c0-9770-486f-ae75-420f8defa3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-a12c0281-9cd4-4f4c-af49-fd2d3db4df47,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-edcf1899-8c01-4751-bfd1-c2c9ea291391,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-015700eb-d4b9-484e-b8a2-03c2a8201101,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-78e2f5f0-3ae1-4521-b030-4ec7bd94ad7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534779676-172.17.0.6-1596871213361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-e3d5f367-0251-436c-af3c-1bfdb1baf930,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-fecd2157-4592-4032-9bca-ca2a662f5a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-0138d0e7-60bc-476b-892a-55b541262cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-fa037247-4a3e-41b1-9f68-4ee00bd7ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-719192c0-1831-4603-bb50-19bcfaa52a66,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-ef2fe629-7296-4733-8b2b-8cd3b037cd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-270c4ebe-17cb-4700-8556-38920a181cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-d48484d2-6a0a-4604-9197-85d704e03a47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534779676-172.17.0.6-1596871213361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-e3d5f367-0251-436c-af3c-1bfdb1baf930,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-fecd2157-4592-4032-9bca-ca2a662f5a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-0138d0e7-60bc-476b-892a-55b541262cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-fa037247-4a3e-41b1-9f68-4ee00bd7ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-719192c0-1831-4603-bb50-19bcfaa52a66,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-ef2fe629-7296-4733-8b2b-8cd3b037cd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-270c4ebe-17cb-4700-8556-38920a181cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-d48484d2-6a0a-4604-9197-85d704e03a47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070729474-172.17.0.6-1596871962094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39096,DS-659ddc18-c4e1-4722-92f4-6bc3ca7a3ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-28552cba-0524-48fe-8185-86a5f3963f72,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-7eccaeb5-eacd-4865-b31a-e570617200dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-6d7c15d8-89c9-471f-ad88-a1d49bef35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-4a5c67dc-3915-40fe-8d43-311375253f47,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-2ade43b1-dde6-466a-b173-4f8eebc3a2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-f74de84a-1987-4c47-9271-d338fbbc3e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-be2073b6-7fab-4e28-b3ba-9daaeea5283d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070729474-172.17.0.6-1596871962094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39096,DS-659ddc18-c4e1-4722-92f4-6bc3ca7a3ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-28552cba-0524-48fe-8185-86a5f3963f72,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-7eccaeb5-eacd-4865-b31a-e570617200dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-6d7c15d8-89c9-471f-ad88-a1d49bef35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-4a5c67dc-3915-40fe-8d43-311375253f47,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-2ade43b1-dde6-466a-b173-4f8eebc3a2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-f74de84a-1987-4c47-9271-d338fbbc3e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-be2073b6-7fab-4e28-b3ba-9daaeea5283d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296901364-172.17.0.6-1596872034212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34456,DS-d9264820-df49-44ff-be23-d99e583572f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-aeadcc71-179e-4b73-87f5-f06c0c97076c,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-76e31ea2-221d-4155-b1dc-76d46065ce85,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-635c2327-a82d-4eb1-86b9-df3325a6280f,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-5e98749a-c9ca-4b26-9d65-4bb3567bf8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-ec1dd0b6-89da-4fff-b187-88f0749a3b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-ad3ce7a5-bcab-4912-af40-7750f5b5cdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-e29a09e8-f6d7-4e27-a64a-72c8932fb46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296901364-172.17.0.6-1596872034212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34456,DS-d9264820-df49-44ff-be23-d99e583572f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-aeadcc71-179e-4b73-87f5-f06c0c97076c,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-76e31ea2-221d-4155-b1dc-76d46065ce85,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-635c2327-a82d-4eb1-86b9-df3325a6280f,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-5e98749a-c9ca-4b26-9d65-4bb3567bf8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-ec1dd0b6-89da-4fff-b187-88f0749a3b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-ad3ce7a5-bcab-4912-af40-7750f5b5cdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-e29a09e8-f6d7-4e27-a64a-72c8932fb46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401950143-172.17.0.6-1596872143327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-82361e73-7d54-4dc6-8429-fe33cdf5d22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-54b552f7-0679-4e19-aa41-d9420213f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-59260fd1-cef5-4ed2-93d3-bc74de4e5ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-2b7ae206-04d3-458b-b8d2-61ccd1733a70,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-5186073e-5664-4185-9eaf-fc7d20856dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-e0906fe4-03a3-4c75-9447-e60b77696bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-ede3e223-4079-4896-9699-78bb12c591ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-1a2f5315-2d83-4ec0-9798-d0dc42e74866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401950143-172.17.0.6-1596872143327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-82361e73-7d54-4dc6-8429-fe33cdf5d22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-54b552f7-0679-4e19-aa41-d9420213f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-59260fd1-cef5-4ed2-93d3-bc74de4e5ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-2b7ae206-04d3-458b-b8d2-61ccd1733a70,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-5186073e-5664-4185-9eaf-fc7d20856dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-e0906fe4-03a3-4c75-9447-e60b77696bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-ede3e223-4079-4896-9699-78bb12c591ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-1a2f5315-2d83-4ec0-9798-d0dc42e74866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5644
