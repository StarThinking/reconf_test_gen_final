reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596049807-172.17.0.6-1596889115717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-9fc9eede-2fec-468c-a74d-ac061cc810b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-50264b1a-c555-4435-9959-f76a445a9a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-91e878ae-5640-41f1-99d6-87ca57dc1b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-2afd9665-5618-41ac-a65f-5be47e7c8aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-8b290e39-3a51-4373-b0a0-3744df443eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-9f27526b-36e5-4bf1-863a-bd437110202e,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e1c044e9-29ec-483d-a3c1-a2ba954d7343,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-0bc32839-f7b1-49bd-a19d-ad5366f7757c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596049807-172.17.0.6-1596889115717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-9fc9eede-2fec-468c-a74d-ac061cc810b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-50264b1a-c555-4435-9959-f76a445a9a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-91e878ae-5640-41f1-99d6-87ca57dc1b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-2afd9665-5618-41ac-a65f-5be47e7c8aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-8b290e39-3a51-4373-b0a0-3744df443eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-9f27526b-36e5-4bf1-863a-bd437110202e,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e1c044e9-29ec-483d-a3c1-a2ba954d7343,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-0bc32839-f7b1-49bd-a19d-ad5366f7757c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757089964-172.17.0.6-1596889678790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-5a53e3b2-3a3f-4ea1-8901-a0a073a917cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-2fc31eeb-42ef-4126-9111-2c1d1982b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-0c9dca4e-fd15-4f53-b1d5-10e65e9ca0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-4848e584-4dd0-44a6-96c2-846c7acf3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-2c937e7b-4711-4ddb-8f01-f8d2a0edf386,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-98cb8c0b-8a77-4630-861b-4e8be974084c,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-eac18930-048f-4073-b601-1d77d837bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-353eb857-5b3c-4bce-943d-1bfcdfab43c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757089964-172.17.0.6-1596889678790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-5a53e3b2-3a3f-4ea1-8901-a0a073a917cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-2fc31eeb-42ef-4126-9111-2c1d1982b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-0c9dca4e-fd15-4f53-b1d5-10e65e9ca0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-4848e584-4dd0-44a6-96c2-846c7acf3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-2c937e7b-4711-4ddb-8f01-f8d2a0edf386,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-98cb8c0b-8a77-4630-861b-4e8be974084c,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-eac18930-048f-4073-b601-1d77d837bfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-353eb857-5b3c-4bce-943d-1bfcdfab43c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104320795-172.17.0.6-1596890544245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39833,DS-603171d3-18c9-42cb-a6a0-03a5104e16f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-656c5f57-664a-48c3-aeba-b948f95680a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-4cd403cf-10eb-449c-b1e1-357e8032a714,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-309c0910-d36d-49f9-b16c-ae1ea45a948e,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-9928becf-7202-477d-b748-911b87faaf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-a25495ba-a228-456f-95ea-5ead5ee6f740,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-e5be051b-08fa-4615-aa0e-398c3fd6a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-9737a37c-ab1f-4b7d-b950-437847979065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104320795-172.17.0.6-1596890544245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39833,DS-603171d3-18c9-42cb-a6a0-03a5104e16f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-656c5f57-664a-48c3-aeba-b948f95680a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-4cd403cf-10eb-449c-b1e1-357e8032a714,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-309c0910-d36d-49f9-b16c-ae1ea45a948e,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-9928becf-7202-477d-b748-911b87faaf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-a25495ba-a228-456f-95ea-5ead5ee6f740,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-e5be051b-08fa-4615-aa0e-398c3fd6a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-9737a37c-ab1f-4b7d-b950-437847979065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286132517-172.17.0.6-1596890821143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34763,DS-deff331a-8648-4a8d-afb8-938eef2dde85,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-dc296e3d-061c-4301-9028-2107ebb4b7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-2372356f-cc4f-4a2f-8a86-f9c51b3006d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-a67adf2c-9e46-44f5-932e-5836348a73bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-46d0ffe0-634e-416e-826e-72a22dc74c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-13c0d267-9c5b-479e-8304-0af709b5ca75,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-b1724fa9-e0de-495b-a7bf-a92b96a08973,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-cde7a85a-b7c3-4f10-9df4-d0f23aa1b4d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286132517-172.17.0.6-1596890821143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34763,DS-deff331a-8648-4a8d-afb8-938eef2dde85,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-dc296e3d-061c-4301-9028-2107ebb4b7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-2372356f-cc4f-4a2f-8a86-f9c51b3006d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-a67adf2c-9e46-44f5-932e-5836348a73bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-46d0ffe0-634e-416e-826e-72a22dc74c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-13c0d267-9c5b-479e-8304-0af709b5ca75,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-b1724fa9-e0de-495b-a7bf-a92b96a08973,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-cde7a85a-b7c3-4f10-9df4-d0f23aa1b4d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118352322-172.17.0.6-1596891412313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37319,DS-4257ca2d-ad99-4f4e-b5cb-62b6a642ab39,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-d19cb16f-9bbd-4d71-ad87-e5a8167d1113,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-477fc7f9-e7a3-4af9-a57f-95e6dfcfeb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-0167c703-6c04-49cb-8660-bdbbfe81ec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-a4687bc5-83ea-457d-a609-11bcac1e085a,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-2602e017-8ec6-44ff-b929-c7395711e7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-b5702a43-140b-45ad-b1d1-4744e2a7b242,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6623eeb3-014f-416f-8468-47cb808619ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118352322-172.17.0.6-1596891412313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37319,DS-4257ca2d-ad99-4f4e-b5cb-62b6a642ab39,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-d19cb16f-9bbd-4d71-ad87-e5a8167d1113,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-477fc7f9-e7a3-4af9-a57f-95e6dfcfeb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-0167c703-6c04-49cb-8660-bdbbfe81ec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-a4687bc5-83ea-457d-a609-11bcac1e085a,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-2602e017-8ec6-44ff-b929-c7395711e7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-b5702a43-140b-45ad-b1d1-4744e2a7b242,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-6623eeb3-014f-416f-8468-47cb808619ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701360642-172.17.0.6-1596892106204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33068,DS-164dea49-be10-493b-a798-350136ed5c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-e9cf10ed-59a9-43ae-99fc-8d6ef357170e,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-1cd95590-b6e2-47be-87b0-0530bf544b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-d4ebb7a6-e9d9-4e80-a0dc-b22bd26a6d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-4d862c2d-70f4-4c6e-998b-ef7705ec4632,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-f543561f-74e3-4bd2-b9ab-04285b461a19,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-51f9ae32-5e7a-4ce1-a646-b12b3ab9508d,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-de7e90ca-21f1-4425-b738-889ffac95591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701360642-172.17.0.6-1596892106204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33068,DS-164dea49-be10-493b-a798-350136ed5c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-e9cf10ed-59a9-43ae-99fc-8d6ef357170e,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-1cd95590-b6e2-47be-87b0-0530bf544b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-d4ebb7a6-e9d9-4e80-a0dc-b22bd26a6d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-4d862c2d-70f4-4c6e-998b-ef7705ec4632,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-f543561f-74e3-4bd2-b9ab-04285b461a19,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-51f9ae32-5e7a-4ce1-a646-b12b3ab9508d,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-de7e90ca-21f1-4425-b738-889ffac95591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760215287-172.17.0.6-1596892253582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-427f9d63-0875-4111-935c-aa50f9868b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-78ad130b-53e4-4ca4-8d5d-c1f9419906eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-e4cba175-b0d9-4dc8-a49c-72c7d70bcaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-f7a00798-3739-4cb9-85d7-0f2d4ef74df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-f1971797-9259-4ead-b6b2-d13179b03f92,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-625665ac-52c7-4109-9525-bcd6179eadbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-5b72ddf9-38e8-44b4-90a6-f3d65f0da526,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-d8241733-8eb6-4e15-871d-9d410000b2e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760215287-172.17.0.6-1596892253582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-427f9d63-0875-4111-935c-aa50f9868b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-78ad130b-53e4-4ca4-8d5d-c1f9419906eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-e4cba175-b0d9-4dc8-a49c-72c7d70bcaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-f7a00798-3739-4cb9-85d7-0f2d4ef74df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-f1971797-9259-4ead-b6b2-d13179b03f92,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-625665ac-52c7-4109-9525-bcd6179eadbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-5b72ddf9-38e8-44b4-90a6-f3d65f0da526,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-d8241733-8eb6-4e15-871d-9d410000b2e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242667879-172.17.0.6-1596892647573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-8cd127b1-1a4f-49c8-8404-9e2746b92c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-1ec91949-ce47-49f5-b2cb-2d82cdaaf707,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-d357c28d-141d-492c-8a7e-95d99e847979,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-2fae205a-f0f4-42ea-b48a-b8be185bb4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-23b0ef6f-3fa8-4ead-9e76-ad7ae55e957b,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-76a8ca3d-f12c-4027-9ec5-dbb0becb7534,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f2a57f2a-a6f6-4702-90e8-2add0ec27486,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-e517f3a2-2405-412b-847f-26d807ff8fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242667879-172.17.0.6-1596892647573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-8cd127b1-1a4f-49c8-8404-9e2746b92c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-1ec91949-ce47-49f5-b2cb-2d82cdaaf707,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-d357c28d-141d-492c-8a7e-95d99e847979,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-2fae205a-f0f4-42ea-b48a-b8be185bb4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-23b0ef6f-3fa8-4ead-9e76-ad7ae55e957b,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-76a8ca3d-f12c-4027-9ec5-dbb0becb7534,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f2a57f2a-a6f6-4702-90e8-2add0ec27486,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-e517f3a2-2405-412b-847f-26d807ff8fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178245120-172.17.0.6-1596892732750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41265,DS-bb612979-0d94-4488-b3d9-4cb7cd4e9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-f9622ddb-a434-41ed-96b1-effeb49be67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-38cc6c74-7c57-4eed-84dc-cbe40cc5d586,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-c42ef160-5e61-4809-af67-8755a0fdd0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-4918d247-9352-4f2c-9577-753769790e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-981632b7-2563-436e-8060-539a6e06d073,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-4e5d30b2-9f20-4b2f-b885-7544f2384a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-3014997e-c959-4259-9210-9e16c2dfa6a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178245120-172.17.0.6-1596892732750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41265,DS-bb612979-0d94-4488-b3d9-4cb7cd4e9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-f9622ddb-a434-41ed-96b1-effeb49be67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-38cc6c74-7c57-4eed-84dc-cbe40cc5d586,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-c42ef160-5e61-4809-af67-8755a0fdd0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-4918d247-9352-4f2c-9577-753769790e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-981632b7-2563-436e-8060-539a6e06d073,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-4e5d30b2-9f20-4b2f-b885-7544f2384a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-3014997e-c959-4259-9210-9e16c2dfa6a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971720968-172.17.0.6-1596892866053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-8eb421e9-3f8e-4510-9b83-5ba49cb5ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-50ea58b9-091c-455b-b565-615697145308,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-33a47ff3-f0db-49e9-9fd2-dfc59440d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-dd1b777b-7247-448c-8925-80825782c779,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-849c5ca0-9c5b-412f-996a-1e59cf5c3e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-e1ece75a-1a45-400d-a7c5-e3f5799fc5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-cb232358-ed22-4ea3-8f2b-472d4ed12771,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-8219fc13-6a9d-4167-a6d9-41b892226d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971720968-172.17.0.6-1596892866053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-8eb421e9-3f8e-4510-9b83-5ba49cb5ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-50ea58b9-091c-455b-b565-615697145308,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-33a47ff3-f0db-49e9-9fd2-dfc59440d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-dd1b777b-7247-448c-8925-80825782c779,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-849c5ca0-9c5b-412f-996a-1e59cf5c3e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-e1ece75a-1a45-400d-a7c5-e3f5799fc5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-cb232358-ed22-4ea3-8f2b-472d4ed12771,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-8219fc13-6a9d-4167-a6d9-41b892226d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369885325-172.17.0.6-1596892955450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-be5dd008-827f-4a72-9a8c-f9348cf4bd00,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-3ce57ea2-2c4f-4a3c-acab-175450f735c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-1e76bf6b-c705-45a1-a248-495984319e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-3632ee05-fc69-447f-a00b-acda924ae8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-cddd3cf1-cfaa-4668-a65b-2b004f3b1206,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-9981e6d1-f4f8-47d6-86fc-28da9c5e9ace,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-75cc9dd4-959a-45b8-ae83-d9f9aeeb8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-56de8a6e-610d-4144-9cb1-378050fefce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369885325-172.17.0.6-1596892955450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-be5dd008-827f-4a72-9a8c-f9348cf4bd00,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-3ce57ea2-2c4f-4a3c-acab-175450f735c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-1e76bf6b-c705-45a1-a248-495984319e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-3632ee05-fc69-447f-a00b-acda924ae8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-cddd3cf1-cfaa-4668-a65b-2b004f3b1206,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-9981e6d1-f4f8-47d6-86fc-28da9c5e9ace,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-75cc9dd4-959a-45b8-ae83-d9f9aeeb8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-56de8a6e-610d-4144-9cb1-378050fefce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823580982-172.17.0.6-1596892997859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-1b1c4f58-38f5-4217-9d8b-82a2166fcebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-9f616a6c-f933-4c4d-9187-b66e130c3d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-58ad861c-4980-42b0-b65a-5776d4e6349f,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-84e49114-0f8f-47c7-b86a-25c37b1270c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-39aa608c-8a3f-4628-ad02-61b707fd4a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-496b9531-f68f-4e0e-a2c5-f140ae0df6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-b54d4a61-6b7e-4fb6-86f7-f6fbefd514be,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-795afa1c-1ade-4016-9132-87e8cd3f07dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823580982-172.17.0.6-1596892997859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-1b1c4f58-38f5-4217-9d8b-82a2166fcebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-9f616a6c-f933-4c4d-9187-b66e130c3d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-58ad861c-4980-42b0-b65a-5776d4e6349f,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-84e49114-0f8f-47c7-b86a-25c37b1270c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-39aa608c-8a3f-4628-ad02-61b707fd4a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-496b9531-f68f-4e0e-a2c5-f140ae0df6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-b54d4a61-6b7e-4fb6-86f7-f6fbefd514be,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-795afa1c-1ade-4016-9132-87e8cd3f07dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083759057-172.17.0.6-1596893046485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42847,DS-41ced3c3-72f8-4702-9636-1300a29217cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-b1080355-e743-4c7b-9611-9b6e1786589b,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-66603a78-b719-4318-ad22-2f36bbfff201,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-f9248177-4c4e-4ac4-bdd9-7b8d5db916bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-3d443c5d-ec3b-421e-80f3-794668a2d123,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-60d9e3b0-ec7f-4465-947d-323761b62640,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-3d6714ec-534a-4734-b413-be345e9979a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-90a11c00-617a-40f1-8018-36fc49e9c9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083759057-172.17.0.6-1596893046485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42847,DS-41ced3c3-72f8-4702-9636-1300a29217cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-b1080355-e743-4c7b-9611-9b6e1786589b,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-66603a78-b719-4318-ad22-2f36bbfff201,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-f9248177-4c4e-4ac4-bdd9-7b8d5db916bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-3d443c5d-ec3b-421e-80f3-794668a2d123,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-60d9e3b0-ec7f-4465-947d-323761b62640,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-3d6714ec-534a-4734-b413-be345e9979a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-90a11c00-617a-40f1-8018-36fc49e9c9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410610076-172.17.0.6-1596893174378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39472,DS-fcc31edd-4c4c-4029-8441-3fd7469e79b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-c73ed64d-0089-48ea-a4e0-0edd7d60bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-d1d59cf2-3323-450a-b1ab-fca53fb2e364,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-d9b034f4-921a-4dfe-9ef7-27222e380ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-acd29a25-742c-40fb-9ab7-2b790b759b97,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-e4986a9e-4c97-4c70-a09b-4b58e7b6910d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-a7033d25-96cd-4517-bd34-c74d7ab4b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-6bb1f79f-a3a2-4bf7-a1f3-c6719c62e156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410610076-172.17.0.6-1596893174378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39472,DS-fcc31edd-4c4c-4029-8441-3fd7469e79b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-c73ed64d-0089-48ea-a4e0-0edd7d60bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-d1d59cf2-3323-450a-b1ab-fca53fb2e364,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-d9b034f4-921a-4dfe-9ef7-27222e380ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-acd29a25-742c-40fb-9ab7-2b790b759b97,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-e4986a9e-4c97-4c70-a09b-4b58e7b6910d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-a7033d25-96cd-4517-bd34-c74d7ab4b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-6bb1f79f-a3a2-4bf7-a1f3-c6719c62e156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666305073-172.17.0.6-1596893955809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36205,DS-845cd751-66f2-444c-9892-e596a2caf31f,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-7aba45d7-8f48-4d65-a029-3132921d82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-99b0e7b1-442b-4aff-8966-fa56ce97be10,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-bd3eb88b-59f0-4c47-b4c5-afac29eb925f,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-6ff73d9c-3e2c-402a-a055-2fefa87cb697,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-6ed556ad-a8eb-4e63-8da6-e76e8990bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-c93ce1c9-4e55-4ede-989c-bf91ae2d1043,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-93c755eb-9573-4136-8b00-b24e4ee8470b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666305073-172.17.0.6-1596893955809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36205,DS-845cd751-66f2-444c-9892-e596a2caf31f,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-7aba45d7-8f48-4d65-a029-3132921d82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-99b0e7b1-442b-4aff-8966-fa56ce97be10,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-bd3eb88b-59f0-4c47-b4c5-afac29eb925f,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-6ff73d9c-3e2c-402a-a055-2fefa87cb697,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-6ed556ad-a8eb-4e63-8da6-e76e8990bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-c93ce1c9-4e55-4ede-989c-bf91ae2d1043,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-93c755eb-9573-4136-8b00-b24e4ee8470b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749647819-172.17.0.6-1596894002013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-cd076ea8-1757-4e11-85c6-d0607cd06043,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-95281e1d-7610-4572-a74f-9f902d4f2c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-94a1101b-f120-41ee-9a89-e21dc23cec7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-6e18a446-85b3-49ba-b61c-619e6b4198b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-dc035171-e2ad-435d-a8b4-ca642e64f0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-f860850f-8288-446d-8479-4faace3edf65,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-7c2c6ce8-f554-4d8e-9dee-8b57a58f3d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-63751d3d-b6fa-46e3-8f27-21f15c466085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749647819-172.17.0.6-1596894002013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-cd076ea8-1757-4e11-85c6-d0607cd06043,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-95281e1d-7610-4572-a74f-9f902d4f2c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-94a1101b-f120-41ee-9a89-e21dc23cec7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-6e18a446-85b3-49ba-b61c-619e6b4198b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-dc035171-e2ad-435d-a8b4-ca642e64f0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-f860850f-8288-446d-8479-4faace3edf65,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-7c2c6ce8-f554-4d8e-9dee-8b57a58f3d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-63751d3d-b6fa-46e3-8f27-21f15c466085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17320546-172.17.0.6-1596894139150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-eeeae407-c9b2-463a-8e5b-36394ec8b57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-121499a0-d232-400b-8dd8-8e274e1a3ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-bd85e930-0d42-4c2f-a031-6433afe7b224,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-1f2def5a-d456-4d85-8660-02ca7ced1228,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-86ec9e80-1f80-44d6-a484-091446a69a18,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-0add6c27-6fc0-4457-91de-7dd412b41275,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-1ba7fcfc-2974-44eb-8bf0-1498737307f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-a604e600-b214-4602-b5bf-f126ab252b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17320546-172.17.0.6-1596894139150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-eeeae407-c9b2-463a-8e5b-36394ec8b57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-121499a0-d232-400b-8dd8-8e274e1a3ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-bd85e930-0d42-4c2f-a031-6433afe7b224,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-1f2def5a-d456-4d85-8660-02ca7ced1228,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-86ec9e80-1f80-44d6-a484-091446a69a18,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-0add6c27-6fc0-4457-91de-7dd412b41275,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-1ba7fcfc-2974-44eb-8bf0-1498737307f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-a604e600-b214-4602-b5bf-f126ab252b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238850341-172.17.0.6-1596894446979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-20740d13-8661-4a4e-91f9-54363116109c,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-c8f20fd5-52dc-4eeb-99af-c9aada163d37,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-13bae061-fe73-4b94-a947-765f190887aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-636e52c6-2d7e-4d66-96c7-14cabf11442f,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-17dec957-3232-429a-b743-a88883b11637,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-6da87192-bb1d-4490-b8f5-4fbb2089bd07,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-7c471efc-70d4-45dd-9afa-8a861f32825f,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-929fdcbe-9de7-43d3-882a-9ed804e45762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238850341-172.17.0.6-1596894446979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-20740d13-8661-4a4e-91f9-54363116109c,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-c8f20fd5-52dc-4eeb-99af-c9aada163d37,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-13bae061-fe73-4b94-a947-765f190887aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-636e52c6-2d7e-4d66-96c7-14cabf11442f,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-17dec957-3232-429a-b743-a88883b11637,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-6da87192-bb1d-4490-b8f5-4fbb2089bd07,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-7c471efc-70d4-45dd-9afa-8a861f32825f,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-929fdcbe-9de7-43d3-882a-9ed804e45762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868111866-172.17.0.6-1596894491951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-2a54f9c4-9d64-46c5-b9f7-4e761789e13d,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-484f325f-1852-440c-bb29-c115f71c9976,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-4a05f25d-541e-49cb-938f-54550a463989,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-9f1b5cb7-062a-49fc-9e1f-0b41e795c3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-606040d6-73b5-4c2d-9404-1d477f3a5869,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-66457647-0ca5-4320-8090-5540aa6c04f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-44976af1-1eae-405b-a9ed-5ec935663eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-bd4731b9-9356-40f5-8ddb-ffa9f7254a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868111866-172.17.0.6-1596894491951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-2a54f9c4-9d64-46c5-b9f7-4e761789e13d,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-484f325f-1852-440c-bb29-c115f71c9976,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-4a05f25d-541e-49cb-938f-54550a463989,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-9f1b5cb7-062a-49fc-9e1f-0b41e795c3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-606040d6-73b5-4c2d-9404-1d477f3a5869,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-66457647-0ca5-4320-8090-5540aa6c04f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-44976af1-1eae-405b-a9ed-5ec935663eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-bd4731b9-9356-40f5-8ddb-ffa9f7254a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115048739-172.17.0.6-1596894862209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-63bc75ff-5032-47b4-b666-37e63bcfd85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-fa5031c8-d6aa-41bb-b6f5-a5bf55cb9c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-3cb8e6c9-95e1-405c-8434-6c9e52a240d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-969b0145-e2f3-4da6-bd1e-bb2f7d5e9d26,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-568cfcb7-4461-4c10-9748-e7c416d227d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-3f64253a-3d70-4a8b-8ae4-2a5bf34843a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-74388968-365d-492b-a723-708ef079283b,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-c5307514-34fb-4610-b3c8-58f5053fd4cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115048739-172.17.0.6-1596894862209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-63bc75ff-5032-47b4-b666-37e63bcfd85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-fa5031c8-d6aa-41bb-b6f5-a5bf55cb9c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-3cb8e6c9-95e1-405c-8434-6c9e52a240d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-969b0145-e2f3-4da6-bd1e-bb2f7d5e9d26,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-568cfcb7-4461-4c10-9748-e7c416d227d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-3f64253a-3d70-4a8b-8ae4-2a5bf34843a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-74388968-365d-492b-a723-708ef079283b,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-c5307514-34fb-4610-b3c8-58f5053fd4cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074154091-172.17.0.6-1596895091783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42695,DS-35e1699e-cca5-4b3c-8893-8cc9a45a74f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-41978e82-e4d5-443d-bb2a-7af3d752afcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-d41bbf1c-8a07-48bf-a697-3d38edc44f92,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-cbadad2f-4586-4f34-b634-cc8f27a148eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-4e63fff1-ec1d-40f7-8d36-9b04b3135326,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-ced089ed-5777-4890-bae9-ccf931753cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-dcccdc8f-0ed4-4a03-baa0-8e4f4a1d67b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-cbbcee28-c2c5-4049-b40c-4ae1ec9c03e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074154091-172.17.0.6-1596895091783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42695,DS-35e1699e-cca5-4b3c-8893-8cc9a45a74f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-41978e82-e4d5-443d-bb2a-7af3d752afcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-d41bbf1c-8a07-48bf-a697-3d38edc44f92,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-cbadad2f-4586-4f34-b634-cc8f27a148eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-4e63fff1-ec1d-40f7-8d36-9b04b3135326,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-ced089ed-5777-4890-bae9-ccf931753cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-dcccdc8f-0ed4-4a03-baa0-8e4f4a1d67b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-cbbcee28-c2c5-4049-b40c-4ae1ec9c03e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6659
