reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546571647-172.17.0.2-1596929654291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-3607b80c-b374-4029-b57d-0150e3338c86,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-602405be-e765-42a3-a6e2-6e2ab7a486d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-e09d2235-657f-4ea9-bb7a-63e7ee9d62c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-d4ee7e41-f90b-485d-b9c9-6c34ffd17722,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-e2176291-2edf-438c-b4f8-5bbdbeb31627,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-5a30a320-6d8f-42c0-9b5b-8504d77c5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-737715ff-7d2d-4457-a367-b40462900313,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-3b7bb6d1-17f2-4a59-b5e1-4f742aab679d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546571647-172.17.0.2-1596929654291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-3607b80c-b374-4029-b57d-0150e3338c86,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-602405be-e765-42a3-a6e2-6e2ab7a486d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-e09d2235-657f-4ea9-bb7a-63e7ee9d62c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-d4ee7e41-f90b-485d-b9c9-6c34ffd17722,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-e2176291-2edf-438c-b4f8-5bbdbeb31627,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-5a30a320-6d8f-42c0-9b5b-8504d77c5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-737715ff-7d2d-4457-a367-b40462900313,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-3b7bb6d1-17f2-4a59-b5e1-4f742aab679d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175491305-172.17.0.2-1596929722068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-ec1fa9c7-8589-4f0c-a829-857fccd80874,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-8ab83405-2618-424e-8fd4-6a9f6c2cef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-bf0f5068-6747-47da-86c6-2bb7a3ea2852,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-74fbd14a-855b-4a26-8f9d-82b61762f4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-eb2bc6c3-44cf-49ce-948e-4e48c6eea9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-b05c7549-a227-4a3b-8232-97f6aee220f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-9a638d43-c5f0-4895-89b2-5305cf6d82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-493ba41b-28dd-4b5a-88cc-be2285690b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175491305-172.17.0.2-1596929722068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-ec1fa9c7-8589-4f0c-a829-857fccd80874,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-8ab83405-2618-424e-8fd4-6a9f6c2cef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-bf0f5068-6747-47da-86c6-2bb7a3ea2852,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-74fbd14a-855b-4a26-8f9d-82b61762f4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-eb2bc6c3-44cf-49ce-948e-4e48c6eea9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-b05c7549-a227-4a3b-8232-97f6aee220f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-9a638d43-c5f0-4895-89b2-5305cf6d82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-493ba41b-28dd-4b5a-88cc-be2285690b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370471723-172.17.0.2-1596929826382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-5311d728-9471-4032-8aa0-1a8a2814488d,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-b2bbf4ba-3da8-47a1-b351-879b44c0113d,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-a7014308-fd34-41e2-a375-69649f99035f,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-6d7b00ae-e898-414b-ad32-8dc38aa60ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-203e6109-300b-4c74-a036-8c446a99e330,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-c668fbef-f3b2-4794-b85d-4306a888c79d,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-d81be429-9c1c-4224-9471-548412346740,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-50d30b7e-7f81-43fc-8cea-0a9141fe6a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370471723-172.17.0.2-1596929826382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-5311d728-9471-4032-8aa0-1a8a2814488d,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-b2bbf4ba-3da8-47a1-b351-879b44c0113d,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-a7014308-fd34-41e2-a375-69649f99035f,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-6d7b00ae-e898-414b-ad32-8dc38aa60ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-203e6109-300b-4c74-a036-8c446a99e330,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-c668fbef-f3b2-4794-b85d-4306a888c79d,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-d81be429-9c1c-4224-9471-548412346740,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-50d30b7e-7f81-43fc-8cea-0a9141fe6a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790921762-172.17.0.2-1596930190755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-b1133e6b-122e-4103-95ac-28df3530ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-0e9a34ba-4008-467d-91f1-8b6ace404c46,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-71e897ee-d397-4a83-9136-0c394e7df9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-52c2b80c-86a0-4cdf-8f20-13055dc1e3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-4b00253e-5677-46ce-8d39-9342444a7af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-76f7e4c3-8ead-4f50-a940-3a44951d3345,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-4e51151c-90fa-475d-a7a6-274bf457b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-735c2d69-d548-4af9-a116-60b47b446156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790921762-172.17.0.2-1596930190755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-b1133e6b-122e-4103-95ac-28df3530ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-0e9a34ba-4008-467d-91f1-8b6ace404c46,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-71e897ee-d397-4a83-9136-0c394e7df9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-52c2b80c-86a0-4cdf-8f20-13055dc1e3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-4b00253e-5677-46ce-8d39-9342444a7af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-76f7e4c3-8ead-4f50-a940-3a44951d3345,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-4e51151c-90fa-475d-a7a6-274bf457b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-735c2d69-d548-4af9-a116-60b47b446156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013649593-172.17.0.2-1596930265233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36999,DS-ef9aab80-d589-41a4-8a94-e8eaac5f797e,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-1e7a9501-64d2-4397-993c-d19862cb642b,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-6ff99191-cd3c-4639-a5ba-cab150655255,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-a69195e9-33a8-41fc-a838-4c6b6e270cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-21364841-ae19-4b14-8d20-29c29719b5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-d1a7ef4a-0208-44ab-9ab0-d97f414845f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-c07820e4-aae0-4f57-81d2-edeb032f9233,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-03008ac6-b19a-44ba-8395-4c3cd80ea69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013649593-172.17.0.2-1596930265233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36999,DS-ef9aab80-d589-41a4-8a94-e8eaac5f797e,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-1e7a9501-64d2-4397-993c-d19862cb642b,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-6ff99191-cd3c-4639-a5ba-cab150655255,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-a69195e9-33a8-41fc-a838-4c6b6e270cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-21364841-ae19-4b14-8d20-29c29719b5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-d1a7ef4a-0208-44ab-9ab0-d97f414845f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-c07820e4-aae0-4f57-81d2-edeb032f9233,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-03008ac6-b19a-44ba-8395-4c3cd80ea69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477480585-172.17.0.2-1596930405143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36818,DS-eaffa1ec-025c-4890-863d-afc215fb914a,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-7abbcd1b-e393-404c-9085-ed47ecb8dc64,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-73d12fb9-4845-43e1-94e8-7c72ece3a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-c8b655fe-96d5-4ff3-b5cb-2b7d6fb329e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-623ecb89-3cde-4be9-ab41-a826959df936,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-398cff1a-b779-44c7-9a60-09ae25df362c,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-0c8fde16-1ed9-415a-a948-3d3933ae0c26,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-de234487-437f-4a90-aa6f-4cf571546a5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477480585-172.17.0.2-1596930405143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36818,DS-eaffa1ec-025c-4890-863d-afc215fb914a,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-7abbcd1b-e393-404c-9085-ed47ecb8dc64,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-73d12fb9-4845-43e1-94e8-7c72ece3a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-c8b655fe-96d5-4ff3-b5cb-2b7d6fb329e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-623ecb89-3cde-4be9-ab41-a826959df936,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-398cff1a-b779-44c7-9a60-09ae25df362c,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-0c8fde16-1ed9-415a-a948-3d3933ae0c26,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-de234487-437f-4a90-aa6f-4cf571546a5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600808190-172.17.0.2-1596930806276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-2a66288b-bd99-4646-b80f-fda49e17e4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-28108dd7-cdb8-48ec-9821-ee3a5c5b1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-772195e4-79ec-4299-8898-920997460315,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-370fb13c-5051-48b5-a464-52eb846cc9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-717b5679-d9c1-4a5c-8fda-b71567318f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-5b9f2b82-d38d-4e91-9607-7d2aae793b13,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-bd7be6b5-07c7-4c21-ab81-5674dbb356e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-ebc135fe-8dee-4177-9536-5efa5c7758fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600808190-172.17.0.2-1596930806276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-2a66288b-bd99-4646-b80f-fda49e17e4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-28108dd7-cdb8-48ec-9821-ee3a5c5b1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-772195e4-79ec-4299-8898-920997460315,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-370fb13c-5051-48b5-a464-52eb846cc9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-717b5679-d9c1-4a5c-8fda-b71567318f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-5b9f2b82-d38d-4e91-9607-7d2aae793b13,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-bd7be6b5-07c7-4c21-ab81-5674dbb356e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-ebc135fe-8dee-4177-9536-5efa5c7758fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678434299-172.17.0.2-1596931182447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34843,DS-34bd8b7e-0fd6-421e-bc5b-4cb21c1eb261,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-96dd636e-0b69-4dc0-ad51-7e9e85f730e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-f67c977f-01ed-497e-b6e7-8e7281fd3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-fea1b41e-1406-4a9c-a2b4-e334de5688e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-dea177d1-08ca-4110-aa0a-9bd7840726f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-8f34df35-1ad4-457b-ad76-c0d16b8fa71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-63c94eab-340e-4f4e-9730-3203328002e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-7547091b-3deb-4ae1-8a04-55206bbfbe79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678434299-172.17.0.2-1596931182447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34843,DS-34bd8b7e-0fd6-421e-bc5b-4cb21c1eb261,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-96dd636e-0b69-4dc0-ad51-7e9e85f730e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-f67c977f-01ed-497e-b6e7-8e7281fd3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-fea1b41e-1406-4a9c-a2b4-e334de5688e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-dea177d1-08ca-4110-aa0a-9bd7840726f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-8f34df35-1ad4-457b-ad76-c0d16b8fa71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-63c94eab-340e-4f4e-9730-3203328002e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-7547091b-3deb-4ae1-8a04-55206bbfbe79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422519982-172.17.0.2-1596931420819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41230,DS-3631835e-071d-4095-a948-93c083e94db8,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-fb2aadcb-e762-4501-a3ff-90128c4b3942,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-8dae1b18-e26b-47a8-8178-c736c4e75dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-e06a2574-953f-445e-91a7-c85d3d91a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-3f91d193-0ff0-4457-ace1-f480d1bf3ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-a2fc39a8-ccd5-4251-98fd-983d05c38418,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-a783b15d-9203-4f4e-b3a7-071b754952d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-80ff0c67-5a55-4699-9c87-1a775ce8e64a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422519982-172.17.0.2-1596931420819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41230,DS-3631835e-071d-4095-a948-93c083e94db8,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-fb2aadcb-e762-4501-a3ff-90128c4b3942,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-8dae1b18-e26b-47a8-8178-c736c4e75dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-e06a2574-953f-445e-91a7-c85d3d91a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-3f91d193-0ff0-4457-ace1-f480d1bf3ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-a2fc39a8-ccd5-4251-98fd-983d05c38418,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-a783b15d-9203-4f4e-b3a7-071b754952d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-80ff0c67-5a55-4699-9c87-1a775ce8e64a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369940130-172.17.0.2-1596931914715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-ae6dea34-a29c-48a9-8370-875324de700c,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-9d26ddfa-830f-4d36-8d82-93ed941bdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-eccffd38-fec0-42a9-bb23-0d2d0f29fbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-e11bfa2d-07bb-4d56-8ecc-4a135c7c07fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-e9a77cd5-42b4-4b68-9cc4-82e9a819c84e,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-e71dae39-fe7e-48b0-a1e5-a9e8a8f1dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-ad36b4bd-1531-4f62-abc8-5d5463a92a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-4bfc687b-080c-429d-9311-40f15a356ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369940130-172.17.0.2-1596931914715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-ae6dea34-a29c-48a9-8370-875324de700c,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-9d26ddfa-830f-4d36-8d82-93ed941bdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-eccffd38-fec0-42a9-bb23-0d2d0f29fbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-e11bfa2d-07bb-4d56-8ecc-4a135c7c07fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-e9a77cd5-42b4-4b68-9cc4-82e9a819c84e,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-e71dae39-fe7e-48b0-a1e5-a9e8a8f1dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-ad36b4bd-1531-4f62-abc8-5d5463a92a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-4bfc687b-080c-429d-9311-40f15a356ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488837857-172.17.0.2-1596932184547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-b166d294-785b-433d-b5c6-fe736cec92da,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-72ba5ab4-7c7c-4dbe-88dc-94f4eca84769,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-9d2ba5b5-a89a-49fb-8ccc-4bcc428b9b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-6dd55e19-8fa1-4ae1-909e-6c554df7157a,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-7018c379-8523-42e5-94a5-b6fb02ca663c,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-711e82a0-d8d2-4857-a8f0-303d7479d03c,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-4203d233-1eb9-412d-b7b3-0079e2884b73,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-3795501f-7ecc-4941-b392-91ac3065560c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488837857-172.17.0.2-1596932184547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-b166d294-785b-433d-b5c6-fe736cec92da,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-72ba5ab4-7c7c-4dbe-88dc-94f4eca84769,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-9d2ba5b5-a89a-49fb-8ccc-4bcc428b9b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-6dd55e19-8fa1-4ae1-909e-6c554df7157a,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-7018c379-8523-42e5-94a5-b6fb02ca663c,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-711e82a0-d8d2-4857-a8f0-303d7479d03c,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-4203d233-1eb9-412d-b7b3-0079e2884b73,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-3795501f-7ecc-4941-b392-91ac3065560c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668672280-172.17.0.2-1596932688786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-ccca0496-d800-4973-a725-a3380ec70549,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-38ac8ec0-f4fb-445b-8321-694608c2279e,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-af327169-5dcd-4779-b514-8b5cfd51f867,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-02060466-37f8-4a2c-aa44-8dac954b155b,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-c02fe987-2b18-4a72-9cbb-a0507221304f,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-57a0b5fa-17e1-4487-b2cf-565314ffd15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-8cd3362e-f610-462d-afca-2846070c11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-5576a195-48ce-43a1-83a3-d1ffec0f7496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668672280-172.17.0.2-1596932688786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-ccca0496-d800-4973-a725-a3380ec70549,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-38ac8ec0-f4fb-445b-8321-694608c2279e,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-af327169-5dcd-4779-b514-8b5cfd51f867,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-02060466-37f8-4a2c-aa44-8dac954b155b,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-c02fe987-2b18-4a72-9cbb-a0507221304f,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-57a0b5fa-17e1-4487-b2cf-565314ffd15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-8cd3362e-f610-462d-afca-2846070c11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-5576a195-48ce-43a1-83a3-d1ffec0f7496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209476345-172.17.0.2-1596932836745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39009,DS-e06929f9-1096-4afb-997e-bab324be31c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-57f85ce4-9b32-4d7d-b186-71c80e1ff02f,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-95716307-ff95-4e29-af0a-e064fc311b10,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-9bb57235-7bdf-4755-bebb-de5a8b5b25c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-d40bab8d-ffc3-47b2-b44d-ef4f9bc33680,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-373c4dbe-bb42-497b-b25c-863783e305d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-2b7c05b6-d800-47df-bcc9-22c01cbc6765,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-9e5eadc2-4e7f-4861-979f-27fc2fbd69e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209476345-172.17.0.2-1596932836745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39009,DS-e06929f9-1096-4afb-997e-bab324be31c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-57f85ce4-9b32-4d7d-b186-71c80e1ff02f,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-95716307-ff95-4e29-af0a-e064fc311b10,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-9bb57235-7bdf-4755-bebb-de5a8b5b25c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-d40bab8d-ffc3-47b2-b44d-ef4f9bc33680,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-373c4dbe-bb42-497b-b25c-863783e305d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-2b7c05b6-d800-47df-bcc9-22c01cbc6765,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-9e5eadc2-4e7f-4861-979f-27fc2fbd69e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354659646-172.17.0.2-1596933033119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43377,DS-3a7e3ee0-640f-48e0-8924-c94cb1975054,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-480019a8-162b-4787-a8b0-49d745dc1231,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-a418bd55-822c-47b7-ac14-652ff22d1288,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-9ebc8ca7-f358-4db4-8491-3bbd14cfbf39,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-a1d8782b-e8da-4429-b2c7-26b9b01eeb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-e1372c85-2f1b-4dab-a999-efaf037aec97,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-dd5c8788-2296-4ea1-9349-6d9003466cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-54a71c9d-7d95-49d5-8008-9a649089fdf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354659646-172.17.0.2-1596933033119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43377,DS-3a7e3ee0-640f-48e0-8924-c94cb1975054,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-480019a8-162b-4787-a8b0-49d745dc1231,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-a418bd55-822c-47b7-ac14-652ff22d1288,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-9ebc8ca7-f358-4db4-8491-3bbd14cfbf39,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-a1d8782b-e8da-4429-b2c7-26b9b01eeb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-e1372c85-2f1b-4dab-a999-efaf037aec97,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-dd5c8788-2296-4ea1-9349-6d9003466cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-54a71c9d-7d95-49d5-8008-9a649089fdf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563706333-172.17.0.2-1596933131980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-34ec94ff-6e33-4e1d-8cec-2ea296e7ee01,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-210668b4-f062-4fb5-b6cb-966539bcc699,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-da713d6a-7b2d-437b-a349-fabdaacfbb51,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-fbff6779-b966-485c-98a4-22e7e0190560,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-5470c7c3-1004-4d3b-aeee-6caac8dc8a30,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-d64aa807-ec7d-4bb8-93a8-f6a394bf08c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-30884153-1c3c-498f-b009-94e7735050f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-33c4c5dc-e353-497e-8ca8-f4322a158355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563706333-172.17.0.2-1596933131980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-34ec94ff-6e33-4e1d-8cec-2ea296e7ee01,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-210668b4-f062-4fb5-b6cb-966539bcc699,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-da713d6a-7b2d-437b-a349-fabdaacfbb51,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-fbff6779-b966-485c-98a4-22e7e0190560,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-5470c7c3-1004-4d3b-aeee-6caac8dc8a30,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-d64aa807-ec7d-4bb8-93a8-f6a394bf08c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-30884153-1c3c-498f-b009-94e7735050f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-33c4c5dc-e353-497e-8ca8-f4322a158355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925322531-172.17.0.2-1596933371660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-5cd709df-883e-4caf-86ee-1760e3c1bd98,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-102a4da7-84a5-4314-b15c-0f66a3f335ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-511afbfe-be14-4e7a-857e-f45892c830c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-4b25d2fc-2a6d-4a45-9bc5-c533e1c2844c,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-86df2504-c7d4-4d70-97c1-c0e40f758815,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-5cfcb3ae-172f-4d75-abdc-30bec7b70d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-cf71be2e-8814-453e-939b-8e0e5130065a,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-25428de3-e285-461e-b6b6-1b74338011e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925322531-172.17.0.2-1596933371660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-5cd709df-883e-4caf-86ee-1760e3c1bd98,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-102a4da7-84a5-4314-b15c-0f66a3f335ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-511afbfe-be14-4e7a-857e-f45892c830c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-4b25d2fc-2a6d-4a45-9bc5-c533e1c2844c,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-86df2504-c7d4-4d70-97c1-c0e40f758815,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-5cfcb3ae-172f-4d75-abdc-30bec7b70d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-cf71be2e-8814-453e-939b-8e0e5130065a,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-25428de3-e285-461e-b6b6-1b74338011e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727919970-172.17.0.2-1596933515234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34430,DS-4ae372ac-ccc2-4166-b59c-86c2d077e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-cae191df-91fc-4f95-b82d-945f87b0b4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-b316d762-7a3f-4714-873c-1ed0abbdd17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-6b5f97ac-dc04-4321-97a0-f43e944b5b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-48d5c7bf-e8ee-4777-8c56-cebb5a89c724,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-87e7f6c1-37fe-4983-ba63-132e11cac6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-e48b7295-0dfe-42a1-aa07-d5e259a54fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-71ddc0f8-763d-49cc-b8f1-1b76e7675e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727919970-172.17.0.2-1596933515234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34430,DS-4ae372ac-ccc2-4166-b59c-86c2d077e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-cae191df-91fc-4f95-b82d-945f87b0b4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-b316d762-7a3f-4714-873c-1ed0abbdd17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-6b5f97ac-dc04-4321-97a0-f43e944b5b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-48d5c7bf-e8ee-4777-8c56-cebb5a89c724,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-87e7f6c1-37fe-4983-ba63-132e11cac6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-e48b7295-0dfe-42a1-aa07-d5e259a54fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-71ddc0f8-763d-49cc-b8f1-1b76e7675e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837547185-172.17.0.2-1596933914483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35236,DS-04eb1ede-a324-4bc5-b3d9-6cb8d48ea3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-acf9452a-872c-43fa-aa14-15d290339441,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-3d0bb5e1-4518-4795-a58a-55e494aaf983,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-032ec2d0-2ce9-4c88-bd0e-e7c08c703d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-59808f79-f050-4c63-b50f-3a6c64815448,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-276bc356-1507-4424-a6ba-bf7d8b4eee33,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-a2dc30fb-46ca-4248-9efc-0b5e1bbc83ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-842fa577-0232-4e08-89c4-76793a89029a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1837547185-172.17.0.2-1596933914483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35236,DS-04eb1ede-a324-4bc5-b3d9-6cb8d48ea3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-acf9452a-872c-43fa-aa14-15d290339441,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-3d0bb5e1-4518-4795-a58a-55e494aaf983,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-032ec2d0-2ce9-4c88-bd0e-e7c08c703d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-59808f79-f050-4c63-b50f-3a6c64815448,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-276bc356-1507-4424-a6ba-bf7d8b4eee33,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-a2dc30fb-46ca-4248-9efc-0b5e1bbc83ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-842fa577-0232-4e08-89c4-76793a89029a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4880
