reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876665147-172.17.0.20-1596901622391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-bbe94d09-d802-4888-a9d0-2458a14aa033,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-1cc7482c-8001-4e8b-8403-9a1ce922f430,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-32078a01-6645-4912-b528-a8216955f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-5b212048-b41c-44ed-b3b9-8a671b2bd507,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-fd038399-dd70-4a01-88c9-3aa20a03d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-8c60abb9-2bf0-4587-980e-1c759aa8fbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-ac4972e1-5540-4033-b7ba-1b70341160b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-b50b5777-c8f3-4579-b8c0-ca940d18f6cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876665147-172.17.0.20-1596901622391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-bbe94d09-d802-4888-a9d0-2458a14aa033,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-1cc7482c-8001-4e8b-8403-9a1ce922f430,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-32078a01-6645-4912-b528-a8216955f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-5b212048-b41c-44ed-b3b9-8a671b2bd507,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-fd038399-dd70-4a01-88c9-3aa20a03d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-8c60abb9-2bf0-4587-980e-1c759aa8fbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-ac4972e1-5540-4033-b7ba-1b70341160b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-b50b5777-c8f3-4579-b8c0-ca940d18f6cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905210696-172.17.0.20-1596901656535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-f2c77ec1-3933-4566-867d-a1f5b530c7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-c53e5544-efca-4b05-a9e4-83f2e2e85183,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-fb1cd847-bc3b-43e2-862a-beb169174fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ce1204a4-92f6-4af6-b791-f037b0528966,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-309e86bc-f950-46cd-ad7a-18cd14d20832,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-916a2ddf-cde7-4655-a2b8-e6850d7b14d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-b7ec2a47-7ec0-48c6-8771-ed786661f5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-c5049c5d-499f-4698-8474-f2986b0cddf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905210696-172.17.0.20-1596901656535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-f2c77ec1-3933-4566-867d-a1f5b530c7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-c53e5544-efca-4b05-a9e4-83f2e2e85183,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-fb1cd847-bc3b-43e2-862a-beb169174fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ce1204a4-92f6-4af6-b791-f037b0528966,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-309e86bc-f950-46cd-ad7a-18cd14d20832,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-916a2ddf-cde7-4655-a2b8-e6850d7b14d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-b7ec2a47-7ec0-48c6-8771-ed786661f5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-c5049c5d-499f-4698-8474-f2986b0cddf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627323523-172.17.0.20-1596901687868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-57179d86-ea4a-4207-821a-ae21d062b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-e9008d9f-73f5-414e-a3a4-0e289725d734,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-fefeef8e-745c-4a8e-ad43-ebdab652be42,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-2fa9f2a2-e3ef-4b7f-b475-683bfbafe277,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-cd4ac0cc-4f3a-4159-baf7-7ebd4dd70a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-cf5f95b2-31ea-442c-a40d-2468a513247a,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-84665e61-57d5-458a-a5b5-5cf75da746f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-5e3ef8d7-a40f-4283-a23b-f2d25eafa00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627323523-172.17.0.20-1596901687868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-57179d86-ea4a-4207-821a-ae21d062b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-e9008d9f-73f5-414e-a3a4-0e289725d734,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-fefeef8e-745c-4a8e-ad43-ebdab652be42,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-2fa9f2a2-e3ef-4b7f-b475-683bfbafe277,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-cd4ac0cc-4f3a-4159-baf7-7ebd4dd70a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-cf5f95b2-31ea-442c-a40d-2468a513247a,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-84665e61-57d5-458a-a5b5-5cf75da746f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-5e3ef8d7-a40f-4283-a23b-f2d25eafa00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636935519-172.17.0.20-1596901718217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40618,DS-3f89eb73-503c-4be5-876d-ca3640a478d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-201cbd35-f29d-4aac-8934-56b988a7b251,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-cda4b9a1-f8bd-42df-bba5-bcdd8aba207c,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-e6684e0d-db63-47c8-ac7d-a552144cd8da,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-43acb692-6e02-4d95-a4fa-91c69eac9d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-12aab4a1-c1b5-40a9-87c9-85bf52722034,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-349314c0-ecca-49bc-bd18-ab4277fb8260,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-c241e89d-073f-42ec-8f9c-e46dd4867fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636935519-172.17.0.20-1596901718217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40618,DS-3f89eb73-503c-4be5-876d-ca3640a478d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-201cbd35-f29d-4aac-8934-56b988a7b251,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-cda4b9a1-f8bd-42df-bba5-bcdd8aba207c,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-e6684e0d-db63-47c8-ac7d-a552144cd8da,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-43acb692-6e02-4d95-a4fa-91c69eac9d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-12aab4a1-c1b5-40a9-87c9-85bf52722034,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-349314c0-ecca-49bc-bd18-ab4277fb8260,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-c241e89d-073f-42ec-8f9c-e46dd4867fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925010495-172.17.0.20-1596901788885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36171,DS-0d318d07-fb71-421b-a869-9a499f543d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-5d558b4f-e93f-4358-a2f0-103c5bd20046,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-5a08904a-63cb-4e7a-8852-1ea2a5083805,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-a02f2e28-e146-4c82-a6d0-6cab0a713aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-202382b0-f97c-4623-bb7c-3cc4d0f83180,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-90f290c0-8127-4e30-a699-c3d7036938b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-92811b36-de96-43af-9bc9-69c46604f358,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-6004a26b-3591-48e1-9515-15589cd0e9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925010495-172.17.0.20-1596901788885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36171,DS-0d318d07-fb71-421b-a869-9a499f543d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-5d558b4f-e93f-4358-a2f0-103c5bd20046,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-5a08904a-63cb-4e7a-8852-1ea2a5083805,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-a02f2e28-e146-4c82-a6d0-6cab0a713aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-202382b0-f97c-4623-bb7c-3cc4d0f83180,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-90f290c0-8127-4e30-a699-c3d7036938b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-92811b36-de96-43af-9bc9-69c46604f358,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-6004a26b-3591-48e1-9515-15589cd0e9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930280232-172.17.0.20-1596902500224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-e68264e7-0531-41f1-9bb4-d7fc9208ce13,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-663e9139-e255-4772-ba06-71d26d17d7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-e2b58858-ae67-4e3d-b8e9-c8f0392c57b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-f74f9b75-3907-4eaa-9109-a68b1f03d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-03069515-0393-4420-b052-3d9961690725,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-5098d5e3-cfb5-497c-8176-70ee279f09e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-1d3f2eae-7423-45c0-9be6-683e84597565,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-966bd956-f68f-464e-823a-84d11d121296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930280232-172.17.0.20-1596902500224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-e68264e7-0531-41f1-9bb4-d7fc9208ce13,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-663e9139-e255-4772-ba06-71d26d17d7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-e2b58858-ae67-4e3d-b8e9-c8f0392c57b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-f74f9b75-3907-4eaa-9109-a68b1f03d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-03069515-0393-4420-b052-3d9961690725,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-5098d5e3-cfb5-497c-8176-70ee279f09e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-1d3f2eae-7423-45c0-9be6-683e84597565,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-966bd956-f68f-464e-823a-84d11d121296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889431517-172.17.0.20-1596903292259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46196,DS-e5c51a3b-9f3d-4243-86ec-b4647092c425,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-c506a9c0-6f3d-43da-bb64-94774194dc13,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-8757856a-c5dd-40b3-900d-fd322e8ac097,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-39499455-dd8b-4f64-8c6e-9d730fb70c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-998222f0-f0d6-409b-ba31-4302de08e669,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-7f485702-eb21-41e8-b43d-67391c2363ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-aac2b8d3-4625-46d0-9914-904a7f0e0867,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-de238bb9-e14e-4adc-9981-c636a77a4ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889431517-172.17.0.20-1596903292259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46196,DS-e5c51a3b-9f3d-4243-86ec-b4647092c425,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-c506a9c0-6f3d-43da-bb64-94774194dc13,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-8757856a-c5dd-40b3-900d-fd322e8ac097,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-39499455-dd8b-4f64-8c6e-9d730fb70c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-998222f0-f0d6-409b-ba31-4302de08e669,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-7f485702-eb21-41e8-b43d-67391c2363ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-aac2b8d3-4625-46d0-9914-904a7f0e0867,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-de238bb9-e14e-4adc-9981-c636a77a4ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987279415-172.17.0.20-1596903421017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46312,DS-1a035fe5-db80-4b4a-8835-ad2cea50a6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-89eba73a-eb08-4074-8aba-7e826e3a212a,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-6c555e06-e490-4fbd-a46f-db2f755768fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-7f42d901-713d-4ca0-a803-e7c97243ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-ea2878b6-0981-4e19-9031-b67db2ebb8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-402c8d53-fa0d-482e-b0bb-999b9a2113e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-2843b78c-5deb-4f4a-a6af-cf609d37f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-c1d81080-20f1-4908-ad5c-4125dbe3ab7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987279415-172.17.0.20-1596903421017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46312,DS-1a035fe5-db80-4b4a-8835-ad2cea50a6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-89eba73a-eb08-4074-8aba-7e826e3a212a,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-6c555e06-e490-4fbd-a46f-db2f755768fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-7f42d901-713d-4ca0-a803-e7c97243ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-ea2878b6-0981-4e19-9031-b67db2ebb8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-402c8d53-fa0d-482e-b0bb-999b9a2113e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-2843b78c-5deb-4f4a-a6af-cf609d37f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-c1d81080-20f1-4908-ad5c-4125dbe3ab7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806229402-172.17.0.20-1596903455117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-ed3d0d4e-e4fc-4630-846b-756b55079569,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-1e3cae8c-9489-4503-bcd2-f6b6ed4d6a66,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-85626459-6322-417e-868f-ae7626900f58,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-898a452e-b4c3-45a2-a846-08a1343229aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-373b5efa-8258-4cbd-b761-5b1bb8ba2006,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-5e9188c3-9869-4833-861b-587f51459754,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-80e3ea5a-9a3e-4bee-b1e7-67d0e8d656c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-1fa03f08-cba5-46d6-b5e9-db62a7782e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806229402-172.17.0.20-1596903455117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-ed3d0d4e-e4fc-4630-846b-756b55079569,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-1e3cae8c-9489-4503-bcd2-f6b6ed4d6a66,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-85626459-6322-417e-868f-ae7626900f58,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-898a452e-b4c3-45a2-a846-08a1343229aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-373b5efa-8258-4cbd-b761-5b1bb8ba2006,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-5e9188c3-9869-4833-861b-587f51459754,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-80e3ea5a-9a3e-4bee-b1e7-67d0e8d656c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-1fa03f08-cba5-46d6-b5e9-db62a7782e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963768145-172.17.0.20-1596903738307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-048f7d65-6c57-4a73-a134-e1d49d997570,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-a5e88f05-8ef7-4033-9959-bbe41153b053,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-fa357bcc-ccae-454e-b517-0d4f997abc35,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-91e45bf4-1d11-4894-bf4b-3f0168093905,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-5e31e778-4169-460a-b1ee-a3805e3b33bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-b26ba86d-d29f-450b-bdc9-4400a707b97e,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-03749110-75f0-4e3e-a137-70b58ed559de,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-a8e44a51-0682-4a4e-9b26-9b6b3bb9934c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963768145-172.17.0.20-1596903738307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-048f7d65-6c57-4a73-a134-e1d49d997570,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-a5e88f05-8ef7-4033-9959-bbe41153b053,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-fa357bcc-ccae-454e-b517-0d4f997abc35,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-91e45bf4-1d11-4894-bf4b-3f0168093905,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-5e31e778-4169-460a-b1ee-a3805e3b33bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-b26ba86d-d29f-450b-bdc9-4400a707b97e,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-03749110-75f0-4e3e-a137-70b58ed559de,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-a8e44a51-0682-4a4e-9b26-9b6b3bb9934c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347681366-172.17.0.20-1596904012746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-b80273ea-b9d7-4a40-8cd8-29096d76ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-378d61eb-a955-4058-a301-a0cf3dd9a4de,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-eb4b02c1-1cda-404c-aa09-1f5137c5a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-a9356f1e-2972-4e1a-b556-536f60d4dcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-c2a8848d-a44a-404d-8c6d-d6a9d18d3627,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-4365d4ba-eaa3-4a85-bbeb-fad7023a5311,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-b9845a69-53bf-424b-ae39-112c56e1e629,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-cb1df848-53d9-4bb6-9586-58341d837fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347681366-172.17.0.20-1596904012746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-b80273ea-b9d7-4a40-8cd8-29096d76ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-378d61eb-a955-4058-a301-a0cf3dd9a4de,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-eb4b02c1-1cda-404c-aa09-1f5137c5a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-a9356f1e-2972-4e1a-b556-536f60d4dcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-c2a8848d-a44a-404d-8c6d-d6a9d18d3627,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-4365d4ba-eaa3-4a85-bbeb-fad7023a5311,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-b9845a69-53bf-424b-ae39-112c56e1e629,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-cb1df848-53d9-4bb6-9586-58341d837fb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721597214-172.17.0.20-1596904231048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35186,DS-f21a008e-a2e1-48a0-bcd6-440fb04ab379,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-fd5b8bc2-1364-4823-b604-124328add6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-713287a5-762b-4058-b561-ca345b20aecd,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-9c0da4ce-d26c-432a-83c2-15d672e52fed,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-47e31d93-61c8-4e93-90c2-13074b6b4634,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-d68a68db-2914-4dc7-b9f6-d2c04a2dec25,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-f1c072bb-c6c0-4165-96d4-b505e0a64862,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-60f8d642-bc82-4335-91fc-e46cc4190f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721597214-172.17.0.20-1596904231048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35186,DS-f21a008e-a2e1-48a0-bcd6-440fb04ab379,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-fd5b8bc2-1364-4823-b604-124328add6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-713287a5-762b-4058-b561-ca345b20aecd,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-9c0da4ce-d26c-432a-83c2-15d672e52fed,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-47e31d93-61c8-4e93-90c2-13074b6b4634,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-d68a68db-2914-4dc7-b9f6-d2c04a2dec25,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-f1c072bb-c6c0-4165-96d4-b505e0a64862,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-60f8d642-bc82-4335-91fc-e46cc4190f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051969413-172.17.0.20-1596904397244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-96378009-5d22-4aed-a080-f0a2f034e0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-37619814-83ac-4bc1-9ff4-2ddfdd63726e,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-eff6829a-c3ce-4fed-8533-6a1be3f6a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-595a670b-fc10-4ea0-8f2c-ced6d5c1ea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-84cb8392-4c7a-4568-aee0-c511ecc715d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-fbadd2c5-3dea-4d35-8148-335e21ebdb56,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-d20475ca-d5d1-4ad9-b1a3-75432dc1c117,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-f41a6b03-f9fc-4b8c-99d7-d78e96b2c04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051969413-172.17.0.20-1596904397244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-96378009-5d22-4aed-a080-f0a2f034e0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-37619814-83ac-4bc1-9ff4-2ddfdd63726e,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-eff6829a-c3ce-4fed-8533-6a1be3f6a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-595a670b-fc10-4ea0-8f2c-ced6d5c1ea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-84cb8392-4c7a-4568-aee0-c511ecc715d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-fbadd2c5-3dea-4d35-8148-335e21ebdb56,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-d20475ca-d5d1-4ad9-b1a3-75432dc1c117,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-f41a6b03-f9fc-4b8c-99d7-d78e96b2c04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995772634-172.17.0.20-1596904476557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-61ab69f7-1e03-449f-9133-0f981951e349,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-d700a0f8-80e2-4917-b55a-19182c0d0b48,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-e4742a01-51b1-4060-be82-fbd7f51e37db,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-4434cb2f-6ac0-451f-b01d-4a4b01c33115,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-f6f01966-9b0b-467f-bc8f-5223e60ee52c,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-66eb4119-36d8-4bb1-8677-868f3af68d47,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-8820e898-4320-4357-ad73-82ec3f215bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-0d9362f3-2d40-4dfc-b2eb-b12a34e7f303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995772634-172.17.0.20-1596904476557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-61ab69f7-1e03-449f-9133-0f981951e349,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-d700a0f8-80e2-4917-b55a-19182c0d0b48,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-e4742a01-51b1-4060-be82-fbd7f51e37db,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-4434cb2f-6ac0-451f-b01d-4a4b01c33115,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-f6f01966-9b0b-467f-bc8f-5223e60ee52c,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-66eb4119-36d8-4bb1-8677-868f3af68d47,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-8820e898-4320-4357-ad73-82ec3f215bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-0d9362f3-2d40-4dfc-b2eb-b12a34e7f303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951279222-172.17.0.20-1596904920621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-49e80212-5bc5-4fef-8270-72606fa7e2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-5c51c9ba-45f4-4c25-8fca-f1dcb980e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-4f7d43a1-509e-4d8a-a866-5809912d9b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-2cf481bc-e3f3-4c49-a373-6ffa73e84ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-ad7d8484-b872-41a4-95f6-77a454d68685,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-f8d39304-4629-4c9a-9f82-20900ffa5e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-c8ce646b-9dad-4a12-8f72-fea3f6f096a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-403e874a-f01d-4f4a-9be7-f36ab1aaff9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951279222-172.17.0.20-1596904920621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-49e80212-5bc5-4fef-8270-72606fa7e2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-5c51c9ba-45f4-4c25-8fca-f1dcb980e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-4f7d43a1-509e-4d8a-a866-5809912d9b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-2cf481bc-e3f3-4c49-a373-6ffa73e84ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-ad7d8484-b872-41a4-95f6-77a454d68685,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-f8d39304-4629-4c9a-9f82-20900ffa5e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-c8ce646b-9dad-4a12-8f72-fea3f6f096a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-403e874a-f01d-4f4a-9be7-f36ab1aaff9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932249962-172.17.0.20-1596904994387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-a9ce9c73-948c-4e3e-938b-9b5ac95f5b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-df7087a3-7827-4ec2-862f-bfcf709f9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-134ddad1-96b8-4986-baf8-9cae1b03a839,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-70c5838c-038e-48d1-a74f-29a4ab3cebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-1cd83af5-91dc-492d-98c9-0764b6a2809a,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-abbc1308-7216-4bcc-b39c-d2ee01fb0740,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-a37c0d6c-42f5-418d-ab94-a07938cb48dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-5e1f1b3f-99f3-4b7a-bbd8-267894c05b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932249962-172.17.0.20-1596904994387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-a9ce9c73-948c-4e3e-938b-9b5ac95f5b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-df7087a3-7827-4ec2-862f-bfcf709f9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-134ddad1-96b8-4986-baf8-9cae1b03a839,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-70c5838c-038e-48d1-a74f-29a4ab3cebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-1cd83af5-91dc-492d-98c9-0764b6a2809a,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-abbc1308-7216-4bcc-b39c-d2ee01fb0740,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-a37c0d6c-42f5-418d-ab94-a07938cb48dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-5e1f1b3f-99f3-4b7a-bbd8-267894c05b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764238544-172.17.0.20-1596905585793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-b3a318db-d5d7-4e2e-931d-73e3df900d67,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-f82d1be1-0f17-4a69-9c79-6c66e51b2d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-ec2ecb7e-09cc-4d80-a9ab-411669d1917d,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-4be07bfc-5a96-4c97-8f31-ea38ced01e18,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-79f7a423-17ae-4dba-bfc4-a686f8a2c638,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-a602b68c-3649-4371-8e3f-9037de2b644d,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-759f29df-24ac-432f-b6cf-bf3025e01a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a4f9b847-059a-4e7f-9fde-fa534ebc5d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764238544-172.17.0.20-1596905585793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-b3a318db-d5d7-4e2e-931d-73e3df900d67,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-f82d1be1-0f17-4a69-9c79-6c66e51b2d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-ec2ecb7e-09cc-4d80-a9ab-411669d1917d,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-4be07bfc-5a96-4c97-8f31-ea38ced01e18,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-79f7a423-17ae-4dba-bfc4-a686f8a2c638,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-a602b68c-3649-4371-8e3f-9037de2b644d,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-759f29df-24ac-432f-b6cf-bf3025e01a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a4f9b847-059a-4e7f-9fde-fa534ebc5d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603351031-172.17.0.20-1596905619615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38074,DS-4c98cb2a-d517-4e3a-8330-5a5cab16dab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-f6c31bcf-be02-4ce4-a22a-d138291557b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-7aab9ab5-ed2f-4fac-9a4c-77b3a4136f89,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-2d3e4fdf-f35b-4d2e-839e-2a468078fb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-4c618013-0c36-4f41-b312-c68f6000d71f,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-e0d76aad-97f7-4766-97d5-3e7329ef7e68,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-40d71970-0a51-4515-ba21-62418a82722f,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-6521d1f9-c914-459c-b9bf-a5bb2440244a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603351031-172.17.0.20-1596905619615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38074,DS-4c98cb2a-d517-4e3a-8330-5a5cab16dab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-f6c31bcf-be02-4ce4-a22a-d138291557b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-7aab9ab5-ed2f-4fac-9a4c-77b3a4136f89,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-2d3e4fdf-f35b-4d2e-839e-2a468078fb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-4c618013-0c36-4f41-b312-c68f6000d71f,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-e0d76aad-97f7-4766-97d5-3e7329ef7e68,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-40d71970-0a51-4515-ba21-62418a82722f,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-6521d1f9-c914-459c-b9bf-a5bb2440244a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13132344-172.17.0.20-1596905657160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34220,DS-0e15c6b8-d4e2-40fa-954d-2853d9d850e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-ff9765df-5bba-4633-a328-6a6491af001e,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-7b411502-2cf4-4184-991a-4a402b7d3381,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-148ce481-aa73-45e8-8072-dfe5c844ea01,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-e42cb9ac-2e99-44f5-bed7-9dc6023c60b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-4a43a831-18d7-42c1-8dad-8981fffbbd30,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-0e559979-eeda-438d-acb0-9b03334305a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-89193914-73bb-4bbc-b196-0e240d3799b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13132344-172.17.0.20-1596905657160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34220,DS-0e15c6b8-d4e2-40fa-954d-2853d9d850e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-ff9765df-5bba-4633-a328-6a6491af001e,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-7b411502-2cf4-4184-991a-4a402b7d3381,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-148ce481-aa73-45e8-8072-dfe5c844ea01,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-e42cb9ac-2e99-44f5-bed7-9dc6023c60b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-4a43a831-18d7-42c1-8dad-8981fffbbd30,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-0e559979-eeda-438d-acb0-9b03334305a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-89193914-73bb-4bbc-b196-0e240d3799b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396002957-172.17.0.20-1596905776583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38969,DS-a632882b-35a3-48b6-b5f9-c0a14f959ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-10ca1cdb-11e7-48af-a4fc-ed090c5fd0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-876563f1-200c-4745-86b4-299652a640ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-4796181c-8cbe-4189-9458-02d284d3ed5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-687f0931-d309-46e0-8c05-610d4e1ea8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-43b38523-0af7-45df-92bb-086fddeb90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-a9b9aedc-16f0-4aa0-80f3-d5c01197c48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-ad58a350-e3c7-495d-a5f3-f90e56081fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396002957-172.17.0.20-1596905776583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38969,DS-a632882b-35a3-48b6-b5f9-c0a14f959ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-10ca1cdb-11e7-48af-a4fc-ed090c5fd0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-876563f1-200c-4745-86b4-299652a640ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-4796181c-8cbe-4189-9458-02d284d3ed5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-687f0931-d309-46e0-8c05-610d4e1ea8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-43b38523-0af7-45df-92bb-086fddeb90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-a9b9aedc-16f0-4aa0-80f3-d5c01197c48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-ad58a350-e3c7-495d-a5f3-f90e56081fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384284326-172.17.0.20-1596906001328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-475d8a00-d2a9-44ba-aa31-61e8922953ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-0f98fe03-f3e9-401f-be37-4ba6d8239cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-5988e889-1357-4cd6-9836-912d3a723f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-174deb55-f75d-4726-ade6-7338814097fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-12fcec24-d3ed-409d-9b16-6a6bdb804e06,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-86a67232-7958-49f1-b33c-49a212b45bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-00bb716d-f951-4e1a-b568-b6f38da7ae56,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-7f093799-0c04-4f38-ac54-61e058e34e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384284326-172.17.0.20-1596906001328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-475d8a00-d2a9-44ba-aa31-61e8922953ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-0f98fe03-f3e9-401f-be37-4ba6d8239cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-5988e889-1357-4cd6-9836-912d3a723f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-174deb55-f75d-4726-ade6-7338814097fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-12fcec24-d3ed-409d-9b16-6a6bdb804e06,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-86a67232-7958-49f1-b33c-49a212b45bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-00bb716d-f951-4e1a-b568-b6f38da7ae56,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-7f093799-0c04-4f38-ac54-61e058e34e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250118836-172.17.0.20-1596906290395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35979,DS-a0b15dd9-eb99-4a19-864b-d8b80aa4fd64,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-f52762e9-e4e8-4394-a26b-bd07bc84ef28,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-0944a716-2690-4f56-9b5b-98c6f93f9fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-d9a176c5-089d-443e-84e3-35e9fece1475,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-746efb4f-fa26-4864-a099-637fc69ea0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-fb6cfef6-346c-4f41-9e0c-c586da3bbb45,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-df31ce4e-3961-4aad-85f8-76693c0e24ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-3fd2b62c-e4c9-4bf5-b6d0-6bf3ea89dce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250118836-172.17.0.20-1596906290395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35979,DS-a0b15dd9-eb99-4a19-864b-d8b80aa4fd64,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-f52762e9-e4e8-4394-a26b-bd07bc84ef28,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-0944a716-2690-4f56-9b5b-98c6f93f9fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-d9a176c5-089d-443e-84e3-35e9fece1475,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-746efb4f-fa26-4864-a099-637fc69ea0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-fb6cfef6-346c-4f41-9e0c-c586da3bbb45,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-df31ce4e-3961-4aad-85f8-76693c0e24ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-3fd2b62c-e4c9-4bf5-b6d0-6bf3ea89dce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698461286-172.17.0.20-1596906599454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-2c177de3-34c7-45be-be8c-5f6e33a7b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-7def7466-c9b2-461a-b212-c7086a8c906c,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-d2fdcb8d-f8cf-4770-9610-c20fac641e80,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-3443255c-4c73-4dc8-9cda-11fdba1e4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-1d5c2d6e-9822-4b0e-9afe-69b222a61390,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-bcfa7e37-ca8d-4d36-b39b-a29e87a99b97,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-e6f68688-4fe9-474a-bcff-c99a9c0bc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-7a5df243-4d52-4e81-bed4-08e2824cd0f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698461286-172.17.0.20-1596906599454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-2c177de3-34c7-45be-be8c-5f6e33a7b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-7def7466-c9b2-461a-b212-c7086a8c906c,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-d2fdcb8d-f8cf-4770-9610-c20fac641e80,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-3443255c-4c73-4dc8-9cda-11fdba1e4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-1d5c2d6e-9822-4b0e-9afe-69b222a61390,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-bcfa7e37-ca8d-4d36-b39b-a29e87a99b97,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-e6f68688-4fe9-474a-bcff-c99a9c0bc2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-7a5df243-4d52-4e81-bed4-08e2824cd0f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5531
