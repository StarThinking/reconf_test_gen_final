reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439065041-172.17.0.15-1596935783402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-c3a2a831-456c-408a-aa2a-6d0c838d5e40,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-86c2bdc5-c6a2-4198-96d6-41c94bfe27a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-886c667f-3338-466f-ae22-281593dbe3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-b82ffdbd-760b-4406-8a5d-8834bdf0edb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-2e4263c9-562a-44fe-a9e2-cf31ed68d964,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-6151b2ac-37f3-45ce-af80-37ebc464fc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-27009659-299c-4d1f-a650-f8f6e600de33,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-8f63a729-77e4-4968-ac88-cbdf511fa46e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439065041-172.17.0.15-1596935783402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-c3a2a831-456c-408a-aa2a-6d0c838d5e40,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-86c2bdc5-c6a2-4198-96d6-41c94bfe27a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-886c667f-3338-466f-ae22-281593dbe3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-b82ffdbd-760b-4406-8a5d-8834bdf0edb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-2e4263c9-562a-44fe-a9e2-cf31ed68d964,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-6151b2ac-37f3-45ce-af80-37ebc464fc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-27009659-299c-4d1f-a650-f8f6e600de33,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-8f63a729-77e4-4968-ac88-cbdf511fa46e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124612910-172.17.0.15-1596936236816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-bd717d00-2bd8-44f3-9a6e-b9fb04b8fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-9a0ecacc-4383-4e1c-b2f4-ae437b78d260,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-950a3ed4-159a-4d4d-b41b-875c7f22ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-67e214c8-a1a7-4935-add8-153c21cd177e,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-a9630daa-0c28-4a20-94c3-41d2359563af,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-ede9dcab-2c6f-4c7e-89e9-168642d8a4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-16b8343f-17cc-4ab9-80bb-2181100335d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-db7ce003-6da2-4d79-ac15-bad2181ea9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124612910-172.17.0.15-1596936236816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-bd717d00-2bd8-44f3-9a6e-b9fb04b8fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-9a0ecacc-4383-4e1c-b2f4-ae437b78d260,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-950a3ed4-159a-4d4d-b41b-875c7f22ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-67e214c8-a1a7-4935-add8-153c21cd177e,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-a9630daa-0c28-4a20-94c3-41d2359563af,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-ede9dcab-2c6f-4c7e-89e9-168642d8a4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-16b8343f-17cc-4ab9-80bb-2181100335d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-db7ce003-6da2-4d79-ac15-bad2181ea9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906351235-172.17.0.15-1596936921589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43594,DS-275d9241-b4d1-4506-9c44-037d2856b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-265599f2-42cb-42a7-99f9-c251fbe26f75,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-4bf8b706-7074-4ca7-afdf-a485c72c753e,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-bab8c80b-438e-49e5-82fb-053d98e58095,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-3a725cd6-7561-4fef-985f-b846bb7af40b,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-7f57163d-3531-4ad9-8765-dda4768bb801,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-7c127d6c-306b-4ee4-8a30-843cc5a72c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-dfc5a268-1d12-4c4e-bbf7-ebfba9fb8075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906351235-172.17.0.15-1596936921589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43594,DS-275d9241-b4d1-4506-9c44-037d2856b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-265599f2-42cb-42a7-99f9-c251fbe26f75,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-4bf8b706-7074-4ca7-afdf-a485c72c753e,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-bab8c80b-438e-49e5-82fb-053d98e58095,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-3a725cd6-7561-4fef-985f-b846bb7af40b,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-7f57163d-3531-4ad9-8765-dda4768bb801,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-7c127d6c-306b-4ee4-8a30-843cc5a72c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-dfc5a268-1d12-4c4e-bbf7-ebfba9fb8075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056322306-172.17.0.15-1596937169962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34533,DS-6095afdd-c3e2-40b8-ac97-b5d7eb32d87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-5ca4f5a1-1d0d-4a16-a0bc-65888b57ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-a6cb5792-5b77-4d91-9c89-6580c0f71450,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-c204912b-f347-4466-ab04-8d7d23778311,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-f5273f14-c668-4d0e-88f3-a68e1893414a,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-2ad5efaf-29a2-4552-8a2a-8b4d44899a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-7908700f-86b3-408d-9649-11474124155b,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-19b9fc27-6fac-4db4-b4b1-f30e7da043ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056322306-172.17.0.15-1596937169962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34533,DS-6095afdd-c3e2-40b8-ac97-b5d7eb32d87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-5ca4f5a1-1d0d-4a16-a0bc-65888b57ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-a6cb5792-5b77-4d91-9c89-6580c0f71450,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-c204912b-f347-4466-ab04-8d7d23778311,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-f5273f14-c668-4d0e-88f3-a68e1893414a,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-2ad5efaf-29a2-4552-8a2a-8b4d44899a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-7908700f-86b3-408d-9649-11474124155b,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-19b9fc27-6fac-4db4-b4b1-f30e7da043ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444962749-172.17.0.15-1596937406078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-108e85da-3d88-46f4-8741-51724d19b329,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-d97bb364-dd1a-422f-b340-043f2b462323,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-3e38e6ac-0c31-4632-8171-a826813fe23a,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-754e100c-8b5b-4677-9d06-41025a42d810,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-e6eb6ea6-1da9-4779-8d08-5a3df41786f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-c99936e7-afdc-47b0-8390-d8f71725167c,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-a47cabfd-54e5-4ea8-82aa-c907b7820f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-6d94f56c-9e38-4b07-8579-0bd9e3dbf937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444962749-172.17.0.15-1596937406078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-108e85da-3d88-46f4-8741-51724d19b329,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-d97bb364-dd1a-422f-b340-043f2b462323,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-3e38e6ac-0c31-4632-8171-a826813fe23a,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-754e100c-8b5b-4677-9d06-41025a42d810,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-e6eb6ea6-1da9-4779-8d08-5a3df41786f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-c99936e7-afdc-47b0-8390-d8f71725167c,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-a47cabfd-54e5-4ea8-82aa-c907b7820f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-6d94f56c-9e38-4b07-8579-0bd9e3dbf937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583283818-172.17.0.15-1596937600641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45669,DS-9ef994a2-295a-4575-8779-cfbd46841533,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-47b320c7-0e63-4e9b-a3e6-4f11a01f5964,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-58691420-f54e-47d9-9d21-06c7d63d05e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-9e3cb1ad-2195-44f7-a812-11ebaa627eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-26f27565-aa62-41e4-8c38-940e29647c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-c76e3d16-2f69-4be3-9870-91c1a934f022,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-053bd0ff-c539-4273-a656-8a52014b996d,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-ef56907f-b305-4f8d-8120-2aa7f56a29e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583283818-172.17.0.15-1596937600641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45669,DS-9ef994a2-295a-4575-8779-cfbd46841533,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-47b320c7-0e63-4e9b-a3e6-4f11a01f5964,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-58691420-f54e-47d9-9d21-06c7d63d05e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-9e3cb1ad-2195-44f7-a812-11ebaa627eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-26f27565-aa62-41e4-8c38-940e29647c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-c76e3d16-2f69-4be3-9870-91c1a934f022,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-053bd0ff-c539-4273-a656-8a52014b996d,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-ef56907f-b305-4f8d-8120-2aa7f56a29e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424194170-172.17.0.15-1596937641677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41824,DS-2f2e6be3-fde8-44f6-a437-fa0856803d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-4b15595c-03d8-4144-8d4d-a1bbf4692630,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-68d19f14-f029-4cc7-a424-89f862e47501,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-fe4fd7d2-3046-4f80-a534-fbf37c9e6525,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-8a37ef0b-9adb-4ace-a846-59fceeac75dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-71250780-572c-42af-9a92-89cc867b632c,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-66e20619-92e7-4d24-81cf-d493930bc142,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-13af5661-fea8-4a50-8e43-0e567444ec05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424194170-172.17.0.15-1596937641677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41824,DS-2f2e6be3-fde8-44f6-a437-fa0856803d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-4b15595c-03d8-4144-8d4d-a1bbf4692630,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-68d19f14-f029-4cc7-a424-89f862e47501,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-fe4fd7d2-3046-4f80-a534-fbf37c9e6525,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-8a37ef0b-9adb-4ace-a846-59fceeac75dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-71250780-572c-42af-9a92-89cc867b632c,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-66e20619-92e7-4d24-81cf-d493930bc142,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-13af5661-fea8-4a50-8e43-0e567444ec05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261167146-172.17.0.15-1596937728869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-667c7f5c-4ce7-446f-81d2-9a126f2ea966,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-ef7676d0-c2b2-4795-9b36-b661e903576c,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-992caea7-05df-4ab7-b585-ed85b651c515,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-ae186e65-7d33-496f-bb85-cae9e413b716,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-7688ccbd-b9e4-4c45-b90a-f2ae9aa5a9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-a6ddf92c-2aeb-47e0-ac80-11f7b3db94ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-2587c130-2f3f-4ea4-bc0a-3ffb50774d74,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-f6dbc0f4-a4d4-40c1-88eb-76b95ca0e3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261167146-172.17.0.15-1596937728869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-667c7f5c-4ce7-446f-81d2-9a126f2ea966,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-ef7676d0-c2b2-4795-9b36-b661e903576c,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-992caea7-05df-4ab7-b585-ed85b651c515,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-ae186e65-7d33-496f-bb85-cae9e413b716,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-7688ccbd-b9e4-4c45-b90a-f2ae9aa5a9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-a6ddf92c-2aeb-47e0-ac80-11f7b3db94ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-2587c130-2f3f-4ea4-bc0a-3ffb50774d74,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-f6dbc0f4-a4d4-40c1-88eb-76b95ca0e3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675365277-172.17.0.15-1596938260283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-5d28e38e-70ed-45ef-9291-2b86d18a4c52,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-d463a125-8829-4531-b9ac-f2aac2e3a447,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-ecbd6cb1-55ee-4fd0-88ca-e31e78afdeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-2c7970b9-4e85-4b60-963e-22c97e229bba,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-a4ce71b3-0b52-4c22-9a04-a9e9e8d5fb19,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-c23bb296-1b38-4f97-bbc2-b4ada63e0789,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-a9531572-c57a-4088-8c57-21e429f1c6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-540fadff-8b62-4f1b-9140-104e8a535bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675365277-172.17.0.15-1596938260283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-5d28e38e-70ed-45ef-9291-2b86d18a4c52,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-d463a125-8829-4531-b9ac-f2aac2e3a447,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-ecbd6cb1-55ee-4fd0-88ca-e31e78afdeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-2c7970b9-4e85-4b60-963e-22c97e229bba,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-a4ce71b3-0b52-4c22-9a04-a9e9e8d5fb19,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-c23bb296-1b38-4f97-bbc2-b4ada63e0789,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-a9531572-c57a-4088-8c57-21e429f1c6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-540fadff-8b62-4f1b-9140-104e8a535bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459003018-172.17.0.15-1596938342669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-e3ad4e06-763d-4407-8591-cc8de3ae90c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-94191ce9-129d-4e3c-ab09-35a9b565524f,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-fbea3b77-ca56-473b-8566-c792994c5aff,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-6a86fafa-7d3a-4425-8502-6643d509aff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-a5027714-2b70-448e-8628-af9578d44c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-074aebfd-f7f9-4177-b1b1-c967981f7c49,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-59e527fa-1ae6-4108-8532-4f126377acca,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-e75f640f-c1db-4937-ab49-55705f0cc436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459003018-172.17.0.15-1596938342669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-e3ad4e06-763d-4407-8591-cc8de3ae90c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-94191ce9-129d-4e3c-ab09-35a9b565524f,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-fbea3b77-ca56-473b-8566-c792994c5aff,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-6a86fafa-7d3a-4425-8502-6643d509aff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-a5027714-2b70-448e-8628-af9578d44c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-074aebfd-f7f9-4177-b1b1-c967981f7c49,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-59e527fa-1ae6-4108-8532-4f126377acca,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-e75f640f-c1db-4937-ab49-55705f0cc436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306604232-172.17.0.15-1596939623680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-ce22f2bd-db8e-48c4-a6a3-1761f3a2c575,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-5eabda93-78f2-44b4-b29b-7f03d4efba90,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-3107c292-b69f-4f61-bb4f-af22370f6cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-e70c01db-0c49-48c3-a224-c32aa308940f,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-221825b2-dc06-4ee0-98d7-060783199d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-36b6b08b-5885-4d10-b642-9bf649f872cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-3f2ecf9c-f94f-4266-9b7c-4f61a90e9540,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-bedad415-4acd-4962-9e24-488b63ab2adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306604232-172.17.0.15-1596939623680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-ce22f2bd-db8e-48c4-a6a3-1761f3a2c575,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-5eabda93-78f2-44b4-b29b-7f03d4efba90,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-3107c292-b69f-4f61-bb4f-af22370f6cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-e70c01db-0c49-48c3-a224-c32aa308940f,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-221825b2-dc06-4ee0-98d7-060783199d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-36b6b08b-5885-4d10-b642-9bf649f872cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-3f2ecf9c-f94f-4266-9b7c-4f61a90e9540,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-bedad415-4acd-4962-9e24-488b63ab2adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228322172-172.17.0.15-1596939897217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-8a659919-c913-4f4d-98b6-b682701d93d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-efe2c170-cad4-4685-98fd-961f3ad4229f,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-36ed7020-0b19-46cc-aab4-9931c8c66482,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-cf520976-fd7d-484d-82b0-c12407a51d33,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-a0d389a6-6bce-4e39-b2e4-7b0f6ba79ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-4a11876c-f4fb-47cd-9b99-1d135f64a208,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-758606f7-c221-4abe-a778-eccb036ea589,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ad37371d-e7e4-4677-bf56-0da4ea356c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228322172-172.17.0.15-1596939897217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-8a659919-c913-4f4d-98b6-b682701d93d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-efe2c170-cad4-4685-98fd-961f3ad4229f,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-36ed7020-0b19-46cc-aab4-9931c8c66482,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-cf520976-fd7d-484d-82b0-c12407a51d33,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-a0d389a6-6bce-4e39-b2e4-7b0f6ba79ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-4a11876c-f4fb-47cd-9b99-1d135f64a208,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-758606f7-c221-4abe-a778-eccb036ea589,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ad37371d-e7e4-4677-bf56-0da4ea356c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872249808-172.17.0.15-1596940074259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35405,DS-09c1902d-d7d9-4a89-9131-e19570f7ce06,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-5ad04e7e-4a7a-4d1e-9096-e27380fe95aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-7e3df388-df39-41a7-a2f8-7202eee480f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-df6419f2-62c1-432f-8a11-2d2671cab06d,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-1babc0bd-45fd-4014-9774-66d8bfc79f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-493e4b1c-7edd-4a58-b622-6d2b2b393a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-7444bd6f-7345-4221-8194-7dddd720d801,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-37e373f1-33c0-46f2-93e1-c307c35a2c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872249808-172.17.0.15-1596940074259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35405,DS-09c1902d-d7d9-4a89-9131-e19570f7ce06,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-5ad04e7e-4a7a-4d1e-9096-e27380fe95aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-7e3df388-df39-41a7-a2f8-7202eee480f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-df6419f2-62c1-432f-8a11-2d2671cab06d,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-1babc0bd-45fd-4014-9774-66d8bfc79f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-493e4b1c-7edd-4a58-b622-6d2b2b393a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-7444bd6f-7345-4221-8194-7dddd720d801,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-37e373f1-33c0-46f2-93e1-c307c35a2c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447493349-172.17.0.15-1596940436637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-a84be4f3-c8c2-43b0-805d-abba737582e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-a2b59446-f28a-4f02-bbab-73c68b8d74d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-abc4d3a6-74d4-4d6b-a5f7-a9b459c7352f,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-760ea16c-97cd-4fef-a101-84da27070bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-8ea7cc10-47ff-4a01-a3fc-e420e8b2b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-eb7228c3-7e2a-4ea4-aaf0-a69a98f8d304,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-14601887-521a-45b9-86b1-a6e2726b2468,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-bb1397cd-272c-426b-920a-eea68c6cfdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447493349-172.17.0.15-1596940436637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-a84be4f3-c8c2-43b0-805d-abba737582e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-a2b59446-f28a-4f02-bbab-73c68b8d74d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-abc4d3a6-74d4-4d6b-a5f7-a9b459c7352f,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-760ea16c-97cd-4fef-a101-84da27070bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-8ea7cc10-47ff-4a01-a3fc-e420e8b2b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-eb7228c3-7e2a-4ea4-aaf0-a69a98f8d304,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-14601887-521a-45b9-86b1-a6e2726b2468,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-bb1397cd-272c-426b-920a-eea68c6cfdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870024288-172.17.0.15-1596940994049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-4bdf7f37-4e49-46a7-8942-ed8f0c6b3fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-cea3af3f-7e47-4eb8-91f0-0f35b09ce8df,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-aaa0c884-3975-4805-b609-8a759fa2d87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-f561e8cc-104a-4a1b-aa21-42a01a595a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-2a1cdfd4-ea60-47c5-9b70-77232428d91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-845d9b13-388d-426f-9aea-3f4caaf98ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-5762f404-e195-47df-b427-73e07746d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-a7d8763c-6cca-475a-9ac2-9e7669289ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870024288-172.17.0.15-1596940994049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-4bdf7f37-4e49-46a7-8942-ed8f0c6b3fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-cea3af3f-7e47-4eb8-91f0-0f35b09ce8df,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-aaa0c884-3975-4805-b609-8a759fa2d87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-f561e8cc-104a-4a1b-aa21-42a01a595a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-2a1cdfd4-ea60-47c5-9b70-77232428d91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-845d9b13-388d-426f-9aea-3f4caaf98ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-5762f404-e195-47df-b427-73e07746d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-a7d8763c-6cca-475a-9ac2-9e7669289ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428454044-172.17.0.15-1596941362035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-8d352858-9c9e-45f9-a95d-d8afe06456fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-038619e5-a78a-4997-8a65-71bb7191da8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-aa7a0a19-2e0e-4a3c-a1e2-e45bc60a6576,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-0b4a41e0-9be5-4256-a461-828debba46b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-fac22755-43ed-420b-9cab-8ad0712ada65,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-54574f91-93f5-4aa7-b9be-aca3ded329bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-8e81de73-29ff-40b9-8e5c-7e2382b8306b,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d3213431-6976-4b93-ad9e-132075cc365b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428454044-172.17.0.15-1596941362035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-8d352858-9c9e-45f9-a95d-d8afe06456fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-038619e5-a78a-4997-8a65-71bb7191da8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-aa7a0a19-2e0e-4a3c-a1e2-e45bc60a6576,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-0b4a41e0-9be5-4256-a461-828debba46b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-fac22755-43ed-420b-9cab-8ad0712ada65,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-54574f91-93f5-4aa7-b9be-aca3ded329bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-8e81de73-29ff-40b9-8e5c-7e2382b8306b,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d3213431-6976-4b93-ad9e-132075cc365b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453007719-172.17.0.15-1596941398019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33491,DS-4d9fb3cf-c6f3-498d-b374-c19ae30d9aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-391c0d58-1e51-4aff-a309-4f4ac9b1e419,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-969af5e7-130f-41a3-8a76-775c9f4021df,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-14861797-15f5-4720-82cb-801f8d8d70f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-8b19ef8c-9a3c-4ef4-a953-86a7de7c08d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-95d98024-46f1-4bca-9d99-a77c7d20eee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-3e9d3db3-7dc5-42bd-98ae-533e8ffe9a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-4e00b07a-fb2a-4aee-8dff-5640f090bafe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453007719-172.17.0.15-1596941398019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33491,DS-4d9fb3cf-c6f3-498d-b374-c19ae30d9aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-391c0d58-1e51-4aff-a309-4f4ac9b1e419,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-969af5e7-130f-41a3-8a76-775c9f4021df,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-14861797-15f5-4720-82cb-801f8d8d70f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-8b19ef8c-9a3c-4ef4-a953-86a7de7c08d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-95d98024-46f1-4bca-9d99-a77c7d20eee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-3e9d3db3-7dc5-42bd-98ae-533e8ffe9a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-4e00b07a-fb2a-4aee-8dff-5640f090bafe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6659
