reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658051654-172.17.0.11-1596933915596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-adcf851a-a83d-49f6-a233-ad2d066b95ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-0ad65905-26ac-4918-ba50-3547393d9bed,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-dfc7c2be-b87e-4685-be0b-4b2bfbed86a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-b46db5b0-8a83-44c4-9930-8ea78263c121,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-06ad43d8-a07c-4d19-b91a-d58aa46997b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-1f8a7fe0-d161-498f-b12e-ab49ef5b3829,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-b2a9e49d-06e2-48e7-8cb5-cba7c8c1acb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-31c2c6e9-e59b-4a03-bdd4-9a1c6d8538f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658051654-172.17.0.11-1596933915596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-adcf851a-a83d-49f6-a233-ad2d066b95ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-0ad65905-26ac-4918-ba50-3547393d9bed,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-dfc7c2be-b87e-4685-be0b-4b2bfbed86a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-b46db5b0-8a83-44c4-9930-8ea78263c121,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-06ad43d8-a07c-4d19-b91a-d58aa46997b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-1f8a7fe0-d161-498f-b12e-ab49ef5b3829,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-b2a9e49d-06e2-48e7-8cb5-cba7c8c1acb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-31c2c6e9-e59b-4a03-bdd4-9a1c6d8538f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977622334-172.17.0.11-1596934783507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43536,DS-6fbb8b63-0b4a-479c-bb22-c3d1a46b9ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-2e417773-cc42-4735-bf59-ca8af22e745d,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-c3e3a2bb-a35e-4e1f-8b80-00f9a7818347,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-979326ac-7bab-4b8c-b038-257a25b1d243,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-c3d4b552-6a71-4f43-9e55-50d830d623c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-781c1ac5-95ec-45ab-9f22-1b48a4b7771f,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-188312fd-4a90-4c86-b0ed-12ec1c993279,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-840d5d31-4cf4-4223-9dae-1dde9eb66036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977622334-172.17.0.11-1596934783507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43536,DS-6fbb8b63-0b4a-479c-bb22-c3d1a46b9ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-2e417773-cc42-4735-bf59-ca8af22e745d,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-c3e3a2bb-a35e-4e1f-8b80-00f9a7818347,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-979326ac-7bab-4b8c-b038-257a25b1d243,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-c3d4b552-6a71-4f43-9e55-50d830d623c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-781c1ac5-95ec-45ab-9f22-1b48a4b7771f,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-188312fd-4a90-4c86-b0ed-12ec1c993279,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-840d5d31-4cf4-4223-9dae-1dde9eb66036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240848333-172.17.0.11-1596935559857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-60600cc3-7eaf-44ea-8c19-9be1e5846745,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-f38bccd3-2348-4373-8b02-fa05d2eed94d,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-77fe81a9-51ac-486c-9b54-0bdc99f196ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-d91cf19f-3ffd-42e1-97f4-054574611612,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-ef75e5a6-c1a8-4d2d-a147-d469fc646442,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-5e14457b-0338-4880-8127-16b2bc042998,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-a5d043bf-a5c1-488d-9ddf-a282b67f34e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-84916f5b-0c48-4595-b596-d03a54132e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240848333-172.17.0.11-1596935559857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-60600cc3-7eaf-44ea-8c19-9be1e5846745,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-f38bccd3-2348-4373-8b02-fa05d2eed94d,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-77fe81a9-51ac-486c-9b54-0bdc99f196ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-d91cf19f-3ffd-42e1-97f4-054574611612,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-ef75e5a6-c1a8-4d2d-a147-d469fc646442,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-5e14457b-0338-4880-8127-16b2bc042998,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-a5d043bf-a5c1-488d-9ddf-a282b67f34e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-84916f5b-0c48-4595-b596-d03a54132e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114845752-172.17.0.11-1596935806585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35042,DS-b5d754dc-f2a3-4418-9cdb-7a9d44fee3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-a5432dcc-b5b6-4cdc-a480-4d89a6261463,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-45d5c1a4-e1c8-460a-91a4-e9d5b9010d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-d7f88406-54cb-42b3-8f2b-3d7c51f50c13,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-bb09901a-4d62-4496-b897-08af17ae0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-31c06d30-aaf5-4c4d-9b28-13c0a32741e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-ab7f5098-f827-43a4-bc0d-15fba91cea1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-04f923cc-9736-4c18-b88f-238042805a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114845752-172.17.0.11-1596935806585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35042,DS-b5d754dc-f2a3-4418-9cdb-7a9d44fee3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-a5432dcc-b5b6-4cdc-a480-4d89a6261463,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-45d5c1a4-e1c8-460a-91a4-e9d5b9010d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-d7f88406-54cb-42b3-8f2b-3d7c51f50c13,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-bb09901a-4d62-4496-b897-08af17ae0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-31c06d30-aaf5-4c4d-9b28-13c0a32741e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-ab7f5098-f827-43a4-bc0d-15fba91cea1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-04f923cc-9736-4c18-b88f-238042805a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55676273-172.17.0.11-1596935853417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-374c4e45-d39d-4e02-8907-50c7295c10d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-32225a5c-72f5-45db-8370-6c97bd9389b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-75b7dd0f-f082-4404-988c-a1e0255102c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-1ad1af9b-8df9-4627-b114-30c146e1c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-9a5c65e4-7138-4fb6-a7ff-f3165f330b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-9a233155-fb41-42ff-8222-11aec0fd720d,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-d6e9f27e-62b0-491d-8a8a-9e7395bd892d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-3217e97a-1459-4957-868d-8ba244e3a954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55676273-172.17.0.11-1596935853417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-374c4e45-d39d-4e02-8907-50c7295c10d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-32225a5c-72f5-45db-8370-6c97bd9389b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-75b7dd0f-f082-4404-988c-a1e0255102c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-1ad1af9b-8df9-4627-b114-30c146e1c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-9a5c65e4-7138-4fb6-a7ff-f3165f330b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-9a233155-fb41-42ff-8222-11aec0fd720d,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-d6e9f27e-62b0-491d-8a8a-9e7395bd892d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-3217e97a-1459-4957-868d-8ba244e3a954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548245475-172.17.0.11-1596935989052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42424,DS-686f13c0-5ccd-4ef0-9133-a7b359316761,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-2bd82145-a88e-481e-accd-45fe22af948d,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-c4a86ba6-f56f-4bb2-a192-9aaccf0874be,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-40d1380f-4f43-4e99-89fb-672eb4e5355e,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-facc2b34-6bd5-498b-a895-075fd1af29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-d77d13ad-ef83-4583-a91f-43502d3c0ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-9e8cd817-115b-4dd1-ae13-7af17f0fc883,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-0f201d8e-92df-479f-b573-7e50735f58f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548245475-172.17.0.11-1596935989052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42424,DS-686f13c0-5ccd-4ef0-9133-a7b359316761,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-2bd82145-a88e-481e-accd-45fe22af948d,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-c4a86ba6-f56f-4bb2-a192-9aaccf0874be,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-40d1380f-4f43-4e99-89fb-672eb4e5355e,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-facc2b34-6bd5-498b-a895-075fd1af29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-d77d13ad-ef83-4583-a91f-43502d3c0ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-9e8cd817-115b-4dd1-ae13-7af17f0fc883,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-0f201d8e-92df-479f-b573-7e50735f58f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365218696-172.17.0.11-1596938067299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-47d50199-64d2-4b0c-a8a2-b33f43c03cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-69a449be-3c44-472d-b9f8-789281023eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-b8de2c41-2d07-4838-976a-4d207e152853,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-3b088b60-cf9a-4040-bec2-161c15d1fab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-a59dbb96-3712-481f-991c-c537c6922c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-5f42d9c4-58a4-4a27-9b7d-b6751dd23545,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-f0da5b9b-9889-4114-964e-e08532b95b29,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-6f7ee5e3-2195-4555-bcf6-988ae4acf95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365218696-172.17.0.11-1596938067299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-47d50199-64d2-4b0c-a8a2-b33f43c03cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-69a449be-3c44-472d-b9f8-789281023eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-b8de2c41-2d07-4838-976a-4d207e152853,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-3b088b60-cf9a-4040-bec2-161c15d1fab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-a59dbb96-3712-481f-991c-c537c6922c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-5f42d9c4-58a4-4a27-9b7d-b6751dd23545,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-f0da5b9b-9889-4114-964e-e08532b95b29,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-6f7ee5e3-2195-4555-bcf6-988ae4acf95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178967192-172.17.0.11-1596938429355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37315,DS-ccadc6b3-01dd-42a6-9c7d-52ef13a5ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-7bfb7341-c1f8-4714-b12c-e26b9e3f485b,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-935e048c-360e-4c15-99ea-4c19954bfd85,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-7eca5ced-e1dc-41f6-8515-3d063865662a,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-a8f19fe4-5431-4d89-be43-d92656c52bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-1f1505b6-be7a-475d-97f6-719bea50331a,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-15aedafe-69e1-4ece-9a3e-4e4ed54fc5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-bbe8c767-0f34-493c-96c9-60cb87d5f23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178967192-172.17.0.11-1596938429355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37315,DS-ccadc6b3-01dd-42a6-9c7d-52ef13a5ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-7bfb7341-c1f8-4714-b12c-e26b9e3f485b,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-935e048c-360e-4c15-99ea-4c19954bfd85,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-7eca5ced-e1dc-41f6-8515-3d063865662a,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-a8f19fe4-5431-4d89-be43-d92656c52bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-1f1505b6-be7a-475d-97f6-719bea50331a,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-15aedafe-69e1-4ece-9a3e-4e4ed54fc5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-bbe8c767-0f34-493c-96c9-60cb87d5f23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991008396-172.17.0.11-1596938985347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-e08e964e-d916-4d63-9a1c-f16a844e8858,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-e79ee3c4-6267-4adc-84f4-851f6e11c0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-1888f921-5347-4b52-804a-f3291f7f53f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-4b5c87c1-6abc-474c-b62d-7381e8a6d480,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-57c95c33-b2e3-4b06-94a8-0d781cccb9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-9dfe6c19-6d72-4139-bcca-e98f1c759d12,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-092b7209-9b34-4715-b641-6e6be47a036d,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-541003fb-0313-4660-b379-37ba3e0f8d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991008396-172.17.0.11-1596938985347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-e08e964e-d916-4d63-9a1c-f16a844e8858,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-e79ee3c4-6267-4adc-84f4-851f6e11c0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-1888f921-5347-4b52-804a-f3291f7f53f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-4b5c87c1-6abc-474c-b62d-7381e8a6d480,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-57c95c33-b2e3-4b06-94a8-0d781cccb9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-9dfe6c19-6d72-4139-bcca-e98f1c759d12,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-092b7209-9b34-4715-b641-6e6be47a036d,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-541003fb-0313-4660-b379-37ba3e0f8d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450480396-172.17.0.11-1596939136580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41519,DS-6f4f28c6-240a-44ee-ab1d-be7f5d3f1f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-e9f331f1-2d68-4017-974a-c4cc06cc2c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-60a0b4fa-bab2-4083-8a95-eeb3b2f5663a,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-293b8936-0bb4-4956-98b6-f3609a3aab3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-bd12bec6-43d3-41aa-ac5f-e497cee116dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-f860679b-8f56-4f47-b9d6-7fb5465f7f03,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-a714285b-88e5-4658-ad4a-602bf740c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-0de75ee7-f07f-4ac7-9bec-f701dcf641f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450480396-172.17.0.11-1596939136580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41519,DS-6f4f28c6-240a-44ee-ab1d-be7f5d3f1f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-e9f331f1-2d68-4017-974a-c4cc06cc2c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-60a0b4fa-bab2-4083-8a95-eeb3b2f5663a,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-293b8936-0bb4-4956-98b6-f3609a3aab3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-bd12bec6-43d3-41aa-ac5f-e497cee116dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-f860679b-8f56-4f47-b9d6-7fb5465f7f03,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-a714285b-88e5-4658-ad4a-602bf740c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-0de75ee7-f07f-4ac7-9bec-f701dcf641f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233405766-172.17.0.11-1596939269121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33892,DS-a02b17cf-73f8-481f-992e-c908d7db0b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-e37f8a5e-e04d-4339-9d8c-d011219a0098,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-618d9a79-3e14-4e35-9551-42fb240fc9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-90fe3850-b963-4172-93e4-63ab84d0fc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-07d39781-c66d-4b11-baee-7e20ed0ac612,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-559bf80e-f749-4391-bace-9b658e0dba84,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-97f857ea-e42a-4094-a3ea-9a2c8d5a14a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-c2f100ff-8239-4df8-bdad-b11123050e87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233405766-172.17.0.11-1596939269121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33892,DS-a02b17cf-73f8-481f-992e-c908d7db0b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-e37f8a5e-e04d-4339-9d8c-d011219a0098,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-618d9a79-3e14-4e35-9551-42fb240fc9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-90fe3850-b963-4172-93e4-63ab84d0fc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-07d39781-c66d-4b11-baee-7e20ed0ac612,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-559bf80e-f749-4391-bace-9b658e0dba84,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-97f857ea-e42a-4094-a3ea-9a2c8d5a14a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-c2f100ff-8239-4df8-bdad-b11123050e87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.capture.openfiles
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028194795-172.17.0.11-1596939439777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34047,DS-5f85b05d-e947-438c-891d-6a01a79e1326,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-4179a48c-3cb6-4055-8f00-e705d06be672,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-4956238f-4802-492c-b2c7-6620938bb24a,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-e9089b35-2dd3-4204-8f89-3598774e9672,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-99a622be-4359-4a53-9830-71d8edbcd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-58d8c643-7115-4919-a5d9-688f32793dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-e4aad0c1-2a5b-40df-883b-e7acbd06948f,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-55d711b6-d813-4756-a280-e9be7b6fa365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028194795-172.17.0.11-1596939439777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34047,DS-5f85b05d-e947-438c-891d-6a01a79e1326,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-4179a48c-3cb6-4055-8f00-e705d06be672,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-4956238f-4802-492c-b2c7-6620938bb24a,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-e9089b35-2dd3-4204-8f89-3598774e9672,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-99a622be-4359-4a53-9830-71d8edbcd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-58d8c643-7115-4919-a5d9-688f32793dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-e4aad0c1-2a5b-40df-883b-e7acbd06948f,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-55d711b6-d813-4756-a280-e9be7b6fa365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6571
