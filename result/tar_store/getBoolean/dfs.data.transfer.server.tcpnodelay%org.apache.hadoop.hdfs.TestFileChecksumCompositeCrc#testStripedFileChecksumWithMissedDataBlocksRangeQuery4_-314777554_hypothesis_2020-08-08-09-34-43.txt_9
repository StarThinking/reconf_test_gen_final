reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373907152-172.17.0.20-1596879756690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40480,DS-78b3325f-2d31-4720-96a6-251440ce9a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-f71b3e49-6565-41dc-aaf9-4ec0355fda67,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-a804a3e1-c884-482a-bd15-c3b213c0bc77,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-2fd16bd8-1ab4-47f4-a996-8e90388559c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-81ddfb23-d6b8-4e2f-9d85-e3c0c77d1276,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-008d4d52-0e25-41a1-a983-efa8d0b3dece,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-f15d8484-1be6-42e8-870f-2ba43456a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-57b8022f-e4e8-464c-8f77-b845927ca566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373907152-172.17.0.20-1596879756690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40480,DS-78b3325f-2d31-4720-96a6-251440ce9a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-f71b3e49-6565-41dc-aaf9-4ec0355fda67,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-a804a3e1-c884-482a-bd15-c3b213c0bc77,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-2fd16bd8-1ab4-47f4-a996-8e90388559c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-81ddfb23-d6b8-4e2f-9d85-e3c0c77d1276,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-008d4d52-0e25-41a1-a983-efa8d0b3dece,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-f15d8484-1be6-42e8-870f-2ba43456a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-57b8022f-e4e8-464c-8f77-b845927ca566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019406070-172.17.0.20-1596880301054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46692,DS-1eb66327-2a01-4c72-a539-b0703de0efff,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-dd572c68-91b3-44d3-8a09-37a3bb89b070,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-a97a0755-f5ab-4b4a-afe4-3fae23de440a,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-d021e10d-61d4-4505-86b5-012907b6cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-948ea5e2-dfbc-4960-aa39-b6f582d5f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-4ee13529-09a2-454a-ac36-b1e0fca896ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-964d5d05-d584-4aff-83c4-6d1dfd6c2be8,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-90ca0d0d-619c-42b9-9036-08052632cfe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019406070-172.17.0.20-1596880301054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46692,DS-1eb66327-2a01-4c72-a539-b0703de0efff,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-dd572c68-91b3-44d3-8a09-37a3bb89b070,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-a97a0755-f5ab-4b4a-afe4-3fae23de440a,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-d021e10d-61d4-4505-86b5-012907b6cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-948ea5e2-dfbc-4960-aa39-b6f582d5f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-4ee13529-09a2-454a-ac36-b1e0fca896ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-964d5d05-d584-4aff-83c4-6d1dfd6c2be8,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-90ca0d0d-619c-42b9-9036-08052632cfe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126945996-172.17.0.20-1596880620587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44908,DS-096fc517-a53d-40bf-9b1d-fe45aad184bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-345e95e1-87f6-459f-bc0e-20b3e8d689dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-ee9fa52d-1d56-4b36-9b75-0896a4bdcff2,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-c0ca2ff1-c4b6-4753-82fc-aae6f96d7e64,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-cda72dcb-aecf-46c9-bc7e-ab1d24b59bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-b77c2b70-9f2f-453d-9dba-1605c6be919a,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-5c39d33c-8ae2-49cc-a528-d9de3efa0433,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-0c22cdb7-817e-4c61-b899-26dae980ecb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126945996-172.17.0.20-1596880620587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44908,DS-096fc517-a53d-40bf-9b1d-fe45aad184bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-345e95e1-87f6-459f-bc0e-20b3e8d689dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-ee9fa52d-1d56-4b36-9b75-0896a4bdcff2,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-c0ca2ff1-c4b6-4753-82fc-aae6f96d7e64,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-cda72dcb-aecf-46c9-bc7e-ab1d24b59bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-b77c2b70-9f2f-453d-9dba-1605c6be919a,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-5c39d33c-8ae2-49cc-a528-d9de3efa0433,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-0c22cdb7-817e-4c61-b899-26dae980ecb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661353821-172.17.0.20-1596880796905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43426,DS-15a4b9c7-3c76-4ab4-94e9-9123633b39b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-bc997842-e03e-4ab9-92cb-94fd6e61355b,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-a04e0dfc-d053-4c6e-9610-3717b6f50a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-15292d7d-0b2f-4575-94da-8003885ec7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-5bd64fec-5d6c-4107-8e40-def216c945c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-72ea7bce-028c-4f80-b992-af6bea063be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-22751b6a-9245-4e6e-83e1-33767e8c0ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-0b70f4f4-bf72-4451-a67c-7bc04ff2bd9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661353821-172.17.0.20-1596880796905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43426,DS-15a4b9c7-3c76-4ab4-94e9-9123633b39b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-bc997842-e03e-4ab9-92cb-94fd6e61355b,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-a04e0dfc-d053-4c6e-9610-3717b6f50a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-15292d7d-0b2f-4575-94da-8003885ec7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-5bd64fec-5d6c-4107-8e40-def216c945c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-72ea7bce-028c-4f80-b992-af6bea063be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-22751b6a-9245-4e6e-83e1-33767e8c0ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-0b70f4f4-bf72-4451-a67c-7bc04ff2bd9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859643300-172.17.0.20-1596881077112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-c7ec0641-10c0-4a98-903d-6a2e5da6ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-3b32cd37-44a3-46f8-b16f-95aaaa443d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-67d30d3f-14f5-4498-a73d-aecefb737eea,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-9587dd3f-ac7e-4f07-ab66-d9b11096c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-cb2f6e26-fa79-47e2-9eaf-3dadaf119844,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-2fd917f0-3685-42e7-9d1a-e946b2d290ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-70b53b8b-c9e0-46ed-8fa3-146f427ebc07,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-f8b18a48-cf2f-4ea3-a4e7-93e2a7cdc1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859643300-172.17.0.20-1596881077112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-c7ec0641-10c0-4a98-903d-6a2e5da6ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-3b32cd37-44a3-46f8-b16f-95aaaa443d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-67d30d3f-14f5-4498-a73d-aecefb737eea,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-9587dd3f-ac7e-4f07-ab66-d9b11096c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-cb2f6e26-fa79-47e2-9eaf-3dadaf119844,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-2fd917f0-3685-42e7-9d1a-e946b2d290ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-70b53b8b-c9e0-46ed-8fa3-146f427ebc07,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-f8b18a48-cf2f-4ea3-a4e7-93e2a7cdc1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764454693-172.17.0.20-1596881109529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46453,DS-264d2a1c-42ff-4e61-a01a-3825118d8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-02b91a08-98c5-424b-b2c1-3bd0882d05bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-3ec5ae76-4a19-42c4-987b-0e990aa6714e,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-92d5d77d-eaa5-4a6b-8d7b-fa84097ffca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-4f6a68cd-fee6-4ba2-97d5-307e84731c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-bfe51b98-1703-4e6e-abef-87b2a9125083,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-9065afe4-3925-45e8-85d2-558e74881709,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-fde46e9f-eb61-4ec6-903d-c36b7dd63fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764454693-172.17.0.20-1596881109529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46453,DS-264d2a1c-42ff-4e61-a01a-3825118d8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-02b91a08-98c5-424b-b2c1-3bd0882d05bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-3ec5ae76-4a19-42c4-987b-0e990aa6714e,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-92d5d77d-eaa5-4a6b-8d7b-fa84097ffca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-4f6a68cd-fee6-4ba2-97d5-307e84731c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-bfe51b98-1703-4e6e-abef-87b2a9125083,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-9065afe4-3925-45e8-85d2-558e74881709,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-fde46e9f-eb61-4ec6-903d-c36b7dd63fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432831764-172.17.0.20-1596881257000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-23c1233c-f6de-4a3a-962c-8a93a74bb423,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-0f984898-2963-4423-a617-950d25d4149f,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-f0116eb7-1a09-497c-bf66-c52538afdbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-b90036cf-7cee-4675-a05e-0d57ea1400a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-84b0d9e6-7af5-4c3d-a466-9f63794b5d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-838d6814-6c58-4280-ae54-2eb23777522a,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-08011bf1-e263-4f5f-a892-82356866e272,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-2ea00b2b-52c4-41e1-90e6-045b6fc0c3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432831764-172.17.0.20-1596881257000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-23c1233c-f6de-4a3a-962c-8a93a74bb423,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-0f984898-2963-4423-a617-950d25d4149f,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-f0116eb7-1a09-497c-bf66-c52538afdbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-b90036cf-7cee-4675-a05e-0d57ea1400a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-84b0d9e6-7af5-4c3d-a466-9f63794b5d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-838d6814-6c58-4280-ae54-2eb23777522a,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-08011bf1-e263-4f5f-a892-82356866e272,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-2ea00b2b-52c4-41e1-90e6-045b6fc0c3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106997746-172.17.0.20-1596881295465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34209,DS-11467a7e-a5d3-4e56-ac47-54f305d3d870,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-9b9bb518-c556-4dd5-8a71-0d20a20429be,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-06bfcce6-467d-4c02-9404-62b062ee8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-bb8ce16b-5417-44cb-b714-7bdd775ceb49,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-f7d28e2b-5f6e-4948-af8b-04858173b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-04e50357-2130-444a-985f-1352eb570bab,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-4e231391-6593-4f0a-a82a-a0b63d07c028,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-8c8db2c8-27de-422f-a616-d399eaab97c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106997746-172.17.0.20-1596881295465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34209,DS-11467a7e-a5d3-4e56-ac47-54f305d3d870,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-9b9bb518-c556-4dd5-8a71-0d20a20429be,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-06bfcce6-467d-4c02-9404-62b062ee8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-bb8ce16b-5417-44cb-b714-7bdd775ceb49,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-f7d28e2b-5f6e-4948-af8b-04858173b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-04e50357-2130-444a-985f-1352eb570bab,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-4e231391-6593-4f0a-a82a-a0b63d07c028,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-8c8db2c8-27de-422f-a616-d399eaab97c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603556718-172.17.0.20-1596881328168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33438,DS-a9a457c1-f599-402d-8099-7727085becb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-ee8cd4cd-3237-42a9-86a4-8245787c0f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-d76cdbba-c9e6-4569-8c0b-5e0ac33491c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-ed08c1a7-8362-4c05-be45-51c364d71cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-4e9e98d3-bdcd-4959-aee4-7ae12fdb5c41,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-c9973069-315f-477e-96e9-1338ee87b282,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-b9e7dc8f-ea87-4b41-9df6-ff024ec20401,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-a555751b-6723-4037-b6c8-11b219549139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603556718-172.17.0.20-1596881328168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33438,DS-a9a457c1-f599-402d-8099-7727085becb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-ee8cd4cd-3237-42a9-86a4-8245787c0f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-d76cdbba-c9e6-4569-8c0b-5e0ac33491c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-ed08c1a7-8362-4c05-be45-51c364d71cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-4e9e98d3-bdcd-4959-aee4-7ae12fdb5c41,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-c9973069-315f-477e-96e9-1338ee87b282,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-b9e7dc8f-ea87-4b41-9df6-ff024ec20401,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-a555751b-6723-4037-b6c8-11b219549139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137028141-172.17.0.20-1596881772740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41343,DS-d63a9752-9480-4fe5-a831-dce856a71844,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-3498846a-d5dd-4a8e-ac36-7aca2813afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-4b5c0587-a87e-472e-bb39-1817117c4f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-74caa24b-e44c-4f5e-a94b-9f9e58d72224,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-a4e05c53-d588-4310-bf29-63e67d39b697,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-c1d1fca6-e400-410c-8c1a-7ec90e305188,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-ba2cb0ba-f95a-4c46-b5b5-42b142f21a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-3da4f270-f6f4-4968-96d2-8a2902c1a8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137028141-172.17.0.20-1596881772740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41343,DS-d63a9752-9480-4fe5-a831-dce856a71844,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-3498846a-d5dd-4a8e-ac36-7aca2813afbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-4b5c0587-a87e-472e-bb39-1817117c4f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-74caa24b-e44c-4f5e-a94b-9f9e58d72224,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-a4e05c53-d588-4310-bf29-63e67d39b697,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-c1d1fca6-e400-410c-8c1a-7ec90e305188,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-ba2cb0ba-f95a-4c46-b5b5-42b142f21a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-3da4f270-f6f4-4968-96d2-8a2902c1a8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121460958-172.17.0.20-1596882062244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-06ade63e-63f8-4fef-a717-7b14e690e8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-a3076949-7fe1-48b8-860e-3e4b01bc5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-cd26b7b3-a3c3-4100-aff0-572a91436a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-15c2a9fd-4384-4dc5-8660-3571a37a37ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-fb0733a2-39e6-4243-ad5a-e686330b38b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-b5e90a62-bdcb-4107-b588-d00f546caef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0a4bc1a2-195c-4c5f-8568-58084b77dfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-9dd9e218-2754-4d2e-9b23-5683647545d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121460958-172.17.0.20-1596882062244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-06ade63e-63f8-4fef-a717-7b14e690e8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-a3076949-7fe1-48b8-860e-3e4b01bc5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-cd26b7b3-a3c3-4100-aff0-572a91436a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-15c2a9fd-4384-4dc5-8660-3571a37a37ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-fb0733a2-39e6-4243-ad5a-e686330b38b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-b5e90a62-bdcb-4107-b588-d00f546caef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0a4bc1a2-195c-4c5f-8568-58084b77dfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-9dd9e218-2754-4d2e-9b23-5683647545d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335666861-172.17.0.20-1596882193137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45904,DS-a352af94-e22f-4a06-a0ad-bb4b0ba5939d,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-7e55dc50-23d8-4407-b0e7-a7fbe9a2b6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-f28a7456-36b8-41ea-a4fd-a654c907832e,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-a9744e53-0ca6-4dbf-824d-d5925bff4f47,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-e1e0318b-9730-4c2d-b165-eb13d570e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1f570986-47d5-4b00-ab0b-05269ed31d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-dbfab80f-979e-4270-9090-181db77668e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-ee8f480c-19b8-40c3-9c26-2817b2e432ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335666861-172.17.0.20-1596882193137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45904,DS-a352af94-e22f-4a06-a0ad-bb4b0ba5939d,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-7e55dc50-23d8-4407-b0e7-a7fbe9a2b6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-f28a7456-36b8-41ea-a4fd-a654c907832e,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-a9744e53-0ca6-4dbf-824d-d5925bff4f47,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-e1e0318b-9730-4c2d-b165-eb13d570e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1f570986-47d5-4b00-ab0b-05269ed31d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-dbfab80f-979e-4270-9090-181db77668e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-ee8f480c-19b8-40c3-9c26-2817b2e432ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100897433-172.17.0.20-1596882339083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-1d38c7cd-3c7b-4c7a-ad24-7b0638e78f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-29cafd0d-7d54-4b06-b560-e587b7a84766,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-9f2dd17e-9d0c-4147-a3b7-5b8101ad90e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-b0cf815a-8f09-4944-8efc-dd7ea19cdccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-d2bb6860-c9de-41e8-b4c4-20274d260ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-20c0f8c4-b866-4880-93fc-13408398314f,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-986d4388-55ab-4ef9-a940-1859b7563610,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-33043325-fd55-4352-b63e-9b987483e0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100897433-172.17.0.20-1596882339083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-1d38c7cd-3c7b-4c7a-ad24-7b0638e78f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-29cafd0d-7d54-4b06-b560-e587b7a84766,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-9f2dd17e-9d0c-4147-a3b7-5b8101ad90e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-b0cf815a-8f09-4944-8efc-dd7ea19cdccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-d2bb6860-c9de-41e8-b4c4-20274d260ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-20c0f8c4-b866-4880-93fc-13408398314f,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-986d4388-55ab-4ef9-a940-1859b7563610,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-33043325-fd55-4352-b63e-9b987483e0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558311345-172.17.0.20-1596882443302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38751,DS-bf12d933-03a6-4782-88fc-cdf5d0cc0ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-b10ee536-5912-4a6e-85ca-c19b274167c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6d4e22fe-fa38-4676-b100-7302a8a6d312,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-2579f290-5bc5-4cd4-8100-fa23533c34ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-67955cbb-faae-481c-94da-39495d8b5128,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-759a96d5-9803-43ca-b55d-86abeadb5ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-8087b79e-87cd-49ac-9bc9-3e8355d16e54,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-a427f115-0aec-4e01-a107-ef0b677c06cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558311345-172.17.0.20-1596882443302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38751,DS-bf12d933-03a6-4782-88fc-cdf5d0cc0ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-b10ee536-5912-4a6e-85ca-c19b274167c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6d4e22fe-fa38-4676-b100-7302a8a6d312,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-2579f290-5bc5-4cd4-8100-fa23533c34ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-67955cbb-faae-481c-94da-39495d8b5128,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-759a96d5-9803-43ca-b55d-86abeadb5ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-8087b79e-87cd-49ac-9bc9-3e8355d16e54,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-a427f115-0aec-4e01-a107-ef0b677c06cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037884389-172.17.0.20-1596883544308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33128,DS-a941f61d-596a-48de-9b3c-a62da91f33e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-74c2c26d-07fa-4a90-993b-bc12d546e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-44f3bfc8-edc4-4b0f-8546-fd7fa3c0c179,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-6eebfed7-34e8-49b1-836f-34bd073480a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-896ff9c1-35a9-431d-81a1-4369cec8af66,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-11503dbf-7142-4b3c-9eab-0025cbfcac33,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-812bd783-fc90-4bf7-846f-f80d97fb5d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-8995b0b8-af9f-4084-b2d3-62f0e5f71fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037884389-172.17.0.20-1596883544308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33128,DS-a941f61d-596a-48de-9b3c-a62da91f33e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-74c2c26d-07fa-4a90-993b-bc12d546e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-44f3bfc8-edc4-4b0f-8546-fd7fa3c0c179,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-6eebfed7-34e8-49b1-836f-34bd073480a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-896ff9c1-35a9-431d-81a1-4369cec8af66,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-11503dbf-7142-4b3c-9eab-0025cbfcac33,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-812bd783-fc90-4bf7-846f-f80d97fb5d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-8995b0b8-af9f-4084-b2d3-62f0e5f71fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742828637-172.17.0.20-1596884229471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39597,DS-3f33eea0-8aa1-4af1-8d29-3abe6830dfee,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-f841f1a9-ad14-4cd2-824b-0a30c66a5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-e9c678cb-2480-43ff-afc4-1185ecddd836,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-9d24aa67-27e4-43e6-8c9b-bdf5ba4a0777,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-b0dab682-52a0-4cd4-8e2f-0654e637398f,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-d7207122-9716-45fe-be15-0acc046c39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-c2b785b8-8f05-4e8b-8a10-289ac2ba65ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-e0def277-0762-4905-a7fd-61c332e3db18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742828637-172.17.0.20-1596884229471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39597,DS-3f33eea0-8aa1-4af1-8d29-3abe6830dfee,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-f841f1a9-ad14-4cd2-824b-0a30c66a5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-e9c678cb-2480-43ff-afc4-1185ecddd836,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-9d24aa67-27e4-43e6-8c9b-bdf5ba4a0777,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-b0dab682-52a0-4cd4-8e2f-0654e637398f,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-d7207122-9716-45fe-be15-0acc046c39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-c2b785b8-8f05-4e8b-8a10-289ac2ba65ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-e0def277-0762-4905-a7fd-61c332e3db18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5378
