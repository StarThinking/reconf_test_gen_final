reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533745551-172.17.0.6-1596898157324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32867,DS-e19bdfe3-f921-4049-9325-24b5f99988de,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-4a4f7f2a-2a6e-4a51-b09f-e703464c7021,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-a7db697c-2d84-4b2e-b3a0-d9542a444c67,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-01ea5a82-6d37-42e4-ba3d-e8846a00c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-358e0017-c9e1-4a23-b645-75a5e0c4a443,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-51a1a781-3289-4a76-8ea0-f636f8cc7866,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-cee7d9ed-1020-422e-ae04-ae2e42f47818,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-9cc3134e-6684-4c77-8337-1062e7b8d44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533745551-172.17.0.6-1596898157324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32867,DS-e19bdfe3-f921-4049-9325-24b5f99988de,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-4a4f7f2a-2a6e-4a51-b09f-e703464c7021,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-a7db697c-2d84-4b2e-b3a0-d9542a444c67,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-01ea5a82-6d37-42e4-ba3d-e8846a00c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-358e0017-c9e1-4a23-b645-75a5e0c4a443,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-51a1a781-3289-4a76-8ea0-f636f8cc7866,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-cee7d9ed-1020-422e-ae04-ae2e42f47818,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-9cc3134e-6684-4c77-8337-1062e7b8d44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964896738-172.17.0.6-1596898358937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34257,DS-9fd1a865-3c07-4d89-b20e-95c1ce5d9b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-58ec3810-d65c-4147-974b-b2b3440124fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-4791c06e-0428-4383-aa4e-deb5ebb89b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-05d0f76d-32c1-4f2a-91e6-b7729d38502e,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-7ab8aa0b-5864-4fe5-ae63-3da32bb82502,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-fa41759f-5e92-46c9-80de-f503e05e22a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-d11aa629-5914-4dcb-bd72-1784ed54e71d,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-db936641-da66-4cc1-aa0b-a01b7bd7a81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964896738-172.17.0.6-1596898358937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34257,DS-9fd1a865-3c07-4d89-b20e-95c1ce5d9b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-58ec3810-d65c-4147-974b-b2b3440124fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-4791c06e-0428-4383-aa4e-deb5ebb89b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-05d0f76d-32c1-4f2a-91e6-b7729d38502e,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-7ab8aa0b-5864-4fe5-ae63-3da32bb82502,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-fa41759f-5e92-46c9-80de-f503e05e22a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-d11aa629-5914-4dcb-bd72-1784ed54e71d,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-db936641-da66-4cc1-aa0b-a01b7bd7a81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927882409-172.17.0.6-1596898497186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34546,DS-9e257c6f-882d-487a-983e-9abba9cd8357,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-ff9ff89b-e23e-450b-a58f-ae6ce8e61213,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-b2ffd1c9-5c60-42cf-8358-950140f15f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-63423ed0-fd7e-4e96-8161-76a8b26d9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-31f4b7e7-7edd-4193-9830-e7134ab5fbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-2549fd34-e337-4ae1-824c-416d6d197560,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-66d61bcf-2412-4e18-adbc-d807b3759cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-9db8cf8d-21e7-4b64-8d26-f0eac8644a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927882409-172.17.0.6-1596898497186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34546,DS-9e257c6f-882d-487a-983e-9abba9cd8357,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-ff9ff89b-e23e-450b-a58f-ae6ce8e61213,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-b2ffd1c9-5c60-42cf-8358-950140f15f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-63423ed0-fd7e-4e96-8161-76a8b26d9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-31f4b7e7-7edd-4193-9830-e7134ab5fbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-2549fd34-e337-4ae1-824c-416d6d197560,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-66d61bcf-2412-4e18-adbc-d807b3759cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-9db8cf8d-21e7-4b64-8d26-f0eac8644a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468949642-172.17.0.6-1596898975039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-cd27de6c-f9d4-4aa5-9a5a-f0c6526e6716,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-4fc3f11b-317d-48ec-8125-1cd4bfd03002,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-6eddb362-0874-4362-aa1b-a2ba318531e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-0ca01089-dd0f-4025-805e-358206c3efb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-55a67884-c7c6-49a7-8bc6-7145cfb100be,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-7deb758c-4dc8-4374-b65e-390ff299a74e,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-f8b31466-dbfa-400a-9323-69aba0624aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-5f28a1d0-812a-4a25-b2ab-e7d300a615ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468949642-172.17.0.6-1596898975039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-cd27de6c-f9d4-4aa5-9a5a-f0c6526e6716,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-4fc3f11b-317d-48ec-8125-1cd4bfd03002,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-6eddb362-0874-4362-aa1b-a2ba318531e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-0ca01089-dd0f-4025-805e-358206c3efb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-55a67884-c7c6-49a7-8bc6-7145cfb100be,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-7deb758c-4dc8-4374-b65e-390ff299a74e,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-f8b31466-dbfa-400a-9323-69aba0624aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-5f28a1d0-812a-4a25-b2ab-e7d300a615ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481584080-172.17.0.6-1596899683199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-8eb46762-67a0-4399-a5bf-7f220cedeecf,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-a15e73eb-03f3-4f96-bf6c-2293f4d8353c,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-ff6982f5-551b-403a-a724-a5502a719b78,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-0c6313e7-c2a7-4eae-939f-f8e7ea30739b,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-78c2b7c1-848d-4c23-ab3b-c4573421b8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-0c0ed8db-9fde-44da-b6cb-ae46d68fa65d,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-58b873ea-5c76-46b9-8b6f-d4b4e328e999,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-9c2c6212-93c3-47d3-9b47-0a82ed9b6120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481584080-172.17.0.6-1596899683199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-8eb46762-67a0-4399-a5bf-7f220cedeecf,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-a15e73eb-03f3-4f96-bf6c-2293f4d8353c,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-ff6982f5-551b-403a-a724-a5502a719b78,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-0c6313e7-c2a7-4eae-939f-f8e7ea30739b,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-78c2b7c1-848d-4c23-ab3b-c4573421b8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-0c0ed8db-9fde-44da-b6cb-ae46d68fa65d,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-58b873ea-5c76-46b9-8b6f-d4b4e328e999,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-9c2c6212-93c3-47d3-9b47-0a82ed9b6120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815232263-172.17.0.6-1596899914599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-e8091431-a895-41e4-8e9b-ad5c997fc048,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-fa10848b-da36-4160-995e-a53b33d6fe94,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-fb41cfbb-eb58-4150-b0dc-9ffc930d6b28,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-52a688e0-6c9b-4fb6-87c8-e552f2ec3c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-020cdf6c-8926-4996-b84c-d43a91179b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-54edba58-a3cf-458e-8d8c-fe3864fe860f,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-0f51d096-310c-4aa8-bf57-3d35d56fbd42,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-c997a419-9f12-49ce-82c2-115616b530dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815232263-172.17.0.6-1596899914599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-e8091431-a895-41e4-8e9b-ad5c997fc048,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-fa10848b-da36-4160-995e-a53b33d6fe94,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-fb41cfbb-eb58-4150-b0dc-9ffc930d6b28,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-52a688e0-6c9b-4fb6-87c8-e552f2ec3c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-020cdf6c-8926-4996-b84c-d43a91179b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-54edba58-a3cf-458e-8d8c-fe3864fe860f,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-0f51d096-310c-4aa8-bf57-3d35d56fbd42,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-c997a419-9f12-49ce-82c2-115616b530dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128352089-172.17.0.6-1596900733165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43243,DS-f87e9c96-1178-48e7-be73-ef8d1dcb5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-4523551a-be14-4125-bd75-a2cf42a4f99d,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-027df155-28df-4179-b6ea-a67c9bc13786,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-5858129f-00f9-4672-850a-db4b3f290c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-5dbd29f1-3bf9-47fa-bc23-06d9135d894a,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-d2832f61-657d-4931-a50d-cb109766a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-bac46d50-751d-4571-80a3-dbb6faf24ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-9adc2dc1-a9bb-4356-b2be-54f519fbeab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128352089-172.17.0.6-1596900733165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43243,DS-f87e9c96-1178-48e7-be73-ef8d1dcb5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-4523551a-be14-4125-bd75-a2cf42a4f99d,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-027df155-28df-4179-b6ea-a67c9bc13786,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-5858129f-00f9-4672-850a-db4b3f290c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-5dbd29f1-3bf9-47fa-bc23-06d9135d894a,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-d2832f61-657d-4931-a50d-cb109766a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-bac46d50-751d-4571-80a3-dbb6faf24ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-9adc2dc1-a9bb-4356-b2be-54f519fbeab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767678902-172.17.0.6-1596901373070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-163c081b-b1c1-4e2c-baca-35fc773da4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-651be7c2-f3ba-4ca9-9ef5-44989f2a613c,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-b60ffd46-45bf-4091-96b7-7f5c57b9a527,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-b542acc8-e7e0-425b-8a67-0c37823ebc46,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-dd908026-3578-4623-9e5e-19b95a4ea2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-07393a14-fb3d-4103-837b-900332a78ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-bd3d3664-703d-44f9-aa70-450cfa563515,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-c9cb32f5-27e2-46f2-885b-945d71b1d898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767678902-172.17.0.6-1596901373070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-163c081b-b1c1-4e2c-baca-35fc773da4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-651be7c2-f3ba-4ca9-9ef5-44989f2a613c,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-b60ffd46-45bf-4091-96b7-7f5c57b9a527,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-b542acc8-e7e0-425b-8a67-0c37823ebc46,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-dd908026-3578-4623-9e5e-19b95a4ea2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-07393a14-fb3d-4103-837b-900332a78ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-bd3d3664-703d-44f9-aa70-450cfa563515,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-c9cb32f5-27e2-46f2-885b-945d71b1d898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703743635-172.17.0.6-1596902790731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42136,DS-1398ebef-2765-4a21-826c-9e22e3e4736f,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-71da909c-80d4-43f7-8c48-e07adf713701,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-4659ffd9-9505-401f-924b-8915a9fc60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-58492468-ffa2-4dde-b7ad-ced8f48c2b96,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-ea8e52fe-0653-4e11-9695-9e3ca46865d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-4b2e8203-884e-496f-af12-6363a3b01887,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-3afe601a-1d22-487e-9ddf-1a2a8e4a1124,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-ee084fdc-3929-4fb1-8564-979d74528661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703743635-172.17.0.6-1596902790731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42136,DS-1398ebef-2765-4a21-826c-9e22e3e4736f,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-71da909c-80d4-43f7-8c48-e07adf713701,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-4659ffd9-9505-401f-924b-8915a9fc60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-58492468-ffa2-4dde-b7ad-ced8f48c2b96,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-ea8e52fe-0653-4e11-9695-9e3ca46865d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-4b2e8203-884e-496f-af12-6363a3b01887,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-3afe601a-1d22-487e-9ddf-1a2a8e4a1124,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-ee084fdc-3929-4fb1-8564-979d74528661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167362856-172.17.0.6-1596903339634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33846,DS-5400fa1b-c1d1-4103-946f-ed24433fb3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-55d598b6-72ce-4ca0-8aa9-5aa72fdae9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-d8526009-e216-4484-9cc1-5b758815c55f,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-7fbdd3e7-17f2-49c6-95b1-e6e936e28b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-0db8a4c5-e1c2-446f-88f8-019bd53a89af,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-57332af2-5140-450b-a055-0ba8f276f461,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-9b7bcdc2-d679-4fdc-8b24-7e4b91cd5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-f7db0cb0-6391-4c90-a020-4bfef6f9a2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167362856-172.17.0.6-1596903339634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33846,DS-5400fa1b-c1d1-4103-946f-ed24433fb3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-55d598b6-72ce-4ca0-8aa9-5aa72fdae9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-d8526009-e216-4484-9cc1-5b758815c55f,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-7fbdd3e7-17f2-49c6-95b1-e6e936e28b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-0db8a4c5-e1c2-446f-88f8-019bd53a89af,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-57332af2-5140-450b-a055-0ba8f276f461,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-9b7bcdc2-d679-4fdc-8b24-7e4b91cd5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-f7db0cb0-6391-4c90-a020-4bfef6f9a2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931800214-172.17.0.6-1596903411294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-76d5eb45-05c5-4de0-8193-2ec424197ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-b0895624-37b5-4cbb-b3c5-d5bb3ea5a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-d6df36d8-bf6a-42cd-b006-bfa3a6fec31d,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-d811e5b6-c963-4fbd-923b-90bc8c1107e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-82da6a6c-c4da-4dad-b0e6-408d37b26639,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-5f98c74d-87b7-458d-8f96-b168f4ea99ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-bc7c7220-17a4-4571-a46e-0e8a9ffa7497,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-c84e59e0-a976-49dc-abb0-c203d50ef955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931800214-172.17.0.6-1596903411294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-76d5eb45-05c5-4de0-8193-2ec424197ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-b0895624-37b5-4cbb-b3c5-d5bb3ea5a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-d6df36d8-bf6a-42cd-b006-bfa3a6fec31d,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-d811e5b6-c963-4fbd-923b-90bc8c1107e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-82da6a6c-c4da-4dad-b0e6-408d37b26639,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-5f98c74d-87b7-458d-8f96-b168f4ea99ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-bc7c7220-17a4-4571-a46e-0e8a9ffa7497,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-c84e59e0-a976-49dc-abb0-c203d50ef955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5502
