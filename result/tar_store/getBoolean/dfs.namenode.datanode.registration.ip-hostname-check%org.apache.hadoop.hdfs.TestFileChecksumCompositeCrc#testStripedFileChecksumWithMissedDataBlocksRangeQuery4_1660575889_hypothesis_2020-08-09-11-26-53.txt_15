reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493530068-172.17.0.5-1596972940420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45594,DS-e3bf2223-6348-4484-bb70-ba7d21e925da,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-4e7a1143-f2c5-48c2-a4c6-b14a54340009,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-000654e7-f032-47cc-8e42-7f5bc1d9f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-93e84dd7-a33a-41d9-8603-8b9950ead313,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-4886c26f-12ae-4ebf-a99e-65ace27714e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-b498ebff-44e9-4adc-a3ff-1f9e439f41c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-5c37ab8a-12b9-42e0-9b53-47de9fc95a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-3aae6088-149a-4fc4-9582-13bf19a6b623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493530068-172.17.0.5-1596972940420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45594,DS-e3bf2223-6348-4484-bb70-ba7d21e925da,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-4e7a1143-f2c5-48c2-a4c6-b14a54340009,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-000654e7-f032-47cc-8e42-7f5bc1d9f5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-93e84dd7-a33a-41d9-8603-8b9950ead313,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-4886c26f-12ae-4ebf-a99e-65ace27714e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-b498ebff-44e9-4adc-a3ff-1f9e439f41c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-5c37ab8a-12b9-42e0-9b53-47de9fc95a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-3aae6088-149a-4fc4-9582-13bf19a6b623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263567550-172.17.0.5-1596973043784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44605,DS-ea5adc3d-45e7-42d4-8e3f-bee3407abd10,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-5ea14615-06d8-468c-afbd-0206ba9d11af,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-afff14ab-eb3f-4dd8-b93d-61728a43add7,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-761a5cac-7dfd-4ac2-adda-9eca252a669b,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-8cef8ff8-7678-4602-a56b-c92e5d2b345e,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-d6e724ff-8364-4eb7-9399-b7769d1b2797,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-bb79cb0e-0b5f-4c7f-99b4-157f7509fcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-6a81ead0-5f54-445f-a84b-44e82e30cb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263567550-172.17.0.5-1596973043784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44605,DS-ea5adc3d-45e7-42d4-8e3f-bee3407abd10,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-5ea14615-06d8-468c-afbd-0206ba9d11af,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-afff14ab-eb3f-4dd8-b93d-61728a43add7,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-761a5cac-7dfd-4ac2-adda-9eca252a669b,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-8cef8ff8-7678-4602-a56b-c92e5d2b345e,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-d6e724ff-8364-4eb7-9399-b7769d1b2797,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-bb79cb0e-0b5f-4c7f-99b4-157f7509fcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-6a81ead0-5f54-445f-a84b-44e82e30cb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097283216-172.17.0.5-1596973081386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-12944c9c-f161-4256-b856-87d76c5255b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-75137c12-65c7-4aa1-a6f3-a6b37c0eafa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-39d69d14-564f-4d51-974f-4671d257fe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-6b3d6b1d-ec55-4961-a80f-781714ae9dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-2efd33a4-49d3-4aed-8aa0-f5d65991185d,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-9dd525e9-aa7e-4b0c-9f3c-986693a1d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-a04ea2f5-0cbf-47cc-beb4-b12f60766bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-22882228-8248-4bd1-a0a3-ca09d635ee2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097283216-172.17.0.5-1596973081386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-12944c9c-f161-4256-b856-87d76c5255b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-75137c12-65c7-4aa1-a6f3-a6b37c0eafa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-39d69d14-564f-4d51-974f-4671d257fe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-6b3d6b1d-ec55-4961-a80f-781714ae9dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-2efd33a4-49d3-4aed-8aa0-f5d65991185d,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-9dd525e9-aa7e-4b0c-9f3c-986693a1d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-a04ea2f5-0cbf-47cc-beb4-b12f60766bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-22882228-8248-4bd1-a0a3-ca09d635ee2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18923731-172.17.0.5-1596973594629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33800,DS-44b672d4-1fe6-4eb6-8fb0-34dd58d605a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-407c777d-44f7-4e7e-ba5a-d18c4d1cee84,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-efb62c05-804a-47b1-8c6c-85fb6c037f78,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-1f244ec3-5607-45bb-b039-4b355a9e8102,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-232f7c97-c62b-40ec-a75c-287269ebce79,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-396e20e2-f50f-40b6-ade4-4fa5dfc41510,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-40190a65-7182-4cc1-ad2a-c09ec4270c02,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-57aace09-da87-4ec8-aae2-5a92ccf5f9a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18923731-172.17.0.5-1596973594629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33800,DS-44b672d4-1fe6-4eb6-8fb0-34dd58d605a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-407c777d-44f7-4e7e-ba5a-d18c4d1cee84,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-efb62c05-804a-47b1-8c6c-85fb6c037f78,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-1f244ec3-5607-45bb-b039-4b355a9e8102,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-232f7c97-c62b-40ec-a75c-287269ebce79,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-396e20e2-f50f-40b6-ade4-4fa5dfc41510,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-40190a65-7182-4cc1-ad2a-c09ec4270c02,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-57aace09-da87-4ec8-aae2-5a92ccf5f9a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410700539-172.17.0.5-1596974214980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-daf75b3e-3571-413a-bf39-abea223373c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-d0fc484c-e527-4bce-b9e1-4ac8baeb669d,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-cbed5f30-76f8-4076-8c55-b96fcac99618,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-31a5b991-d72c-4189-89c7-533c11213bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-07d0ae1c-d04c-4a56-9059-d4ec94d304d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-5cf449df-21c3-4093-8e38-dfd17002237e,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-13e28802-e0c0-475e-a2ad-c51fc3db9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-7b01205e-fa95-4916-a526-d497fdfbe004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410700539-172.17.0.5-1596974214980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-daf75b3e-3571-413a-bf39-abea223373c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-d0fc484c-e527-4bce-b9e1-4ac8baeb669d,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-cbed5f30-76f8-4076-8c55-b96fcac99618,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-31a5b991-d72c-4189-89c7-533c11213bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-07d0ae1c-d04c-4a56-9059-d4ec94d304d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-5cf449df-21c3-4093-8e38-dfd17002237e,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-13e28802-e0c0-475e-a2ad-c51fc3db9b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-7b01205e-fa95-4916-a526-d497fdfbe004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312346075-172.17.0.5-1596974638850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-f408a4d3-8de3-439a-8118-12ccaab0fcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-6ba2988b-8611-419a-9edd-23b83da3b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-979bde20-6bcf-4b69-bd69-4750526ab576,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-6961e2e9-5cd0-4f2b-ad2b-0ef09ba5a183,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-8d0c6933-e56e-4027-84bc-7c84d950386d,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-b44ac42d-f4df-4de7-afce-04c6bdf2ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-d4c3e5c3-ae0a-404a-850f-87f3205848e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-5dcbf378-133f-44cf-a7f5-fa52c3354ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312346075-172.17.0.5-1596974638850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-f408a4d3-8de3-439a-8118-12ccaab0fcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-6ba2988b-8611-419a-9edd-23b83da3b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-979bde20-6bcf-4b69-bd69-4750526ab576,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-6961e2e9-5cd0-4f2b-ad2b-0ef09ba5a183,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-8d0c6933-e56e-4027-84bc-7c84d950386d,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-b44ac42d-f4df-4de7-afce-04c6bdf2ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-d4c3e5c3-ae0a-404a-850f-87f3205848e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-5dcbf378-133f-44cf-a7f5-fa52c3354ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790188841-172.17.0.5-1596974854996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35512,DS-26cdf02d-4286-4a89-a73d-f43135ec8ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-5f036cd4-14cf-40a2-ad04-fa615fc44c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-72ca096d-61f8-434e-a365-ea7ca255eb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-963f7173-2100-4cfa-bd0c-1448af522e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-62984cb2-f285-40e9-aaba-5ed584726564,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-5cb629ff-b5d6-43ea-8727-cafe23dffe92,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-3dd596a5-ee3f-488a-9a5f-f32ed38c074c,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-684d4c58-8d5d-4119-b5e1-771dc41eff2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790188841-172.17.0.5-1596974854996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35512,DS-26cdf02d-4286-4a89-a73d-f43135ec8ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-5f036cd4-14cf-40a2-ad04-fa615fc44c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-72ca096d-61f8-434e-a365-ea7ca255eb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-963f7173-2100-4cfa-bd0c-1448af522e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-62984cb2-f285-40e9-aaba-5ed584726564,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-5cb629ff-b5d6-43ea-8727-cafe23dffe92,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-3dd596a5-ee3f-488a-9a5f-f32ed38c074c,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-684d4c58-8d5d-4119-b5e1-771dc41eff2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340058197-172.17.0.5-1596974965694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-30805fbe-af23-45fe-84f0-820a07e6b439,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-015b17ca-26b0-4d0f-ac5a-757fbbf64bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-a5e95166-94c8-47b8-bbf0-a15a3c80d978,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-ebee0b2a-9bef-4383-a692-d13f1d463bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-022963ee-d19a-4d1b-b006-d110d75a726a,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-53f4c25d-032d-4db1-a97d-cb7ea91613ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-a7408995-4921-4cbc-90b5-19f8c17ddca0,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-c339e9f5-f2e6-40de-a622-ba0826b3588f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340058197-172.17.0.5-1596974965694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-30805fbe-af23-45fe-84f0-820a07e6b439,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-015b17ca-26b0-4d0f-ac5a-757fbbf64bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-a5e95166-94c8-47b8-bbf0-a15a3c80d978,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-ebee0b2a-9bef-4383-a692-d13f1d463bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-022963ee-d19a-4d1b-b006-d110d75a726a,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-53f4c25d-032d-4db1-a97d-cb7ea91613ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-a7408995-4921-4cbc-90b5-19f8c17ddca0,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-c339e9f5-f2e6-40de-a622-ba0826b3588f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377712612-172.17.0.5-1596975952808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-553209d7-1b2a-4604-9e46-2c22603fd7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-8e0c23a5-d39d-47b3-929f-939cb6310fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-e1ffc832-0958-4018-b858-201e30fa312c,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-3bdabfb4-d8ff-458e-b879-e51958049e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-e90ae97a-3cd1-4702-bc87-17f9318c29b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-1c3c53c9-893d-412c-ac17-bad621aab523,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-4bc6128a-0b98-4013-932b-ebf63475692b,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-4fc2d7a8-5dca-4c17-98a8-ce9eaf28ce1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377712612-172.17.0.5-1596975952808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-553209d7-1b2a-4604-9e46-2c22603fd7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-8e0c23a5-d39d-47b3-929f-939cb6310fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-e1ffc832-0958-4018-b858-201e30fa312c,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-3bdabfb4-d8ff-458e-b879-e51958049e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-e90ae97a-3cd1-4702-bc87-17f9318c29b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-1c3c53c9-893d-412c-ac17-bad621aab523,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-4bc6128a-0b98-4013-932b-ebf63475692b,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-4fc2d7a8-5dca-4c17-98a8-ce9eaf28ce1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609624175-172.17.0.5-1596976376434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-63ae4a06-76ae-420d-8cfb-c4f3cee41eea,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-26d225b5-aa3a-4937-a6a5-c0791bf7f079,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-887a138f-64a6-451b-abf9-31b1227d32ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-484ebbfd-e41f-468e-ae63-085f49b68bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-afccb886-85f6-4bc9-80cb-4026ac845599,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-df53ef5b-a93c-4c3b-bb36-bb3cec0962cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-1310231e-3060-4117-a287-0980a19ca455,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-286e60e8-1386-4b84-b548-f46cd730b04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609624175-172.17.0.5-1596976376434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-63ae4a06-76ae-420d-8cfb-c4f3cee41eea,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-26d225b5-aa3a-4937-a6a5-c0791bf7f079,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-887a138f-64a6-451b-abf9-31b1227d32ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-484ebbfd-e41f-468e-ae63-085f49b68bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-afccb886-85f6-4bc9-80cb-4026ac845599,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-df53ef5b-a93c-4c3b-bb36-bb3cec0962cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-1310231e-3060-4117-a287-0980a19ca455,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-286e60e8-1386-4b84-b548-f46cd730b04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963386354-172.17.0.5-1596976442530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-be698612-93fb-4f60-ad9c-04ddecd80eab,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-e3bbc3aa-f618-483f-8456-f68e1d3fe470,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-12786dd2-5e1d-459b-9fc1-dbf93920b24c,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-8bdc1c4b-f558-4d8e-b327-d0ff37af3217,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-f022f2e5-e956-418d-af16-16fedc91bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-8fe6bced-39bb-4488-9033-d7e22d3becdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-a973a51e-d6de-4c4a-a65d-a00ecf164e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-c238324a-4c9b-4b45-9267-c931fb00d361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963386354-172.17.0.5-1596976442530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-be698612-93fb-4f60-ad9c-04ddecd80eab,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-e3bbc3aa-f618-483f-8456-f68e1d3fe470,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-12786dd2-5e1d-459b-9fc1-dbf93920b24c,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-8bdc1c4b-f558-4d8e-b327-d0ff37af3217,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-f022f2e5-e956-418d-af16-16fedc91bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-8fe6bced-39bb-4488-9033-d7e22d3becdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-a973a51e-d6de-4c4a-a65d-a00ecf164e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-c238324a-4c9b-4b45-9267-c931fb00d361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532349545-172.17.0.5-1596976730164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-2765ce76-efd9-4aba-abc7-bb6dd6bc60e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-fb01a12f-f91a-48f8-8c43-1f6e2ea5da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-94752e4b-a2c5-4547-9049-660dcb26b99f,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-0c1f6532-9cde-4d03-a8ee-cfd2864db329,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-5ce04c03-f1bd-4298-b5bb-005fc2a30628,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-12204810-1e3c-4912-b26a-291aeec468d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-e5e568e0-7413-4735-abd4-6b2d8d9fae77,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-03d45a0c-0f52-4fc5-aea7-956172499a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532349545-172.17.0.5-1596976730164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-2765ce76-efd9-4aba-abc7-bb6dd6bc60e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-fb01a12f-f91a-48f8-8c43-1f6e2ea5da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-94752e4b-a2c5-4547-9049-660dcb26b99f,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-0c1f6532-9cde-4d03-a8ee-cfd2864db329,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-5ce04c03-f1bd-4298-b5bb-005fc2a30628,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-12204810-1e3c-4912-b26a-291aeec468d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-e5e568e0-7413-4735-abd4-6b2d8d9fae77,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-03d45a0c-0f52-4fc5-aea7-956172499a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034779101-172.17.0.5-1596976771453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37490,DS-f2cd6b1e-0874-4ead-9577-cb415312b378,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-ac395f4c-83c0-453d-85c3-4d6f6e329fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-07600938-3ac9-490b-a8ff-7a03b4366542,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-8ab9c9bf-6feb-4fdd-90a0-ea28ca46c150,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-04df5b1e-7d98-42c7-9d8b-758de5dfb2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-a2cd9e42-00f8-4e7c-8dcb-c8e59f2d11d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-6319c744-c6d9-4243-9577-4d8c392a0f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-54903487-314b-423f-9f83-e781bd8452db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034779101-172.17.0.5-1596976771453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37490,DS-f2cd6b1e-0874-4ead-9577-cb415312b378,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-ac395f4c-83c0-453d-85c3-4d6f6e329fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-07600938-3ac9-490b-a8ff-7a03b4366542,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-8ab9c9bf-6feb-4fdd-90a0-ea28ca46c150,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-04df5b1e-7d98-42c7-9d8b-758de5dfb2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-a2cd9e42-00f8-4e7c-8dcb-c8e59f2d11d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-6319c744-c6d9-4243-9577-4d8c392a0f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-54903487-314b-423f-9f83-e781bd8452db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737150352-172.17.0.5-1596977029624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35149,DS-e9e9260d-b29e-4cb3-8c9a-2f8ced8ec7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-9613abc3-b384-4bea-91a9-886cd5dd7c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-c0489cfb-694b-4641-9c85-b79540654b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-ee9baa66-7e58-4080-9165-a678d777ffec,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-a77119f2-cff1-4748-92c8-ff1c4e65fce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-b23dc4d4-a057-4cfb-a38c-04f297a307e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-e58e112a-d670-4782-a995-28f8c6ac88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-4cb9790a-aeed-478e-b030-076e9cf77e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737150352-172.17.0.5-1596977029624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35149,DS-e9e9260d-b29e-4cb3-8c9a-2f8ced8ec7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-9613abc3-b384-4bea-91a9-886cd5dd7c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-c0489cfb-694b-4641-9c85-b79540654b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-ee9baa66-7e58-4080-9165-a678d777ffec,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-a77119f2-cff1-4748-92c8-ff1c4e65fce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-b23dc4d4-a057-4cfb-a38c-04f297a307e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-e58e112a-d670-4782-a995-28f8c6ac88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-4cb9790a-aeed-478e-b030-076e9cf77e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437396179-172.17.0.5-1596977392119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-1f746730-1c54-44bc-811c-04374a4b01e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-d6cd9973-ccf0-4e5a-b051-3038ca7ba56a,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-fe55da51-6173-4ee3-8981-d58ab6bbfe08,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-71ba3806-a162-4354-a650-5a8b1d95efd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-799ab470-f313-49c9-bfb6-78b2e773f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-e78fc5b1-9619-49a4-890d-1b2b854213f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-67396416-f4cb-42e2-a150-d2aedccd73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-9e11a3c7-7a38-46de-a560-068bd2af38c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437396179-172.17.0.5-1596977392119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-1f746730-1c54-44bc-811c-04374a4b01e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-d6cd9973-ccf0-4e5a-b051-3038ca7ba56a,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-fe55da51-6173-4ee3-8981-d58ab6bbfe08,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-71ba3806-a162-4354-a650-5a8b1d95efd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-799ab470-f313-49c9-bfb6-78b2e773f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-e78fc5b1-9619-49a4-890d-1b2b854213f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-67396416-f4cb-42e2-a150-d2aedccd73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-9e11a3c7-7a38-46de-a560-068bd2af38c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869222104-172.17.0.5-1596977430791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-c59736f3-ed26-4899-9b72-28df70c58ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-f9498de0-6297-44a1-9d0d-f4c52ab4b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-11ed19fc-9098-4324-88e8-552ec8b398a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-4e8661dc-621a-4b9f-aa40-7f7fb4e3591a,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-f3971076-3c21-4764-b53b-417667bff69a,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-5974cdbb-ef40-45ff-a8de-7fc8bb9a63b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-60b85317-3e8d-40e9-9964-60592b518b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-90b46400-9c77-42a3-8fdf-aad2d27d7ba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869222104-172.17.0.5-1596977430791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-c59736f3-ed26-4899-9b72-28df70c58ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-f9498de0-6297-44a1-9d0d-f4c52ab4b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-11ed19fc-9098-4324-88e8-552ec8b398a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-4e8661dc-621a-4b9f-aa40-7f7fb4e3591a,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-f3971076-3c21-4764-b53b-417667bff69a,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-5974cdbb-ef40-45ff-a8de-7fc8bb9a63b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-60b85317-3e8d-40e9-9964-60592b518b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-90b46400-9c77-42a3-8fdf-aad2d27d7ba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5360
