reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662680432-172.17.0.15-1596915503857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41403,DS-8e85950c-43fa-4cfc-8a9d-068cfaffb852,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-4426ba94-09dd-4103-b263-3908d55a86bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-e60ee00d-c4aa-4a91-b59b-d49b2e238e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-1ffb72ea-76f7-4159-8f10-b1490033d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-bd80a628-5398-4dfe-a4ed-2a594cc1ab37,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-4219eda0-7006-43c7-9253-450e6c0c0de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-e09da1f9-7188-433b-ba88-c9240ce50ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-12b46185-005f-4e6d-baee-c659f24e2c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662680432-172.17.0.15-1596915503857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41403,DS-8e85950c-43fa-4cfc-8a9d-068cfaffb852,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-4426ba94-09dd-4103-b263-3908d55a86bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-e60ee00d-c4aa-4a91-b59b-d49b2e238e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-1ffb72ea-76f7-4159-8f10-b1490033d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-bd80a628-5398-4dfe-a4ed-2a594cc1ab37,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-4219eda0-7006-43c7-9253-450e6c0c0de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-e09da1f9-7188-433b-ba88-c9240ce50ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-12b46185-005f-4e6d-baee-c659f24e2c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417527768-172.17.0.15-1596917391084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45867,DS-5f2ad27d-6b5b-42ce-8fc7-e454b5089c73,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-fbc571f6-3dde-42c5-b579-e41d10df84e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-dcfe3f52-1740-46ba-b8fd-44bb3f69ec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-9796919a-90b0-465e-a01a-c7bc174a0ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-3c53284c-261b-4b02-8b15-2c51a887fdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-74da9513-07ca-471d-9342-db328ad0da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-70e57e44-942a-4177-826d-f2391f8bd36b,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-956fd9d1-807e-4504-8ae2-1a50ed048a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417527768-172.17.0.15-1596917391084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45867,DS-5f2ad27d-6b5b-42ce-8fc7-e454b5089c73,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-fbc571f6-3dde-42c5-b579-e41d10df84e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-dcfe3f52-1740-46ba-b8fd-44bb3f69ec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-9796919a-90b0-465e-a01a-c7bc174a0ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-3c53284c-261b-4b02-8b15-2c51a887fdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-74da9513-07ca-471d-9342-db328ad0da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-70e57e44-942a-4177-826d-f2391f8bd36b,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-956fd9d1-807e-4504-8ae2-1a50ed048a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536709261-172.17.0.15-1596917792159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-4851a2b0-1ae0-4dfe-9ef8-d2c0d479bf75,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-c49c836d-7961-445c-975b-e4518b52c701,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-6572745c-ad09-4e9e-9c4c-5e33771ea952,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-89b09dc2-cb06-4f3d-bdf1-a4247a25a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-b93d4721-d813-48c5-9e19-23210610ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-1d89847b-4579-4f2f-b948-951211164b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-d1fc6616-424a-44a7-bb9d-ebb8b16d1317,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-639d8107-02ca-4cb8-b82f-5427892d3854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536709261-172.17.0.15-1596917792159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-4851a2b0-1ae0-4dfe-9ef8-d2c0d479bf75,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-c49c836d-7961-445c-975b-e4518b52c701,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-6572745c-ad09-4e9e-9c4c-5e33771ea952,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-89b09dc2-cb06-4f3d-bdf1-a4247a25a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-b93d4721-d813-48c5-9e19-23210610ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-1d89847b-4579-4f2f-b948-951211164b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-d1fc6616-424a-44a7-bb9d-ebb8b16d1317,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-639d8107-02ca-4cb8-b82f-5427892d3854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066646151-172.17.0.15-1596918500723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45906,DS-68f83d45-b66c-4a9c-bb16-34d6a31d3c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-fa5b3cc5-4c13-4afd-969d-88c9019a1ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-74f2838b-6cd0-4de9-be61-26cc4f2a8e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-aef675f8-074a-4b79-94fa-0a64f96607f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-0fe437e8-bb74-408f-b1b7-2a6a51c19d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-a868192b-7602-46c1-b6f7-eede2f91c1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-6a2a8b3f-5f24-4f09-8095-62fc4bb51381,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-84e9db77-6892-46fc-af3f-cf44a599ab10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066646151-172.17.0.15-1596918500723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45906,DS-68f83d45-b66c-4a9c-bb16-34d6a31d3c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-fa5b3cc5-4c13-4afd-969d-88c9019a1ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-74f2838b-6cd0-4de9-be61-26cc4f2a8e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-aef675f8-074a-4b79-94fa-0a64f96607f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-0fe437e8-bb74-408f-b1b7-2a6a51c19d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-a868192b-7602-46c1-b6f7-eede2f91c1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-6a2a8b3f-5f24-4f09-8095-62fc4bb51381,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-84e9db77-6892-46fc-af3f-cf44a599ab10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065515710-172.17.0.15-1596919424551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32971,DS-c3fb1f75-0290-4a6d-8b93-f7784f08b589,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-4e491c20-8379-4887-94ed-468d84279756,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-d88e6f30-36c8-42a6-9c74-a734761829d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-d5dfa765-82a6-4af5-bc4d-c6451d5e9ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-d467fae8-b8f9-4af3-b770-0082cd0eab48,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-e4a39b0e-32ac-435c-bd91-f58f9c5ca5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-fc93284e-770b-4a3e-9d51-582b81627e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-1cc4ac67-77c1-4f60-ae97-52be1054e146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065515710-172.17.0.15-1596919424551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32971,DS-c3fb1f75-0290-4a6d-8b93-f7784f08b589,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-4e491c20-8379-4887-94ed-468d84279756,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-d88e6f30-36c8-42a6-9c74-a734761829d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-d5dfa765-82a6-4af5-bc4d-c6451d5e9ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-d467fae8-b8f9-4af3-b770-0082cd0eab48,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-e4a39b0e-32ac-435c-bd91-f58f9c5ca5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-fc93284e-770b-4a3e-9d51-582b81627e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-1cc4ac67-77c1-4f60-ae97-52be1054e146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548469913-172.17.0.15-1596919605120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39135,DS-cc3caf22-b8b9-4dd9-b9a2-213c90b70124,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-b554f306-6235-44e6-9ad2-a1db87c6247f,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-2b6f27d9-5a27-4972-b4d5-30b49493a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-c09513b8-1e32-49ea-b0e5-42f000756b42,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-fef07ffe-2384-436f-86cb-6bf8eeda6a54,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-bfe5b4b0-3b2f-46f1-9f73-0736ccc720af,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-99e27499-905b-4dde-a52d-4502cea45f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-601d489a-cc1d-4f96-b004-4342302fc291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548469913-172.17.0.15-1596919605120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39135,DS-cc3caf22-b8b9-4dd9-b9a2-213c90b70124,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-b554f306-6235-44e6-9ad2-a1db87c6247f,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-2b6f27d9-5a27-4972-b4d5-30b49493a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-c09513b8-1e32-49ea-b0e5-42f000756b42,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-fef07ffe-2384-436f-86cb-6bf8eeda6a54,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-bfe5b4b0-3b2f-46f1-9f73-0736ccc720af,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-99e27499-905b-4dde-a52d-4502cea45f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-601d489a-cc1d-4f96-b004-4342302fc291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780688451-172.17.0.15-1596920419342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37975,DS-d25f6256-0d2b-44b4-8cd0-36430fa3aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-e0e33b29-7e4f-4f9c-b42f-8ee3e538c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-15e1c829-5380-4867-a0bc-a2da5b1df9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-b4ad76b6-cc5b-4549-9090-e4c9a5edbd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-1ce48df2-9164-4526-bb6d-8d28f8e15cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-cf6b00f0-d526-4598-82ea-5772de5db7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-01595164-3f11-4d09-a87c-f0a9a85d02fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-3d323aff-ae3d-4c7c-bd81-d56f69efe556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780688451-172.17.0.15-1596920419342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37975,DS-d25f6256-0d2b-44b4-8cd0-36430fa3aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-e0e33b29-7e4f-4f9c-b42f-8ee3e538c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-15e1c829-5380-4867-a0bc-a2da5b1df9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-b4ad76b6-cc5b-4549-9090-e4c9a5edbd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-1ce48df2-9164-4526-bb6d-8d28f8e15cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-cf6b00f0-d526-4598-82ea-5772de5db7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-01595164-3f11-4d09-a87c-f0a9a85d02fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-3d323aff-ae3d-4c7c-bd81-d56f69efe556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679576319-172.17.0.15-1596920509502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36115,DS-2a080cbc-741b-4d6e-837d-7dbb8912a715,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-f4d6821e-a582-4fb8-9614-38c701d61b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-61dadc49-f92a-4a04-98b9-40588c3b5aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-aafda852-28ee-4fb0-83b8-dcd31a1eec62,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-1478d945-2c81-4974-8d05-bb4832f154ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-0f5e6d7d-9af1-456c-92a3-a2d1920b8702,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-1a878abf-cbff-48f9-9237-38bc09c994e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-89f3d5f7-e830-4adf-badb-15b7728a2434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679576319-172.17.0.15-1596920509502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36115,DS-2a080cbc-741b-4d6e-837d-7dbb8912a715,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-f4d6821e-a582-4fb8-9614-38c701d61b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-61dadc49-f92a-4a04-98b9-40588c3b5aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-aafda852-28ee-4fb0-83b8-dcd31a1eec62,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-1478d945-2c81-4974-8d05-bb4832f154ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-0f5e6d7d-9af1-456c-92a3-a2d1920b8702,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-1a878abf-cbff-48f9-9237-38bc09c994e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-89f3d5f7-e830-4adf-badb-15b7728a2434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806559860-172.17.0.15-1596920630325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-d4bd4574-146b-470c-8c62-1413210d6a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-19ad1fa3-9724-4ab6-a1a6-81a982f3bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-07f9c46b-5827-4a73-97f3-3adbc6093a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-de4ada95-d4fa-4a58-a187-fb04cd08aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-dbdc448d-cd5f-41f1-a3fc-0f263f2d119c,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-4b78abb1-6dda-441c-9538-d584d219f1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-2a07629c-1687-4d25-9151-8b73737ca432,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-c7d55faa-5347-4611-8f83-52fa135cf0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806559860-172.17.0.15-1596920630325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-d4bd4574-146b-470c-8c62-1413210d6a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-19ad1fa3-9724-4ab6-a1a6-81a982f3bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-07f9c46b-5827-4a73-97f3-3adbc6093a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-de4ada95-d4fa-4a58-a187-fb04cd08aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-dbdc448d-cd5f-41f1-a3fc-0f263f2d119c,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-4b78abb1-6dda-441c-9538-d584d219f1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-2a07629c-1687-4d25-9151-8b73737ca432,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-c7d55faa-5347-4611-8f83-52fa135cf0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772150078-172.17.0.15-1596920750051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38553,DS-1afb7ed5-74c8-4b3f-8aa2-8d86e3892b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-3d0f206f-2710-4ba2-a2a1-878372b57669,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-ce8e197a-9749-4200-b213-a8a1672d6daf,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-d8adbb20-2e95-406d-a395-99dfdee5c320,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-c84f4896-c11d-4c3c-a71b-4d94c95d675b,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-892a6f9b-fe16-438d-aae8-eb8659ef3be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-27582b6c-6315-4bd2-ad5d-fe74f1950305,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-e2a2e4e0-22a2-4b72-ad6a-faf0c7040a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772150078-172.17.0.15-1596920750051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38553,DS-1afb7ed5-74c8-4b3f-8aa2-8d86e3892b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-3d0f206f-2710-4ba2-a2a1-878372b57669,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-ce8e197a-9749-4200-b213-a8a1672d6daf,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-d8adbb20-2e95-406d-a395-99dfdee5c320,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-c84f4896-c11d-4c3c-a71b-4d94c95d675b,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-892a6f9b-fe16-438d-aae8-eb8659ef3be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-27582b6c-6315-4bd2-ad5d-fe74f1950305,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-e2a2e4e0-22a2-4b72-ad6a-faf0c7040a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880099236-172.17.0.15-1596920837301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33075,DS-2096ae2c-7eff-4f25-ac0f-c7158fc0614b,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-c3ee8325-ad3f-4cf0-8400-7cbf342b285e,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-dba99da9-6484-4feb-b118-4c9a26e2b898,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-413ce407-8623-4fda-a9f9-6f4133440bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-2812500a-f8be-4f28-a29f-f0ebc034d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-d3a3621f-6c3a-4cd1-b768-dffce524dea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-9e1d542e-2cc5-47d5-84c1-2ceabe69ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-aea84bee-f623-478a-84a4-902493533e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880099236-172.17.0.15-1596920837301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33075,DS-2096ae2c-7eff-4f25-ac0f-c7158fc0614b,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-c3ee8325-ad3f-4cf0-8400-7cbf342b285e,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-dba99da9-6484-4feb-b118-4c9a26e2b898,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-413ce407-8623-4fda-a9f9-6f4133440bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-2812500a-f8be-4f28-a29f-f0ebc034d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-d3a3621f-6c3a-4cd1-b768-dffce524dea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-9e1d542e-2cc5-47d5-84c1-2ceabe69ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-aea84bee-f623-478a-84a4-902493533e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978870996-172.17.0.15-1596920889591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35872,DS-725a47ac-074d-4af2-8a4e-49211819e118,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-07838e70-1074-46ab-b95d-f5288b6b2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-2547351e-3c68-4633-ac01-a4619bcdd1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-bb5635aa-a5a1-4c74-a962-5fe84aa1ef68,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-07a40287-067a-4a42-aa2f-619a1bbe479f,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-c49221cc-a1e4-4c0a-8c49-d01c6c6c4a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-b49c7fff-bc72-4437-8d20-ec0f63c92a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-e1128cc3-b8a0-41f4-ae91-749c95120f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978870996-172.17.0.15-1596920889591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35872,DS-725a47ac-074d-4af2-8a4e-49211819e118,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-07838e70-1074-46ab-b95d-f5288b6b2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-2547351e-3c68-4633-ac01-a4619bcdd1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-bb5635aa-a5a1-4c74-a962-5fe84aa1ef68,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-07a40287-067a-4a42-aa2f-619a1bbe479f,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-c49221cc-a1e4-4c0a-8c49-d01c6c6c4a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-b49c7fff-bc72-4437-8d20-ec0f63c92a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-e1128cc3-b8a0-41f4-ae91-749c95120f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001245544-172.17.0.15-1596920975052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36624,DS-228ed16e-b6fb-486a-b34a-64f78165f67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-6c139c73-4eee-4d4f-bdb7-ffb30de571eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-92e21869-56a2-4e05-90ec-3e384258e3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-692df9b8-3247-4443-aec6-8c15957f85dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-ba11b1dc-3464-4574-8035-4c783ad2c04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-afefd049-1872-4951-a1a7-848499693b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-07ab6119-ef45-4f74-9bce-9e473d6770f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-6f741d7a-2c61-4995-a4ad-b489afffa925,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001245544-172.17.0.15-1596920975052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36624,DS-228ed16e-b6fb-486a-b34a-64f78165f67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-6c139c73-4eee-4d4f-bdb7-ffb30de571eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-92e21869-56a2-4e05-90ec-3e384258e3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-692df9b8-3247-4443-aec6-8c15957f85dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-ba11b1dc-3464-4574-8035-4c783ad2c04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-afefd049-1872-4951-a1a7-848499693b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-07ab6119-ef45-4f74-9bce-9e473d6770f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-6f741d7a-2c61-4995-a4ad-b489afffa925,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101291701-172.17.0.15-1596921532646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-3a7b4276-ff29-4e36-9121-ab1c7a8d0f24,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-23ccda7f-bb0c-411f-9c4f-ea9d2f7fcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-ce9ba3ef-b157-410a-9580-311fba68c487,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-1c01da55-031b-4a2f-9252-6b42121a3250,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-355a8f99-62c9-4bd4-a437-74107e365842,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-71523246-1cb8-46bb-9ddf-f76c89174e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-5c5f453b-5983-4f2e-9e36-ba2fdbdda2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-a9a06991-2e34-42e7-b86e-69c00d0655e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101291701-172.17.0.15-1596921532646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-3a7b4276-ff29-4e36-9121-ab1c7a8d0f24,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-23ccda7f-bb0c-411f-9c4f-ea9d2f7fcf21,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-ce9ba3ef-b157-410a-9580-311fba68c487,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-1c01da55-031b-4a2f-9252-6b42121a3250,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-355a8f99-62c9-4bd4-a437-74107e365842,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-71523246-1cb8-46bb-9ddf-f76c89174e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-5c5f453b-5983-4f2e-9e36-ba2fdbdda2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-a9a06991-2e34-42e7-b86e-69c00d0655e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6725
