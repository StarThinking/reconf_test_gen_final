reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085085924-172.17.0.8-1595516700853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-e0a57c89-8268-477e-91ec-6d5faaee1f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-46c92024-379c-4204-9739-5975e77660e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-a7869aba-c491-41e2-b191-e7d1c09859b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-986be4aa-8cbe-4654-91e1-f04baf9bc35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-bf3aa2df-cc5e-4b9f-99f4-14adc4c6186e,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-77f04f89-b32b-4546-9917-9b0c01a4e0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-f9bb568a-c2b1-435f-8c56-f0d084a0d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-627e670e-3d97-4d76-92bf-8e208a9f5862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085085924-172.17.0.8-1595516700853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-e0a57c89-8268-477e-91ec-6d5faaee1f19,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-46c92024-379c-4204-9739-5975e77660e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-a7869aba-c491-41e2-b191-e7d1c09859b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-986be4aa-8cbe-4654-91e1-f04baf9bc35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-bf3aa2df-cc5e-4b9f-99f4-14adc4c6186e,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-77f04f89-b32b-4546-9917-9b0c01a4e0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-f9bb568a-c2b1-435f-8c56-f0d084a0d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-627e670e-3d97-4d76-92bf-8e208a9f5862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947121968-172.17.0.8-1595516903445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45741,DS-2b8f9f34-b105-4671-8a8a-84983ead1d08,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-818246e3-7564-44f5-ae4d-d753af5569f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-0fea2131-050d-4334-a49a-6807ad3fb6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-2d25f8c1-058e-4a6f-80df-3b318eed6024,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-d3ad2671-9067-42b5-a47b-dc6091555486,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-c6cc7d81-b170-4c13-aff6-1f95b5c6b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-947aff11-e5c9-46e0-8afd-64fec25939ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-90e1fe4c-d23e-46ce-96cc-e09e9e33705b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947121968-172.17.0.8-1595516903445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45741,DS-2b8f9f34-b105-4671-8a8a-84983ead1d08,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-818246e3-7564-44f5-ae4d-d753af5569f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-0fea2131-050d-4334-a49a-6807ad3fb6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-2d25f8c1-058e-4a6f-80df-3b318eed6024,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-d3ad2671-9067-42b5-a47b-dc6091555486,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-c6cc7d81-b170-4c13-aff6-1f95b5c6b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-947aff11-e5c9-46e0-8afd-64fec25939ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-90e1fe4c-d23e-46ce-96cc-e09e9e33705b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107762825-172.17.0.8-1595517104805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-5898e099-ab92-4d50-bb67-e8769e0509f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-4d3b04cb-f403-491d-b1aa-27a43737d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-a3a12f08-458d-4a12-9283-00e9dbea37ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-e60369cb-4d45-4535-b381-9f6952c6e64f,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-a607d9e1-392b-432c-a9e4-a6fc7fda406e,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-ef5224a7-cd82-4a40-a09c-2c659385f0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-d345b1b7-ddcf-43a0-b985-9b675d9a4d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-cef1cfbe-f74c-4994-8ff6-7292309d88c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107762825-172.17.0.8-1595517104805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-5898e099-ab92-4d50-bb67-e8769e0509f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-4d3b04cb-f403-491d-b1aa-27a43737d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-a3a12f08-458d-4a12-9283-00e9dbea37ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-e60369cb-4d45-4535-b381-9f6952c6e64f,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-a607d9e1-392b-432c-a9e4-a6fc7fda406e,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-ef5224a7-cd82-4a40-a09c-2c659385f0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-d345b1b7-ddcf-43a0-b985-9b675d9a4d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-cef1cfbe-f74c-4994-8ff6-7292309d88c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101323647-172.17.0.8-1595517592221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-70a080ec-5730-43e2-94bf-349eff762945,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-c0f0cd28-b175-4078-8bd5-ecc26b2bd6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-f5c89b72-7342-4bb5-b28c-73b811beeb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-babe1510-76e1-4644-87d1-9380d4a4b9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-b825cd79-750d-44ee-8073-60d3d56aa095,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-0656a155-42cd-4448-840a-a487f0b8b29a,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-9c034467-9327-4a65-ac4b-0d6ea1cdafeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-29867ef9-e020-4844-b9eb-318224c32cbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101323647-172.17.0.8-1595517592221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-70a080ec-5730-43e2-94bf-349eff762945,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-c0f0cd28-b175-4078-8bd5-ecc26b2bd6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-f5c89b72-7342-4bb5-b28c-73b811beeb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-babe1510-76e1-4644-87d1-9380d4a4b9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-b825cd79-750d-44ee-8073-60d3d56aa095,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-0656a155-42cd-4448-840a-a487f0b8b29a,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-9c034467-9327-4a65-ac4b-0d6ea1cdafeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-29867ef9-e020-4844-b9eb-318224c32cbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624908060-172.17.0.8-1595517800124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-ac392656-702d-4dc0-baf6-520a997e1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-4de99635-608e-4a7a-aec8-894878849cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-3dc2a9dc-ed93-4872-a659-f2100ee892d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ccd652ab-b447-42bf-ad70-abeb320533d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-f517536c-ca93-4982-8368-fe5f622d313b,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-5859aead-6e1b-4e00-90fc-fd3ea7c534c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-3f33109a-13c4-404d-a6d2-07aafec6d242,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-72692172-ac05-4644-a664-ba2e46cb5176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624908060-172.17.0.8-1595517800124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-ac392656-702d-4dc0-baf6-520a997e1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-4de99635-608e-4a7a-aec8-894878849cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-3dc2a9dc-ed93-4872-a659-f2100ee892d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ccd652ab-b447-42bf-ad70-abeb320533d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-f517536c-ca93-4982-8368-fe5f622d313b,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-5859aead-6e1b-4e00-90fc-fd3ea7c534c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-3f33109a-13c4-404d-a6d2-07aafec6d242,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-72692172-ac05-4644-a664-ba2e46cb5176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810553216-172.17.0.8-1595517878592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34707,DS-955b3761-2fa1-4a25-8160-b5e17eb842ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-afb10cb0-b7e1-497b-ac65-984e12e4fc44,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-236fcac8-edea-47d4-9805-42ebacf66136,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-50b19274-df9f-467f-83a9-f9843e0865ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-90967e49-a126-40f1-8353-24d704c7309f,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-adb7c586-f1d6-4335-ae28-bea772e32d34,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-1e7063fb-5da0-460f-9a07-fff09631729f,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-12177c01-fc89-473e-8c48-6e5ff4b6d7ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810553216-172.17.0.8-1595517878592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34707,DS-955b3761-2fa1-4a25-8160-b5e17eb842ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-afb10cb0-b7e1-497b-ac65-984e12e4fc44,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-236fcac8-edea-47d4-9805-42ebacf66136,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-50b19274-df9f-467f-83a9-f9843e0865ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-90967e49-a126-40f1-8353-24d704c7309f,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-adb7c586-f1d6-4335-ae28-bea772e32d34,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-1e7063fb-5da0-460f-9a07-fff09631729f,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-12177c01-fc89-473e-8c48-6e5ff4b6d7ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427254763-172.17.0.8-1595518446090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36435,DS-c81bd8f5-a077-45f9-a067-c6519ccfe5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-a47967f4-5136-4bab-ad76-31f60c0aa61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-b2a38bd6-5c02-4934-8091-a49c9eef9283,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-8d497f60-30b0-4ec7-b3c0-87701f9ecc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-1adbe902-bf9a-4c52-beb5-10e5c72c357e,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-5f48bbb1-c763-46a4-a6ac-9e8f7689211b,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-dcb82d79-8d0a-4bbe-af45-11d354515b52,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-47dc9d81-b73b-4df9-a773-f7d844df7958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427254763-172.17.0.8-1595518446090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36435,DS-c81bd8f5-a077-45f9-a067-c6519ccfe5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-a47967f4-5136-4bab-ad76-31f60c0aa61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-b2a38bd6-5c02-4934-8091-a49c9eef9283,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-8d497f60-30b0-4ec7-b3c0-87701f9ecc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-1adbe902-bf9a-4c52-beb5-10e5c72c357e,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-5f48bbb1-c763-46a4-a6ac-9e8f7689211b,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-dcb82d79-8d0a-4bbe-af45-11d354515b52,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-47dc9d81-b73b-4df9-a773-f7d844df7958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198529380-172.17.0.8-1595519368442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-642a226e-5f49-4165-ac24-0ea702883bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-930d13dd-dd19-4d58-a153-0a2c78013344,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-0257dbce-755f-45dd-a786-148d169b4498,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-9ad8173a-7bf4-40e0-af36-14943b5cfa95,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-c0a27cec-61cb-4c19-80b2-16c34fe52d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-217e8f28-6e44-4586-a4e5-c3e92f6dce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-49cb0d3e-db0e-462d-9c26-80c36d14ec42,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-4e5a298e-4883-4bbf-b51e-0b82aa9520da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198529380-172.17.0.8-1595519368442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-642a226e-5f49-4165-ac24-0ea702883bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-930d13dd-dd19-4d58-a153-0a2c78013344,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-0257dbce-755f-45dd-a786-148d169b4498,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-9ad8173a-7bf4-40e0-af36-14943b5cfa95,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-c0a27cec-61cb-4c19-80b2-16c34fe52d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-217e8f28-6e44-4586-a4e5-c3e92f6dce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-49cb0d3e-db0e-462d-9c26-80c36d14ec42,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-4e5a298e-4883-4bbf-b51e-0b82aa9520da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288753973-172.17.0.8-1595520159032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-aa6f97ee-cced-4b0b-9aa0-ea7132c488e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-2fe5ce48-6c13-4254-a253-89637e8fbc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-ac306f45-c7bf-4689-9459-9892face1497,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-48ebc0d6-a40a-482f-867b-9576b8bc2ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-1f6ce253-8c40-40ac-b8ff-5da0b6321257,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-288190be-18d5-43d1-8f5d-96792382253f,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-0eebe61e-abdb-4742-9a56-ceed0c07bf96,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-39d05de3-fdb2-4f80-9367-b87ae002307a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288753973-172.17.0.8-1595520159032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-aa6f97ee-cced-4b0b-9aa0-ea7132c488e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-2fe5ce48-6c13-4254-a253-89637e8fbc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-ac306f45-c7bf-4689-9459-9892face1497,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-48ebc0d6-a40a-482f-867b-9576b8bc2ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-1f6ce253-8c40-40ac-b8ff-5da0b6321257,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-288190be-18d5-43d1-8f5d-96792382253f,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-0eebe61e-abdb-4742-9a56-ceed0c07bf96,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-39d05de3-fdb2-4f80-9367-b87ae002307a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760972516-172.17.0.8-1595520187272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44521,DS-8bd63145-9562-4f7a-8373-71dcd4ce025c,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-4b09d8f5-692f-43ab-a62d-ea2da8045f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-3f93a5f2-0c46-4056-9554-1f059ff93f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-e9346bcb-2880-4d77-8e1d-3b4eaca24509,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-94eb5784-a6ad-4800-aff0-8b810801aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-d2d7eeff-11ca-4044-ba7e-15a46be1cb84,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-329aaa86-675c-483d-b517-41eaaff7a3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-723e247a-b2b4-4666-a0ab-776f2cf8e6de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760972516-172.17.0.8-1595520187272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44521,DS-8bd63145-9562-4f7a-8373-71dcd4ce025c,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-4b09d8f5-692f-43ab-a62d-ea2da8045f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-3f93a5f2-0c46-4056-9554-1f059ff93f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-e9346bcb-2880-4d77-8e1d-3b4eaca24509,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-94eb5784-a6ad-4800-aff0-8b810801aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-d2d7eeff-11ca-4044-ba7e-15a46be1cb84,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-329aaa86-675c-483d-b517-41eaaff7a3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-723e247a-b2b4-4666-a0ab-776f2cf8e6de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457058654-172.17.0.8-1595521322082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-ac3ab899-e801-4403-920a-00c674d2f61f,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-ec924208-e16c-4d02-a2b3-84fcfaff71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-3c4ef7e7-c372-4b5f-907a-d15edeff2df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-9d3998b2-01e8-4308-a6f3-4629f92c7d12,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-78e3051c-bac2-4a39-bf58-ef9129ed12b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-09115068-04c8-4e9a-8cb8-2e8d9773b3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-48d97596-dcaa-4a6f-9ce0-3866469244bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-08c98ae7-f48d-4205-88d9-a5bcaa8731f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457058654-172.17.0.8-1595521322082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-ac3ab899-e801-4403-920a-00c674d2f61f,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-ec924208-e16c-4d02-a2b3-84fcfaff71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-3c4ef7e7-c372-4b5f-907a-d15edeff2df2,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-9d3998b2-01e8-4308-a6f3-4629f92c7d12,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-78e3051c-bac2-4a39-bf58-ef9129ed12b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-09115068-04c8-4e9a-8cb8-2e8d9773b3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-48d97596-dcaa-4a6f-9ce0-3866469244bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-08c98ae7-f48d-4205-88d9-a5bcaa8731f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339449317-172.17.0.8-1595521394028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40744,DS-c26d9687-ca16-4c36-8a5a-f0037c7a82ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-04dda566-a0a1-4429-803d-2fd0a4e667d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-5b5e838b-ec4c-484a-8119-a2b6de6f7cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-c7cc1ec1-74d7-45dc-9478-04d2a8e50f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-9d350140-0308-42a9-a067-3721d9cc8d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-66807384-4711-40d1-bbc8-fc5f9ebeef28,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-2700c94d-d359-4910-bddb-8b19a8f0124b,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-40f44a96-84c2-4901-a05b-a6147861e31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339449317-172.17.0.8-1595521394028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40744,DS-c26d9687-ca16-4c36-8a5a-f0037c7a82ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-04dda566-a0a1-4429-803d-2fd0a4e667d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-5b5e838b-ec4c-484a-8119-a2b6de6f7cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-c7cc1ec1-74d7-45dc-9478-04d2a8e50f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-9d350140-0308-42a9-a067-3721d9cc8d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-66807384-4711-40d1-bbc8-fc5f9ebeef28,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-2700c94d-d359-4910-bddb-8b19a8f0124b,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-40f44a96-84c2-4901-a05b-a6147861e31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114237604-172.17.0.8-1595521724179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38652,DS-dde82575-6124-49a5-b9ac-c40785ae2982,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-b001f4ac-97de-4a22-a8d9-24dedcbf2069,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-7b3d45f3-96e7-4ef8-9699-7a42c6b638bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-f0518704-c3f0-40c6-8f41-a9b1037b116c,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-157de91c-e932-4425-b894-48261b8220ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-52baa766-6f04-4779-acd2-8567918c0b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-73f3aac7-fa85-4f4b-a89d-dbcdf4115c53,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-7fabf1b3-38fb-475e-90a4-a82fbfb61884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114237604-172.17.0.8-1595521724179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38652,DS-dde82575-6124-49a5-b9ac-c40785ae2982,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-b001f4ac-97de-4a22-a8d9-24dedcbf2069,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-7b3d45f3-96e7-4ef8-9699-7a42c6b638bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-f0518704-c3f0-40c6-8f41-a9b1037b116c,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-157de91c-e932-4425-b894-48261b8220ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-52baa766-6f04-4779-acd2-8567918c0b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-73f3aac7-fa85-4f4b-a89d-dbcdf4115c53,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-7fabf1b3-38fb-475e-90a4-a82fbfb61884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5174
