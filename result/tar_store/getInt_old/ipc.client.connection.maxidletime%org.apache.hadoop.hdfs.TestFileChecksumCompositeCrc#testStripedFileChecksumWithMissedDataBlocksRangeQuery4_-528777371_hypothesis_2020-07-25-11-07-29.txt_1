reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542072791-172.17.0.4-1595675567156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-d951b617-8867-4355-8a36-72d9a416abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-34351690-08b7-403a-bb57-13e2e272a908,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-85593f4e-43f3-4e77-bbef-3e28c5e92ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-473f1bf1-00ab-421a-855a-82ab9b926181,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-3fcd66c3-3495-4f7f-a09f-ccbee2630951,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-9ac794f9-6991-4570-97fd-68a0178c69df,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-49600794-b99e-4baf-abce-85cec0a5f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-1bcba532-ef1f-41f2-b840-41e42f17e02b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542072791-172.17.0.4-1595675567156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-d951b617-8867-4355-8a36-72d9a416abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-34351690-08b7-403a-bb57-13e2e272a908,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-85593f4e-43f3-4e77-bbef-3e28c5e92ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-473f1bf1-00ab-421a-855a-82ab9b926181,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-3fcd66c3-3495-4f7f-a09f-ccbee2630951,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-9ac794f9-6991-4570-97fd-68a0178c69df,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-49600794-b99e-4baf-abce-85cec0a5f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-1bcba532-ef1f-41f2-b840-41e42f17e02b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783002204-172.17.0.4-1595675675756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35712,DS-d83a90c0-163a-4c93-b2ce-4731a251c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-a1a70471-98ac-4f8d-a667-f4bb5922e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-972788ae-112a-4555-bcb3-433f1542725c,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-fa22c7b1-7f48-42d6-887d-e3474a41848f,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-e690f27b-935e-4fb2-be45-8ab420c37f35,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-02a67a44-5284-4f5a-800f-2c5e26e94832,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-4d42980e-50f4-46a1-833d-08235be06040,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-5e42ffe9-bcdc-4c47-aef2-d143f9922f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783002204-172.17.0.4-1595675675756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35712,DS-d83a90c0-163a-4c93-b2ce-4731a251c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-a1a70471-98ac-4f8d-a667-f4bb5922e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-972788ae-112a-4555-bcb3-433f1542725c,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-fa22c7b1-7f48-42d6-887d-e3474a41848f,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-e690f27b-935e-4fb2-be45-8ab420c37f35,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-02a67a44-5284-4f5a-800f-2c5e26e94832,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-4d42980e-50f4-46a1-833d-08235be06040,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-5e42ffe9-bcdc-4c47-aef2-d143f9922f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747314466-172.17.0.4-1595675795135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-fd7ffb7a-df93-4a59-a3af-510e383e92b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-8a43b5e2-803a-43f1-8777-89d58f2a01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-60ee834f-e20c-435f-b2a8-98f10361feec,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-14e45f05-7654-411b-b26f-2f76ba6aae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-85066f98-3a84-4c84-b6e9-decf515f5a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-53cf796f-6358-458b-a8a3-b65bac72a6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-9d1168fe-7b26-4eb7-9bb7-691c15bfb2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-00a8a467-3fb5-4ea7-8e56-7e8b392a548c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747314466-172.17.0.4-1595675795135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-fd7ffb7a-df93-4a59-a3af-510e383e92b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-8a43b5e2-803a-43f1-8777-89d58f2a01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-60ee834f-e20c-435f-b2a8-98f10361feec,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-14e45f05-7654-411b-b26f-2f76ba6aae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-85066f98-3a84-4c84-b6e9-decf515f5a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-53cf796f-6358-458b-a8a3-b65bac72a6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-9d1168fe-7b26-4eb7-9bb7-691c15bfb2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-00a8a467-3fb5-4ea7-8e56-7e8b392a548c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476585201-172.17.0.4-1595675908353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-4daf2c31-cda5-4c13-994f-3081c2e86be2,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-d3f53f96-f91b-474a-a7b5-2073aea32306,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-8aac2668-f6be-4d39-8e2c-a619ffa0e949,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-27ab9a13-b175-4a38-b18c-910745532a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-b24455e7-1eb7-442a-90fd-75de6ce8e389,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-144ac52f-8a41-460e-98a1-2b528789374d,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-e2eba228-6c50-4738-93c0-97e5246a877a,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-42ed51bd-5193-4931-87fd-87d7178786e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476585201-172.17.0.4-1595675908353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-4daf2c31-cda5-4c13-994f-3081c2e86be2,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-d3f53f96-f91b-474a-a7b5-2073aea32306,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-8aac2668-f6be-4d39-8e2c-a619ffa0e949,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-27ab9a13-b175-4a38-b18c-910745532a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-b24455e7-1eb7-442a-90fd-75de6ce8e389,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-144ac52f-8a41-460e-98a1-2b528789374d,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-e2eba228-6c50-4738-93c0-97e5246a877a,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-42ed51bd-5193-4931-87fd-87d7178786e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747303531-172.17.0.4-1595676429163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-3ce19ed6-7e72-405a-af56-3cc1d9b04c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-7f35be20-25da-49e6-bd9c-20e281f30a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-64c5d3bc-5337-42da-8c2e-2e5d561cb543,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-3852160b-d762-49d1-aada-4a205a518d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-c2be92c5-cc9c-49bc-8879-bd6c2dd6bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-513d136d-abd5-4a68-adc6-8971c83badb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-e0dda64b-6c98-40e9-9254-eb0a0370834a,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-90ab6cd5-a6d8-493f-957c-f236a1e10483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747303531-172.17.0.4-1595676429163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-3ce19ed6-7e72-405a-af56-3cc1d9b04c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-7f35be20-25da-49e6-bd9c-20e281f30a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-64c5d3bc-5337-42da-8c2e-2e5d561cb543,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-3852160b-d762-49d1-aada-4a205a518d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-c2be92c5-cc9c-49bc-8879-bd6c2dd6bcee,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-513d136d-abd5-4a68-adc6-8971c83badb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-e0dda64b-6c98-40e9-9254-eb0a0370834a,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-90ab6cd5-a6d8-493f-957c-f236a1e10483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249754883-172.17.0.4-1595677265571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38449,DS-6f1d9954-845c-4b66-95c2-cba00110b525,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-ea8ff101-bdf5-40d5-8a2d-e5c992b51dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-29c94452-5488-4f60-b575-1930080adbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-1e254086-1d55-4c78-9de7-4b4c6d9fd193,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-b6fced4d-86e3-4d96-88e1-da92433d4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-c083613a-92f5-4ecf-8a4b-78d5db053dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-c35bd8e2-b407-46be-a878-20dac4fcc6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-f7230f0a-9ebd-449a-bb26-dbb8f3977df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249754883-172.17.0.4-1595677265571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38449,DS-6f1d9954-845c-4b66-95c2-cba00110b525,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-ea8ff101-bdf5-40d5-8a2d-e5c992b51dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-29c94452-5488-4f60-b575-1930080adbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-1e254086-1d55-4c78-9de7-4b4c6d9fd193,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-b6fced4d-86e3-4d96-88e1-da92433d4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-c083613a-92f5-4ecf-8a4b-78d5db053dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-c35bd8e2-b407-46be-a878-20dac4fcc6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-f7230f0a-9ebd-449a-bb26-dbb8f3977df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346872984-172.17.0.4-1595678040007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-1dc00c70-1f13-4a02-9c87-3279d8afc531,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-25fca8b5-dbd8-4c0c-b73c-fafa40421d18,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-fbc468cb-e1d4-4242-bc79-6914a43d80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-633e01d1-eb7b-4155-9ccc-f50fee1bf457,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-978f8a8b-6201-4c85-8e36-d676300a1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-428e5115-6b41-4374-89b7-f01664be81a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-9e613000-54f4-4150-b068-c79c8b29c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-c492f331-49d8-40fd-9f01-c0695e701c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346872984-172.17.0.4-1595678040007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-1dc00c70-1f13-4a02-9c87-3279d8afc531,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-25fca8b5-dbd8-4c0c-b73c-fafa40421d18,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-fbc468cb-e1d4-4242-bc79-6914a43d80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-633e01d1-eb7b-4155-9ccc-f50fee1bf457,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-978f8a8b-6201-4c85-8e36-d676300a1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-428e5115-6b41-4374-89b7-f01664be81a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-9e613000-54f4-4150-b068-c79c8b29c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-c492f331-49d8-40fd-9f01-c0695e701c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150345552-172.17.0.4-1595678359738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40104,DS-bd2b1a96-bd1c-41b6-99ed-ebf9131b2f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-aac1c878-2921-4892-b610-b2cf71b64ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-30b22175-0da0-43dd-b612-ab6a4c2e8ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-3e50d667-681f-40ee-bd9e-19482fcf266b,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-502518dc-8fd0-40d3-82a8-098d4da4f554,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-32e5d298-2a46-4082-9c7d-97cca7053ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-724e3ebd-cd3d-41b4-a444-1b05d0b17b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-95110efa-6afd-4284-bdf5-0280afff312a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150345552-172.17.0.4-1595678359738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40104,DS-bd2b1a96-bd1c-41b6-99ed-ebf9131b2f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-aac1c878-2921-4892-b610-b2cf71b64ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-30b22175-0da0-43dd-b612-ab6a4c2e8ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-3e50d667-681f-40ee-bd9e-19482fcf266b,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-502518dc-8fd0-40d3-82a8-098d4da4f554,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-32e5d298-2a46-4082-9c7d-97cca7053ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-724e3ebd-cd3d-41b4-a444-1b05d0b17b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-95110efa-6afd-4284-bdf5-0280afff312a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996018707-172.17.0.4-1595678391914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-178668eb-ee23-4e25-bf92-159389350b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-6fab9dc3-7fe2-4401-a71a-c0c211697d16,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-f8fb399a-9518-424c-87e2-ab76626ae975,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-497ac973-f46f-44ed-9104-ab0fffcb70e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-82e9860a-6440-44af-8947-bc98af74b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-dca70516-3b32-46d0-b041-3e8452fcb594,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-24665b91-c684-4869-9b80-e9fb6dabb2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-737d8957-5282-4431-b0d4-17809921ffdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996018707-172.17.0.4-1595678391914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-178668eb-ee23-4e25-bf92-159389350b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-6fab9dc3-7fe2-4401-a71a-c0c211697d16,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-f8fb399a-9518-424c-87e2-ab76626ae975,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-497ac973-f46f-44ed-9104-ab0fffcb70e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-82e9860a-6440-44af-8947-bc98af74b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-dca70516-3b32-46d0-b041-3e8452fcb594,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-24665b91-c684-4869-9b80-e9fb6dabb2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-737d8957-5282-4431-b0d4-17809921ffdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397587887-172.17.0.4-1595678579348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37067,DS-ed66be42-ca39-4438-af60-7de088f216f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-2848047d-e388-4c0f-9ca6-76fe1e3816f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-a09bdafb-696b-489c-8c5b-3a5352fb5834,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-3e357818-e6d5-49cf-bb7a-5f1f2b95de5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-760e7164-e508-40bc-93b3-77fcec487b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-6fa92332-ace4-41f9-9cf1-cc8d2681d8da,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-06c5b53f-ab58-410c-a89d-02617db08ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-f219db3f-2c60-4258-af04-7b1f63a00ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397587887-172.17.0.4-1595678579348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37067,DS-ed66be42-ca39-4438-af60-7de088f216f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-2848047d-e388-4c0f-9ca6-76fe1e3816f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-a09bdafb-696b-489c-8c5b-3a5352fb5834,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-3e357818-e6d5-49cf-bb7a-5f1f2b95de5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-760e7164-e508-40bc-93b3-77fcec487b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-6fa92332-ace4-41f9-9cf1-cc8d2681d8da,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-06c5b53f-ab58-410c-a89d-02617db08ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-f219db3f-2c60-4258-af04-7b1f63a00ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457494764-172.17.0.4-1595678659710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-70a2a5eb-1c0b-4968-8aa3-2f3689797d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-6ae4de32-fad4-4adb-8fa1-a83d401e2fff,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-bd43d250-85e6-4ce2-be9c-58a2a4229dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-af9d0212-bc18-4e36-b5bd-a7c42a2545ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-c1a242fb-a8d5-4fad-a537-aa5831e5d165,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-2e5eaf06-b68e-4855-a187-846707306041,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-cd08eaf4-d5ba-4f76-b5de-512be85e0676,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-ef2d1189-aa97-4a9b-a23f-0a5c894620bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457494764-172.17.0.4-1595678659710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-70a2a5eb-1c0b-4968-8aa3-2f3689797d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-6ae4de32-fad4-4adb-8fa1-a83d401e2fff,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-bd43d250-85e6-4ce2-be9c-58a2a4229dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-af9d0212-bc18-4e36-b5bd-a7c42a2545ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-c1a242fb-a8d5-4fad-a537-aa5831e5d165,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-2e5eaf06-b68e-4855-a187-846707306041,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-cd08eaf4-d5ba-4f76-b5de-512be85e0676,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-ef2d1189-aa97-4a9b-a23f-0a5c894620bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945340211-172.17.0.4-1595678699266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-6612fdac-f848-4cb7-bb42-a25c18e712c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-b79e8597-3c67-4cb9-9dd4-ad3daa7f3936,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-6ce3ad82-7207-408d-8451-e3ac3261e7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-4a39d3c2-ceaf-45a9-bd84-77124ff9894e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-e17bcd80-2969-435e-826a-ce64022c40bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-4f72d792-c760-4079-9347-16d1b682a635,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-5d5029c6-2339-4d31-bcb2-04df002f419a,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-8c143e20-b488-431d-8a0b-3920c1d99c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945340211-172.17.0.4-1595678699266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-6612fdac-f848-4cb7-bb42-a25c18e712c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-b79e8597-3c67-4cb9-9dd4-ad3daa7f3936,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-6ce3ad82-7207-408d-8451-e3ac3261e7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-4a39d3c2-ceaf-45a9-bd84-77124ff9894e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-e17bcd80-2969-435e-826a-ce64022c40bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-4f72d792-c760-4079-9347-16d1b682a635,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-5d5029c6-2339-4d31-bcb2-04df002f419a,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-8c143e20-b488-431d-8a0b-3920c1d99c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922248693-172.17.0.4-1595678962916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36429,DS-b8d9205a-06f4-4612-9dc8-b62418e9ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-432e23a4-046c-4455-9c26-bdaeb4f45a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-1abba336-8a05-4fa8-a3a3-b77ca7a9e145,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-f41ed86b-f4eb-4ed9-be41-e4f70a8ee17e,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-d794a502-9dfe-4b26-beb8-41f9172d6024,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-d041e9a2-9d42-4fef-9941-faa3a429a47f,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-a9631e69-c49e-4488-81d4-03899e5e2e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-85b86b71-62ff-4032-9b33-b2f9498f5e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922248693-172.17.0.4-1595678962916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36429,DS-b8d9205a-06f4-4612-9dc8-b62418e9ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-432e23a4-046c-4455-9c26-bdaeb4f45a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-1abba336-8a05-4fa8-a3a3-b77ca7a9e145,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-f41ed86b-f4eb-4ed9-be41-e4f70a8ee17e,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-d794a502-9dfe-4b26-beb8-41f9172d6024,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-d041e9a2-9d42-4fef-9941-faa3a429a47f,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-a9631e69-c49e-4488-81d4-03899e5e2e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-85b86b71-62ff-4032-9b33-b2f9498f5e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782789853-172.17.0.4-1595679230833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41527,DS-9e39e287-3373-4dce-a85e-cc955db20101,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-e535cb80-fa32-42f7-a22d-a17b59af2fca,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-8f2eb80a-0834-4f1e-8c6d-d9cf3667df53,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-8d103547-dd22-4a35-bf67-aaa92e9715c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-d41e55e1-dd32-4131-988e-26676a35d221,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-cfcd7103-e79b-41f8-be69-2f7b77ee6035,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-6ba24065-db0f-4333-9d3c-bb139de89722,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-aebffe5f-f1b9-4511-9396-0d3406d478bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782789853-172.17.0.4-1595679230833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41527,DS-9e39e287-3373-4dce-a85e-cc955db20101,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-e535cb80-fa32-42f7-a22d-a17b59af2fca,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-8f2eb80a-0834-4f1e-8c6d-d9cf3667df53,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-8d103547-dd22-4a35-bf67-aaa92e9715c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-d41e55e1-dd32-4131-988e-26676a35d221,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-cfcd7103-e79b-41f8-be69-2f7b77ee6035,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-6ba24065-db0f-4333-9d3c-bb139de89722,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-aebffe5f-f1b9-4511-9396-0d3406d478bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70211118-172.17.0.4-1595680302561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-5e05a73c-bc83-4698-b192-f4db77a6f438,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-bd6045a6-94bd-4b2f-b7e4-35bca37e7833,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-69edeaf2-86c3-430c-9c0a-d8ed299d9b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-253ac45c-7960-44e7-a7e6-f222b8d685fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-56ff06e5-3eed-4336-bdc5-1ab341a3f348,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-a7424d94-c486-4a33-9584-1056f5fdbca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-ac805539-6931-4fa3-9015-06945b179099,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-aa39bbd8-8f30-4bd1-af97-33c0d96bcdf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70211118-172.17.0.4-1595680302561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-5e05a73c-bc83-4698-b192-f4db77a6f438,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-bd6045a6-94bd-4b2f-b7e4-35bca37e7833,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-69edeaf2-86c3-430c-9c0a-d8ed299d9b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-253ac45c-7960-44e7-a7e6-f222b8d685fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-56ff06e5-3eed-4336-bdc5-1ab341a3f348,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-a7424d94-c486-4a33-9584-1056f5fdbca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-ac805539-6931-4fa3-9015-06945b179099,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-aa39bbd8-8f30-4bd1-af97-33c0d96bcdf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841203958-172.17.0.4-1595680518977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-f35600db-1f8f-480e-8697-18ef08e878c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-66abf9ff-c57c-4647-bae5-48ec748443dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-edd96d30-95a4-421e-9ae7-7462681c7f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-86ae6f0c-fafc-4cba-adab-60342e60dc67,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-b832676f-4280-4cb1-b1e6-eb8e0a062d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-b768e247-dc85-4e1f-9b46-e2a13467a38f,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-b8db8836-634e-4ab9-862c-03bf6afa98c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-5d2e1919-43c8-40a0-8f53-3d47dff4b05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841203958-172.17.0.4-1595680518977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-f35600db-1f8f-480e-8697-18ef08e878c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-66abf9ff-c57c-4647-bae5-48ec748443dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-edd96d30-95a4-421e-9ae7-7462681c7f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-86ae6f0c-fafc-4cba-adab-60342e60dc67,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-b832676f-4280-4cb1-b1e6-eb8e0a062d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-b768e247-dc85-4e1f-9b46-e2a13467a38f,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-b8db8836-634e-4ab9-862c-03bf6afa98c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-5d2e1919-43c8-40a0-8f53-3d47dff4b05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5673
