reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323751951-172.17.0.19-1595526058304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-7d13f27f-bf1b-4601-8f1f-fd2a669417b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-aad3e77c-0dd2-45f0-9451-9bac2cc73b84,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-24056664-c0df-46d0-93e8-8451d862009a,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-3eacc462-4bd5-45e5-a326-cf4e6b49f004,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-f5267163-279b-4cb1-a63f-995721b70bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-1d71ed5a-a35a-4c62-a80a-d75bd367296f,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-5d05db97-e3b8-444b-8130-b4b40127f9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-f10755c1-c875-437e-b644-4900ce914b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323751951-172.17.0.19-1595526058304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-7d13f27f-bf1b-4601-8f1f-fd2a669417b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-aad3e77c-0dd2-45f0-9451-9bac2cc73b84,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-24056664-c0df-46d0-93e8-8451d862009a,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-3eacc462-4bd5-45e5-a326-cf4e6b49f004,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-f5267163-279b-4cb1-a63f-995721b70bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-1d71ed5a-a35a-4c62-a80a-d75bd367296f,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-5d05db97-e3b8-444b-8130-b4b40127f9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-f10755c1-c875-437e-b644-4900ce914b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751281813-172.17.0.19-1595526329076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35500,DS-610f7e6a-23c8-4f82-bea8-bd2b814a4757,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-0904e1e9-c0c2-48cc-94c5-1786cd4bf6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-8686e284-720f-4e4e-b679-ef2a7ec5a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-4855e504-5f11-474f-a2ed-15e80d44e80a,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-eb700824-eb86-4c80-b5af-9a89c1316308,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-fd59fdc3-5a9e-4cd0-8721-9e2c434cb8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-93dad585-3d42-4605-a6d8-b1abb971b857,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-db1ed8e3-251e-4b0b-88c6-9d6d8255760d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751281813-172.17.0.19-1595526329076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35500,DS-610f7e6a-23c8-4f82-bea8-bd2b814a4757,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-0904e1e9-c0c2-48cc-94c5-1786cd4bf6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-8686e284-720f-4e4e-b679-ef2a7ec5a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-4855e504-5f11-474f-a2ed-15e80d44e80a,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-eb700824-eb86-4c80-b5af-9a89c1316308,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-fd59fdc3-5a9e-4cd0-8721-9e2c434cb8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-93dad585-3d42-4605-a6d8-b1abb971b857,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-db1ed8e3-251e-4b0b-88c6-9d6d8255760d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478773066-172.17.0.19-1595526644300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-ff11186f-2a60-418a-8d91-a9b8fa916f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-edfaabdf-5fa9-4ada-9e75-6cc5ab254890,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-1699e3fb-1888-4ec4-81f1-248eff153b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-7e5185ca-c75f-464e-afad-26ec87acac14,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-c6140af4-f79f-4c1d-be77-68851a66f0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-572fde5a-ef4c-4fe2-a527-af0ec1167c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-e1132b6c-9421-471f-a481-bef001ae600f,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-d72a9f75-a3bf-41f4-82ce-a81f6f29d5a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478773066-172.17.0.19-1595526644300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36761,DS-ff11186f-2a60-418a-8d91-a9b8fa916f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-edfaabdf-5fa9-4ada-9e75-6cc5ab254890,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-1699e3fb-1888-4ec4-81f1-248eff153b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-7e5185ca-c75f-464e-afad-26ec87acac14,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-c6140af4-f79f-4c1d-be77-68851a66f0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-572fde5a-ef4c-4fe2-a527-af0ec1167c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-e1132b6c-9421-471f-a481-bef001ae600f,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-d72a9f75-a3bf-41f4-82ce-a81f6f29d5a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417454277-172.17.0.19-1595526762901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41345,DS-dcf8c2d5-6804-4311-a43e-dc695f61e34a,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-477c929f-4085-4e0c-9d14-263c0b9c37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-c58f4f67-ca35-4ddd-b9ca-8f64c3c46604,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-21000c34-b8cb-4422-bc44-0ec80dead62e,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-430a8262-5af3-473e-9826-290c86b18993,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-6f329088-a850-42d6-81de-adecedc1467e,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-2bf98879-0376-456f-aba8-f36601aca995,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-6c0243a5-33c4-4642-81f8-b38679919180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417454277-172.17.0.19-1595526762901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41345,DS-dcf8c2d5-6804-4311-a43e-dc695f61e34a,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-477c929f-4085-4e0c-9d14-263c0b9c37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-c58f4f67-ca35-4ddd-b9ca-8f64c3c46604,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-21000c34-b8cb-4422-bc44-0ec80dead62e,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-430a8262-5af3-473e-9826-290c86b18993,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-6f329088-a850-42d6-81de-adecedc1467e,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-2bf98879-0376-456f-aba8-f36601aca995,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-6c0243a5-33c4-4642-81f8-b38679919180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817713635-172.17.0.19-1595526876425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-ccfdb6a5-bbd7-44fc-9c59-38818d05adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-79568110-286c-43ca-b716-6412f0570caa,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-fdac4f53-6139-456d-addb-0d9a8d48d268,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-bfabce93-67cb-4fc7-a118-6853e2107405,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-4efd2ed4-696c-478b-85b8-379f6ec1d1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-2dd094f8-9e1e-4d16-a942-12c04d0cfc69,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-4721c110-8f3e-4a22-86e0-2fdc488856f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-1563cbf6-f7fd-4453-a22a-f1e44e04314e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817713635-172.17.0.19-1595526876425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-ccfdb6a5-bbd7-44fc-9c59-38818d05adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-79568110-286c-43ca-b716-6412f0570caa,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-fdac4f53-6139-456d-addb-0d9a8d48d268,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-bfabce93-67cb-4fc7-a118-6853e2107405,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-4efd2ed4-696c-478b-85b8-379f6ec1d1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-2dd094f8-9e1e-4d16-a942-12c04d0cfc69,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-4721c110-8f3e-4a22-86e0-2fdc488856f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-1563cbf6-f7fd-4453-a22a-f1e44e04314e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817933016-172.17.0.19-1595527325476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-33f95421-2515-4000-a087-a21a8b1d5416,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-054d2f2d-462a-4cb7-8f77-aca6ace25d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-fc7ef429-2113-4c7e-aee4-07beac5aaf74,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-4a30aa7e-f063-4331-9d3f-db4ae12c1b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-b48994d5-42f9-4087-ae77-7098df18c152,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-dd71de15-de73-4f1e-bc7e-549b26ae5808,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-b51fe89b-caa4-42b5-9db4-55361710431d,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-b37eea52-ad47-4ac0-9f5a-52bfdbf8f3f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817933016-172.17.0.19-1595527325476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-33f95421-2515-4000-a087-a21a8b1d5416,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-054d2f2d-462a-4cb7-8f77-aca6ace25d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-fc7ef429-2113-4c7e-aee4-07beac5aaf74,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-4a30aa7e-f063-4331-9d3f-db4ae12c1b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-b48994d5-42f9-4087-ae77-7098df18c152,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-dd71de15-de73-4f1e-bc7e-549b26ae5808,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-b51fe89b-caa4-42b5-9db4-55361710431d,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-b37eea52-ad47-4ac0-9f5a-52bfdbf8f3f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033521484-172.17.0.19-1595527460948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41706,DS-2a08f550-3f6f-4505-ad50-e74c2ccbf3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-d1c83928-47f4-4f00-adf6-92dcbba83a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-10fabeab-7a98-412f-9f15-ff0c3696ac87,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-4aa3670d-041d-4305-bc4e-eee78710b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-ed9f8dad-19f3-4430-8a70-91a93a606bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-f23a73eb-f9b2-45b9-800e-d7c3b12b50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-4793169b-897d-488d-a330-14698a9ea440,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-cc7f4e38-b697-421c-9f82-765fa527a7be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033521484-172.17.0.19-1595527460948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41706,DS-2a08f550-3f6f-4505-ad50-e74c2ccbf3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-d1c83928-47f4-4f00-adf6-92dcbba83a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-10fabeab-7a98-412f-9f15-ff0c3696ac87,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-4aa3670d-041d-4305-bc4e-eee78710b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-ed9f8dad-19f3-4430-8a70-91a93a606bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-f23a73eb-f9b2-45b9-800e-d7c3b12b50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-4793169b-897d-488d-a330-14698a9ea440,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-cc7f4e38-b697-421c-9f82-765fa527a7be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673406572-172.17.0.19-1595527611385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-4345dc4f-6c64-4182-b10b-4304e1149794,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-7e64c88b-b76c-4f65-bb65-0edb0ce662da,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-0aac638c-6294-4b64-b159-2bb9ed43f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-9da9fb72-8a01-4c39-a6c2-3f1f697a1a92,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-085c2a9b-5f52-45f0-95fd-00d38bda13de,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-efb417a8-2535-4c4d-8cc8-8bd082fe9494,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-d77014e8-2cdf-4a9a-960e-04a9b197c388,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-34296a53-31f1-4916-9538-6dfcd6db9937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673406572-172.17.0.19-1595527611385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-4345dc4f-6c64-4182-b10b-4304e1149794,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-7e64c88b-b76c-4f65-bb65-0edb0ce662da,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-0aac638c-6294-4b64-b159-2bb9ed43f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-9da9fb72-8a01-4c39-a6c2-3f1f697a1a92,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-085c2a9b-5f52-45f0-95fd-00d38bda13de,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-efb417a8-2535-4c4d-8cc8-8bd082fe9494,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-d77014e8-2cdf-4a9a-960e-04a9b197c388,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-34296a53-31f1-4916-9538-6dfcd6db9937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875181570-172.17.0.19-1595527683277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-66d88ba0-b27f-4863-8d8a-6d36c4d1ed02,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-c1bd9eb7-eefd-4cf4-88b1-f4adb3649de7,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-ca2d3cde-7bdf-4577-b2aa-7d54901d0c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-b02a8a2a-d848-42f4-9d58-c2efe69f33a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-4055275f-a4b3-457a-8eda-ce0e05dd1196,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-613a20cd-c9a4-44a5-a007-e60572628e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-36073097-4a78-49a4-80a4-7e1656dd07b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-722a196f-75d7-4ebe-89e0-9a95e288188f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875181570-172.17.0.19-1595527683277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-66d88ba0-b27f-4863-8d8a-6d36c4d1ed02,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-c1bd9eb7-eefd-4cf4-88b1-f4adb3649de7,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-ca2d3cde-7bdf-4577-b2aa-7d54901d0c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-b02a8a2a-d848-42f4-9d58-c2efe69f33a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-4055275f-a4b3-457a-8eda-ce0e05dd1196,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-613a20cd-c9a4-44a5-a007-e60572628e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-36073097-4a78-49a4-80a4-7e1656dd07b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-722a196f-75d7-4ebe-89e0-9a95e288188f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106650115-172.17.0.19-1595528461480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-031c5b4e-445b-4ecf-94a8-86e6ece60c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-38e8d2f8-5410-4aab-a1d2-9e18db3cb60f,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-91617959-48f7-4088-a9b7-8bc5fb57b42d,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-80783df4-ba1c-4528-a39c-f19bedfed282,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-5d11cfc7-9969-4d97-a2c4-a72af061bea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-178433e2-9474-4d3e-97d7-95e17ed521f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-a16c5e85-41cb-4c06-8c06-1f6a0b487cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-f529a94f-8cdc-45e1-87d9-a5eba3460be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106650115-172.17.0.19-1595528461480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-031c5b4e-445b-4ecf-94a8-86e6ece60c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-38e8d2f8-5410-4aab-a1d2-9e18db3cb60f,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-91617959-48f7-4088-a9b7-8bc5fb57b42d,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-80783df4-ba1c-4528-a39c-f19bedfed282,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-5d11cfc7-9969-4d97-a2c4-a72af061bea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-178433e2-9474-4d3e-97d7-95e17ed521f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-a16c5e85-41cb-4c06-8c06-1f6a0b487cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-f529a94f-8cdc-45e1-87d9-a5eba3460be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976801028-172.17.0.19-1595528611922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-f320169a-37e3-4dca-9859-6aa33664cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-7cc5d07d-2825-46c3-a3ca-7afdacb7d5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-c6be9d0e-1c36-4905-ba7a-2e09d05041ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-4f3fe9e9-e8d2-41aa-9e3e-e6b473bddddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-0e40b085-9306-4f3c-bf5c-144d1433f254,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-4e748be9-7507-4ec8-a53d-de6652e39d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-e97e4128-14d8-432f-b6fc-945c6699a59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-e1a20e0f-f410-4021-89a4-19f9fce42218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976801028-172.17.0.19-1595528611922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-f320169a-37e3-4dca-9859-6aa33664cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-7cc5d07d-2825-46c3-a3ca-7afdacb7d5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-c6be9d0e-1c36-4905-ba7a-2e09d05041ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-4f3fe9e9-e8d2-41aa-9e3e-e6b473bddddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-0e40b085-9306-4f3c-bf5c-144d1433f254,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-4e748be9-7507-4ec8-a53d-de6652e39d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-e97e4128-14d8-432f-b6fc-945c6699a59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-e1a20e0f-f410-4021-89a4-19f9fce42218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916539502-172.17.0.19-1595528801932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-caec6fed-be72-4a24-b5c6-11ef0a5e7858,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-cc9a2e10-9ac0-4268-aec8-a924221203af,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-ca33cc61-062c-487c-8f5b-09dbd2f98b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-cfb1eb53-ba98-4535-b367-28683b00060a,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-1ee5f1b7-67da-4fbc-94b3-7369bc73fc97,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-2864a3bf-95ae-4d3f-8286-4b29a1f3e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-455f59c6-fb46-4f94-90b1-03f92287bd33,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-2110c19b-8ad4-4a28-ad9d-b575a3026559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916539502-172.17.0.19-1595528801932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-caec6fed-be72-4a24-b5c6-11ef0a5e7858,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-cc9a2e10-9ac0-4268-aec8-a924221203af,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-ca33cc61-062c-487c-8f5b-09dbd2f98b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-cfb1eb53-ba98-4535-b367-28683b00060a,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-1ee5f1b7-67da-4fbc-94b3-7369bc73fc97,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-2864a3bf-95ae-4d3f-8286-4b29a1f3e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-455f59c6-fb46-4f94-90b1-03f92287bd33,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-2110c19b-8ad4-4a28-ad9d-b575a3026559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671643583-172.17.0.19-1595528994697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-431bd521-58ed-4c24-8c2c-bd15e08abcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-771b1c99-3fc2-4062-bffc-bca5c43dfa63,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-f80f222f-f3aa-4c80-80af-0c8324ceffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-ee541a3c-ec22-4921-ac02-6e15319ef48b,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-fd4ff7d8-5ae3-4e51-ac3a-35fb1b077f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-ece52592-94c3-451b-861b-333d0c3ec7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-87fa0b88-0d47-49b1-a4a6-46c7ce651f26,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-34af937c-e918-48c0-b764-9e01a9354a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671643583-172.17.0.19-1595528994697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-431bd521-58ed-4c24-8c2c-bd15e08abcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-771b1c99-3fc2-4062-bffc-bca5c43dfa63,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-f80f222f-f3aa-4c80-80af-0c8324ceffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-ee541a3c-ec22-4921-ac02-6e15319ef48b,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-fd4ff7d8-5ae3-4e51-ac3a-35fb1b077f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-ece52592-94c3-451b-861b-333d0c3ec7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-87fa0b88-0d47-49b1-a4a6-46c7ce651f26,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-34af937c-e918-48c0-b764-9e01a9354a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837222700-172.17.0.19-1595529026973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41070,DS-fd65e3cc-3f2f-40b9-9c4a-15f2ae1c70b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-efb21094-e0b9-4a47-85cf-17d33df87077,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-7f88e069-c4de-48d9-b39d-a0507806e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-a6d05725-b801-42e3-8768-f3cf3f4c8b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-12761b9b-ef57-4c04-9ca2-cdbdf326fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-453258a2-3d7e-487c-b3bc-82314bca606e,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-ed52c3fa-073e-4df0-a78b-ebb3997aca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-766774ad-32bb-4920-8630-771a6b17035b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837222700-172.17.0.19-1595529026973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41070,DS-fd65e3cc-3f2f-40b9-9c4a-15f2ae1c70b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-efb21094-e0b9-4a47-85cf-17d33df87077,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-7f88e069-c4de-48d9-b39d-a0507806e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-a6d05725-b801-42e3-8768-f3cf3f4c8b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-12761b9b-ef57-4c04-9ca2-cdbdf326fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-453258a2-3d7e-487c-b3bc-82314bca606e,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-ed52c3fa-073e-4df0-a78b-ebb3997aca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-766774ad-32bb-4920-8630-771a6b17035b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77706898-172.17.0.19-1595529269507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41024,DS-7a22196b-e673-414a-a4aa-162f0a682dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-f5f157e0-3422-489e-84ca-a90fa3a115fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-35bb03c6-c569-4b8a-bd55-8f193580097f,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-52223ff4-22b2-4960-affa-82bc5c39d0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-c3f5b83d-123d-4ff6-aca5-72f3f0b99d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-ae4c0b47-55ed-4ce7-a69f-ae1ec318a7af,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-8e87d5eb-c9de-4efa-8f21-55f82f28e861,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-09a61546-5248-451b-b020-efba7651f4de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77706898-172.17.0.19-1595529269507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41024,DS-7a22196b-e673-414a-a4aa-162f0a682dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-f5f157e0-3422-489e-84ca-a90fa3a115fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-35bb03c6-c569-4b8a-bd55-8f193580097f,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-52223ff4-22b2-4960-affa-82bc5c39d0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-c3f5b83d-123d-4ff6-aca5-72f3f0b99d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-ae4c0b47-55ed-4ce7-a69f-ae1ec318a7af,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-8e87d5eb-c9de-4efa-8f21-55f82f28e861,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-09a61546-5248-451b-b020-efba7651f4de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52567942-172.17.0.19-1595529366035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36584,DS-e4513dc7-f254-42af-9356-8774dfc21da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-8660443f-fd1b-4aee-a1ec-f1c6485141a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-bbc55422-0a88-4a5c-901c-6d572093724e,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-832358e2-a5f2-4786-b30e-7a3dc1d6ddc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-782de532-5400-40ba-a58d-dbbf5d491c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-6bb2fbc8-ab44-4c32-8661-1098a9587cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-f821c77b-d957-4e73-bd80-bbf562bfd306,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-f984fd8b-0af5-4b18-bcbb-c20691ea4969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52567942-172.17.0.19-1595529366035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36584,DS-e4513dc7-f254-42af-9356-8774dfc21da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-8660443f-fd1b-4aee-a1ec-f1c6485141a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-bbc55422-0a88-4a5c-901c-6d572093724e,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-832358e2-a5f2-4786-b30e-7a3dc1d6ddc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-782de532-5400-40ba-a58d-dbbf5d491c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-6bb2fbc8-ab44-4c32-8661-1098a9587cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-f821c77b-d957-4e73-bd80-bbf562bfd306,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-f984fd8b-0af5-4b18-bcbb-c20691ea4969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167369544-172.17.0.19-1595529396243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-aa26dd06-0cf7-4eed-9eae-bcf851656630,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-41dfc017-6c62-47b8-87f3-0e627b889cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-2e9a03c7-2482-40a1-89f8-e6fc0ea64bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-a7aee3a2-d5ed-49b0-8400-13b9f890f1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-08701e6d-863b-489b-89c8-825096a40270,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-89656989-c810-47ee-a862-2489c39cd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-17335560-50fb-4aa6-8ae6-02a8ce4c4d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-c128cf68-8758-4ca6-88d3-94d9cd3d42a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167369544-172.17.0.19-1595529396243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-aa26dd06-0cf7-4eed-9eae-bcf851656630,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-41dfc017-6c62-47b8-87f3-0e627b889cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-2e9a03c7-2482-40a1-89f8-e6fc0ea64bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-a7aee3a2-d5ed-49b0-8400-13b9f890f1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-08701e6d-863b-489b-89c8-825096a40270,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-89656989-c810-47ee-a862-2489c39cd18c,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-17335560-50fb-4aa6-8ae6-02a8ce4c4d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-c128cf68-8758-4ca6-88d3-94d9cd3d42a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319192924-172.17.0.19-1595529493108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-30ee87a4-24d7-4852-82fb-6ec43592243d,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-3efd2ed9-4eea-4e00-87ee-ed6190ee614c,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-f3511510-215f-493c-a49e-08b422208690,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-ac29a9df-9b39-4c50-9c7b-37d42c3b8f85,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-d00a6d5f-7611-4dd3-bf3c-37eb8caaded0,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-d0da5549-9b81-4aca-802f-da2ef23ed23e,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-92d91be4-fda8-42be-9c41-255c9d022d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-fb2f7c75-58fb-40bb-bd04-e30e10d8ef66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319192924-172.17.0.19-1595529493108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-30ee87a4-24d7-4852-82fb-6ec43592243d,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-3efd2ed9-4eea-4e00-87ee-ed6190ee614c,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-f3511510-215f-493c-a49e-08b422208690,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-ac29a9df-9b39-4c50-9c7b-37d42c3b8f85,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-d00a6d5f-7611-4dd3-bf3c-37eb8caaded0,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-d0da5549-9b81-4aca-802f-da2ef23ed23e,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-92d91be4-fda8-42be-9c41-255c9d022d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-fb2f7c75-58fb-40bb-bd04-e30e10d8ef66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973727385-172.17.0.19-1595529563284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42045,DS-6bddfa15-1e8e-43ca-8dd3-9ae38f431ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-b15b1a0a-2b84-40ce-a7c4-1856093b1626,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-093df8ee-d0c2-4faf-98b1-11df0cf6c274,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-24e1ad9e-d850-41bf-b46a-65514885b859,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-b67637b8-53cc-48fa-aff2-6bec1f063f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-b1bb9441-98f3-4146-ad57-3813acc4d169,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-2d79d1cd-3025-403b-acaf-2b13867d1c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-484faebe-3b0a-4bf3-81c1-45bf5067c5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973727385-172.17.0.19-1595529563284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42045,DS-6bddfa15-1e8e-43ca-8dd3-9ae38f431ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-b15b1a0a-2b84-40ce-a7c4-1856093b1626,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-093df8ee-d0c2-4faf-98b1-11df0cf6c274,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-24e1ad9e-d850-41bf-b46a-65514885b859,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-b67637b8-53cc-48fa-aff2-6bec1f063f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-b1bb9441-98f3-4146-ad57-3813acc4d169,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-2d79d1cd-3025-403b-acaf-2b13867d1c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-484faebe-3b0a-4bf3-81c1-45bf5067c5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436378742-172.17.0.19-1595530490481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38557,DS-8af50460-9a03-4fbc-8634-61d08d8b4a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-ba37cd59-243b-46ec-91f8-2c7592b15472,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-39df8549-4dce-4243-83cc-4a7a64943fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-5852de37-b81f-4354-844c-4cfdfb95095d,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-e5eec2ed-4721-45c0-8723-4eaa2e735ade,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-6e7900c3-4502-44ce-aeed-8b6f1b7ffb98,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-7db17d38-e826-4c76-a98e-193e1d693d70,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-76df8fb4-2769-4b3e-a20b-32fcdc77f3f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436378742-172.17.0.19-1595530490481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38557,DS-8af50460-9a03-4fbc-8634-61d08d8b4a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-ba37cd59-243b-46ec-91f8-2c7592b15472,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-39df8549-4dce-4243-83cc-4a7a64943fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-5852de37-b81f-4354-844c-4cfdfb95095d,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-e5eec2ed-4721-45c0-8723-4eaa2e735ade,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-6e7900c3-4502-44ce-aeed-8b6f1b7ffb98,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-7db17d38-e826-4c76-a98e-193e1d693d70,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-76df8fb4-2769-4b3e-a20b-32fcdc77f3f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873698726-172.17.0.19-1595530594578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37985,DS-c661b7c2-9e08-41f9-aab3-f369b8c4f909,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-beab7303-cc10-4e31-ad7c-fee73ff81e70,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-3744f23d-f650-457d-a7b8-0d87ada0d9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-1118a8a2-7eac-4330-a232-89d0fced17c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-16754ce2-44a1-46a1-986e-db58c7fe1397,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-33706fde-13df-4e94-a31b-f5c4dd86497d,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-4e9d4e8a-620f-49e5-9c41-0496f8f70e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-1c4f324a-aebd-4859-a98e-2fa0dff9b28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873698726-172.17.0.19-1595530594578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37985,DS-c661b7c2-9e08-41f9-aab3-f369b8c4f909,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-beab7303-cc10-4e31-ad7c-fee73ff81e70,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-3744f23d-f650-457d-a7b8-0d87ada0d9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-1118a8a2-7eac-4330-a232-89d0fced17c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-16754ce2-44a1-46a1-986e-db58c7fe1397,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-33706fde-13df-4e94-a31b-f5c4dd86497d,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-4e9d4e8a-620f-49e5-9c41-0496f8f70e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-1c4f324a-aebd-4859-a98e-2fa0dff9b28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 15000000
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291401263-172.17.0.19-1595531097240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33162,DS-046812bb-ecd4-4528-9f6a-43fb347da16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-f976cf01-03b9-42b7-9ab4-b2bfc4245f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-776e651b-f378-4de5-9398-ee7e1b0571e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-2b7a767c-164a-4304-a527-f1cbe1e41827,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-8de42e0b-d3e0-4547-9b08-150d497e1f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-d87c1e8d-5df6-444d-9e65-751e851ebc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-93269a60-aed8-4cd3-b5ad-5e7771df5328,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-8ebdf223-1680-4999-95b0-2d5c65c81d63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291401263-172.17.0.19-1595531097240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33162,DS-046812bb-ecd4-4528-9f6a-43fb347da16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-f976cf01-03b9-42b7-9ab4-b2bfc4245f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-776e651b-f378-4de5-9398-ee7e1b0571e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-2b7a767c-164a-4304-a527-f1cbe1e41827,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-8de42e0b-d3e0-4547-9b08-150d497e1f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-d87c1e8d-5df6-444d-9e65-751e851ebc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-93269a60-aed8-4cd3-b5ad-5e7771df5328,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-8ebdf223-1680-4999-95b0-2d5c65c81d63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5571
