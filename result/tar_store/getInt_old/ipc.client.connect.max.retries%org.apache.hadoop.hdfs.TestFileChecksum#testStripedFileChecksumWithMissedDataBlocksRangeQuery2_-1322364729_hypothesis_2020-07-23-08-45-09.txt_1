reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047537263-172.17.0.15-1595494456651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-58ae4a72-f507-4f16-8e92-72d404244134,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-ce36ad9b-2d51-4307-a60c-3fa3c948cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-21158bf5-3ed7-4bc4-8c94-cff48e7d4cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-bfa8c779-7d61-4ac5-9b37-1982ab1e1063,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-f1a01bbb-405b-4082-a325-ef3795f62c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-222a8661-6660-4fbf-a52d-cf69dafee354,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-f704e599-68a5-45bf-83d5-9faf611cda00,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-e58a05fc-a7a4-4e1a-bcce-86ccbe34d786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047537263-172.17.0.15-1595494456651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-58ae4a72-f507-4f16-8e92-72d404244134,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-ce36ad9b-2d51-4307-a60c-3fa3c948cce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-21158bf5-3ed7-4bc4-8c94-cff48e7d4cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-bfa8c779-7d61-4ac5-9b37-1982ab1e1063,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-f1a01bbb-405b-4082-a325-ef3795f62c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-222a8661-6660-4fbf-a52d-cf69dafee354,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-f704e599-68a5-45bf-83d5-9faf611cda00,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-e58a05fc-a7a4-4e1a-bcce-86ccbe34d786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443499998-172.17.0.15-1595494537601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-dd1bbff1-39ba-440a-aa4c-108e298100ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-589b6295-0336-4301-bac9-5defa7bd046d,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-7b16658c-ea5e-4ac2-a386-9b9dab0ceec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-04be2c1f-4cae-475b-9d0c-6fe433022b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-eae0fd09-6eb6-493f-87b9-93acce3e909f,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-f3fc2fc5-d918-4470-8182-ab2e92ed42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-fa59f1b6-95c5-4a0e-a320-38a2ed429e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-96c6b4a9-c80d-4e7e-a7a9-8850f9f33877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443499998-172.17.0.15-1595494537601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-dd1bbff1-39ba-440a-aa4c-108e298100ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-589b6295-0336-4301-bac9-5defa7bd046d,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-7b16658c-ea5e-4ac2-a386-9b9dab0ceec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-04be2c1f-4cae-475b-9d0c-6fe433022b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-eae0fd09-6eb6-493f-87b9-93acce3e909f,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-f3fc2fc5-d918-4470-8182-ab2e92ed42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-fa59f1b6-95c5-4a0e-a320-38a2ed429e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-96c6b4a9-c80d-4e7e-a7a9-8850f9f33877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908044623-172.17.0.15-1595494837106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39757,DS-ebe9f49e-6431-4a27-bdea-85e80160e465,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-d46fad29-c306-4569-9fae-8a9e370ccdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-aba057a2-b082-4dcc-96ba-8d81254b7e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-b4d5d6f9-2743-4252-96fa-6172d6cc7422,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-c270cb34-6c91-4e13-9017-64e2de812e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-0bf51ad6-92b5-4af2-9e5e-5849338ed1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-9e909a3e-f3da-4723-a8e9-c4a52d1d3e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-86b4cf4e-64ce-46f1-9f22-a9ffa789cf6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908044623-172.17.0.15-1595494837106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39757,DS-ebe9f49e-6431-4a27-bdea-85e80160e465,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-d46fad29-c306-4569-9fae-8a9e370ccdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-aba057a2-b082-4dcc-96ba-8d81254b7e12,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-b4d5d6f9-2743-4252-96fa-6172d6cc7422,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-c270cb34-6c91-4e13-9017-64e2de812e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-0bf51ad6-92b5-4af2-9e5e-5849338ed1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-9e909a3e-f3da-4723-a8e9-c4a52d1d3e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-86b4cf4e-64ce-46f1-9f22-a9ffa789cf6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188686500-172.17.0.15-1595495637821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35275,DS-93857c22-c780-4bfb-b1e8-3b3eb0377c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-4534aed5-dfe0-4b53-957a-f5a97924ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-aafb34c2-7606-405b-87ac-0a708e5fd693,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e557f40f-3a66-4bec-8b9a-5b05a969a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-a5979b41-660c-43f3-9a10-013b04104c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-5fe5307e-2eb9-499d-ba7b-2f025aaa6340,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-e4f7f2c2-dd62-46fc-a2e8-d76638d78bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-207ace9e-2c0b-421a-a515-54d424b02ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188686500-172.17.0.15-1595495637821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35275,DS-93857c22-c780-4bfb-b1e8-3b3eb0377c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-4534aed5-dfe0-4b53-957a-f5a97924ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-aafb34c2-7606-405b-87ac-0a708e5fd693,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e557f40f-3a66-4bec-8b9a-5b05a969a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-a5979b41-660c-43f3-9a10-013b04104c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-5fe5307e-2eb9-499d-ba7b-2f025aaa6340,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-e4f7f2c2-dd62-46fc-a2e8-d76638d78bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-207ace9e-2c0b-421a-a515-54d424b02ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996806611-172.17.0.15-1595495839588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-8c37a1ad-524a-4a80-97a0-699ef7c8b898,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-9da7dcf9-9ebe-4415-ad5d-48e8ebedc4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-46b0ebd3-2fa4-4832-bc3a-6e3cee506b42,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-14a47e6b-1d55-4a51-a705-f400def4cb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-8766fd43-8dcf-4632-9ae7-a273eaefe403,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-7ece3d0a-6029-41ef-9f8e-a5d798e351ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-9193e1f5-7668-4d12-aa08-afca24d67461,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-a6dc7cbd-7297-48ef-b2f5-48825c3e0fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996806611-172.17.0.15-1595495839588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-8c37a1ad-524a-4a80-97a0-699ef7c8b898,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-9da7dcf9-9ebe-4415-ad5d-48e8ebedc4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-46b0ebd3-2fa4-4832-bc3a-6e3cee506b42,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-14a47e6b-1d55-4a51-a705-f400def4cb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-8766fd43-8dcf-4632-9ae7-a273eaefe403,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-7ece3d0a-6029-41ef-9f8e-a5d798e351ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-9193e1f5-7668-4d12-aa08-afca24d67461,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-a6dc7cbd-7297-48ef-b2f5-48825c3e0fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534505894-172.17.0.15-1595496804430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42516,DS-d7f654ee-9cee-4f0a-ba85-6f96d34b731e,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-9c7903f8-5fe0-4f11-8fb3-666ff09ff3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-2ee0c5e6-d412-416a-ab00-3bfd097b68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-724c94f4-e039-4071-bee8-8a4441429b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-f3ec1991-6fa9-4ce8-a8e6-515c3a42c570,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-217436b8-595a-479a-9542-eb6157c2f981,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-972818bd-f330-41d8-b124-ee5ed67e8a70,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-c550b143-797c-4f49-b4a5-c9e97c2b67e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534505894-172.17.0.15-1595496804430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42516,DS-d7f654ee-9cee-4f0a-ba85-6f96d34b731e,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-9c7903f8-5fe0-4f11-8fb3-666ff09ff3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-2ee0c5e6-d412-416a-ab00-3bfd097b68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-724c94f4-e039-4071-bee8-8a4441429b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-f3ec1991-6fa9-4ce8-a8e6-515c3a42c570,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-217436b8-595a-479a-9542-eb6157c2f981,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-972818bd-f330-41d8-b124-ee5ed67e8a70,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-c550b143-797c-4f49-b4a5-c9e97c2b67e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025784999-172.17.0.15-1595496956079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43122,DS-e7501e6a-4312-437a-9a91-e1146bcd4278,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-6eb97af1-aa19-4244-862a-26a2c82204a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-856c4d16-e1ed-4ddf-9c78-5ddea166706c,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-cbac454b-6a48-4c32-a6ac-b5305b206a66,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-4ac3dde7-d10f-4220-ab6a-7731fac6df77,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-ad7509da-4eb8-4f86-9e04-ae9ebb5db9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e9e398da-de51-408e-ad2d-9996e91fdb76,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-a82acd8a-df9e-4318-b460-dfbe62f69556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025784999-172.17.0.15-1595496956079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43122,DS-e7501e6a-4312-437a-9a91-e1146bcd4278,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-6eb97af1-aa19-4244-862a-26a2c82204a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-856c4d16-e1ed-4ddf-9c78-5ddea166706c,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-cbac454b-6a48-4c32-a6ac-b5305b206a66,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-4ac3dde7-d10f-4220-ab6a-7731fac6df77,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-ad7509da-4eb8-4f86-9e04-ae9ebb5db9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e9e398da-de51-408e-ad2d-9996e91fdb76,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-a82acd8a-df9e-4318-b460-dfbe62f69556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835460847-172.17.0.15-1595497586520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-739b993a-4cf8-47ce-bec3-50ddc889dff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-6a7ec770-c7f3-450e-8688-4cb73e378426,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-acee3fe3-d8bc-4424-aaf3-16aa1c377dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-4082b253-58ff-4d67-ace0-f85373051e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-72b7e3d5-1d79-4ec0-bcad-7539246421d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-db67d6c1-605e-472d-930c-b736bac45845,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-b0158d14-7a6f-44b7-b299-2143f19b4cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-99c86f1c-3284-4ae7-a7bf-d35a6921ce2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835460847-172.17.0.15-1595497586520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-739b993a-4cf8-47ce-bec3-50ddc889dff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-6a7ec770-c7f3-450e-8688-4cb73e378426,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-acee3fe3-d8bc-4424-aaf3-16aa1c377dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-4082b253-58ff-4d67-ace0-f85373051e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-72b7e3d5-1d79-4ec0-bcad-7539246421d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-db67d6c1-605e-472d-930c-b736bac45845,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-b0158d14-7a6f-44b7-b299-2143f19b4cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-99c86f1c-3284-4ae7-a7bf-d35a6921ce2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058094761-172.17.0.15-1595497645831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36405,DS-a25b2497-4ac7-49e7-9ce5-86d099e53492,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-f8d2e0e5-33d4-4251-96af-34c3ab17be34,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-9363f13a-f30b-4a41-9b8d-5dfbd10c193d,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-f9f9c934-47c9-40db-8887-161a319b761b,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-154dd342-21f6-4558-bcf9-fa56c09b933f,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-49f761de-bcdd-4c17-98f4-83f6fd5e1356,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-e34787e6-2ed9-4693-b12b-ed019269e018,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-be383190-b6b5-4f8f-b12f-c2b1064ad44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058094761-172.17.0.15-1595497645831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36405,DS-a25b2497-4ac7-49e7-9ce5-86d099e53492,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-f8d2e0e5-33d4-4251-96af-34c3ab17be34,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-9363f13a-f30b-4a41-9b8d-5dfbd10c193d,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-f9f9c934-47c9-40db-8887-161a319b761b,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-154dd342-21f6-4558-bcf9-fa56c09b933f,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-49f761de-bcdd-4c17-98f4-83f6fd5e1356,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-e34787e6-2ed9-4693-b12b-ed019269e018,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-be383190-b6b5-4f8f-b12f-c2b1064ad44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369837009-172.17.0.15-1595497768002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41500,DS-cd8baa8d-bc16-4718-b248-c159689c5280,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-df7e3275-19aa-4f0f-8b9e-a5c759b60b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-2243d02a-e9f8-42ab-aff1-4b46871e305c,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-1f352495-ee4b-455b-9ff4-d1c53befd2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-d4cb3a11-cd99-4bc4-a244-1424a70973ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-ae814ec1-51ac-41e4-ba64-d7b922772030,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-4f69e5d5-c423-41eb-a1f7-6e8953e3850f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-3edbae10-f03f-43c4-b4e2-6a01ac7fb955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369837009-172.17.0.15-1595497768002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41500,DS-cd8baa8d-bc16-4718-b248-c159689c5280,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-df7e3275-19aa-4f0f-8b9e-a5c759b60b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-2243d02a-e9f8-42ab-aff1-4b46871e305c,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-1f352495-ee4b-455b-9ff4-d1c53befd2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-d4cb3a11-cd99-4bc4-a244-1424a70973ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-ae814ec1-51ac-41e4-ba64-d7b922772030,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-4f69e5d5-c423-41eb-a1f7-6e8953e3850f,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-3edbae10-f03f-43c4-b4e2-6a01ac7fb955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424719997-172.17.0.15-1595497920290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-9c1249e0-4022-4c33-a487-6434250708a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-53d16579-7015-4c61-bf62-712ea0237112,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-67d6999d-b407-48d1-a4eb-08660e2b59f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-f431fd7e-469f-47de-a98a-f1e58a59a41b,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-4cab896d-2d48-48e8-86ce-935a9e38e78f,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-83286d89-145c-42f2-bbd0-b92f705dbdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-5907de4f-dcbc-43ce-827b-379a0632c720,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-71392c5c-dba9-4d12-9172-60ecd19e8a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424719997-172.17.0.15-1595497920290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-9c1249e0-4022-4c33-a487-6434250708a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-53d16579-7015-4c61-bf62-712ea0237112,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-67d6999d-b407-48d1-a4eb-08660e2b59f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-f431fd7e-469f-47de-a98a-f1e58a59a41b,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-4cab896d-2d48-48e8-86ce-935a9e38e78f,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-83286d89-145c-42f2-bbd0-b92f705dbdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-5907de4f-dcbc-43ce-827b-379a0632c720,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-71392c5c-dba9-4d12-9172-60ecd19e8a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10974772-172.17.0.15-1595498416463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-ea8f1ae4-99f7-4c42-bc8e-3599b733bfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-a379334f-7274-46b7-9667-f4925a52428c,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-2f783c9d-e5d6-4a0c-86ce-2661c8e957ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-805841bc-1a37-457c-88f7-ea8114640cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-bb8209de-9689-4752-bc2e-689c84b6fc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-b4d5c2a9-57f7-40c9-9eea-ad48c588492c,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-689697f9-6163-40d4-b2c1-9ddb9aa2caec,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-97f7b046-e75c-4224-a21a-9c23ccbf01ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10974772-172.17.0.15-1595498416463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-ea8f1ae4-99f7-4c42-bc8e-3599b733bfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-a379334f-7274-46b7-9667-f4925a52428c,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-2f783c9d-e5d6-4a0c-86ce-2661c8e957ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-805841bc-1a37-457c-88f7-ea8114640cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-bb8209de-9689-4752-bc2e-689c84b6fc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-b4d5c2a9-57f7-40c9-9eea-ad48c588492c,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-689697f9-6163-40d4-b2c1-9ddb9aa2caec,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-97f7b046-e75c-4224-a21a-9c23ccbf01ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465867828-172.17.0.15-1595498517668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-19f0c938-bccd-450f-bc71-74054f609bed,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-e1ebc7aa-0314-4b08-9162-e64539c79350,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-0d79f855-11c9-43ca-8c49-b941947c3380,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-eb5e7a7e-6b33-4465-a879-4ba4202ab760,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-7a828885-0cc4-4c0d-8c03-2a6d0f3ec8db,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-2204ecdf-10bb-4fb6-92d7-9762e81a938a,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-2a9c3b03-ba3e-4150-8ede-dc908cf8d4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-e6d35881-7e97-4e25-9922-f16ebe7bd468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465867828-172.17.0.15-1595498517668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-19f0c938-bccd-450f-bc71-74054f609bed,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-e1ebc7aa-0314-4b08-9162-e64539c79350,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-0d79f855-11c9-43ca-8c49-b941947c3380,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-eb5e7a7e-6b33-4465-a879-4ba4202ab760,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-7a828885-0cc4-4c0d-8c03-2a6d0f3ec8db,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-2204ecdf-10bb-4fb6-92d7-9762e81a938a,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-2a9c3b03-ba3e-4150-8ede-dc908cf8d4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-e6d35881-7e97-4e25-9922-f16ebe7bd468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264852929-172.17.0.15-1595498641884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40965,DS-166b2ade-9a6f-42e7-9177-2a9744e583c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-81cbb81c-31dd-4a41-b5ff-a4d02804efab,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-8c010a57-7e51-45eb-8884-33994635a195,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-ddca852e-1ceb-4a1e-b10f-2edc1f8c46f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-97f07f9e-33a2-48ac-8c90-0b5b0564b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-46c22c5c-c0f5-444c-a58a-cbebb10c9fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-bb09710e-c81d-4ad7-99d6-14a4182405f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-e6e6a2c2-c5d5-40cc-92a1-bb3d44ef976c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264852929-172.17.0.15-1595498641884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40965,DS-166b2ade-9a6f-42e7-9177-2a9744e583c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-81cbb81c-31dd-4a41-b5ff-a4d02804efab,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-8c010a57-7e51-45eb-8884-33994635a195,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-ddca852e-1ceb-4a1e-b10f-2edc1f8c46f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-97f07f9e-33a2-48ac-8c90-0b5b0564b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-46c22c5c-c0f5-444c-a58a-cbebb10c9fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-bb09710e-c81d-4ad7-99d6-14a4182405f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-e6e6a2c2-c5d5-40cc-92a1-bb3d44ef976c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362909936-172.17.0.15-1595498666038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44361,DS-d606a092-e6a1-4039-90fd-3dce741b1674,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-d73ceb2f-eb89-46a8-9944-a36530e25fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-f6fff975-d4f2-4113-a531-10e814f0f378,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-146f8e4e-50d6-4fa3-8b45-b666c67dc307,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-41d5adf5-af4d-4ce1-a92f-c2d0d71f7166,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-b52d9efe-f938-4d16-950b-ab756547cad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-4de24495-c803-453b-a041-2c4f021d3186,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-f73980ce-f627-46bc-a31f-61a1cff7aec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362909936-172.17.0.15-1595498666038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44361,DS-d606a092-e6a1-4039-90fd-3dce741b1674,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-d73ceb2f-eb89-46a8-9944-a36530e25fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-f6fff975-d4f2-4113-a531-10e814f0f378,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-146f8e4e-50d6-4fa3-8b45-b666c67dc307,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-41d5adf5-af4d-4ce1-a92f-c2d0d71f7166,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-b52d9efe-f938-4d16-950b-ab756547cad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-4de24495-c803-453b-a041-2c4f021d3186,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-f73980ce-f627-46bc-a31f-61a1cff7aec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5141
