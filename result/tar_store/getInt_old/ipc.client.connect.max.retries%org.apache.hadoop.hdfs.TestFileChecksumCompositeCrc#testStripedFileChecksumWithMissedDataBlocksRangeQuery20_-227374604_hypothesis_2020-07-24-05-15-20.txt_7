reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693639375-172.17.0.20-1595567772297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33571,DS-83e6eb4f-a0f9-4bbf-b572-17e9b341554d,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-e4bd3008-3dbe-432b-8e99-884713fb9a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-3611c8f8-3be4-4b82-8684-21e44af50f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-e31a490c-8fae-40a4-8747-2bf0e25f6b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-44cf99c3-e972-401f-b4f3-b0b4006ac377,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-fa51c423-2832-466a-a678-a82ced5ae324,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-96a760d6-f346-429e-b7c3-f90a6370ce68,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-434cb681-50fc-4a4b-8cf6-0fa2e41ff5a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693639375-172.17.0.20-1595567772297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33571,DS-83e6eb4f-a0f9-4bbf-b572-17e9b341554d,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-e4bd3008-3dbe-432b-8e99-884713fb9a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-3611c8f8-3be4-4b82-8684-21e44af50f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-e31a490c-8fae-40a4-8747-2bf0e25f6b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-44cf99c3-e972-401f-b4f3-b0b4006ac377,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-fa51c423-2832-466a-a678-a82ced5ae324,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-96a760d6-f346-429e-b7c3-f90a6370ce68,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-434cb681-50fc-4a4b-8cf6-0fa2e41ff5a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219047085-172.17.0.20-1595568088558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-6d9c6e50-57b6-4e36-bc45-bd01e7a553b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-54a9c0bf-fe89-46d7-bd63-2d3707030429,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-c30d1db4-5cf2-4b61-9357-cd5c0c2b8d06,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-6e2e6cfb-f52c-4481-a75b-09ba700cc632,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-7cfff09d-5ad6-4fdd-9515-d806e6b33345,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-939231aa-ef58-443a-be03-112a08ed4bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-917b4378-1e75-4f5c-ba8c-0a7cf268fa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-e513fc48-7aa3-4ffd-b4fe-25c6921ec97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219047085-172.17.0.20-1595568088558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-6d9c6e50-57b6-4e36-bc45-bd01e7a553b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-54a9c0bf-fe89-46d7-bd63-2d3707030429,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-c30d1db4-5cf2-4b61-9357-cd5c0c2b8d06,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-6e2e6cfb-f52c-4481-a75b-09ba700cc632,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-7cfff09d-5ad6-4fdd-9515-d806e6b33345,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-939231aa-ef58-443a-be03-112a08ed4bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-917b4378-1e75-4f5c-ba8c-0a7cf268fa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-e513fc48-7aa3-4ffd-b4fe-25c6921ec97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199702221-172.17.0.20-1595568206201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-8cab9f29-71e1-4333-a285-b171dc886329,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-e5760408-2013-4ef0-ac2c-923bc3bd77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-8c85301b-5a7f-41e3-9d9b-3fbe8bf50d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-d8bf5da0-6b0e-44f6-ac35-d000587c3f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-d48bb259-9b3f-472d-a7ef-e49687effc39,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-21778091-79ef-4a6c-82e8-95323ea4562a,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-1d848fe0-6a1b-4135-92b6-2e56f4a0a96e,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-bc4db549-8768-40b9-ba9d-ae195dfb7bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199702221-172.17.0.20-1595568206201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-8cab9f29-71e1-4333-a285-b171dc886329,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-e5760408-2013-4ef0-ac2c-923bc3bd77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-8c85301b-5a7f-41e3-9d9b-3fbe8bf50d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-d8bf5da0-6b0e-44f6-ac35-d000587c3f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-d48bb259-9b3f-472d-a7ef-e49687effc39,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-21778091-79ef-4a6c-82e8-95323ea4562a,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-1d848fe0-6a1b-4135-92b6-2e56f4a0a96e,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-bc4db549-8768-40b9-ba9d-ae195dfb7bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796247948-172.17.0.20-1595568354536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41860,DS-6f8ecfff-98e2-4f9b-8630-e3979760d8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-68048719-11bc-4c94-97b4-3b9fa2f85432,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-d6c48cbb-644e-4994-973a-e64e88d75adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-34a20b20-6732-4a12-b5f7-cb52a1cd93b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-c64753ad-caeb-4cd1-af37-36803a05a0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-292ac1a5-2c07-4291-8344-22076cb8e5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-762801aa-1afe-4500-b417-16a30278ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-f3bcf246-f3fa-419e-98ea-1877e728f57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796247948-172.17.0.20-1595568354536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41860,DS-6f8ecfff-98e2-4f9b-8630-e3979760d8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-68048719-11bc-4c94-97b4-3b9fa2f85432,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-d6c48cbb-644e-4994-973a-e64e88d75adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-34a20b20-6732-4a12-b5f7-cb52a1cd93b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-c64753ad-caeb-4cd1-af37-36803a05a0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-292ac1a5-2c07-4291-8344-22076cb8e5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-762801aa-1afe-4500-b417-16a30278ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-f3bcf246-f3fa-419e-98ea-1877e728f57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236098012-172.17.0.20-1595568536555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-3fea4859-9de2-43cc-88fe-25e9e0051601,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-5af3e9b3-438d-4384-ae8a-7e269ded4d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-58d05c53-7184-4c25-985d-fd3f5f1c1e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-b5da39e7-9896-4b73-b2cb-4ff7b9bcfe51,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-80038574-bdbf-4766-924f-16c690bee61b,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-8a8ee5c3-2244-4aa4-9443-5b4e9c160ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-442a2b10-3282-4fe5-acce-e45ad0ec4e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-d26f4b3b-226b-42ee-b53b-cb57a14ad92b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236098012-172.17.0.20-1595568536555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-3fea4859-9de2-43cc-88fe-25e9e0051601,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-5af3e9b3-438d-4384-ae8a-7e269ded4d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-58d05c53-7184-4c25-985d-fd3f5f1c1e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-b5da39e7-9896-4b73-b2cb-4ff7b9bcfe51,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-80038574-bdbf-4766-924f-16c690bee61b,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-8a8ee5c3-2244-4aa4-9443-5b4e9c160ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-442a2b10-3282-4fe5-acce-e45ad0ec4e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-d26f4b3b-226b-42ee-b53b-cb57a14ad92b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231130379-172.17.0.20-1595568939498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41751,DS-39b40727-c949-4d42-8e0d-8f4c4d464de1,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-78e4f11b-222b-4ac0-8917-61106d990ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-10b770f8-2ebc-4a17-b78a-f77f6bf62a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-b3351a5d-476d-4e58-88bd-589be4a0ec62,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-dad32b2a-f723-442b-a5bc-c9f7777a9d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-9a262e1f-7d7e-476e-a841-87b20d994993,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-7226ed6a-06e0-44d5-8de6-cdc8b09789bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-94c35f8c-4b34-4c3d-adb1-1622fbabf960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231130379-172.17.0.20-1595568939498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41751,DS-39b40727-c949-4d42-8e0d-8f4c4d464de1,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-78e4f11b-222b-4ac0-8917-61106d990ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-10b770f8-2ebc-4a17-b78a-f77f6bf62a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-b3351a5d-476d-4e58-88bd-589be4a0ec62,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-dad32b2a-f723-442b-a5bc-c9f7777a9d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-9a262e1f-7d7e-476e-a841-87b20d994993,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-7226ed6a-06e0-44d5-8de6-cdc8b09789bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-94c35f8c-4b34-4c3d-adb1-1622fbabf960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609585029-172.17.0.20-1595569167123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-d1669289-e17a-4508-b2fb-4289fcc23c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-da67b51e-02b1-4d9f-8797-d6378b386dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-099ae4ab-dfdd-49ff-8912-e134b6d86a95,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-8007331a-b0c2-4a6a-9bcc-3b6b2c1b8340,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-68c16f68-21ac-4dbb-9524-34e621d74361,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-90ddc599-a84e-4fc8-bf7c-ee5d8b3cb372,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-d4337800-ccba-4b43-95e1-88dc048b8650,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-e065ead8-e713-4de3-a78e-0c9da563d444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609585029-172.17.0.20-1595569167123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-d1669289-e17a-4508-b2fb-4289fcc23c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-da67b51e-02b1-4d9f-8797-d6378b386dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-099ae4ab-dfdd-49ff-8912-e134b6d86a95,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-8007331a-b0c2-4a6a-9bcc-3b6b2c1b8340,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-68c16f68-21ac-4dbb-9524-34e621d74361,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-90ddc599-a84e-4fc8-bf7c-ee5d8b3cb372,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-d4337800-ccba-4b43-95e1-88dc048b8650,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-e065ead8-e713-4de3-a78e-0c9da563d444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507466378-172.17.0.20-1595569786142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46109,DS-fa128ed3-e586-47cf-be5a-f12538c81fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-461be5eb-a9f2-4c25-a652-f9311da4a563,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-f8184f53-979f-4431-8b96-a501a98ac5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-0704a23f-e31c-4706-a7f6-190d97439709,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-b567fdb3-3301-4908-a5c8-69724977e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-e1b292fa-f959-432c-845c-0af49dbc6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-9e7dbbda-b14a-408a-b0de-b182f998c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-4b597e63-b00c-4812-9175-b7f01b88c4b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507466378-172.17.0.20-1595569786142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46109,DS-fa128ed3-e586-47cf-be5a-f12538c81fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-461be5eb-a9f2-4c25-a652-f9311da4a563,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-f8184f53-979f-4431-8b96-a501a98ac5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-0704a23f-e31c-4706-a7f6-190d97439709,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-b567fdb3-3301-4908-a5c8-69724977e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-e1b292fa-f959-432c-845c-0af49dbc6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-9e7dbbda-b14a-408a-b0de-b182f998c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-4b597e63-b00c-4812-9175-b7f01b88c4b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536884361-172.17.0.20-1595569821562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46320,DS-152ce331-5a67-4370-bf4f-75ae25cc965b,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-bb9c48eb-bd5b-4e22-a5c7-f763d71c023d,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-56ee7f8e-060a-4168-bf74-4761839af26b,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-59308f4f-a1f1-48c9-a214-d2b413439320,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-30a016d5-2531-4af4-9154-6654271d87e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-10728546-d8b0-413a-b7a4-b604d720b719,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-1a692dcc-0a3d-44e0-ab11-e12d0776cbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-0060fc27-44aa-45f1-bfed-e833564eb82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536884361-172.17.0.20-1595569821562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46320,DS-152ce331-5a67-4370-bf4f-75ae25cc965b,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-bb9c48eb-bd5b-4e22-a5c7-f763d71c023d,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-56ee7f8e-060a-4168-bf74-4761839af26b,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-59308f4f-a1f1-48c9-a214-d2b413439320,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-30a016d5-2531-4af4-9154-6654271d87e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-10728546-d8b0-413a-b7a4-b604d720b719,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-1a692dcc-0a3d-44e0-ab11-e12d0776cbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-0060fc27-44aa-45f1-bfed-e833564eb82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415327398-172.17.0.20-1595569854894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45562,DS-ab967493-fb63-416d-8fd5-1cf2fc8d05e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-563a00e9-e481-471d-b5ea-bec6b104dae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-1666db54-fd4b-44fc-867d-02423de934ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-24696eb5-19f9-48a4-87eb-be2654ddeb64,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-2f5316df-5eab-4aa5-8303-9b1f12329dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-adb743b1-ecb2-40f5-9cc5-2ee3c17c6946,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-8dfeaf36-4a5b-45e0-a509-a3efa0ae544f,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-29766f77-c09f-4cea-9ecd-2ff9461abcfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415327398-172.17.0.20-1595569854894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45562,DS-ab967493-fb63-416d-8fd5-1cf2fc8d05e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-563a00e9-e481-471d-b5ea-bec6b104dae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-1666db54-fd4b-44fc-867d-02423de934ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-24696eb5-19f9-48a4-87eb-be2654ddeb64,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-2f5316df-5eab-4aa5-8303-9b1f12329dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-adb743b1-ecb2-40f5-9cc5-2ee3c17c6946,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-8dfeaf36-4a5b-45e0-a509-a3efa0ae544f,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-29766f77-c09f-4cea-9ecd-2ff9461abcfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850982098-172.17.0.20-1595570241376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46772,DS-86899be5-461b-4d43-bb40-bd7cc1c6b2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-670e3743-52a5-4f13-bf78-1ee51b2175c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-c0898e70-d42f-48c3-baa3-895abc2fcbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-2a91a0a2-d94d-4fa9-81f8-19748f55c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-9274a6e8-9e70-4e06-975d-62e9e698a033,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-f899ced0-6088-46cd-afda-afe0c420fb68,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-530d9117-2f5e-46c3-ba31-9db45fa3fe26,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-012c4dff-7b56-44f3-b274-761685cab0e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850982098-172.17.0.20-1595570241376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46772,DS-86899be5-461b-4d43-bb40-bd7cc1c6b2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-670e3743-52a5-4f13-bf78-1ee51b2175c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-c0898e70-d42f-48c3-baa3-895abc2fcbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-2a91a0a2-d94d-4fa9-81f8-19748f55c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-9274a6e8-9e70-4e06-975d-62e9e698a033,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-f899ced0-6088-46cd-afda-afe0c420fb68,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-530d9117-2f5e-46c3-ba31-9db45fa3fe26,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-012c4dff-7b56-44f3-b274-761685cab0e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594624266-172.17.0.20-1595570725981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37953,DS-e15d6874-9adf-41dc-8f70-8663f6d7b3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-486e7c92-b9c7-4971-ac38-64dcfd015bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-232eff21-effb-4b0c-b239-cc169aad9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-d1fffd92-112a-4dda-9ada-fa60da05d90e,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-130aa17d-29b1-423a-8fa0-6a0be1ea1f00,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-b38969bc-5721-4822-a15a-1f9b83eabfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-b05a5a7e-a90b-4828-8371-3599bbdae0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-2228656b-1583-46af-b036-0febeaa1748f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594624266-172.17.0.20-1595570725981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37953,DS-e15d6874-9adf-41dc-8f70-8663f6d7b3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-486e7c92-b9c7-4971-ac38-64dcfd015bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-232eff21-effb-4b0c-b239-cc169aad9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-d1fffd92-112a-4dda-9ada-fa60da05d90e,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-130aa17d-29b1-423a-8fa0-6a0be1ea1f00,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-b38969bc-5721-4822-a15a-1f9b83eabfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-b05a5a7e-a90b-4828-8371-3599bbdae0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-2228656b-1583-46af-b036-0febeaa1748f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953832972-172.17.0.20-1595571012872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-79e9e269-215b-4078-af8d-9222a434b542,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-3dbcf448-81c2-423b-80cd-baf1a67d9caf,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-34071637-8699-44e6-817e-7f08da290e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-ee91e852-b5b4-436a-930f-129dfccd9eba,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-e1ad626d-27f3-4e77-ac90-4b4a3e1a33aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-fedbe9bd-a730-42b9-aea7-2d35171eff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-22d631ae-8238-403b-a332-13612740176a,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-25a7df30-eb0e-4192-b1ad-7068a545c0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953832972-172.17.0.20-1595571012872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-79e9e269-215b-4078-af8d-9222a434b542,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-3dbcf448-81c2-423b-80cd-baf1a67d9caf,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-34071637-8699-44e6-817e-7f08da290e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-ee91e852-b5b4-436a-930f-129dfccd9eba,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-e1ad626d-27f3-4e77-ac90-4b4a3e1a33aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-fedbe9bd-a730-42b9-aea7-2d35171eff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-22d631ae-8238-403b-a332-13612740176a,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-25a7df30-eb0e-4192-b1ad-7068a545c0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127553761-172.17.0.20-1595571161508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-b9c8de4f-b0ff-42b3-a6c9-6accd8811bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-b9f25aca-285f-4d1d-aa84-b1b69e725bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-923b60f6-9e4a-4261-b34d-7a90cd354574,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-04be6a1f-c320-49e2-95cc-e997557d0769,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-b45d458c-5714-4bb9-bd79-cc5d8e79b17e,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-b7ecdd54-379c-425f-a527-2cabaf827046,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-6ce0e119-f504-4d51-9acd-6cab4049fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-25d37e46-9fee-4ca4-8779-652ad483af12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127553761-172.17.0.20-1595571161508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-b9c8de4f-b0ff-42b3-a6c9-6accd8811bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-b9f25aca-285f-4d1d-aa84-b1b69e725bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-923b60f6-9e4a-4261-b34d-7a90cd354574,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-04be6a1f-c320-49e2-95cc-e997557d0769,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-b45d458c-5714-4bb9-bd79-cc5d8e79b17e,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-b7ecdd54-379c-425f-a527-2cabaf827046,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-6ce0e119-f504-4d51-9acd-6cab4049fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-25d37e46-9fee-4ca4-8779-652ad483af12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040554657-172.17.0.20-1595571200806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33437,DS-a1b9bec9-8868-4c77-baf4-9d3dc808ceec,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-74c7663a-98be-48d7-b36e-884a2fb227fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-98fd321b-071d-4f8a-8ac1-d847c704e33e,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-b0a8a7c8-264e-4eba-a1ff-96b4ab86305a,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-993a0775-e3cd-4af6-b430-32fd4a00bfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-0b2875e0-e461-4c07-b8b6-36057a55feba,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-3043dc11-48a9-456e-abb2-94a58fa33cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-bf3ba4da-91d1-4c8d-bd27-05adf85b59cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040554657-172.17.0.20-1595571200806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33437,DS-a1b9bec9-8868-4c77-baf4-9d3dc808ceec,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-74c7663a-98be-48d7-b36e-884a2fb227fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-98fd321b-071d-4f8a-8ac1-d847c704e33e,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-b0a8a7c8-264e-4eba-a1ff-96b4ab86305a,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-993a0775-e3cd-4af6-b430-32fd4a00bfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-0b2875e0-e461-4c07-b8b6-36057a55feba,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-3043dc11-48a9-456e-abb2-94a58fa33cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-bf3ba4da-91d1-4c8d-bd27-05adf85b59cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597105140-172.17.0.20-1595571240053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-aa9d2232-9af5-45e6-a3e2-27d1c5d792ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-a97711f2-a413-41b4-867e-9b9152addd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-d8e9865a-06da-440c-a8c0-8458365d752e,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-fbf3af6a-7ab7-41bf-aa52-3257702463dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-ef39863e-8f12-4ca8-8529-f28b6431bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-03fdebb2-4f36-43f9-902b-2d43848cb8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-c6babad1-4074-4195-8211-321c21437363,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-d5988a83-ed96-4728-b57c-26bd95a3c0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597105140-172.17.0.20-1595571240053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-aa9d2232-9af5-45e6-a3e2-27d1c5d792ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-a97711f2-a413-41b4-867e-9b9152addd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-d8e9865a-06da-440c-a8c0-8458365d752e,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-fbf3af6a-7ab7-41bf-aa52-3257702463dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-ef39863e-8f12-4ca8-8529-f28b6431bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-03fdebb2-4f36-43f9-902b-2d43848cb8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-c6babad1-4074-4195-8211-321c21437363,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-d5988a83-ed96-4728-b57c-26bd95a3c0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909500451-172.17.0.20-1595571274659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43167,DS-9b17337e-9500-4576-b0a6-8037a8e3cf30,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-0f430f48-6335-4249-bf8d-cc3b2908cd28,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-2ffadeb9-6141-489b-bd61-0000453ed518,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-40cb779d-9780-437c-9086-55b69f4ddeea,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-2237745c-e6fd-4d53-a2b9-a7d02637a002,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-6c043282-ea7d-4390-88a2-44b73d127b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-37b759fe-b8f5-4814-abff-e967f1b8e694,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-5f551b7f-cd2c-43d3-ac05-a43be52b4311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909500451-172.17.0.20-1595571274659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43167,DS-9b17337e-9500-4576-b0a6-8037a8e3cf30,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-0f430f48-6335-4249-bf8d-cc3b2908cd28,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-2ffadeb9-6141-489b-bd61-0000453ed518,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-40cb779d-9780-437c-9086-55b69f4ddeea,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-2237745c-e6fd-4d53-a2b9-a7d02637a002,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-6c043282-ea7d-4390-88a2-44b73d127b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-37b759fe-b8f5-4814-abff-e967f1b8e694,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-5f551b7f-cd2c-43d3-ac05-a43be52b4311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053651220-172.17.0.20-1595571311453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37958,DS-29312778-d9a7-4c0b-89d7-9d3b24033d51,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-6f7f803d-5c15-44a5-a2e4-9f468bdc285c,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-1b97acf5-5923-4077-94c4-3af80d696dad,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-deef5228-b3ec-4fa6-aac0-8c1f192c22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-f57bd859-a745-47ed-8df7-0e2e8afccb32,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-88d92ace-41ed-4e4e-a0a2-be1472b0a449,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-fea41b45-6519-46ea-87ab-7eb71c995644,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-53eec8c3-cbab-4988-894c-a7ec6096aa8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053651220-172.17.0.20-1595571311453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37958,DS-29312778-d9a7-4c0b-89d7-9d3b24033d51,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-6f7f803d-5c15-44a5-a2e4-9f468bdc285c,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-1b97acf5-5923-4077-94c4-3af80d696dad,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-deef5228-b3ec-4fa6-aac0-8c1f192c22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-f57bd859-a745-47ed-8df7-0e2e8afccb32,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-88d92ace-41ed-4e4e-a0a2-be1472b0a449,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-fea41b45-6519-46ea-87ab-7eb71c995644,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-53eec8c3-cbab-4988-894c-a7ec6096aa8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602406534-172.17.0.20-1595571378777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36854,DS-0f3bf11e-251c-43e3-89bf-eea1710a75f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-bf36ed4f-90da-4d8d-a654-af6446483219,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-8315c9b1-a305-4173-b834-8443ebe74413,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-2e6bc6f2-e80c-45c0-8202-7b5bc2facc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-e91669c2-b06a-4c47-8f93-7c58e2e8b39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-22bec4ec-bed2-402b-921b-dd8ea834a327,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-6e23b121-2508-4f85-a449-05f4a3b75500,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-6a0ac8d1-b37a-4644-8d55-4541e0e4b8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602406534-172.17.0.20-1595571378777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36854,DS-0f3bf11e-251c-43e3-89bf-eea1710a75f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-bf36ed4f-90da-4d8d-a654-af6446483219,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-8315c9b1-a305-4173-b834-8443ebe74413,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-2e6bc6f2-e80c-45c0-8202-7b5bc2facc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-e91669c2-b06a-4c47-8f93-7c58e2e8b39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-22bec4ec-bed2-402b-921b-dd8ea834a327,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-6e23b121-2508-4f85-a449-05f4a3b75500,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-6a0ac8d1-b37a-4644-8d55-4541e0e4b8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92469054-172.17.0.20-1595571862486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-bb4f5544-da4f-4244-bbc9-e8a43d87c0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-eb97cdc4-0a2d-4035-a4a1-3f2286c49a98,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-3b8075c1-69af-443a-b344-074a68e3b99d,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-6d57d950-5145-47be-9df9-4c97269c8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-1f3d8b33-0f1d-49b0-9bde-64c51951f41d,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-892fc445-6c35-497f-9849-d047e1b5dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-c2e78e02-8fb2-4c43-bf97-fccd9c99677c,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-3832e0f6-7ab9-415b-aa97-c215c47fed94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92469054-172.17.0.20-1595571862486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-bb4f5544-da4f-4244-bbc9-e8a43d87c0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-eb97cdc4-0a2d-4035-a4a1-3f2286c49a98,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-3b8075c1-69af-443a-b344-074a68e3b99d,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-6d57d950-5145-47be-9df9-4c97269c8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-1f3d8b33-0f1d-49b0-9bde-64c51951f41d,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-892fc445-6c35-497f-9849-d047e1b5dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-c2e78e02-8fb2-4c43-bf97-fccd9c99677c,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-3832e0f6-7ab9-415b-aa97-c215c47fed94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559253145-172.17.0.20-1595572202225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37026,DS-fe2985a4-8a6b-4567-9a86-55955d732f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-04f86cfd-1f3e-4da8-b6a9-83143f87ac9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-d905605b-f922-4a11-ad28-cb7dd58b2a08,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-e1fc44b4-0fdb-4ea1-b2de-ef2f10e3730c,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-204d6dfe-42bc-4b8c-a2ad-5c57d4d8cdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-bbd9277b-cc5d-4f67-aba7-0191f7382cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-a6fa70a2-f157-47ef-b6e5-b56824ee8695,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-ea5f53e4-521b-4bf3-b1a8-1375b8f42949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559253145-172.17.0.20-1595572202225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37026,DS-fe2985a4-8a6b-4567-9a86-55955d732f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-04f86cfd-1f3e-4da8-b6a9-83143f87ac9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-d905605b-f922-4a11-ad28-cb7dd58b2a08,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-e1fc44b4-0fdb-4ea1-b2de-ef2f10e3730c,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-204d6dfe-42bc-4b8c-a2ad-5c57d4d8cdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-bbd9277b-cc5d-4f67-aba7-0191f7382cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-a6fa70a2-f157-47ef-b6e5-b56824ee8695,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-ea5f53e4-521b-4bf3-b1a8-1375b8f42949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507006945-172.17.0.20-1595572349009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-74e644df-54d4-4213-9864-3064d68e95e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-a8297d1c-3124-44b7-94ff-241ac30f0f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-7582e780-92a6-456f-9ca6-7c22f875274a,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-2b3656e3-a412-4811-8608-f5614b7561d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-6c3501e2-1074-4938-b052-a3348a05c9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-ab1fa84b-ca23-4a5a-abf7-f38ef2de91c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-945b6ffe-6f71-47a4-b343-29a25afe13b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-0f4d0f2e-3953-441d-a25f-73400f104f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507006945-172.17.0.20-1595572349009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-74e644df-54d4-4213-9864-3064d68e95e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-a8297d1c-3124-44b7-94ff-241ac30f0f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-7582e780-92a6-456f-9ca6-7c22f875274a,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-2b3656e3-a412-4811-8608-f5614b7561d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-6c3501e2-1074-4938-b052-a3348a05c9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-ab1fa84b-ca23-4a5a-abf7-f38ef2de91c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-945b6ffe-6f71-47a4-b343-29a25afe13b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-0f4d0f2e-3953-441d-a25f-73400f104f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849996720-172.17.0.20-1595572632561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34407,DS-1118ec65-f844-438a-8041-7423c06b5fea,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-54e68081-3361-4edc-aa6b-4e4c256b77c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-4e29c316-8ec8-447a-be83-4203032d11a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-5413c06a-0a1d-4425-b725-215120db6fda,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-68a50e11-e436-432c-b982-e2387d44f6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-1517f8c6-978d-447a-8097-6dc65c81c424,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-1e09206e-231b-45dd-ab4f-86d2e0ff0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-7bb907a9-25cf-4236-be3e-6544453dd003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849996720-172.17.0.20-1595572632561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34407,DS-1118ec65-f844-438a-8041-7423c06b5fea,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-54e68081-3361-4edc-aa6b-4e4c256b77c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-4e29c316-8ec8-447a-be83-4203032d11a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-5413c06a-0a1d-4425-b725-215120db6fda,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-68a50e11-e436-432c-b982-e2387d44f6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-1517f8c6-978d-447a-8097-6dc65c81c424,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-1e09206e-231b-45dd-ab4f-86d2e0ff0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-7bb907a9-25cf-4236-be3e-6544453dd003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221211635-172.17.0.20-1595572668034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-dfe09493-5418-4db5-b9ad-392bec32e525,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-462d5129-ea83-403a-9292-6d637d9397e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-ffddcaae-bd5e-4ac3-9002-750cd5e20cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-b1780ada-d8ab-4d2b-91ea-57e311636c44,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-86f7771c-0e6c-4ac9-9777-07b2e144cce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-6d11c65a-232a-4fb6-a7f0-fb2bc82880ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-d2e6e8f1-c1e3-46d5-842e-c6a3ac353027,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-09ba2428-056e-4b1c-b7b4-ef61bd0397e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221211635-172.17.0.20-1595572668034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-dfe09493-5418-4db5-b9ad-392bec32e525,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-462d5129-ea83-403a-9292-6d637d9397e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-ffddcaae-bd5e-4ac3-9002-750cd5e20cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-b1780ada-d8ab-4d2b-91ea-57e311636c44,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-86f7771c-0e6c-4ac9-9777-07b2e144cce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-6d11c65a-232a-4fb6-a7f0-fb2bc82880ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-d2e6e8f1-c1e3-46d5-842e-c6a3ac353027,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-09ba2428-056e-4b1c-b7b4-ef61bd0397e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747701460-172.17.0.20-1595573062049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44946,DS-6b6b20bc-ab16-44b8-8669-2cf603f57f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-ac9e2cef-572f-473e-a7bb-459d222958ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-c2662f21-9f8f-41c8-82f3-e0675b698754,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-2bb189f7-4255-4522-9ac5-603db6fbb7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-712a087f-00b6-4928-ac86-324a745d3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-0e205113-ff59-4c06-a7a3-ffe8381e5591,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-43a3d149-e52b-49f1-95df-5db14028a416,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-a1de5ea9-cc74-4469-88b0-2f69d8973e05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747701460-172.17.0.20-1595573062049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44946,DS-6b6b20bc-ab16-44b8-8669-2cf603f57f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-ac9e2cef-572f-473e-a7bb-459d222958ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-c2662f21-9f8f-41c8-82f3-e0675b698754,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-2bb189f7-4255-4522-9ac5-603db6fbb7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-712a087f-00b6-4928-ac86-324a745d3de9,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-0e205113-ff59-4c06-a7a3-ffe8381e5591,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-43a3d149-e52b-49f1-95df-5db14028a416,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-a1de5ea9-cc74-4469-88b0-2f69d8973e05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254275499-172.17.0.20-1595573143275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37990,DS-4fbc1784-b7c6-4162-975e-6dc0454cfe32,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-4e335e9a-27ec-41b6-80f7-43da7d60b47b,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-6d02b37a-0788-4b13-8a8d-c28dba365436,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-ac15a642-3d5f-44c1-bd1d-9a5920eba7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-d43dbc5b-27d7-41bf-8275-d917c1ae1553,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-188ca08e-9aea-41e2-b1ad-c6b0427ba604,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-6f8b475c-16b6-4aec-94ff-fa9ce4e07908,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-105e6080-0f09-40f5-8152-1defaee872bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254275499-172.17.0.20-1595573143275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37990,DS-4fbc1784-b7c6-4162-975e-6dc0454cfe32,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-4e335e9a-27ec-41b6-80f7-43da7d60b47b,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-6d02b37a-0788-4b13-8a8d-c28dba365436,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-ac15a642-3d5f-44c1-bd1d-9a5920eba7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-d43dbc5b-27d7-41bf-8275-d917c1ae1553,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-188ca08e-9aea-41e2-b1ad-c6b0427ba604,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-6f8b475c-16b6-4aec-94ff-fa9ce4e07908,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-105e6080-0f09-40f5-8152-1defaee872bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5443
