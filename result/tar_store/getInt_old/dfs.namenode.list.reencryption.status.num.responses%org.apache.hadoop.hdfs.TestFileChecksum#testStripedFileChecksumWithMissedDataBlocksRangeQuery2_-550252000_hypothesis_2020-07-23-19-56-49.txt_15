reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239546027-172.17.0.4-1595534398623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-1ce4a2b9-bae4-470c-9c11-db0bc6da9b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-f8c02b4e-d2ba-453e-bf11-e4602e916332,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-a0ff30a7-8190-4ec1-981b-fc6ee8ec4891,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-7b5476e9-e2c8-4287-9d8d-6cadd7ad84e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-140125f4-8a76-4a76-86fe-82694da862a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-f72c59b5-552e-4bf8-ab88-6d53f06fc141,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-cd46324e-fe6b-42a6-9404-17f8bfa8be12,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-013d65d4-a9ac-4912-a6aa-bdcb3b3c15f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239546027-172.17.0.4-1595534398623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-1ce4a2b9-bae4-470c-9c11-db0bc6da9b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-f8c02b4e-d2ba-453e-bf11-e4602e916332,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-a0ff30a7-8190-4ec1-981b-fc6ee8ec4891,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-7b5476e9-e2c8-4287-9d8d-6cadd7ad84e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-140125f4-8a76-4a76-86fe-82694da862a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-f72c59b5-552e-4bf8-ab88-6d53f06fc141,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-cd46324e-fe6b-42a6-9404-17f8bfa8be12,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-013d65d4-a9ac-4912-a6aa-bdcb3b3c15f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825033831-172.17.0.4-1595534649678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34326,DS-69255c55-c98b-4839-943c-92913d44dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-b9828a6c-c02d-479f-8ce8-6e14b6c2b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-7fdbaf9b-0903-4d90-bb39-2d77dfbd377c,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-a52595e8-6bd3-4932-b4a8-e9bfdd0ed3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-c6596112-d1c3-4e38-9891-dedf250f8c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-04494859-932f-49bd-8b10-d51cd2f8f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-4dfc67e0-50b5-42f7-97dc-b4a85ca46065,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-44af2596-32b4-49ed-8336-686f996dc8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825033831-172.17.0.4-1595534649678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34326,DS-69255c55-c98b-4839-943c-92913d44dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-b9828a6c-c02d-479f-8ce8-6e14b6c2b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-7fdbaf9b-0903-4d90-bb39-2d77dfbd377c,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-a52595e8-6bd3-4932-b4a8-e9bfdd0ed3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-c6596112-d1c3-4e38-9891-dedf250f8c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-04494859-932f-49bd-8b10-d51cd2f8f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-4dfc67e0-50b5-42f7-97dc-b4a85ca46065,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-44af2596-32b4-49ed-8336-686f996dc8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163379928-172.17.0.4-1595534810380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-7586708d-1b54-45d4-9c46-1d50b65586f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-37807e23-957c-4ec7-a02a-3bf6347548d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3089b568-8183-4d7e-9c76-cfafff9ad70f,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-5d3a8d3a-c187-495c-b384-49a2df83381e,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-ad518c9f-65e1-4e0c-8554-dfdbf0391fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-0b4cf1d2-a20d-4da2-b5f1-ac503f00eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-c01b0cae-f3be-45de-b1f6-0df71859a683,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-370d9ce9-d064-4707-84c1-1e05dd0a3748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163379928-172.17.0.4-1595534810380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-7586708d-1b54-45d4-9c46-1d50b65586f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-37807e23-957c-4ec7-a02a-3bf6347548d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3089b568-8183-4d7e-9c76-cfafff9ad70f,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-5d3a8d3a-c187-495c-b384-49a2df83381e,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-ad518c9f-65e1-4e0c-8554-dfdbf0391fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-0b4cf1d2-a20d-4da2-b5f1-ac503f00eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-c01b0cae-f3be-45de-b1f6-0df71859a683,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-370d9ce9-d064-4707-84c1-1e05dd0a3748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105300849-172.17.0.4-1595535052980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-f11bf09a-5406-4c7d-97a1-2d8d6a870f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-bd5dd9ec-40dd-4a56-a46c-37be5690813b,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-7d12aa28-9027-4f0e-ab0b-051b0d6f1565,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-1a1ca13e-c18a-4571-bd76-4364b0551285,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-98035d0f-403e-4898-bd81-d3e9817bdacd,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-951571c5-aa9b-44c8-94c2-a2bc0515fbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-ea10d933-c8b0-4b8f-9265-7db51d17a572,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-18e3b139-3a92-4de4-a202-5263e5dc0886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105300849-172.17.0.4-1595535052980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-f11bf09a-5406-4c7d-97a1-2d8d6a870f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-bd5dd9ec-40dd-4a56-a46c-37be5690813b,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-7d12aa28-9027-4f0e-ab0b-051b0d6f1565,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-1a1ca13e-c18a-4571-bd76-4364b0551285,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-98035d0f-403e-4898-bd81-d3e9817bdacd,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-951571c5-aa9b-44c8-94c2-a2bc0515fbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-ea10d933-c8b0-4b8f-9265-7db51d17a572,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-18e3b139-3a92-4de4-a202-5263e5dc0886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655201259-172.17.0.4-1595535409050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-361ed938-f84b-4840-bb0c-86d857f3c209,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-cdbd6697-f9bb-4385-8d6e-f3cc88afedee,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-2f36d379-37e1-4694-852f-f202579cb1df,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-847007a8-3129-4f63-9fbc-226b236b2136,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-8947e0fc-74f5-43f8-8eae-eb8e1e1e04b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-85b07d9b-0100-4286-93ff-1d1a70d1e625,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-d7d6e4ad-56e8-4087-8917-af944cd5ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-c8bf6051-1cdf-4e04-9f12-e52906b113ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655201259-172.17.0.4-1595535409050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-361ed938-f84b-4840-bb0c-86d857f3c209,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-cdbd6697-f9bb-4385-8d6e-f3cc88afedee,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-2f36d379-37e1-4694-852f-f202579cb1df,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-847007a8-3129-4f63-9fbc-226b236b2136,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-8947e0fc-74f5-43f8-8eae-eb8e1e1e04b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-85b07d9b-0100-4286-93ff-1d1a70d1e625,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-d7d6e4ad-56e8-4087-8917-af944cd5ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-c8bf6051-1cdf-4e04-9f12-e52906b113ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447331181-172.17.0.4-1595535779384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42757,DS-d95081e9-f0a2-49be-b158-058fcef268eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-160e343d-bccc-4f97-b008-ab3abd0869d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-e49ce2a3-8b3f-40b2-8cb4-19728b319f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-3327f96d-d01a-4c2c-928b-f4e0a682e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-fc6dc183-0de1-411d-9e90-21eacb7fd212,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-68d57773-dad5-4125-8682-617a8f444547,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-36d849b1-97eb-4f33-b856-74adc3282dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-60590a65-bcb5-4982-81f3-546cee503a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447331181-172.17.0.4-1595535779384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42757,DS-d95081e9-f0a2-49be-b158-058fcef268eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-160e343d-bccc-4f97-b008-ab3abd0869d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-e49ce2a3-8b3f-40b2-8cb4-19728b319f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-3327f96d-d01a-4c2c-928b-f4e0a682e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-fc6dc183-0de1-411d-9e90-21eacb7fd212,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-68d57773-dad5-4125-8682-617a8f444547,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-36d849b1-97eb-4f33-b856-74adc3282dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-60590a65-bcb5-4982-81f3-546cee503a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892076055-172.17.0.4-1595535928033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43109,DS-9ae8e03d-62ec-4830-b614-ce659cb57dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-b2df4597-11d0-4a23-a972-5a58ca5649da,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-d6c71526-d5ea-4dc6-b4c3-623076361037,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-64770500-7afe-49c1-8545-4d56343bec22,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-f7e2e400-3b8b-4ec0-99dc-ab4a44eec3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-bbca863a-d848-435c-b193-9ff52a0ecc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-375ce769-38c2-4e42-920d-8bcb06598a59,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-29176f02-e1f9-45af-bffa-459352a7faf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892076055-172.17.0.4-1595535928033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43109,DS-9ae8e03d-62ec-4830-b614-ce659cb57dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-b2df4597-11d0-4a23-a972-5a58ca5649da,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-d6c71526-d5ea-4dc6-b4c3-623076361037,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-64770500-7afe-49c1-8545-4d56343bec22,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-f7e2e400-3b8b-4ec0-99dc-ab4a44eec3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-bbca863a-d848-435c-b193-9ff52a0ecc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-375ce769-38c2-4e42-920d-8bcb06598a59,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-29176f02-e1f9-45af-bffa-459352a7faf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438187613-172.17.0.4-1595535959332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-eee72802-3e04-4f2a-8897-7b44943f0c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-8771386d-dab2-4e24-ba4b-8bdcb068e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-5527f2c8-0b3b-4764-b4f8-51c46c48beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-2c6eeb66-6ac0-4fc0-9a5b-41d7af19619d,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-a96643df-309a-4fca-8364-2e5341ee8a41,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-3535a556-66a2-4fc9-9321-07b8ca40142c,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-4fff3ea1-030e-4059-bde3-b1a297a9a58e,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-23422c8a-7645-4948-b14a-53eb0de1b93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438187613-172.17.0.4-1595535959332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-eee72802-3e04-4f2a-8897-7b44943f0c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-8771386d-dab2-4e24-ba4b-8bdcb068e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-5527f2c8-0b3b-4764-b4f8-51c46c48beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-2c6eeb66-6ac0-4fc0-9a5b-41d7af19619d,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-a96643df-309a-4fca-8364-2e5341ee8a41,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-3535a556-66a2-4fc9-9321-07b8ca40142c,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-4fff3ea1-030e-4059-bde3-b1a297a9a58e,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-23422c8a-7645-4948-b14a-53eb0de1b93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505740925-172.17.0.4-1595536171912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-2df521fd-cc1c-42f2-b2e4-c740e5cfee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-2ea89397-10bd-4d8c-9b4f-420d0be5d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-0b55d9b8-fa21-452c-bcd4-c8b15032c918,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-26c753e4-1f4f-40b8-9457-27a643125f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-99958656-af25-4e15-bd72-7d9e6d976155,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-b6849031-cad7-4377-bc51-8b8f4f44b04c,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-ee7336ef-f69a-4cbf-9482-50e1f246b460,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-96ba8725-2376-4bef-b816-94365165971d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505740925-172.17.0.4-1595536171912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-2df521fd-cc1c-42f2-b2e4-c740e5cfee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-2ea89397-10bd-4d8c-9b4f-420d0be5d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-0b55d9b8-fa21-452c-bcd4-c8b15032c918,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-26c753e4-1f4f-40b8-9457-27a643125f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-99958656-af25-4e15-bd72-7d9e6d976155,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-b6849031-cad7-4377-bc51-8b8f4f44b04c,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-ee7336ef-f69a-4cbf-9482-50e1f246b460,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-96ba8725-2376-4bef-b816-94365165971d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231596716-172.17.0.4-1595536515253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-4b7761f6-eea3-494b-9a16-32d59f0e09f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-4fd8b980-1c7c-4715-8465-4b0fa7c275ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-6265afe4-56be-4014-a826-098c2821398c,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-a4fcae0e-467e-4a0f-a88b-381ba32f844c,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-a5fae480-fcfc-479d-9b4a-55d44b274e70,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-388aa376-551f-44de-83ff-76dd1634734f,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-e5e842a3-7e38-4ff8-b22a-72d1c6e73518,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-9fa514ed-f05e-4d77-951f-e3b0b9d89666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231596716-172.17.0.4-1595536515253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-4b7761f6-eea3-494b-9a16-32d59f0e09f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-4fd8b980-1c7c-4715-8465-4b0fa7c275ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-6265afe4-56be-4014-a826-098c2821398c,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-a4fcae0e-467e-4a0f-a88b-381ba32f844c,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-a5fae480-fcfc-479d-9b4a-55d44b274e70,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-388aa376-551f-44de-83ff-76dd1634734f,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-e5e842a3-7e38-4ff8-b22a-72d1c6e73518,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-9fa514ed-f05e-4d77-951f-e3b0b9d89666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47193854-172.17.0.4-1595537364840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-a70c0feb-9dcb-4f16-9fc5-cd009e0417dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-541fed4d-5478-49a8-a258-cd28c23fe6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-2a598de9-d638-4688-b738-d6209441ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-72a51550-fc96-4e1e-8fcd-2daecbb6134b,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-78670af6-82fa-479b-8c2e-df043be866df,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-bf4065c7-6b6e-4b84-9b81-77b3454afb41,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-9ec978dd-95a7-4c93-911f-6280179fd5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-912fe105-bfac-4216-9c71-4e2440479dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47193854-172.17.0.4-1595537364840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46039,DS-a70c0feb-9dcb-4f16-9fc5-cd009e0417dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-541fed4d-5478-49a8-a258-cd28c23fe6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-2a598de9-d638-4688-b738-d6209441ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-72a51550-fc96-4e1e-8fcd-2daecbb6134b,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-78670af6-82fa-479b-8c2e-df043be866df,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-bf4065c7-6b6e-4b84-9b81-77b3454afb41,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-9ec978dd-95a7-4c93-911f-6280179fd5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-912fe105-bfac-4216-9c71-4e2440479dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019163842-172.17.0.4-1595537479032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-d65b3568-f86e-4a40-8d31-dd5e441a2fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-78734311-75ff-4347-a5e2-f88b308b6cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-d1ae4f33-4c3c-451d-9dd1-96cd061c0e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-515e552d-dc70-4774-a62a-ce083307b54d,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-05c2bc6c-bb96-4ae1-8911-1562d88befcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-dda03326-b334-4c0f-9b15-a1307e7c0061,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-32631ce0-8db7-4044-a250-8b4213ce52e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-22b6a95e-86a1-4ed7-aee9-98dcf6005431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019163842-172.17.0.4-1595537479032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-d65b3568-f86e-4a40-8d31-dd5e441a2fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-78734311-75ff-4347-a5e2-f88b308b6cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-d1ae4f33-4c3c-451d-9dd1-96cd061c0e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-515e552d-dc70-4774-a62a-ce083307b54d,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-05c2bc6c-bb96-4ae1-8911-1562d88befcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-dda03326-b334-4c0f-9b15-a1307e7c0061,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-32631ce0-8db7-4044-a250-8b4213ce52e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-22b6a95e-86a1-4ed7-aee9-98dcf6005431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050146232-172.17.0.4-1595537550063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-8402dd6a-5974-4c48-ad4f-c0337d2cc5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-0e5f0f30-2a4f-4267-aa8b-f10c1cd14efd,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-6e8488b8-e1cf-4dff-824d-18fc6beda9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-0e481205-d31d-4c53-8bf3-f19df54cbf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-a6c327eb-188f-4782-bfb5-99b01de04770,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-869d154a-250d-4347-b86a-3909d892bac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-2b69dc82-7633-4f48-b14f-6a74b3d359d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-328eb556-ba20-416f-bdff-86c2a038b20b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050146232-172.17.0.4-1595537550063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-8402dd6a-5974-4c48-ad4f-c0337d2cc5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-0e5f0f30-2a4f-4267-aa8b-f10c1cd14efd,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-6e8488b8-e1cf-4dff-824d-18fc6beda9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-0e481205-d31d-4c53-8bf3-f19df54cbf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-a6c327eb-188f-4782-bfb5-99b01de04770,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-869d154a-250d-4347-b86a-3909d892bac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-2b69dc82-7633-4f48-b14f-6a74b3d359d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-328eb556-ba20-416f-bdff-86c2a038b20b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725701462-172.17.0.4-1595538129098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-0428055c-9f4c-4ee6-a9e0-16c6a1e5ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-b5e794b1-c294-4ae4-ba5d-2db89d35652e,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-4811f604-68b5-4636-8c77-e4e98c059bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-b5191bf3-42a9-41ff-a593-30618b9b49a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-9ff547b4-14d9-4fa0-9267-e8b27624d1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-f26b17a9-e1cc-4439-9207-e29ec2a19d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-2cc78136-e176-4243-ac3f-6ff4e47c6cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-6c0490f8-a9c5-465b-9d41-d029c428f4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725701462-172.17.0.4-1595538129098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-0428055c-9f4c-4ee6-a9e0-16c6a1e5ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-b5e794b1-c294-4ae4-ba5d-2db89d35652e,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-4811f604-68b5-4636-8c77-e4e98c059bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-b5191bf3-42a9-41ff-a593-30618b9b49a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-9ff547b4-14d9-4fa0-9267-e8b27624d1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-f26b17a9-e1cc-4439-9207-e29ec2a19d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-2cc78136-e176-4243-ac3f-6ff4e47c6cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-6c0490f8-a9c5-465b-9d41-d029c428f4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113382917-172.17.0.4-1595538540710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-3a697542-cab8-49ee-b472-19439c6ea944,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-e3db6160-d03d-42a1-b6ef-3d7b6a5b5df3,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-199be3ef-7512-4a2d-8f9c-b663b16cea41,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-2f1c1b64-7c89-48c4-9dc8-54b1acf5a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-7371d0f3-81ea-4e81-9094-1427d170e013,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-25f299d8-2466-438f-9941-839e7d39fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-7acb9f73-f299-4808-a454-37296352fdba,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-df543401-331c-48b2-a47a-04b9f2719fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113382917-172.17.0.4-1595538540710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-3a697542-cab8-49ee-b472-19439c6ea944,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-e3db6160-d03d-42a1-b6ef-3d7b6a5b5df3,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-199be3ef-7512-4a2d-8f9c-b663b16cea41,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-2f1c1b64-7c89-48c4-9dc8-54b1acf5a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-7371d0f3-81ea-4e81-9094-1427d170e013,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-25f299d8-2466-438f-9941-839e7d39fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-7acb9f73-f299-4808-a454-37296352fdba,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-df543401-331c-48b2-a47a-04b9f2719fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785809685-172.17.0.4-1595538875614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-ea7a5e4d-d34e-4d94-83c0-32433300020d,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-bcb2ead9-406e-402f-bf22-0fb06294eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-643e6955-43a8-4998-a844-921d8ff43bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-745fa2c4-318a-407a-b4e9-46b5617ae024,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-694c597c-e720-45b4-8bb6-cf43b16bb9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-9334c3d7-55a7-42e5-b6c0-59bfbb71ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-ee07e30d-bf7c-4ea3-a1b7-abe5d68c3c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-030ca3af-0734-48a3-8524-92d0b11bff31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785809685-172.17.0.4-1595538875614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-ea7a5e4d-d34e-4d94-83c0-32433300020d,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-bcb2ead9-406e-402f-bf22-0fb06294eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-643e6955-43a8-4998-a844-921d8ff43bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-745fa2c4-318a-407a-b4e9-46b5617ae024,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-694c597c-e720-45b4-8bb6-cf43b16bb9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-9334c3d7-55a7-42e5-b6c0-59bfbb71ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-ee07e30d-bf7c-4ea3-a1b7-abe5d68c3c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-030ca3af-0734-48a3-8524-92d0b11bff31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582182904-172.17.0.4-1595539067914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36737,DS-ae015148-7552-4e60-a337-dfb751f05535,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-d6e7e811-dc60-40b7-be99-00189d67cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-17fbbada-fb1d-4b7e-968f-ebbc71c3aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-51c6fc45-9d64-49d5-abb7-f1d22f4b33c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-7d8b6cca-81a6-4a77-85d7-0bab5164a10a,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-8ee75a81-883e-4bc4-8e5d-2386d33efba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-9d4f6300-5d18-4d25-bfa7-0777e6314dec,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-3fc6a8d2-64d9-4852-9db7-3604f322b60d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582182904-172.17.0.4-1595539067914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36737,DS-ae015148-7552-4e60-a337-dfb751f05535,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-d6e7e811-dc60-40b7-be99-00189d67cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-17fbbada-fb1d-4b7e-968f-ebbc71c3aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-51c6fc45-9d64-49d5-abb7-f1d22f4b33c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-7d8b6cca-81a6-4a77-85d7-0bab5164a10a,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-8ee75a81-883e-4bc4-8e5d-2386d33efba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-9d4f6300-5d18-4d25-bfa7-0777e6314dec,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-3fc6a8d2-64d9-4852-9db7-3604f322b60d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533445646-172.17.0.4-1595539280055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46294,DS-bd99778f-d119-41c8-abe6-bd952800b5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-955178a7-5ed1-4660-9448-8a448c153775,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-2bb5af84-a4f1-45e6-92ab-26727708d1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-462ea3e7-8062-4038-bb01-729d0132b8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-e9a6bf11-046f-428e-87c7-a49114a8f5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-d3f319a3-cbcf-407a-a1e8-1bf7d2379f90,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-1a0671cb-805c-4779-8dbf-3e28c50e2bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-6ccc5463-6ad8-4a63-95bb-5126020249ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533445646-172.17.0.4-1595539280055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46294,DS-bd99778f-d119-41c8-abe6-bd952800b5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-955178a7-5ed1-4660-9448-8a448c153775,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-2bb5af84-a4f1-45e6-92ab-26727708d1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-462ea3e7-8062-4038-bb01-729d0132b8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-e9a6bf11-046f-428e-87c7-a49114a8f5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-d3f319a3-cbcf-407a-a1e8-1bf7d2379f90,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-1a0671cb-805c-4779-8dbf-3e28c50e2bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-6ccc5463-6ad8-4a63-95bb-5126020249ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5150
