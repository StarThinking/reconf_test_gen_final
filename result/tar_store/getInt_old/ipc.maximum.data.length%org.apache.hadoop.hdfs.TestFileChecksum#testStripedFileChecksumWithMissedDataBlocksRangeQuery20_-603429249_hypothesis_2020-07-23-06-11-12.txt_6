reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798893529-172.17.0.5-1595485463912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34558,DS-d1f0397b-8d4d-4c01-b1f3-be04e78ba3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-ea5a54be-0fe9-4a51-82e2-c8f95cb48074,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-052d8d86-242e-4f9c-ad2c-d67dbf13bf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-356ad42f-ee1c-43d8-acd6-3c2581e8fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-601708d3-3dca-4945-8331-0ded86ffa026,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-5ea16a4c-1adf-4b99-9837-58b844dcec70,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-e3a68bf6-b294-4598-a4ae-9608c7e25a32,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-ad45d28d-4fe4-4122-a219-4b5a63cac14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798893529-172.17.0.5-1595485463912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34558,DS-d1f0397b-8d4d-4c01-b1f3-be04e78ba3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-ea5a54be-0fe9-4a51-82e2-c8f95cb48074,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-052d8d86-242e-4f9c-ad2c-d67dbf13bf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-356ad42f-ee1c-43d8-acd6-3c2581e8fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-601708d3-3dca-4945-8331-0ded86ffa026,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-5ea16a4c-1adf-4b99-9837-58b844dcec70,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-e3a68bf6-b294-4598-a4ae-9608c7e25a32,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-ad45d28d-4fe4-4122-a219-4b5a63cac14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090382088-172.17.0.5-1595485799590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-b3962f89-d5ae-4f9c-b215-a64b86593cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-10b274e4-a0a4-4ef0-94be-951113c7727c,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-100c0b70-e532-458b-88f9-5fea2ab908e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-461876c3-9e48-4965-a994-02fa8ddff03a,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-37b66dc4-801e-48db-80cc-07cf7fb84f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-29b38307-f086-41a3-a168-b1a272ea0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-40c19c7d-1235-42d3-9557-53eeff06303f,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-d5bc6902-f9f4-4bad-9fa8-2e9e56a16046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090382088-172.17.0.5-1595485799590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-b3962f89-d5ae-4f9c-b215-a64b86593cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-10b274e4-a0a4-4ef0-94be-951113c7727c,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-100c0b70-e532-458b-88f9-5fea2ab908e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-461876c3-9e48-4965-a994-02fa8ddff03a,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-37b66dc4-801e-48db-80cc-07cf7fb84f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-29b38307-f086-41a3-a168-b1a272ea0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-40c19c7d-1235-42d3-9557-53eeff06303f,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-d5bc6902-f9f4-4bad-9fa8-2e9e56a16046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199469580-172.17.0.5-1595486487624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-d9f72399-68cc-45b1-9948-3e9224b14974,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-afedb8b7-f029-42cf-b020-7566f29a7775,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-0d4060ad-1a86-4b59-a6f1-043d866d33ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-1ad8b3be-3697-427a-a544-70e40758a97c,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-49c23845-7519-44ac-9f3c-875ae3fa05ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-21c36318-2897-4a4d-97f2-d14a72a67df7,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-b93ca1ed-c0ec-45aa-9385-a5dc90843afe,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-cba7eb4b-2f9c-4243-ab99-8ebed4194cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199469580-172.17.0.5-1595486487624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-d9f72399-68cc-45b1-9948-3e9224b14974,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-afedb8b7-f029-42cf-b020-7566f29a7775,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-0d4060ad-1a86-4b59-a6f1-043d866d33ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-1ad8b3be-3697-427a-a544-70e40758a97c,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-49c23845-7519-44ac-9f3c-875ae3fa05ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-21c36318-2897-4a4d-97f2-d14a72a67df7,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-b93ca1ed-c0ec-45aa-9385-a5dc90843afe,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-cba7eb4b-2f9c-4243-ab99-8ebed4194cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185762957-172.17.0.5-1595486560027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41084,DS-8d0ded9f-a248-4217-b476-d5dc83edc143,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-80fffbe6-1b21-44f7-ba9b-b8d8f7d25e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-6ba20488-5297-43ce-9896-07a5b7da1654,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-d354185c-7b0e-4c16-9426-009ec26848af,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-82f3dbee-289b-410a-a806-f67f4eb3004f,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-e38bed3d-6d51-431f-b4be-33dc2fae0ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-085057df-16c2-4e14-90db-5a95856adbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-b6d7676c-3da6-4a2e-af79-a592b54eab66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185762957-172.17.0.5-1595486560027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41084,DS-8d0ded9f-a248-4217-b476-d5dc83edc143,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-80fffbe6-1b21-44f7-ba9b-b8d8f7d25e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-6ba20488-5297-43ce-9896-07a5b7da1654,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-d354185c-7b0e-4c16-9426-009ec26848af,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-82f3dbee-289b-410a-a806-f67f4eb3004f,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-e38bed3d-6d51-431f-b4be-33dc2fae0ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-085057df-16c2-4e14-90db-5a95856adbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-b6d7676c-3da6-4a2e-af79-a592b54eab66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945982958-172.17.0.5-1595487563862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-5e1e007c-c91d-453b-b067-3b8e2ea09999,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-a06d4d55-7312-4867-be3d-664e3c6ad05d,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-b6dfaeeb-21b2-4051-b814-3134a5507327,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-7be9361a-3556-4613-b912-44302ecffe25,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-06a057c4-160e-451d-95eb-9a030f15bde9,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-d55b845f-a58b-4bcf-91d4-d0eabccf4cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-b37c882f-dc12-4c01-ad98-e62c602a86a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-d2880c13-4482-4b68-90cd-b23c84f78e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945982958-172.17.0.5-1595487563862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-5e1e007c-c91d-453b-b067-3b8e2ea09999,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-a06d4d55-7312-4867-be3d-664e3c6ad05d,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-b6dfaeeb-21b2-4051-b814-3134a5507327,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-7be9361a-3556-4613-b912-44302ecffe25,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-06a057c4-160e-451d-95eb-9a030f15bde9,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-d55b845f-a58b-4bcf-91d4-d0eabccf4cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-b37c882f-dc12-4c01-ad98-e62c602a86a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-d2880c13-4482-4b68-90cd-b23c84f78e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266858017-172.17.0.5-1595488140669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-a7274421-1198-40eb-94ec-1f9a35c773ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-83fcdc19-0526-4cf8-9dd2-ee7a395a89eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-e3084836-0a07-4cb7-bad6-233ece4f64e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-a911508e-b609-4106-bed9-9bd8542927bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-8f1f82d2-730a-4cd0-a468-49de6b109ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-aed0b9c5-8445-4f61-b0b3-7b3eb0dc0351,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-db90ecff-fc55-4eaa-a9c7-9c130e7ebad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-60d340a5-e2a1-4628-8492-5526a8b115d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266858017-172.17.0.5-1595488140669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-a7274421-1198-40eb-94ec-1f9a35c773ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-83fcdc19-0526-4cf8-9dd2-ee7a395a89eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-e3084836-0a07-4cb7-bad6-233ece4f64e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-a911508e-b609-4106-bed9-9bd8542927bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-8f1f82d2-730a-4cd0-a468-49de6b109ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-aed0b9c5-8445-4f61-b0b3-7b3eb0dc0351,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-db90ecff-fc55-4eaa-a9c7-9c130e7ebad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-60d340a5-e2a1-4628-8492-5526a8b115d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172612536-172.17.0.5-1595488313670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-bd05333b-3139-4227-928f-83f53d07769b,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-a9fe870c-cdc5-41f7-bae0-bfa391a90323,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-411dacec-d65a-4b78-9292-b792a018e331,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-0d102b4a-e45b-4d21-8ae3-37cad644eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-e3b7d032-f2f6-4e80-a1b4-67e2ec114213,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-7f45e12a-f195-44c3-914e-5727c2f533cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-bd9a6855-f809-4d70-9e41-f5163ead44f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-243dbe8d-9c44-45cb-a469-575b1b68cc4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172612536-172.17.0.5-1595488313670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-bd05333b-3139-4227-928f-83f53d07769b,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-a9fe870c-cdc5-41f7-bae0-bfa391a90323,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-411dacec-d65a-4b78-9292-b792a018e331,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-0d102b4a-e45b-4d21-8ae3-37cad644eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-e3b7d032-f2f6-4e80-a1b4-67e2ec114213,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-7f45e12a-f195-44c3-914e-5727c2f533cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-bd9a6855-f809-4d70-9e41-f5163ead44f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-243dbe8d-9c44-45cb-a469-575b1b68cc4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588965378-172.17.0.5-1595488381937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34068,DS-98ef73d7-3b2d-424e-a315-6f351615cd23,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-eddb2108-3ef1-4b90-8c83-d96d19c9d87d,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-6e888033-9409-48d5-b4bf-68a54a1cf5da,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-e525b9bc-1ec2-4017-8dd6-75711cef5a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-986adcd9-20f2-4e83-945f-83827371a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-ee3eff4a-b4e4-47f1-b49a-3cde6760b001,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-769255c9-748d-4cd9-b282-cf9f764f9fca,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-86d025d3-2a35-456e-b51a-a223bec23416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588965378-172.17.0.5-1595488381937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34068,DS-98ef73d7-3b2d-424e-a315-6f351615cd23,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-eddb2108-3ef1-4b90-8c83-d96d19c9d87d,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-6e888033-9409-48d5-b4bf-68a54a1cf5da,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-e525b9bc-1ec2-4017-8dd6-75711cef5a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-986adcd9-20f2-4e83-945f-83827371a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-ee3eff4a-b4e4-47f1-b49a-3cde6760b001,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-769255c9-748d-4cd9-b282-cf9f764f9fca,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-86d025d3-2a35-456e-b51a-a223bec23416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662586389-172.17.0.5-1595488494054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-71c0eb91-6a84-4119-8b9e-abe09b876716,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-2278488e-dbd9-4f8b-9f1a-a2252b9f0107,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-c6a8ae04-81f0-4751-b398-4f90e0077c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-cc5b7d32-3aa3-40c7-9b06-6d8102ff3969,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-c99d2698-1806-4bd1-a8d6-7de8c4062147,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-5a554964-5ee2-4622-b5c8-278cc6c585db,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-57ed3d2d-9a43-45cf-afe7-71267e96ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-23043bbf-497f-4774-95be-64034e170e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662586389-172.17.0.5-1595488494054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-71c0eb91-6a84-4119-8b9e-abe09b876716,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-2278488e-dbd9-4f8b-9f1a-a2252b9f0107,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-c6a8ae04-81f0-4751-b398-4f90e0077c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-cc5b7d32-3aa3-40c7-9b06-6d8102ff3969,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-c99d2698-1806-4bd1-a8d6-7de8c4062147,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-5a554964-5ee2-4622-b5c8-278cc6c585db,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-57ed3d2d-9a43-45cf-afe7-71267e96ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-23043bbf-497f-4774-95be-64034e170e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785978365-172.17.0.5-1595488575277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44995,DS-130d2fe0-b34b-4edc-ace4-c1cce4ef1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b0c28b5c-8935-449f-9cae-5b63bc356c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-16977b5f-c1cf-421b-853c-2dad48dc2c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-9b1073ce-938f-4718-b5ee-44d3ffcd74bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-15e11e60-5a9e-4c98-b32c-4ea98783bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-31515786-7465-4acc-a69a-55faf436f00a,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-9a17c975-542b-47ae-a9fb-24054b02e878,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-2ccf2448-ebe6-4f97-a907-3246fbe39819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785978365-172.17.0.5-1595488575277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44995,DS-130d2fe0-b34b-4edc-ace4-c1cce4ef1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b0c28b5c-8935-449f-9cae-5b63bc356c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-16977b5f-c1cf-421b-853c-2dad48dc2c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-9b1073ce-938f-4718-b5ee-44d3ffcd74bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-15e11e60-5a9e-4c98-b32c-4ea98783bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-31515786-7465-4acc-a69a-55faf436f00a,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-9a17c975-542b-47ae-a9fb-24054b02e878,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-2ccf2448-ebe6-4f97-a907-3246fbe39819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921392862-172.17.0.5-1595489159577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43170,DS-4cf3e300-032b-4b53-a65f-f79d0bdf9f82,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-baad0881-e0c5-45bc-b35b-fa571e38f1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-1eb31c61-8db2-4e59-9cca-d08760aa21c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-de5c017c-d969-4fe5-a2c6-85edb0366485,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-b66084b2-7e10-4e83-bf10-c76ea8e1f31a,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-5cfd361e-27aa-48e2-819e-30af6d8bcd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-41148d5d-6e89-452a-8ae3-cd1e465b0143,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-65ef6a26-2a83-4593-b687-c463e026f68a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921392862-172.17.0.5-1595489159577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43170,DS-4cf3e300-032b-4b53-a65f-f79d0bdf9f82,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-baad0881-e0c5-45bc-b35b-fa571e38f1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-1eb31c61-8db2-4e59-9cca-d08760aa21c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-de5c017c-d969-4fe5-a2c6-85edb0366485,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-b66084b2-7e10-4e83-bf10-c76ea8e1f31a,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-5cfd361e-27aa-48e2-819e-30af6d8bcd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-41148d5d-6e89-452a-8ae3-cd1e465b0143,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-65ef6a26-2a83-4593-b687-c463e026f68a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696666399-172.17.0.5-1595489381481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35775,DS-d42c2bdd-23b8-40ea-857d-7ef23c64921d,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-78341168-d9ee-4ebe-bcda-0ddd89bb3e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-77156c98-4a10-4b1d-91e3-66fe073e4bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-fecdb81c-e82e-4201-8550-fbcec624804a,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-3eec705a-4e40-44ad-aa52-30158b8c9831,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-8509a132-e2d8-4d13-b142-6bc9da905379,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-bf979e2e-7130-47ed-b398-b68ed2997f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-13fd2e0b-8302-427f-b742-0c0c9e77a431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696666399-172.17.0.5-1595489381481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35775,DS-d42c2bdd-23b8-40ea-857d-7ef23c64921d,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-78341168-d9ee-4ebe-bcda-0ddd89bb3e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-77156c98-4a10-4b1d-91e3-66fe073e4bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-fecdb81c-e82e-4201-8550-fbcec624804a,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-3eec705a-4e40-44ad-aa52-30158b8c9831,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-8509a132-e2d8-4d13-b142-6bc9da905379,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-bf979e2e-7130-47ed-b398-b68ed2997f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-13fd2e0b-8302-427f-b742-0c0c9e77a431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579758909-172.17.0.5-1595489419981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-8fecdac1-3b8f-460d-8b53-8dfe536e316f,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-c87dea85-0deb-40b0-a119-3ef45ba929ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-5571f7e4-cb4a-4293-abc0-cd3f74769966,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-adbe3052-c4d3-4985-868c-5866cb88148e,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-c0484fdd-641d-4d30-b0d2-b946464582ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-e6c8bbbc-2982-4e86-99cb-364b308217ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-13d43a72-5b9d-4c6f-8f69-73661ac37dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-9343c4c9-c3f8-40e8-8336-a802b38f0fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579758909-172.17.0.5-1595489419981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-8fecdac1-3b8f-460d-8b53-8dfe536e316f,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-c87dea85-0deb-40b0-a119-3ef45ba929ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-5571f7e4-cb4a-4293-abc0-cd3f74769966,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-adbe3052-c4d3-4985-868c-5866cb88148e,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-c0484fdd-641d-4d30-b0d2-b946464582ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-e6c8bbbc-2982-4e86-99cb-364b308217ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-13d43a72-5b9d-4c6f-8f69-73661ac37dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-9343c4c9-c3f8-40e8-8336-a802b38f0fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262312544-172.17.0.5-1595489564768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-6a2fa6e7-b73b-4ea6-9511-10e83c09b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-00f19f61-47ee-427c-92f3-a920f17b8f61,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-85cc1adf-3a59-40e9-80f0-889e69544d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-a9480ae7-1fea-4868-9ddd-c217eada6820,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-d5c74938-b614-43df-bb8c-9d94ba7d6b91,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-d21a43ab-f5e6-48f5-9f35-d653fd335533,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-2565637b-cf7c-43e6-a89b-62b8bb1afaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-0952670b-9899-4807-a80d-68ebaa6e5351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262312544-172.17.0.5-1595489564768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-6a2fa6e7-b73b-4ea6-9511-10e83c09b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-00f19f61-47ee-427c-92f3-a920f17b8f61,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-85cc1adf-3a59-40e9-80f0-889e69544d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-a9480ae7-1fea-4868-9ddd-c217eada6820,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-d5c74938-b614-43df-bb8c-9d94ba7d6b91,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-d21a43ab-f5e6-48f5-9f35-d653fd335533,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-2565637b-cf7c-43e6-a89b-62b8bb1afaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-0952670b-9899-4807-a80d-68ebaa6e5351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5354
