reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781502101-172.17.0.11-1595689748297:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38397,DS-c9dba9b9-7f60-4f19-8851-d232798c3a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-3c127bdf-f26e-410f-8fdd-1ca3a7464589,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-efe81dc9-f03c-46d8-8303-6cb0fd6700f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-1a97e2fd-681e-4288-8ce9-4b1167308deb,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-fa1f5481-dc28-48a7-8ad7-708cd0424aee,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-80a7653b-7698-4491-ba90-e1bfbe503125,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-818aa467-05a9-4497-8583-8ddbc079ded9,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-8ef8fb1c-4eda-4c89-a41f-919c5babddf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781502101-172.17.0.11-1595689748297:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38397,DS-c9dba9b9-7f60-4f19-8851-d232798c3a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-3c127bdf-f26e-410f-8fdd-1ca3a7464589,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-efe81dc9-f03c-46d8-8303-6cb0fd6700f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-1a97e2fd-681e-4288-8ce9-4b1167308deb,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-fa1f5481-dc28-48a7-8ad7-708cd0424aee,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-80a7653b-7698-4491-ba90-e1bfbe503125,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-818aa467-05a9-4497-8583-8ddbc079ded9,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-8ef8fb1c-4eda-4c89-a41f-919c5babddf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941339349-172.17.0.11-1595690084755:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35423,DS-100cdcdf-c411-4858-9717-b7ce13256ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-7884f995-988f-4ab1-880d-3e4bb3428a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-c7dfdfd1-58b7-4f30-a243-77a7f56bac70,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-0818947d-a027-43c0-9cf3-6bc7037d3e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-d5a99804-db1c-443a-b68f-861c8d5aa4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-0cba0e49-7b7d-4e17-9524-c90aa1db15ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-5fc9a779-6041-4a93-bdde-9e6e94b6a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-c6ecbcd1-1698-4e8f-b1e8-a322218d5c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941339349-172.17.0.11-1595690084755:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35423,DS-100cdcdf-c411-4858-9717-b7ce13256ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-7884f995-988f-4ab1-880d-3e4bb3428a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-c7dfdfd1-58b7-4f30-a243-77a7f56bac70,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-0818947d-a027-43c0-9cf3-6bc7037d3e20,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-d5a99804-db1c-443a-b68f-861c8d5aa4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-0cba0e49-7b7d-4e17-9524-c90aa1db15ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-5fc9a779-6041-4a93-bdde-9e6e94b6a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-c6ecbcd1-1698-4e8f-b1e8-a322218d5c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245590880-172.17.0.11-1595690148497:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42010,DS-04489895-9e40-4d9b-a8e4-54c5681a7b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-0afcc540-2f06-44ec-b770-0e4bb7811b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-98669430-ddb8-4eae-b90a-49ee3c263d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-ea4b77a9-99d2-443d-b1a3-d5ce58e1d78e,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-6c0b9a22-8039-4982-9980-75e746e96338,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-bf947538-2b89-4474-a40c-dfe6ed5aff78,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-b63f6449-3cd7-46d1-bfc7-e6ec7e909ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-208afa1d-4a35-4b3e-b9e0-5a0e1caa3726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245590880-172.17.0.11-1595690148497:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42010,DS-04489895-9e40-4d9b-a8e4-54c5681a7b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-0afcc540-2f06-44ec-b770-0e4bb7811b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-98669430-ddb8-4eae-b90a-49ee3c263d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-ea4b77a9-99d2-443d-b1a3-d5ce58e1d78e,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-6c0b9a22-8039-4982-9980-75e746e96338,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-bf947538-2b89-4474-a40c-dfe6ed5aff78,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-b63f6449-3cd7-46d1-bfc7-e6ec7e909ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-208afa1d-4a35-4b3e-b9e0-5a0e1caa3726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102315228-172.17.0.11-1595691124673:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36228,DS-a67a2dea-6e8a-4b5e-b8f4-0cae3d8144fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-c578d979-ab47-41f6-9af4-415150ef8c99,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-aced3bb6-d162-472e-9f0e-0a66a5b40237,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-7a9f243d-31f5-4600-ad82-9e1e42438b01,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-dbbddbaa-472c-4af0-b799-407a483c614f,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-c83dba16-ee63-4735-aa09-d90f29ec87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-01fb3d27-0709-4214-86e3-98007c7c1977,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-c3439bf9-1d43-4d82-afc6-9071007793f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102315228-172.17.0.11-1595691124673:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36228,DS-a67a2dea-6e8a-4b5e-b8f4-0cae3d8144fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-c578d979-ab47-41f6-9af4-415150ef8c99,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-aced3bb6-d162-472e-9f0e-0a66a5b40237,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-7a9f243d-31f5-4600-ad82-9e1e42438b01,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-dbbddbaa-472c-4af0-b799-407a483c614f,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-c83dba16-ee63-4735-aa09-d90f29ec87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-01fb3d27-0709-4214-86e3-98007c7c1977,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-c3439bf9-1d43-4d82-afc6-9071007793f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739030140-172.17.0.11-1595691635944:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-af32dcab-1189-4e2b-af16-b0d92b9f3b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-d058e185-9a79-4906-b10f-1d0321fe1bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-24ce9ce8-f420-4fcc-988a-bb76af0b35a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-74936091-baf1-464c-b9c8-1e5d86cbe631,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-798a0356-70f7-452f-b456-c5cedd9ba18b,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-29398881-f1b3-4a08-b6f1-07ce281b2b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-9a228b28-d8cb-4196-ac95-63522def3e76,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-8775b5ac-8d9f-4825-a7f5-b4e4f09c89f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739030140-172.17.0.11-1595691635944:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-af32dcab-1189-4e2b-af16-b0d92b9f3b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-d058e185-9a79-4906-b10f-1d0321fe1bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-24ce9ce8-f420-4fcc-988a-bb76af0b35a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-74936091-baf1-464c-b9c8-1e5d86cbe631,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-798a0356-70f7-452f-b456-c5cedd9ba18b,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-29398881-f1b3-4a08-b6f1-07ce281b2b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-9a228b28-d8cb-4196-ac95-63522def3e76,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-8775b5ac-8d9f-4825-a7f5-b4e4f09c89f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532861412-172.17.0.11-1595691756651:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-c6c3e58b-27ed-47b6-82b8-64d8f826cb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-a0e1ebd9-2d29-4b79-8c80-9904fe3f85e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-61592655-5ec5-4f79-b72e-8195c8912edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-a4cae45b-eb83-43aa-9348-710634d7eff7,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-325cb726-0981-45bd-8e44-48fc293477a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-13d63da3-45b2-4542-80be-49af19122b54,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-06bbfbff-0df4-4fca-a166-5b55d8cde58a,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-e9502709-fc62-4f8a-bf07-727bf0f22f76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532861412-172.17.0.11-1595691756651:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-c6c3e58b-27ed-47b6-82b8-64d8f826cb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-a0e1ebd9-2d29-4b79-8c80-9904fe3f85e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-61592655-5ec5-4f79-b72e-8195c8912edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-a4cae45b-eb83-43aa-9348-710634d7eff7,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-325cb726-0981-45bd-8e44-48fc293477a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-13d63da3-45b2-4542-80be-49af19122b54,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-06bbfbff-0df4-4fca-a166-5b55d8cde58a,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-e9502709-fc62-4f8a-bf07-727bf0f22f76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527561671-172.17.0.11-1595691822382:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-1515a57f-f1b2-432b-a536-e4dc657b67b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-f40697fe-06c2-41f5-8bc8-a7c744eede6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-401c3b5f-d2e6-4ee1-878f-569c080bb895,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-03479f14-89cc-4925-852a-c8ea83874a39,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-6851a7b5-cd2f-4a84-ad7c-4ed25ccff727,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-3ccc8854-e124-4558-bb61-d168bf2858ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-d842c854-f5d3-4be6-b59d-15701df8543a,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-2a021899-8940-4b01-adf0-8d84fded61c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527561671-172.17.0.11-1595691822382:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-1515a57f-f1b2-432b-a536-e4dc657b67b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-f40697fe-06c2-41f5-8bc8-a7c744eede6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-401c3b5f-d2e6-4ee1-878f-569c080bb895,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-03479f14-89cc-4925-852a-c8ea83874a39,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-6851a7b5-cd2f-4a84-ad7c-4ed25ccff727,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-3ccc8854-e124-4558-bb61-d168bf2858ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-d842c854-f5d3-4be6-b59d-15701df8543a,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-2a021899-8940-4b01-adf0-8d84fded61c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512123277-172.17.0.11-1595692007253:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-919f32a7-e82f-463d-9126-501cbb86c877,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-22dbdd93-e263-4582-ba0c-ea5d06eaabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-a8357923-210b-41aa-a7d1-73ac3f5344f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-f8b68db6-084d-404f-bd3a-3cfdc8d20847,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-b1e859da-fa55-4609-b6ad-c2a9560393b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-46b1f37b-72ce-4622-a6cb-2e74f465bd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-df168ac0-8bc6-467b-a04c-a89aa5b99ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-ada5aa72-68d2-497e-83b4-bdf7d1ef4f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512123277-172.17.0.11-1595692007253:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-919f32a7-e82f-463d-9126-501cbb86c877,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-22dbdd93-e263-4582-ba0c-ea5d06eaabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-a8357923-210b-41aa-a7d1-73ac3f5344f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-f8b68db6-084d-404f-bd3a-3cfdc8d20847,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-b1e859da-fa55-4609-b6ad-c2a9560393b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-46b1f37b-72ce-4622-a6cb-2e74f465bd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-df168ac0-8bc6-467b-a04c-a89aa5b99ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-ada5aa72-68d2-497e-83b4-bdf7d1ef4f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1296324166-172.17.0.11-1595692261203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43146,DS-a85d6a90-9a29-425b-951d-0546b2f0791d,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-c522d718-37ad-49c9-84d2-03204294ab6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-18a9d886-677b-409d-b3dd-74f163dd1d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-dd9b0b0e-ea38-4887-81c3-21d026092cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-1d29ce77-ad05-4223-804d-9b91f1af51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-8e0a52fc-5fc1-4649-9e7a-9d5a04cd868c,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-08389bb1-5ecb-4d83-b3b3-2630b9ef9b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-bdebd924-2f5d-44b8-9340-35a357008f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1296324166-172.17.0.11-1595692261203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43146,DS-a85d6a90-9a29-425b-951d-0546b2f0791d,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-c522d718-37ad-49c9-84d2-03204294ab6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-18a9d886-677b-409d-b3dd-74f163dd1d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-dd9b0b0e-ea38-4887-81c3-21d026092cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-1d29ce77-ad05-4223-804d-9b91f1af51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-8e0a52fc-5fc1-4649-9e7a-9d5a04cd868c,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-08389bb1-5ecb-4d83-b3b3-2630b9ef9b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-bdebd924-2f5d-44b8-9340-35a357008f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827221988-172.17.0.11-1595692427963:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34641,DS-67eb6baf-585e-4497-8f8f-e75b44f7f322,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-eca7ad8f-8598-42cf-b434-55b0d640704f,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-4d4a1836-81ae-4991-87b0-726676d17143,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-607c6ae5-4277-431b-94b0-06d6c6241b08,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-54f20ef5-cdfc-4ac1-8ad0-2d84df176b65,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-cf911591-fc86-4b31-a0ab-d90756aefc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-a812ec57-9754-4b28-862b-4938aa3bfeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-56cb25a5-1108-4288-9e20-a0be6f9a1bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827221988-172.17.0.11-1595692427963:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34641,DS-67eb6baf-585e-4497-8f8f-e75b44f7f322,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-eca7ad8f-8598-42cf-b434-55b0d640704f,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-4d4a1836-81ae-4991-87b0-726676d17143,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-607c6ae5-4277-431b-94b0-06d6c6241b08,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-54f20ef5-cdfc-4ac1-8ad0-2d84df176b65,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-cf911591-fc86-4b31-a0ab-d90756aefc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-a812ec57-9754-4b28-862b-4938aa3bfeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-56cb25a5-1108-4288-9e20-a0be6f9a1bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475953117-172.17.0.11-1595692964862:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39270,DS-fd6f43a2-d1ed-4bf6-a1c5-79f9c55e6b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-ec70897c-8d6f-4308-bc69-9824b8f68d21,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-f96e896a-329c-48e2-bd50-7fa76f76bd92,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-7e1d4800-c4ce-4ddd-bd11-611b461d1d34,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-ada39611-ad29-4b1b-b682-8b59442dacc7,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-6b43d96a-57be-4224-bcc9-afdeebec39be,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-fb792a52-c836-4373-89bd-24f7b620b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-0c8804ea-5946-4353-b4b5-a751969d4141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475953117-172.17.0.11-1595692964862:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39270,DS-fd6f43a2-d1ed-4bf6-a1c5-79f9c55e6b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-ec70897c-8d6f-4308-bc69-9824b8f68d21,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-f96e896a-329c-48e2-bd50-7fa76f76bd92,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-7e1d4800-c4ce-4ddd-bd11-611b461d1d34,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-ada39611-ad29-4b1b-b682-8b59442dacc7,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-6b43d96a-57be-4224-bcc9-afdeebec39be,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-fb792a52-c836-4373-89bd-24f7b620b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-0c8804ea-5946-4353-b4b5-a751969d4141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469887555-172.17.0.11-1595693113940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33723,DS-e7a28835-1753-480e-ad5e-25091d54da12,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-b6b31306-24fb-444d-b4d4-d45029d739ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-8ee6d003-1f94-437a-987d-9b9bcd4530b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-4500e83f-3600-44e5-b41e-9ef9fd9e5497,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-2979236b-c71b-41f6-bd7d-17d53444bdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-aba47bbd-27d2-4c84-95e5-69f7ffce98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-de60b368-b651-4f31-baea-9f3922092ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-9ca1b819-7acc-46fa-8839-b88aac552758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469887555-172.17.0.11-1595693113940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33723,DS-e7a28835-1753-480e-ad5e-25091d54da12,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-b6b31306-24fb-444d-b4d4-d45029d739ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-8ee6d003-1f94-437a-987d-9b9bcd4530b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-4500e83f-3600-44e5-b41e-9ef9fd9e5497,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-2979236b-c71b-41f6-bd7d-17d53444bdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-aba47bbd-27d2-4c84-95e5-69f7ffce98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-de60b368-b651-4f31-baea-9f3922092ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-9ca1b819-7acc-46fa-8839-b88aac552758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958849542-172.17.0.11-1595693560066:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-28630367-1e75-4094-8002-8f06fd922720,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-03892f6f-4d20-4b74-9f33-d5a58c0439a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-ac72f584-ff47-4b97-a316-8888da6cef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-6e271515-7014-4bf8-b8c7-c7d06f04ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-b75ebfad-33f4-40ff-9715-1918a09dfb78,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-0b2d4795-be68-4555-bc52-32013a394cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-920f317a-173b-434c-9cc8-887ddb618509,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-26b166d0-96c5-48a6-810f-782f5d2c5e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958849542-172.17.0.11-1595693560066:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-28630367-1e75-4094-8002-8f06fd922720,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-03892f6f-4d20-4b74-9f33-d5a58c0439a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-ac72f584-ff47-4b97-a316-8888da6cef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-6e271515-7014-4bf8-b8c7-c7d06f04ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-b75ebfad-33f4-40ff-9715-1918a09dfb78,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-0b2d4795-be68-4555-bc52-32013a394cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-920f317a-173b-434c-9cc8-887ddb618509,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-26b166d0-96c5-48a6-810f-782f5d2c5e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428350264-172.17.0.11-1595694276600:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-421d7544-2d7f-4f82-85b2-21dac28a1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-a08ca248-038b-4550-8657-430b18ba920b,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-7445ef52-a877-41fe-972c-72f0c84f8e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-b1072d3c-a798-4ac4-82c8-53b6168d9943,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-197a9a4f-8eb4-4885-9a47-6a02d251cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-6e5d13db-55f8-4727-9785-906fa67f25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-3b24e0df-27c3-4cc8-aea5-fdfd86f4e959,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-497a89ed-cc9c-4972-bbf2-fbb3aa0de686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428350264-172.17.0.11-1595694276600:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-421d7544-2d7f-4f82-85b2-21dac28a1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-a08ca248-038b-4550-8657-430b18ba920b,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-7445ef52-a877-41fe-972c-72f0c84f8e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-b1072d3c-a798-4ac4-82c8-53b6168d9943,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-197a9a4f-8eb4-4885-9a47-6a02d251cba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-6e5d13db-55f8-4727-9785-906fa67f25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-3b24e0df-27c3-4cc8-aea5-fdfd86f4e959,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-497a89ed-cc9c-4972-bbf2-fbb3aa0de686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4794
