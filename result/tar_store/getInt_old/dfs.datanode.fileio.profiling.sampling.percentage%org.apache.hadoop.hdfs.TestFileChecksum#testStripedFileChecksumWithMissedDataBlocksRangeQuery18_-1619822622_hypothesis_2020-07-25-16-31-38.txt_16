reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305375753-172.17.0.15-1595694750466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-3ed6778b-9da2-490e-92c0-b9749e1b4e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-d56b6c34-b654-4f99-b0c3-045b081c0805,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-506ac38e-c6e7-4556-b6f1-99c83c848ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-49e3bc98-6c7f-42e7-8f66-52020a6fb0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-32cf67fe-af19-4fb2-9555-23cc1c9a3635,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-92650c05-da17-43e5-b053-e1f39579c972,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-963f7894-3c02-4680-8a7f-9bc1b9945a54,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-0e9c31b9-c0fd-4f7a-8a51-4ac2cd11f0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305375753-172.17.0.15-1595694750466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-3ed6778b-9da2-490e-92c0-b9749e1b4e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-d56b6c34-b654-4f99-b0c3-045b081c0805,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-506ac38e-c6e7-4556-b6f1-99c83c848ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-49e3bc98-6c7f-42e7-8f66-52020a6fb0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-32cf67fe-af19-4fb2-9555-23cc1c9a3635,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-92650c05-da17-43e5-b053-e1f39579c972,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-963f7894-3c02-4680-8a7f-9bc1b9945a54,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-0e9c31b9-c0fd-4f7a-8a51-4ac2cd11f0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748542246-172.17.0.15-1595694789980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-b639b4bc-7a66-4844-bf99-a11b4f00233c,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-182b3bde-edfe-4303-8843-84f308cc57a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-d42ae4dd-8254-46f9-859f-7252f7e916ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-cae6a67b-61d9-442a-a341-9e631f35fa7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-a38fd072-af50-4b6a-be6e-a35e86a559c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-737ed709-6cca-495d-a4cf-94119c1298e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-84ef320c-c483-4f34-bae3-b1fa4ae55e32,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-a694e224-9d01-4b1e-8925-085d1ea3591f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748542246-172.17.0.15-1595694789980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-b639b4bc-7a66-4844-bf99-a11b4f00233c,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-182b3bde-edfe-4303-8843-84f308cc57a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-d42ae4dd-8254-46f9-859f-7252f7e916ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-cae6a67b-61d9-442a-a341-9e631f35fa7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-a38fd072-af50-4b6a-be6e-a35e86a559c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-737ed709-6cca-495d-a4cf-94119c1298e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-84ef320c-c483-4f34-bae3-b1fa4ae55e32,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-a694e224-9d01-4b1e-8925-085d1ea3591f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796662380-172.17.0.15-1595694969272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35820,DS-172ca600-e553-4cf5-94f0-d4254ef27151,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-05ac531d-1f2c-419f-84f4-9ba1196cf76b,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-9df20b28-79af-449f-93b8-466126112784,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-57ea1faf-a726-42ca-bf8f-fdcd6cc409ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-3900d074-659c-4ebb-855b-1ed09e620889,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-03e2943f-1188-4812-8f69-49c8143e6c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-45e3d3e8-3bbf-4941-a9a4-b1b867372dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-55bb163a-94f5-44a5-97ad-a67fda98da11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796662380-172.17.0.15-1595694969272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35820,DS-172ca600-e553-4cf5-94f0-d4254ef27151,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-05ac531d-1f2c-419f-84f4-9ba1196cf76b,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-9df20b28-79af-449f-93b8-466126112784,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-57ea1faf-a726-42ca-bf8f-fdcd6cc409ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-3900d074-659c-4ebb-855b-1ed09e620889,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-03e2943f-1188-4812-8f69-49c8143e6c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-45e3d3e8-3bbf-4941-a9a4-b1b867372dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-55bb163a-94f5-44a5-97ad-a67fda98da11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791327515-172.17.0.15-1595695054084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-048dbab4-c893-4519-a16d-2132f6a7fd37,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-3fdfedaf-4780-4d90-8a93-67aaef000d65,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-3cc1f68e-7db9-4455-a333-32479fc84611,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-bf2b98a4-c084-4e10-958c-617d87b089ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-1a1bb3c6-cd4c-4cd1-8c12-e043d99abba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-99052baa-dfc9-4d4b-9e16-ebac28470e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-600f75b5-06db-4d25-ad1e-9712f1fbe273,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-f41d5b22-c34a-4160-a3c5-6362d9be8a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791327515-172.17.0.15-1595695054084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-048dbab4-c893-4519-a16d-2132f6a7fd37,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-3fdfedaf-4780-4d90-8a93-67aaef000d65,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-3cc1f68e-7db9-4455-a333-32479fc84611,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-bf2b98a4-c084-4e10-958c-617d87b089ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-1a1bb3c6-cd4c-4cd1-8c12-e043d99abba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-99052baa-dfc9-4d4b-9e16-ebac28470e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-600f75b5-06db-4d25-ad1e-9712f1fbe273,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-f41d5b22-c34a-4160-a3c5-6362d9be8a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305698245-172.17.0.15-1595695175567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-bd7e70af-7e0a-4691-97f1-0edd3e289fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-e1d3baf5-4100-49ad-86af-49dff8bd937c,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-0e4da0f3-42a3-4852-ad77-c446e0ef771c,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-a4d68586-c344-43cb-acca-74257128cf73,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-7633c38b-6488-423a-9c8e-9209e7017ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-04414cb2-70c9-4282-8a80-9e2f825ade8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-0899a010-7f91-4b89-b484-f2001fd79fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-b63c10e6-0e1c-41d5-9464-8d844dbbc29e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305698245-172.17.0.15-1595695175567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-bd7e70af-7e0a-4691-97f1-0edd3e289fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-e1d3baf5-4100-49ad-86af-49dff8bd937c,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-0e4da0f3-42a3-4852-ad77-c446e0ef771c,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-a4d68586-c344-43cb-acca-74257128cf73,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-7633c38b-6488-423a-9c8e-9209e7017ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-04414cb2-70c9-4282-8a80-9e2f825ade8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-0899a010-7f91-4b89-b484-f2001fd79fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-b63c10e6-0e1c-41d5-9464-8d844dbbc29e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638402521-172.17.0.15-1595695223983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-508078fc-8224-4c90-ad93-29fb126aeef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-5c70cfd4-e91a-4caf-86cc-019385637359,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-49d4baf8-b106-4c16-b872-7ed113e82ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-346b6feb-ce18-4f51-9cf9-479182808091,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-e6ac9a05-48b2-4789-95d7-f4e6624c0a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-5951c7e8-d3b3-4e75-971f-88c8da3c7f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-f098f653-d771-4f2f-9d58-ba51d716030e,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-27e0d16d-05b6-4f42-bf97-8bc1e03bdffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638402521-172.17.0.15-1595695223983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-508078fc-8224-4c90-ad93-29fb126aeef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-5c70cfd4-e91a-4caf-86cc-019385637359,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-49d4baf8-b106-4c16-b872-7ed113e82ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-346b6feb-ce18-4f51-9cf9-479182808091,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-e6ac9a05-48b2-4789-95d7-f4e6624c0a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-5951c7e8-d3b3-4e75-971f-88c8da3c7f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-f098f653-d771-4f2f-9d58-ba51d716030e,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-27e0d16d-05b6-4f42-bf97-8bc1e03bdffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216733867-172.17.0.15-1595696224431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-d8ff77aa-17e0-4457-a0be-717faad9dc45,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-f2ae16ed-70f6-4f68-8692-3ef2529953b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-18c10c3c-ea60-46c0-ad08-399a97333c18,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-81940359-0fd3-41de-939b-369714bfb3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-5825c56a-3c06-4290-990b-25b42a2ad381,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-de392e55-c09a-4e25-9a86-722f4b033f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-3073d951-c098-4b42-9097-4787e8a0d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-1feefaf7-7ec8-437b-865a-9eed8a877c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216733867-172.17.0.15-1595696224431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-d8ff77aa-17e0-4457-a0be-717faad9dc45,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-f2ae16ed-70f6-4f68-8692-3ef2529953b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-18c10c3c-ea60-46c0-ad08-399a97333c18,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-81940359-0fd3-41de-939b-369714bfb3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-5825c56a-3c06-4290-990b-25b42a2ad381,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-de392e55-c09a-4e25-9a86-722f4b033f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-3073d951-c098-4b42-9097-4787e8a0d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-1feefaf7-7ec8-437b-865a-9eed8a877c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662639317-172.17.0.15-1595696366754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45450,DS-fd2571c3-0afa-4a7f-ba04-d66c14654418,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-a191532c-29ce-4553-8e0f-bc92d36c9911,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-b640e530-bf8a-4cde-9cfe-74a8d7693831,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-97c8e9ce-fdd9-4233-926a-b176f9c97554,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-6e9c85fe-f4e0-4181-a843-c5cde1e6d70e,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-16f3e903-2dde-4004-a0d7-7addafc47b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-811f76f8-88df-413e-8eef-eb8d9808113d,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-0712b259-5c3e-48e6-8ce0-5b528e96a0fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662639317-172.17.0.15-1595696366754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45450,DS-fd2571c3-0afa-4a7f-ba04-d66c14654418,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-a191532c-29ce-4553-8e0f-bc92d36c9911,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-b640e530-bf8a-4cde-9cfe-74a8d7693831,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-97c8e9ce-fdd9-4233-926a-b176f9c97554,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-6e9c85fe-f4e0-4181-a843-c5cde1e6d70e,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-16f3e903-2dde-4004-a0d7-7addafc47b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-811f76f8-88df-413e-8eef-eb8d9808113d,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-0712b259-5c3e-48e6-8ce0-5b528e96a0fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482298558-172.17.0.15-1595696463679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40009,DS-386fafc5-84f9-4026-baed-75e28ac58147,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-cc3348b2-1c4b-4e84-af4d-810db843e4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-6acda77a-f651-4b39-8556-e01fcdf86ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-1ae2f92c-dfd2-42ab-bb9e-b3dc0dcb5ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-88d7fc29-4e28-4125-8517-a9dcf6687830,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-5ed1857d-13c1-4013-ad69-f0c1f99b85ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-2527c65c-ac9a-4534-bf4b-56b53f1118d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-4dbec855-f576-45f5-8620-b19bb545eca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482298558-172.17.0.15-1595696463679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40009,DS-386fafc5-84f9-4026-baed-75e28ac58147,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-cc3348b2-1c4b-4e84-af4d-810db843e4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-6acda77a-f651-4b39-8556-e01fcdf86ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-1ae2f92c-dfd2-42ab-bb9e-b3dc0dcb5ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-88d7fc29-4e28-4125-8517-a9dcf6687830,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-5ed1857d-13c1-4013-ad69-f0c1f99b85ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-2527c65c-ac9a-4534-bf4b-56b53f1118d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-4dbec855-f576-45f5-8620-b19bb545eca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251617293-172.17.0.15-1595697613524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37691,DS-3b364a87-1302-4d63-9739-a2f2c53bb024,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-ea8e9b0c-2641-4fb2-8c34-8cf8e8c6a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-c1dc1001-21df-401f-af37-a67e3779010f,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-328dac99-b1a1-42aa-8b7d-2542ab3b5c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-5d2f1167-7959-492a-9b6e-0a857a735ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-20e256b1-3e8a-45cd-9cec-67080e2188a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-696c12c3-aed5-4c54-bd99-cf13ec861304,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-04e927a3-1a8c-4a41-bb16-8f5b249633b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251617293-172.17.0.15-1595697613524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37691,DS-3b364a87-1302-4d63-9739-a2f2c53bb024,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-ea8e9b0c-2641-4fb2-8c34-8cf8e8c6a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-c1dc1001-21df-401f-af37-a67e3779010f,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-328dac99-b1a1-42aa-8b7d-2542ab3b5c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-5d2f1167-7959-492a-9b6e-0a857a735ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-20e256b1-3e8a-45cd-9cec-67080e2188a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-696c12c3-aed5-4c54-bd99-cf13ec861304,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-04e927a3-1a8c-4a41-bb16-8f5b249633b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845973869-172.17.0.15-1595697711988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-e675a3f7-c5a2-42c5-a3a3-c49623ce5ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-33225057-9695-42d9-9511-2f00ab3e092b,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-0dd53ea1-8fee-4a54-b7e7-09aadcb7895f,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-f0de1ed8-df55-4106-a647-23e7b9c5839c,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-7273737d-686c-4bf7-b8c9-3db6701b73c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-ca767a35-4cdb-4568-9a7a-a76685c1f927,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-01ea5df4-e6c7-4541-a730-7f78e4528219,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-39273a5a-81ae-4163-8009-95bd379b493b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845973869-172.17.0.15-1595697711988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-e675a3f7-c5a2-42c5-a3a3-c49623ce5ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-33225057-9695-42d9-9511-2f00ab3e092b,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-0dd53ea1-8fee-4a54-b7e7-09aadcb7895f,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-f0de1ed8-df55-4106-a647-23e7b9c5839c,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-7273737d-686c-4bf7-b8c9-3db6701b73c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-ca767a35-4cdb-4568-9a7a-a76685c1f927,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-01ea5df4-e6c7-4541-a730-7f78e4528219,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-39273a5a-81ae-4163-8009-95bd379b493b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422292697-172.17.0.15-1595698162568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33747,DS-3f34c807-0c14-4fb2-96f1-6dd2b169e561,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-1281636f-4fc7-47fd-95dc-25c91e9eb236,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-cdb9fdfa-9306-4353-96d7-6cf450fad990,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-c3dbd81e-7e39-4765-97e9-2c4320f33ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-d325ba36-2141-454d-9257-f71207c2f700,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-6c410a78-cd22-4e1a-9ead-2d893f0bc0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-0cc4bc49-ba70-4955-8816-0dbdea5c6f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-d8bf28e4-8139-4567-a1c3-bce0475b999a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422292697-172.17.0.15-1595698162568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33747,DS-3f34c807-0c14-4fb2-96f1-6dd2b169e561,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-1281636f-4fc7-47fd-95dc-25c91e9eb236,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-cdb9fdfa-9306-4353-96d7-6cf450fad990,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-c3dbd81e-7e39-4765-97e9-2c4320f33ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-d325ba36-2141-454d-9257-f71207c2f700,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-6c410a78-cd22-4e1a-9ead-2d893f0bc0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-0cc4bc49-ba70-4955-8816-0dbdea5c6f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-d8bf28e4-8139-4567-a1c3-bce0475b999a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608582442-172.17.0.15-1595699408123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33587,DS-c10e9e91-e60e-4809-994c-83e4ea9d9e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-3f0108ca-ec26-45fb-94af-c723637a0e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-f594d616-f240-488a-a5d9-a086b2267661,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-81d5e4d4-07fc-4d8d-9152-44a8bd60f8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-66e4ca7d-fd7a-406f-8a84-7370c5d7245c,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-ad3ed7c0-0de4-462c-88b5-24f2777052eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-c5c3e927-8082-4db7-aecf-9e7b86cf8cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-0e3e1006-b28f-4eb6-be20-08fdfecca52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608582442-172.17.0.15-1595699408123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33587,DS-c10e9e91-e60e-4809-994c-83e4ea9d9e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-3f0108ca-ec26-45fb-94af-c723637a0e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-f594d616-f240-488a-a5d9-a086b2267661,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-81d5e4d4-07fc-4d8d-9152-44a8bd60f8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-66e4ca7d-fd7a-406f-8a84-7370c5d7245c,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-ad3ed7c0-0de4-462c-88b5-24f2777052eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-c5c3e927-8082-4db7-aecf-9e7b86cf8cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-0e3e1006-b28f-4eb6-be20-08fdfecca52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881174731-172.17.0.15-1595699763804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36237,DS-c513f475-f0bb-49b1-9293-6dda0d7274aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-ee96bf74-90ff-4e86-9014-636ed090eab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-1443bdb6-7a80-4c76-a2c3-eaa2d16181ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-2600d906-717c-4eac-8b6d-575cc04e03cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-7e9829b7-5ab0-4db6-9835-705d5f576557,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-0bd6366f-2ab8-4f4d-81de-727b40aaf0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-4146b6a5-ad90-410c-874a-acc17e09ef22,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-09ad727d-4bd6-4f1c-b45e-ebec736ecb09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881174731-172.17.0.15-1595699763804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36237,DS-c513f475-f0bb-49b1-9293-6dda0d7274aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-ee96bf74-90ff-4e86-9014-636ed090eab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-1443bdb6-7a80-4c76-a2c3-eaa2d16181ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-2600d906-717c-4eac-8b6d-575cc04e03cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-7e9829b7-5ab0-4db6-9835-705d5f576557,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-0bd6366f-2ab8-4f4d-81de-727b40aaf0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-4146b6a5-ad90-410c-874a-acc17e09ef22,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-09ad727d-4bd6-4f1c-b45e-ebec736ecb09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292725756-172.17.0.15-1595700114031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-df75f2ed-f34d-4412-a6fc-de4688a360cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-0b49d91b-9bc3-41da-bec2-02143e702d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-2577afb3-7524-4daa-b6e5-f965446f7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-8eddd8d0-05ed-4c02-a718-13428b7d6c58,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-08486df9-ab30-4a12-b747-e348c15c82d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-6716a909-0aa5-4153-83e8-4288ab576a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-7fbb854a-7edb-4998-a165-90bfc695fa26,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-693075f5-7d67-463c-8199-fab4ce92c208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292725756-172.17.0.15-1595700114031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-df75f2ed-f34d-4412-a6fc-de4688a360cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-0b49d91b-9bc3-41da-bec2-02143e702d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-2577afb3-7524-4daa-b6e5-f965446f7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-8eddd8d0-05ed-4c02-a718-13428b7d6c58,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-08486df9-ab30-4a12-b747-e348c15c82d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-6716a909-0aa5-4153-83e8-4288ab576a62,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-7fbb854a-7edb-4998-a165-90bfc695fa26,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-693075f5-7d67-463c-8199-fab4ce92c208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335556731-172.17.0.15-1595700299805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34340,DS-b3b285ae-01b6-4dca-b6e2-712cdc3f7ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-6dcc9427-61ec-4d6c-a160-31bc5c7b960f,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-40f0dcdf-81f4-4945-9054-773b620a7511,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-9dd4b353-7957-4a06-9d8d-0684c9fd1bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-a9cb3b22-a6de-4646-a0fe-68a49b8ca3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-c6dc7e7e-e8d0-4c1a-b310-0edc48d303c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-8ae3340b-e25e-442b-b1ca-871bf5507961,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-46a84870-a4aa-49f9-a26c-c1b157df2fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335556731-172.17.0.15-1595700299805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34340,DS-b3b285ae-01b6-4dca-b6e2-712cdc3f7ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-6dcc9427-61ec-4d6c-a160-31bc5c7b960f,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-40f0dcdf-81f4-4945-9054-773b620a7511,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-9dd4b353-7957-4a06-9d8d-0684c9fd1bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-a9cb3b22-a6de-4646-a0fe-68a49b8ca3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-c6dc7e7e-e8d0-4c1a-b310-0edc48d303c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-8ae3340b-e25e-442b-b1ca-871bf5507961,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-46a84870-a4aa-49f9-a26c-c1b157df2fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487606876-172.17.0.15-1595700347040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45667,DS-bd3ac5d1-616a-45cd-9458-9edbdbab66fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-1411f1ed-c997-4912-86f4-6ed7bfe67512,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-2af77536-0a84-487f-9bb9-43a312773b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-2e02e116-145f-4606-b1e5-1483eb019f78,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-de412247-9994-4c8d-a752-f9c7490c61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-ff1e2f6d-7029-4d90-ace7-6e107ef1f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-6c66932a-4ff9-428c-8791-577ef5ff5ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-3cc4435e-2770-4c05-b5d4-ebfe832babfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487606876-172.17.0.15-1595700347040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45667,DS-bd3ac5d1-616a-45cd-9458-9edbdbab66fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-1411f1ed-c997-4912-86f4-6ed7bfe67512,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-2af77536-0a84-487f-9bb9-43a312773b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-2e02e116-145f-4606-b1e5-1483eb019f78,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-de412247-9994-4c8d-a752-f9c7490c61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-ff1e2f6d-7029-4d90-ace7-6e107ef1f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-6c66932a-4ff9-428c-8791-577ef5ff5ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-3cc4435e-2770-4c05-b5d4-ebfe832babfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354672950-172.17.0.15-1595700433053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36780,DS-33caff50-416c-4dd5-a694-020d7bbd1162,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-d2c3b481-cd22-4e3e-a121-0513f7c7a933,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-145f4760-c81f-48db-bbd9-3858f48f85b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-11bf1fbc-7308-4d3f-b1f1-9ed3fa6a2887,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-565cf79f-1271-471c-9f57-13ce31ddf41e,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-a880ebea-fa92-4956-b898-46852ddc000d,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-7c690820-ff13-44b8-8761-107310b5a105,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-5b355456-2936-41c3-9d46-1be3d2acdc56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354672950-172.17.0.15-1595700433053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36780,DS-33caff50-416c-4dd5-a694-020d7bbd1162,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-d2c3b481-cd22-4e3e-a121-0513f7c7a933,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-145f4760-c81f-48db-bbd9-3858f48f85b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-11bf1fbc-7308-4d3f-b1f1-9ed3fa6a2887,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-565cf79f-1271-471c-9f57-13ce31ddf41e,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-a880ebea-fa92-4956-b898-46852ddc000d,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-7c690820-ff13-44b8-8761-107310b5a105,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-5b355456-2936-41c3-9d46-1be3d2acdc56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613967787-172.17.0.15-1595700824540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-320645cf-e413-45ac-b958-bc7669c5c205,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-255f112c-3885-41c8-b74f-a76321fdf024,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-d116e934-d6d2-4e57-abc9-2fed4cc23e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-4b3f7c4e-d9e1-4c8f-9835-11cdb0a7aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-c4b1367a-9e53-4f33-8a4f-0fc4d50ab8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-3491dcdf-b4e8-451a-a321-d43c471e3ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-830ad416-0bda-44b8-9093-c5536ec9eec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-44b31fd9-1b54-40ce-be8f-eb3dd44c58bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613967787-172.17.0.15-1595700824540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-320645cf-e413-45ac-b958-bc7669c5c205,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-255f112c-3885-41c8-b74f-a76321fdf024,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-d116e934-d6d2-4e57-abc9-2fed4cc23e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-4b3f7c4e-d9e1-4c8f-9835-11cdb0a7aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-c4b1367a-9e53-4f33-8a4f-0fc4d50ab8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-3491dcdf-b4e8-451a-a321-d43c471e3ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-830ad416-0bda-44b8-9093-c5536ec9eec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-44b31fd9-1b54-40ce-be8f-eb3dd44c58bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6561
