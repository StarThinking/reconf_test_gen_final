reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682446150-172.17.0.5-1595587238760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-01fbb2d3-bb30-4660-9311-2a2a4ccf8d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-b0f2bdf8-d3ac-4778-a36e-f9d9a8a8aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-4271d189-a68c-462a-ab30-f6ff68d7de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-cc73d8ca-1fc3-43c5-a323-3a762e23ad7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-3ff644b0-41a4-478f-9ad8-bea2be93ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-d4d2cf8c-2491-4a1b-890e-caeb3524d04a,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-91eaf0cf-668e-4050-b737-64fc703d5453,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-bf50ff87-0371-4fef-a505-4cf2227a707c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682446150-172.17.0.5-1595587238760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-01fbb2d3-bb30-4660-9311-2a2a4ccf8d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-b0f2bdf8-d3ac-4778-a36e-f9d9a8a8aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-4271d189-a68c-462a-ab30-f6ff68d7de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-cc73d8ca-1fc3-43c5-a323-3a762e23ad7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-3ff644b0-41a4-478f-9ad8-bea2be93ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-d4d2cf8c-2491-4a1b-890e-caeb3524d04a,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-91eaf0cf-668e-4050-b737-64fc703d5453,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-bf50ff87-0371-4fef-a505-4cf2227a707c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919400578-172.17.0.5-1595587537588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45525,DS-fc8fa7d0-e43c-44ee-947d-9247cb4f90bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-0a672f43-0aa4-4d55-8c82-c9a45f738ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-83e08c9b-9dbd-4b01-81d7-f283e955875b,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-a0bb3bd1-2daf-4e6c-acfd-a731048f36d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-68788034-7c32-475f-b1b4-61651a94a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-fc374c99-f090-4eb3-8552-e32b8e37ca07,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-990cebc5-ca96-4ff4-abaa-518c35bd2be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-7d1285d3-e629-46b3-b970-9217051bdbb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919400578-172.17.0.5-1595587537588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45525,DS-fc8fa7d0-e43c-44ee-947d-9247cb4f90bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-0a672f43-0aa4-4d55-8c82-c9a45f738ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-83e08c9b-9dbd-4b01-81d7-f283e955875b,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-a0bb3bd1-2daf-4e6c-acfd-a731048f36d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-68788034-7c32-475f-b1b4-61651a94a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-fc374c99-f090-4eb3-8552-e32b8e37ca07,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-990cebc5-ca96-4ff4-abaa-518c35bd2be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-7d1285d3-e629-46b3-b970-9217051bdbb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411308584-172.17.0.5-1595587746427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39802,DS-0a701796-bc13-4590-bfe4-504c808f107c,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-4ce7d55a-adfb-4a5e-966d-0454c417b2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-03ce40aa-5f4c-4e28-9e1e-c3fb9d4a335a,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-66a50e19-1e4d-412c-b1ba-b116d698aeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-b1271d61-84d9-4222-995d-a5a40d613363,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-45e9dee2-908e-4b7e-99ae-b12a030fe7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-5cbd4ec5-41a0-4d1f-970c-cafb9943f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-701c0d79-ebc7-4c42-8a60-7cb94494f96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411308584-172.17.0.5-1595587746427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39802,DS-0a701796-bc13-4590-bfe4-504c808f107c,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-4ce7d55a-adfb-4a5e-966d-0454c417b2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-03ce40aa-5f4c-4e28-9e1e-c3fb9d4a335a,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-66a50e19-1e4d-412c-b1ba-b116d698aeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-b1271d61-84d9-4222-995d-a5a40d613363,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-45e9dee2-908e-4b7e-99ae-b12a030fe7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-5cbd4ec5-41a0-4d1f-970c-cafb9943f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-701c0d79-ebc7-4c42-8a60-7cb94494f96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51221011-172.17.0.5-1595587809734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-332b5bdc-15df-4f78-b868-48cd634b5444,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-b839e14f-90a4-488b-bf0c-9fce783b9f14,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-bb904e7e-4bee-4fe0-9533-29f2191107c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-65e338e5-ef24-4061-9981-9a60f9e90ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-2f1b4c0f-f482-49a2-9279-52079cd2f4af,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-f5882cd8-53ad-4889-b554-4dd14e9eeb81,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-1e49fb47-0936-4441-84ba-6723d220dd82,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d09db784-4a90-4b8c-b8b7-7ec5c36ecc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51221011-172.17.0.5-1595587809734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-332b5bdc-15df-4f78-b868-48cd634b5444,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-b839e14f-90a4-488b-bf0c-9fce783b9f14,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-bb904e7e-4bee-4fe0-9533-29f2191107c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-65e338e5-ef24-4061-9981-9a60f9e90ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-2f1b4c0f-f482-49a2-9279-52079cd2f4af,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-f5882cd8-53ad-4889-b554-4dd14e9eeb81,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-1e49fb47-0936-4441-84ba-6723d220dd82,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d09db784-4a90-4b8c-b8b7-7ec5c36ecc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975082739-172.17.0.5-1595588308420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-9596e7ad-8156-4a6d-8f0c-8be9c175fec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-f2ee3754-05f1-45e3-b87c-2b1787f3dbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-7fba8344-33d3-4fed-82fa-4a6684303c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-3b72145d-8070-48c0-b972-358a287c0d16,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-0153a5e5-557c-467d-a537-00e7aa01e418,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-5ce02252-f8cb-49b6-8646-906143fed656,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-957b6142-f45f-49ee-b673-2ea1b7afad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-cd927306-60cc-463a-a2d7-94a6f1110d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975082739-172.17.0.5-1595588308420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-9596e7ad-8156-4a6d-8f0c-8be9c175fec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-f2ee3754-05f1-45e3-b87c-2b1787f3dbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-7fba8344-33d3-4fed-82fa-4a6684303c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-3b72145d-8070-48c0-b972-358a287c0d16,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-0153a5e5-557c-467d-a537-00e7aa01e418,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-5ce02252-f8cb-49b6-8646-906143fed656,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-957b6142-f45f-49ee-b673-2ea1b7afad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-cd927306-60cc-463a-a2d7-94a6f1110d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719698698-172.17.0.5-1595588608767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-4e81e47f-3935-4c4b-b206-59f4b9250505,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-b05c526c-25fd-4586-a16a-7b43e72c7dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-cf796011-779e-4874-abfc-a61dffe2aafa,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-66f7375d-839b-4ce6-9458-72db646da346,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-6decc173-995d-45c1-be8a-e8da78c6ec23,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-8aa6b86f-a235-4102-aada-90ad51f229f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-d2d30e65-6600-48e8-84e6-a9e056ddb34b,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-f1d66e3e-355f-4b0d-b7bf-f14583035333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719698698-172.17.0.5-1595588608767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-4e81e47f-3935-4c4b-b206-59f4b9250505,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-b05c526c-25fd-4586-a16a-7b43e72c7dab,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-cf796011-779e-4874-abfc-a61dffe2aafa,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-66f7375d-839b-4ce6-9458-72db646da346,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-6decc173-995d-45c1-be8a-e8da78c6ec23,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-8aa6b86f-a235-4102-aada-90ad51f229f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-d2d30e65-6600-48e8-84e6-a9e056ddb34b,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-f1d66e3e-355f-4b0d-b7bf-f14583035333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024378383-172.17.0.5-1595588731569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38296,DS-9c795b3f-1cc9-4558-b27e-f01623c71e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-8fa1538d-5214-4c79-bc4a-6d987d2de444,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-c1455606-734b-469f-a3aa-15869c889701,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-0f3aacb4-2ff4-4ce4-85bf-bc3f6084f9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-15bb08cd-fd25-4c21-a510-9d9833d4ab60,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-661311ec-d38f-44cd-a475-51ef1da39026,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-4e7b281c-f24a-4934-87f6-7a8bc8a125c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-6e4781d5-83e8-4bee-b068-f8fea92f9d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024378383-172.17.0.5-1595588731569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38296,DS-9c795b3f-1cc9-4558-b27e-f01623c71e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-8fa1538d-5214-4c79-bc4a-6d987d2de444,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-c1455606-734b-469f-a3aa-15869c889701,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-0f3aacb4-2ff4-4ce4-85bf-bc3f6084f9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-15bb08cd-fd25-4c21-a510-9d9833d4ab60,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-661311ec-d38f-44cd-a475-51ef1da39026,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-4e7b281c-f24a-4934-87f6-7a8bc8a125c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-6e4781d5-83e8-4bee-b068-f8fea92f9d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700905070-172.17.0.5-1595589566664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-67052a96-615d-48af-b821-13f4892eae19,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-4c779286-d4a6-4d06-b3d9-8d88c1469676,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-01f16ec0-eb52-42d4-b393-4ce32f8437a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-e4d19e43-3244-4315-97cc-3f9f09313b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-af2741ff-c501-40e4-bdda-95182f7fc3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-a1201fb0-8973-4d98-924d-a2f788b1bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-3dab9437-368a-48e5-9952-8221345eeb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-bd2adde2-4b36-463d-8afb-a73c7bbef3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700905070-172.17.0.5-1595589566664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-67052a96-615d-48af-b821-13f4892eae19,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-4c779286-d4a6-4d06-b3d9-8d88c1469676,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-01f16ec0-eb52-42d4-b393-4ce32f8437a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-e4d19e43-3244-4315-97cc-3f9f09313b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-af2741ff-c501-40e4-bdda-95182f7fc3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-a1201fb0-8973-4d98-924d-a2f788b1bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-3dab9437-368a-48e5-9952-8221345eeb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-bd2adde2-4b36-463d-8afb-a73c7bbef3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200121110-172.17.0.5-1595590216294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35961,DS-5facfb1a-1e3c-477a-a8b4-66a462ad7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-a27b03ad-4913-40b9-813a-3b9e53762e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-034db1ed-7d33-42d9-a558-c36596089909,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-f60d8575-2e9a-4367-822f-f80559698f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-67d2d361-15af-4416-b776-241ea67f8472,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-e7fbb763-69a3-45d3-abd7-85137ffacfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-2b45e209-9b01-4d80-b96c-a8853d6397bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-c04b4d73-2774-4a9d-ac25-c2e175404bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200121110-172.17.0.5-1595590216294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35961,DS-5facfb1a-1e3c-477a-a8b4-66a462ad7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-a27b03ad-4913-40b9-813a-3b9e53762e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-034db1ed-7d33-42d9-a558-c36596089909,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-f60d8575-2e9a-4367-822f-f80559698f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-67d2d361-15af-4416-b776-241ea67f8472,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-e7fbb763-69a3-45d3-abd7-85137ffacfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-2b45e209-9b01-4d80-b96c-a8853d6397bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-c04b4d73-2774-4a9d-ac25-c2e175404bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563747625-172.17.0.5-1595591277547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44145,DS-1ac6cbb6-2b75-4dbe-88fd-c0bf067f1b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-275c2d3f-bde1-4ffb-9100-38a8e3158721,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-c68388c6-a93f-4db0-91e0-85515dd56117,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-84bf5cfc-a3d2-4778-b8fd-6522c9fda91e,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-d88b7484-fb68-4a4b-9990-594f3c6a8560,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-3b89db7f-feb9-4513-84cb-0e2a1aa49851,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-551ee2ce-7d73-4e4f-9e51-a4079debe849,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-68560ac1-cb40-449c-b35c-7e3717c6944d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563747625-172.17.0.5-1595591277547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44145,DS-1ac6cbb6-2b75-4dbe-88fd-c0bf067f1b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-275c2d3f-bde1-4ffb-9100-38a8e3158721,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-c68388c6-a93f-4db0-91e0-85515dd56117,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-84bf5cfc-a3d2-4778-b8fd-6522c9fda91e,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-d88b7484-fb68-4a4b-9990-594f3c6a8560,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-3b89db7f-feb9-4513-84cb-0e2a1aa49851,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-551ee2ce-7d73-4e4f-9e51-a4079debe849,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-68560ac1-cb40-449c-b35c-7e3717c6944d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881927549-172.17.0.5-1595591611256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-6d6a8f6b-1c22-4eef-9e3b-5d26b22f1dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-ed6b404c-f0a5-4879-b025-fb5a82fb56b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-4189b34b-256e-4c57-9667-994a89c7ecdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-1c5f55a2-7ab6-421b-80ed-1f48775b3668,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-de6f9b6b-6dec-4789-896b-8af1dfb27741,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-e82f6d40-af92-4e5d-a206-2ab91169552a,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-32f963e3-0af2-4c26-bb96-d7ba17355eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-956e85b6-69a2-4f10-9dd5-4166a2880155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881927549-172.17.0.5-1595591611256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-6d6a8f6b-1c22-4eef-9e3b-5d26b22f1dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-ed6b404c-f0a5-4879-b025-fb5a82fb56b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-4189b34b-256e-4c57-9667-994a89c7ecdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-1c5f55a2-7ab6-421b-80ed-1f48775b3668,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-de6f9b6b-6dec-4789-896b-8af1dfb27741,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-e82f6d40-af92-4e5d-a206-2ab91169552a,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-32f963e3-0af2-4c26-bb96-d7ba17355eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-956e85b6-69a2-4f10-9dd5-4166a2880155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477908631-172.17.0.5-1595591825379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-4a8dc429-9f7f-475f-941d-9af7289292c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-7b15fbe9-ea67-40e8-a028-7274a20eb41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-0589f3d8-0d15-4186-af2a-2f5c5c4ccffb,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-8ea6533a-aeb0-4342-a6a0-d28c062a6c34,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-3c00a9a4-4432-4c2c-b754-9668ca478354,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-3126fc02-c058-4c0f-802f-a528ffe4c0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-59fd32c0-0f62-4c45-9f1b-f8b7ab1839fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-eb72f016-5b9b-4512-b3f7-c915782951bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477908631-172.17.0.5-1595591825379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36231,DS-4a8dc429-9f7f-475f-941d-9af7289292c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-7b15fbe9-ea67-40e8-a028-7274a20eb41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-0589f3d8-0d15-4186-af2a-2f5c5c4ccffb,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-8ea6533a-aeb0-4342-a6a0-d28c062a6c34,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-3c00a9a4-4432-4c2c-b754-9668ca478354,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-3126fc02-c058-4c0f-802f-a528ffe4c0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-59fd32c0-0f62-4c45-9f1b-f8b7ab1839fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-eb72f016-5b9b-4512-b3f7-c915782951bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4869
