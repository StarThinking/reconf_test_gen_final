reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442706405-172.17.0.5-1595588684292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-58ef3c26-d6b4-47cb-b275-7ad922962a34,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-c6b2c127-6be7-40e1-a406-0d9c030085c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-890efaf7-5c9f-4cdf-84cb-5eed45c4d328,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c6299829-de6b-421d-8094-0f9e3ddfc4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-8a8dded4-9c35-4db1-8190-e02914f51bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-d2ad7859-495a-46b2-9f32-c0fa3228251e,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-048edeea-88ac-4554-b93a-88b52278d215,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-8a9bc3c4-cc45-4e6b-8b4b-aeb21c2daf8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442706405-172.17.0.5-1595588684292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-58ef3c26-d6b4-47cb-b275-7ad922962a34,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-c6b2c127-6be7-40e1-a406-0d9c030085c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-890efaf7-5c9f-4cdf-84cb-5eed45c4d328,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c6299829-de6b-421d-8094-0f9e3ddfc4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-8a8dded4-9c35-4db1-8190-e02914f51bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-d2ad7859-495a-46b2-9f32-c0fa3228251e,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-048edeea-88ac-4554-b93a-88b52278d215,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-8a9bc3c4-cc45-4e6b-8b4b-aeb21c2daf8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128825067-172.17.0.5-1595588715638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43355,DS-ffd5ae42-dff3-472a-942c-fe12a6d0e879,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-6eef704c-d8cc-4f2b-a356-2b9b620b915a,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-c2d7c90e-5a49-4e45-8e91-9843984cd0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-2c7c8bb0-a3ba-48f9-bc27-e83203a3d1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-b30d643c-dd5d-4aeb-8cb0-c1b04325d201,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-5fca9b47-986c-4130-bfc2-20146fff03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-d1355f4b-dff7-4792-9085-391a447c0a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-c0f08af3-484d-4c8e-bf70-0a5eb7c8307c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128825067-172.17.0.5-1595588715638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43355,DS-ffd5ae42-dff3-472a-942c-fe12a6d0e879,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-6eef704c-d8cc-4f2b-a356-2b9b620b915a,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-c2d7c90e-5a49-4e45-8e91-9843984cd0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-2c7c8bb0-a3ba-48f9-bc27-e83203a3d1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-b30d643c-dd5d-4aeb-8cb0-c1b04325d201,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-5fca9b47-986c-4130-bfc2-20146fff03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-d1355f4b-dff7-4792-9085-391a447c0a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-c0f08af3-484d-4c8e-bf70-0a5eb7c8307c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561824583-172.17.0.5-1595588867185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-6a1d5fa8-6abd-49a7-962a-f390cf09682a,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-79cd1d1f-38d5-42d7-85a7-bc2eca01529a,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-64997e51-a295-418c-9153-bbeaf6550a77,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-e9c3451f-d832-41cb-ba99-f5979edd9bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-ed22af91-0315-492b-8cd4-7c7d46613b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-3d99e9b2-9ed9-4253-a329-4b2849cbad52,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-24fcc370-0951-4304-8aee-6cacc7eba4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-8f18f7b1-6154-4a5b-8cd4-01bfe9bb041f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561824583-172.17.0.5-1595588867185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-6a1d5fa8-6abd-49a7-962a-f390cf09682a,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-79cd1d1f-38d5-42d7-85a7-bc2eca01529a,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-64997e51-a295-418c-9153-bbeaf6550a77,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-e9c3451f-d832-41cb-ba99-f5979edd9bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-ed22af91-0315-492b-8cd4-7c7d46613b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-3d99e9b2-9ed9-4253-a329-4b2849cbad52,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-24fcc370-0951-4304-8aee-6cacc7eba4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-8f18f7b1-6154-4a5b-8cd4-01bfe9bb041f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978507441-172.17.0.5-1595589368226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-b161c581-a708-4637-a272-f75fded6dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-ff9684e1-25b8-4445-9461-bf0ab82e15b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-730d5c9f-a7de-4da1-8d12-ba00c7c2254e,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-a7fc784d-8aad-4883-a2af-89bc4552d5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-167c5d8c-ddb6-404d-bc24-92db05c790e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-5f72ea76-f63c-4b35-95b4-312de941ac52,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-0b7d0420-9a99-441f-af35-6b81a3ba15a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-c841bf27-94ad-498c-aa06-be121a4523ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978507441-172.17.0.5-1595589368226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-b161c581-a708-4637-a272-f75fded6dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-ff9684e1-25b8-4445-9461-bf0ab82e15b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-730d5c9f-a7de-4da1-8d12-ba00c7c2254e,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-a7fc784d-8aad-4883-a2af-89bc4552d5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-167c5d8c-ddb6-404d-bc24-92db05c790e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-5f72ea76-f63c-4b35-95b4-312de941ac52,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-0b7d0420-9a99-441f-af35-6b81a3ba15a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-c841bf27-94ad-498c-aa06-be121a4523ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943110821-172.17.0.5-1595589845148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-aedb5b93-b2af-4b61-9117-5b6362c060f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-c7e1c92b-bb2d-4988-b4e2-510c6600479b,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-9b0f00a3-53ed-40e1-a918-e7c503a508fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-48017af3-3253-4bab-a01a-1b24627c8212,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-e5e09c14-85ac-430c-b983-30066fcc6d50,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-64674b62-f470-4fa8-bb5b-20d2b8b2dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-1c008f46-c3bc-4d59-b554-741be46d534a,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-bac54438-ffd7-4cb7-954c-0b48ea53be5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943110821-172.17.0.5-1595589845148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-aedb5b93-b2af-4b61-9117-5b6362c060f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-c7e1c92b-bb2d-4988-b4e2-510c6600479b,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-9b0f00a3-53ed-40e1-a918-e7c503a508fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-48017af3-3253-4bab-a01a-1b24627c8212,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-e5e09c14-85ac-430c-b983-30066fcc6d50,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-64674b62-f470-4fa8-bb5b-20d2b8b2dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-1c008f46-c3bc-4d59-b554-741be46d534a,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-bac54438-ffd7-4cb7-954c-0b48ea53be5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494259434-172.17.0.5-1595590271458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43555,DS-7b5b38f0-d491-448a-9ced-1f5c7c2cb75f,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-c90ddd95-1792-4769-8126-c35d602a5510,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-f3802597-5da3-4f0b-909f-16e9ecd4f9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-18c656d2-c26d-4d7f-b78f-9aaead66c633,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-2c83cd02-2d49-4bd7-856b-fc103956cbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-ddc61c29-3f5c-469a-bc68-51a0b139b961,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-e774bb4f-f790-48d9-bd6e-2987541c2588,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-df49d4c8-63ce-4b47-b254-efbde7533296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494259434-172.17.0.5-1595590271458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43555,DS-7b5b38f0-d491-448a-9ced-1f5c7c2cb75f,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-c90ddd95-1792-4769-8126-c35d602a5510,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-f3802597-5da3-4f0b-909f-16e9ecd4f9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-18c656d2-c26d-4d7f-b78f-9aaead66c633,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-2c83cd02-2d49-4bd7-856b-fc103956cbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-ddc61c29-3f5c-469a-bc68-51a0b139b961,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-e774bb4f-f790-48d9-bd6e-2987541c2588,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-df49d4c8-63ce-4b47-b254-efbde7533296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638473040-172.17.0.5-1595590879171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35157,DS-cdc8f7b7-0361-49a4-a22c-be844473112a,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-2e0aa08b-808b-4582-ada6-503d5d793da7,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-b58f21a7-e4bd-4998-baa9-a441aeab0e21,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-945e2477-2fa4-416a-8c48-5082bfe932af,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-23a5c368-3f17-4e91-85db-512aa72cdda5,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-f0bb5173-62c4-4fdf-aad8-37ab320980b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-a337f106-0519-4853-a517-28a56d8d02b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-8ee8ce79-3ea9-4d6e-a4f1-eda54ffdce97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638473040-172.17.0.5-1595590879171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35157,DS-cdc8f7b7-0361-49a4-a22c-be844473112a,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-2e0aa08b-808b-4582-ada6-503d5d793da7,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-b58f21a7-e4bd-4998-baa9-a441aeab0e21,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-945e2477-2fa4-416a-8c48-5082bfe932af,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-23a5c368-3f17-4e91-85db-512aa72cdda5,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-f0bb5173-62c4-4fdf-aad8-37ab320980b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-a337f106-0519-4853-a517-28a56d8d02b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-8ee8ce79-3ea9-4d6e-a4f1-eda54ffdce97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896994827-172.17.0.5-1595591269763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46216,DS-1b0cb897-b9fa-476f-9668-70b6320fc639,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-0f4f75ce-a2fc-4368-8e16-10f8ef7c67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-6f65e3c0-5d9d-4ee9-8231-0c6aa4fef423,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-83ff208b-e43b-4591-bf77-a85e9f5faa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-102cf94c-4108-4a77-8227-1fa273eaf340,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-f2c19122-033c-44fe-a43d-42b69f775329,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-70062ce9-bd19-42f6-992e-1af84a81abb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-8586afe4-67ac-4903-904f-b3881898930f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896994827-172.17.0.5-1595591269763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46216,DS-1b0cb897-b9fa-476f-9668-70b6320fc639,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-0f4f75ce-a2fc-4368-8e16-10f8ef7c67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-6f65e3c0-5d9d-4ee9-8231-0c6aa4fef423,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-83ff208b-e43b-4591-bf77-a85e9f5faa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-102cf94c-4108-4a77-8227-1fa273eaf340,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-f2c19122-033c-44fe-a43d-42b69f775329,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-70062ce9-bd19-42f6-992e-1af84a81abb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-8586afe4-67ac-4903-904f-b3881898930f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516678583-172.17.0.5-1595591566551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-bea57ea1-c898-46fc-a1fd-201ced02bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-63da9952-34ef-4cba-8512-1a13d01310df,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-6b15fd3d-9f34-4905-abc9-8042621f62b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-29b8241f-9b36-4680-83a0-8fff1e739c16,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-5fc74d4a-26bd-496a-8c33-d17ffc54819d,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-0f14bd13-6266-4966-b526-b9b14efd1951,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-94a24ccc-a3da-411c-b6fc-c68881794b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-f188be88-ba35-4dd5-9abf-866e7b92773d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516678583-172.17.0.5-1595591566551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-bea57ea1-c898-46fc-a1fd-201ced02bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-63da9952-34ef-4cba-8512-1a13d01310df,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-6b15fd3d-9f34-4905-abc9-8042621f62b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-29b8241f-9b36-4680-83a0-8fff1e739c16,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-5fc74d4a-26bd-496a-8c33-d17ffc54819d,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-0f14bd13-6266-4966-b526-b9b14efd1951,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-94a24ccc-a3da-411c-b6fc-c68881794b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-f188be88-ba35-4dd5-9abf-866e7b92773d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194112705-172.17.0.5-1595592161311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-a30bc65e-107b-4597-8520-be22a9cc3846,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-e0720633-e957-42df-b991-3f86c190fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-5feb4678-f887-4569-ad8b-e86eba5de988,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-6b4c4ddd-6f86-4b9f-8345-4c6849ea6d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-884fd2bf-d7ed-4481-8d47-d6ebf16c861c,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-1665759c-e4e1-4bd2-9182-b0f0029c2233,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-ef8b7050-b8be-4d80-8099-1e0efc7cf57c,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-f3ee2426-0a71-4b89-a1d9-9a49eec6f28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194112705-172.17.0.5-1595592161311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-a30bc65e-107b-4597-8520-be22a9cc3846,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-e0720633-e957-42df-b991-3f86c190fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-5feb4678-f887-4569-ad8b-e86eba5de988,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-6b4c4ddd-6f86-4b9f-8345-4c6849ea6d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-884fd2bf-d7ed-4481-8d47-d6ebf16c861c,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-1665759c-e4e1-4bd2-9182-b0f0029c2233,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-ef8b7050-b8be-4d80-8099-1e0efc7cf57c,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-f3ee2426-0a71-4b89-a1d9-9a49eec6f28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088133197-172.17.0.5-1595592305676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-d788a63d-02c9-470a-a333-65923bbc68ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-2dca0e55-becf-4156-9352-faa452a5fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-c7edad50-5c42-4b60-a21e-ee62b1a6ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-4e3fbfb0-4b88-40c9-8c0f-74e22b8c0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-d34d394b-d65a-46de-bcd2-befda7e661b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-7f5fc547-459b-4aaa-8ccc-1bcf5e48091d,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-484c0bb6-b429-436b-803e-25a7e5c97ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-7ad10ac5-8258-40dd-ba3d-a616f8fa385b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088133197-172.17.0.5-1595592305676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-d788a63d-02c9-470a-a333-65923bbc68ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-2dca0e55-becf-4156-9352-faa452a5fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-c7edad50-5c42-4b60-a21e-ee62b1a6ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-4e3fbfb0-4b88-40c9-8c0f-74e22b8c0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-d34d394b-d65a-46de-bcd2-befda7e661b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-7f5fc547-459b-4aaa-8ccc-1bcf5e48091d,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-484c0bb6-b429-436b-803e-25a7e5c97ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-7ad10ac5-8258-40dd-ba3d-a616f8fa385b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074117135-172.17.0.5-1595592622750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45698,DS-effe2beb-f973-462b-98d9-4d698ef0c028,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-339001d1-b044-4a32-bf24-4c353642b806,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-918dcb4b-6a70-47ae-bb5b-436541c2361d,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-a2aea91e-2234-43d4-a93a-85f9cbf17283,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-786e7e4b-d1b4-4dd8-b854-2dea30203fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-796063eb-2eec-4448-951a-d812084bd697,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-3feef411-4528-4213-a8fa-92ab1c185c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-c0ea1452-1780-4a40-86a8-fee65eeea879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074117135-172.17.0.5-1595592622750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45698,DS-effe2beb-f973-462b-98d9-4d698ef0c028,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-339001d1-b044-4a32-bf24-4c353642b806,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-918dcb4b-6a70-47ae-bb5b-436541c2361d,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-a2aea91e-2234-43d4-a93a-85f9cbf17283,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-786e7e4b-d1b4-4dd8-b854-2dea30203fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-796063eb-2eec-4448-951a-d812084bd697,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-3feef411-4528-4213-a8fa-92ab1c185c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-c0ea1452-1780-4a40-86a8-fee65eeea879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888581272-172.17.0.5-1595592692090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-84b285c6-d50c-48ed-ad93-f7f2221d227f,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-b724a86a-b23d-4c3c-9b0a-29b4003f6b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-ef9e0a27-5b47-4e71-8109-b824b6cbee58,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-dcead7f8-bf2d-423b-b442-9126cc0b6e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-85ba8dd5-9e1a-4ef9-8e7c-dfb847825d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-f14ea59b-2065-4832-96c3-eccb4d5e679d,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-fa04d40f-2454-416f-88e2-9a9080c843aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-feea69f8-8111-49b5-a736-dcf55e60b816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888581272-172.17.0.5-1595592692090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-84b285c6-d50c-48ed-ad93-f7f2221d227f,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-b724a86a-b23d-4c3c-9b0a-29b4003f6b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-ef9e0a27-5b47-4e71-8109-b824b6cbee58,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-dcead7f8-bf2d-423b-b442-9126cc0b6e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-85ba8dd5-9e1a-4ef9-8e7c-dfb847825d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-f14ea59b-2065-4832-96c3-eccb4d5e679d,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-fa04d40f-2454-416f-88e2-9a9080c843aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-feea69f8-8111-49b5-a736-dcf55e60b816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279582514-172.17.0.5-1595593037306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34301,DS-c9c1be1e-bd9c-4807-b99e-4067ec754675,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-f2bd54f9-f609-4ed2-8f8d-c71e94ad22a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-9fb37090-7b2a-4482-b374-c8be12f08ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-ac26df8a-2c54-4122-b3cf-9d39f1cb4011,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-0f696d11-eabb-489e-9faa-5a8444830346,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-92291937-3a3a-4efb-9d6d-79868b9657b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-a4d260ee-3c3e-4aa3-bf81-ef7617a486c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-7eb1ec83-6c54-42c1-aca3-a8f18980be49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279582514-172.17.0.5-1595593037306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34301,DS-c9c1be1e-bd9c-4807-b99e-4067ec754675,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-f2bd54f9-f609-4ed2-8f8d-c71e94ad22a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-9fb37090-7b2a-4482-b374-c8be12f08ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-ac26df8a-2c54-4122-b3cf-9d39f1cb4011,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-0f696d11-eabb-489e-9faa-5a8444830346,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-92291937-3a3a-4efb-9d6d-79868b9657b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-a4d260ee-3c3e-4aa3-bf81-ef7617a486c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-7eb1ec83-6c54-42c1-aca3-a8f18980be49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688364128-172.17.0.5-1595593447222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33233,DS-a4587bba-de85-4f4f-94ec-cf58b14526c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-67e77885-d4de-4feb-87e4-cdce0462a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-8b98278b-d872-4968-9c54-5065ebfd683a,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-4eac922b-f94e-4c5a-83ab-257d1a0d5a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-42ce622d-d005-402c-88a6-ce05d4299948,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-171f9dcd-3502-4bfa-b7f5-a5e4cbc75dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-8e14aa53-bee3-46a4-a54a-8653261100d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-54205543-56e1-4758-b481-2bb96557f476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688364128-172.17.0.5-1595593447222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33233,DS-a4587bba-de85-4f4f-94ec-cf58b14526c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-67e77885-d4de-4feb-87e4-cdce0462a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-8b98278b-d872-4968-9c54-5065ebfd683a,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-4eac922b-f94e-4c5a-83ab-257d1a0d5a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-42ce622d-d005-402c-88a6-ce05d4299948,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-171f9dcd-3502-4bfa-b7f5-a5e4cbc75dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-8e14aa53-bee3-46a4-a54a-8653261100d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-54205543-56e1-4758-b481-2bb96557f476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072222553-172.17.0.5-1595593697320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39305,DS-27d0fb77-f2aa-4582-904d-0197e5de9fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-cecd1176-5124-447a-a954-068d656e9092,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-f75cc6c7-2799-4159-84b2-1801dd98e044,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-df9d3fd2-2e89-4842-8396-a9356b88ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-877ac443-1882-42ae-9bc2-214a7a976203,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-de1e247d-6b72-49d8-8707-74bd22821dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-355b8653-da12-4ee5-9209-50af3fab1e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-81b85923-04e9-4782-a52d-7721842524a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072222553-172.17.0.5-1595593697320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39305,DS-27d0fb77-f2aa-4582-904d-0197e5de9fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-cecd1176-5124-447a-a954-068d656e9092,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-f75cc6c7-2799-4159-84b2-1801dd98e044,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-df9d3fd2-2e89-4842-8396-a9356b88ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-877ac443-1882-42ae-9bc2-214a7a976203,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-de1e247d-6b72-49d8-8707-74bd22821dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-355b8653-da12-4ee5-9209-50af3fab1e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-81b85923-04e9-4782-a52d-7721842524a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012322346-172.17.0.5-1595593834010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-ad2e9fe9-cf69-429c-86b1-4072f76301ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-f14db314-1fc7-481e-b8b8-62d0611b19e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-122de735-4ef7-4b8e-8b35-9e3011840b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-c4e687c0-d5fa-40fd-b94b-e83ce66bdfab,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-3e856ce1-a662-4120-9897-32b1f70a5d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-dddd872d-18fb-424b-9a44-091b7e9a1156,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-dfa65859-3b45-47bb-9fd3-415da034ab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-c7197d1e-c4de-43ee-a2c3-62ebe29a57ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012322346-172.17.0.5-1595593834010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-ad2e9fe9-cf69-429c-86b1-4072f76301ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-f14db314-1fc7-481e-b8b8-62d0611b19e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-122de735-4ef7-4b8e-8b35-9e3011840b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-c4e687c0-d5fa-40fd-b94b-e83ce66bdfab,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-3e856ce1-a662-4120-9897-32b1f70a5d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-dddd872d-18fb-424b-9a44-091b7e9a1156,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-dfa65859-3b45-47bb-9fd3-415da034ab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-c7197d1e-c4de-43ee-a2c3-62ebe29a57ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981916299-172.17.0.5-1595593937975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36223,DS-3483d50b-f294-4546-8d08-5213696fb2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-0b2e7698-ea25-4e07-a8c3-f94be43b0853,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-18535233-7d65-4b8d-90d0-e54683a0bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-c7032ab8-f043-431f-a292-3e7b86698ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-b5f2cb3e-4533-4d7e-af8b-56a3942cf81b,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-801d4052-9afb-484f-bd13-b086f4f7b75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-3d80be23-9010-4460-8fe2-7abb05a453c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-164a2f7d-ec68-4237-a58d-2ddb971c7456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981916299-172.17.0.5-1595593937975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36223,DS-3483d50b-f294-4546-8d08-5213696fb2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-0b2e7698-ea25-4e07-a8c3-f94be43b0853,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-18535233-7d65-4b8d-90d0-e54683a0bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-c7032ab8-f043-431f-a292-3e7b86698ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-b5f2cb3e-4533-4d7e-af8b-56a3942cf81b,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-801d4052-9afb-484f-bd13-b086f4f7b75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-3d80be23-9010-4460-8fe2-7abb05a453c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-164a2f7d-ec68-4237-a58d-2ddb971c7456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5394
