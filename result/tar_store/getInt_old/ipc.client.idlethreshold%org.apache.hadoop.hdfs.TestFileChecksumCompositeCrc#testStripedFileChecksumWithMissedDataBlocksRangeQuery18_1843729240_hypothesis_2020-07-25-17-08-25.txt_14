reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443570862-172.17.0.9-1595696956276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-3b726e0b-a7ac-49a2-8738-36681393c31c,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-496bb439-35e0-48e5-88da-2974012b7b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-87779902-5367-4d30-8145-31cc24f2f3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-0d099772-a9ae-4186-a64c-9d1fb1f7c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-a8588d98-9a54-4c50-b517-0b2f5a0f95a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-78dab456-50b7-492e-8864-0e60bef56596,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-408e1448-57fc-4fa4-a180-460cdd6e49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-e029c9f4-b687-4fe6-8e40-af3d0dcac95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443570862-172.17.0.9-1595696956276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-3b726e0b-a7ac-49a2-8738-36681393c31c,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-496bb439-35e0-48e5-88da-2974012b7b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-87779902-5367-4d30-8145-31cc24f2f3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-0d099772-a9ae-4186-a64c-9d1fb1f7c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-a8588d98-9a54-4c50-b517-0b2f5a0f95a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-78dab456-50b7-492e-8864-0e60bef56596,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-408e1448-57fc-4fa4-a180-460cdd6e49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-e029c9f4-b687-4fe6-8e40-af3d0dcac95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652963156-172.17.0.9-1595697065329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42192,DS-ef0aff81-24c0-44bf-b4b6-d2d23c3b7bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-9d283478-8267-4e9a-8f6a-20ddeafb53ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-8a9f9013-ea80-48df-9168-da11ad95cc22,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-f0a2d5f5-a60c-435d-8a22-88bd32038437,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-696d7382-8bc0-40eb-a8af-f8c2aecb646e,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-569a46aa-f0b5-4a86-9aea-ccd544af7709,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-23bcc200-982e-4619-81a7-1482961dae71,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-32d0eb2d-7355-4b91-a889-b218d4619eea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652963156-172.17.0.9-1595697065329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42192,DS-ef0aff81-24c0-44bf-b4b6-d2d23c3b7bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-9d283478-8267-4e9a-8f6a-20ddeafb53ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-8a9f9013-ea80-48df-9168-da11ad95cc22,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-f0a2d5f5-a60c-435d-8a22-88bd32038437,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-696d7382-8bc0-40eb-a8af-f8c2aecb646e,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-569a46aa-f0b5-4a86-9aea-ccd544af7709,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-23bcc200-982e-4619-81a7-1482961dae71,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-32d0eb2d-7355-4b91-a889-b218d4619eea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821240609-172.17.0.9-1595697182417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-bd14923f-86e4-4191-827d-135eca8d8a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-cc10aa87-1241-41d3-b315-a19d99fabe46,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-18200e50-7530-4230-9e59-ef5cdd7f45ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-806fb77e-3373-4a2a-a39c-14d97b685882,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-7ae8e98e-c069-447d-b30a-e33e179177c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-76a41a24-6bf3-4736-bc9c-c5f0f232b577,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-1ac11bd8-f5bb-438d-b22f-4ebb54b20402,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-a375ccd2-4a5f-40ad-aca5-94cc1a4c65d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821240609-172.17.0.9-1595697182417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-bd14923f-86e4-4191-827d-135eca8d8a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-cc10aa87-1241-41d3-b315-a19d99fabe46,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-18200e50-7530-4230-9e59-ef5cdd7f45ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-806fb77e-3373-4a2a-a39c-14d97b685882,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-7ae8e98e-c069-447d-b30a-e33e179177c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-76a41a24-6bf3-4736-bc9c-c5f0f232b577,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-1ac11bd8-f5bb-438d-b22f-4ebb54b20402,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-a375ccd2-4a5f-40ad-aca5-94cc1a4c65d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602092225-172.17.0.9-1595697583413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38159,DS-85f0fb32-7e42-4079-866a-dda4728531f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-f5dee3a1-73ba-4199-ab2c-4b70f099c3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-7834ae1a-7fdc-4e10-92b7-d86598a6e79d,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-b8938943-bc08-4402-b6ac-747269555d77,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-59a34c57-5a07-4fdb-8326-6003ea43be05,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-d9bbee94-66b8-4749-9c54-fcbcbc0bf471,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-360cf589-ce5e-4959-8ab1-bf5d2c62851b,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-0f929a5e-f1ec-4be6-9aba-a6d458ec48d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602092225-172.17.0.9-1595697583413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38159,DS-85f0fb32-7e42-4079-866a-dda4728531f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-f5dee3a1-73ba-4199-ab2c-4b70f099c3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-7834ae1a-7fdc-4e10-92b7-d86598a6e79d,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-b8938943-bc08-4402-b6ac-747269555d77,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-59a34c57-5a07-4fdb-8326-6003ea43be05,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-d9bbee94-66b8-4749-9c54-fcbcbc0bf471,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-360cf589-ce5e-4959-8ab1-bf5d2c62851b,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-0f929a5e-f1ec-4be6-9aba-a6d458ec48d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216876206-172.17.0.9-1595698574743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-e522b633-6530-4ffa-8958-aa3f353767dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-cfaba0c5-646c-439b-9c03-97c0cc8da267,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-9580998e-0087-437f-a6b0-8bbfbc4c803f,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-74df9d7e-c84b-45be-9a33-b50294696816,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-95642637-6b89-4e27-b4e1-a5a184a7f588,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-a99c87ee-9971-4071-a26f-151ebb6a0908,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-097f6485-4a07-426c-9579-67422fa655f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-5d5b3e90-255c-467d-abf2-e25848431a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216876206-172.17.0.9-1595698574743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-e522b633-6530-4ffa-8958-aa3f353767dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-cfaba0c5-646c-439b-9c03-97c0cc8da267,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-9580998e-0087-437f-a6b0-8bbfbc4c803f,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-74df9d7e-c84b-45be-9a33-b50294696816,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-95642637-6b89-4e27-b4e1-a5a184a7f588,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-a99c87ee-9971-4071-a26f-151ebb6a0908,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-097f6485-4a07-426c-9579-67422fa655f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-5d5b3e90-255c-467d-abf2-e25848431a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758651708-172.17.0.9-1595698642180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37509,DS-fdf6eff9-9490-449e-82d9-d0832fbada09,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-95fd13c1-855b-41b2-bcf0-1e61da91c4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-b4b1f05c-35d1-4dfd-bec3-593e5697b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-f7514afb-fb81-46b9-a217-3a77762c481c,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-538a1279-af8b-482f-be75-b635c55bd393,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-c1ea3a2f-1c26-4bb5-ae66-bb171e247a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-cdf88226-57f3-4317-9578-63fb1c2c2dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-7d51ea61-b91c-4ba2-a025-a85331a40627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758651708-172.17.0.9-1595698642180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37509,DS-fdf6eff9-9490-449e-82d9-d0832fbada09,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-95fd13c1-855b-41b2-bcf0-1e61da91c4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-b4b1f05c-35d1-4dfd-bec3-593e5697b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-f7514afb-fb81-46b9-a217-3a77762c481c,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-538a1279-af8b-482f-be75-b635c55bd393,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-c1ea3a2f-1c26-4bb5-ae66-bb171e247a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-cdf88226-57f3-4317-9578-63fb1c2c2dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-7d51ea61-b91c-4ba2-a025-a85331a40627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165288456-172.17.0.9-1595698903752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-0940e7f1-6bcd-41d4-9405-c18bf6328dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-d09a8efa-4b3a-4092-94e7-b2f13d66fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-18757358-6808-498b-bde8-0de1e98aead2,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-7cec26d2-2aba-4fce-8946-ce778d0ba50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-4f6636fd-339b-4067-9e2c-bfc854dd5890,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-608bfbc8-bb32-4529-a3d9-3f5efa3270ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-afb87f34-8d53-49fa-a044-65d8ecf20fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-7b6a2d28-bf9f-4ac0-b3f1-0aeca94044ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165288456-172.17.0.9-1595698903752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-0940e7f1-6bcd-41d4-9405-c18bf6328dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-d09a8efa-4b3a-4092-94e7-b2f13d66fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-18757358-6808-498b-bde8-0de1e98aead2,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-7cec26d2-2aba-4fce-8946-ce778d0ba50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-4f6636fd-339b-4067-9e2c-bfc854dd5890,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-608bfbc8-bb32-4529-a3d9-3f5efa3270ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-afb87f34-8d53-49fa-a044-65d8ecf20fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-7b6a2d28-bf9f-4ac0-b3f1-0aeca94044ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247366304-172.17.0.9-1595699470157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37796,DS-5c04213d-293c-46aa-863e-f46b27158970,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-387d048c-f5e2-46a5-9e76-fe81573cd05d,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-6af5c657-d279-4df3-b747-8055615bbf46,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-84491d88-cb72-401f-8fd2-e3eb9a1a4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-d85e46e7-6a24-47dd-beca-f3e1b758edb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-025a7da9-95e5-48fb-ad21-8665c60bc6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-2df13100-a405-4ae1-a0e2-c997ed645fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-714935df-aa46-41bd-812b-6fde8b9388ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247366304-172.17.0.9-1595699470157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37796,DS-5c04213d-293c-46aa-863e-f46b27158970,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-387d048c-f5e2-46a5-9e76-fe81573cd05d,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-6af5c657-d279-4df3-b747-8055615bbf46,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-84491d88-cb72-401f-8fd2-e3eb9a1a4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-d85e46e7-6a24-47dd-beca-f3e1b758edb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-025a7da9-95e5-48fb-ad21-8665c60bc6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-2df13100-a405-4ae1-a0e2-c997ed645fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-714935df-aa46-41bd-812b-6fde8b9388ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-360778012-172.17.0.9-1595699658401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-619761ab-9d18-4d6e-b462-64e942536756,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-fa153018-6359-48af-9180-03a2c1a95191,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-90a01740-9d3d-43db-81a7-909d4baa1dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-b75768d0-ded0-411a-af79-2531d8a49ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-3bf616c9-4e9a-4a04-a91a-4231e678303d,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-164c7f08-0373-4903-9f55-f6cc50662b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-c43c1007-1e9b-4f35-86b6-62648ee44266,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-c7a129cf-4129-4af6-b3bb-4ec0ab1ca83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-360778012-172.17.0.9-1595699658401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-619761ab-9d18-4d6e-b462-64e942536756,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-fa153018-6359-48af-9180-03a2c1a95191,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-90a01740-9d3d-43db-81a7-909d4baa1dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-b75768d0-ded0-411a-af79-2531d8a49ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-3bf616c9-4e9a-4a04-a91a-4231e678303d,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-164c7f08-0373-4903-9f55-f6cc50662b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-c43c1007-1e9b-4f35-86b6-62648ee44266,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-c7a129cf-4129-4af6-b3bb-4ec0ab1ca83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335829130-172.17.0.9-1595699990421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-844443ef-bc55-4b5a-84d8-84dc7e9835a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-122b5963-55f6-4745-be4e-10d90f7889f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-22847621-fdff-4f9a-9fb4-5762eabdbf15,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-6ee1c2a9-da40-433b-bdb7-31db70552f78,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-c480cfe6-68e1-403d-a7d2-3b9ae94397c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-184548d5-4c02-4ef5-8f48-5a2898aefa57,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-d1a0d83d-627c-41e6-9c1c-7fca03acbbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-0d74599a-7a4c-4847-bb43-3be89558a78c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335829130-172.17.0.9-1595699990421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-844443ef-bc55-4b5a-84d8-84dc7e9835a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-122b5963-55f6-4745-be4e-10d90f7889f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-22847621-fdff-4f9a-9fb4-5762eabdbf15,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-6ee1c2a9-da40-433b-bdb7-31db70552f78,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-c480cfe6-68e1-403d-a7d2-3b9ae94397c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-184548d5-4c02-4ef5-8f48-5a2898aefa57,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-d1a0d83d-627c-41e6-9c1c-7fca03acbbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-0d74599a-7a4c-4847-bb43-3be89558a78c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66151107-172.17.0.9-1595700026081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35166,DS-00ece059-bba1-4b95-a2ae-ac7d3af12db1,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-3781fc00-4d81-4de8-960a-c3de4fe3f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-baeac190-1ab2-4b7f-a4d2-d97154146677,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-b618f45e-648d-4a32-88cb-ae6d200cad83,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-8a5e5723-f1d2-4162-b40a-10faf9ec1743,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-743959d9-58be-4c9e-ac94-f923e753b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-e069be1e-5348-4575-b08e-225b73315fec,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-09195326-8780-4d93-91fd-0bf77e027aa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66151107-172.17.0.9-1595700026081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35166,DS-00ece059-bba1-4b95-a2ae-ac7d3af12db1,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-3781fc00-4d81-4de8-960a-c3de4fe3f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-baeac190-1ab2-4b7f-a4d2-d97154146677,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-b618f45e-648d-4a32-88cb-ae6d200cad83,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-8a5e5723-f1d2-4162-b40a-10faf9ec1743,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-743959d9-58be-4c9e-ac94-f923e753b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-e069be1e-5348-4575-b08e-225b73315fec,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-09195326-8780-4d93-91fd-0bf77e027aa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253152450-172.17.0.9-1595700097406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32932,DS-c67776c9-1e81-4bff-8d7a-01a7fabbf745,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-679e026c-113b-42ea-bb77-72aa5e6da37f,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-1901b99a-684f-4d74-afdf-532a52540778,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-a06a61ee-650c-409d-8adc-53fc01d31b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-d497592c-9937-474c-bc57-c0ed0d937998,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-52d48e2e-68fd-44f0-9cdf-363651191ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-2dc37d2b-ec74-46f3-83ec-020bc1c94876,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-0a34703d-02d0-4263-99c8-5cb8acd9c123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253152450-172.17.0.9-1595700097406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32932,DS-c67776c9-1e81-4bff-8d7a-01a7fabbf745,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-679e026c-113b-42ea-bb77-72aa5e6da37f,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-1901b99a-684f-4d74-afdf-532a52540778,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-a06a61ee-650c-409d-8adc-53fc01d31b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-d497592c-9937-474c-bc57-c0ed0d937998,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-52d48e2e-68fd-44f0-9cdf-363651191ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-2dc37d2b-ec74-46f3-83ec-020bc1c94876,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-0a34703d-02d0-4263-99c8-5cb8acd9c123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-263614652-172.17.0.9-1595700420457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42361,DS-25900846-2945-4c49-8700-2069d2409f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-864f931c-c46a-4870-9fbb-b1a622e0b8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-5f2ef53e-a0ec-43cf-a11b-da0b87035f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-173fca1a-31ab-496b-9742-8cb776076cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b4d83265-4a41-4bad-9158-0a7afa2bd950,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-404df1b6-cb35-43c6-a926-df436cc9acc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-82b322f1-00e3-4137-90ac-89cab2fd1718,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-8d9c25eb-d471-4185-9632-31b604738ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-263614652-172.17.0.9-1595700420457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42361,DS-25900846-2945-4c49-8700-2069d2409f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-864f931c-c46a-4870-9fbb-b1a622e0b8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-5f2ef53e-a0ec-43cf-a11b-da0b87035f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-173fca1a-31ab-496b-9742-8cb776076cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b4d83265-4a41-4bad-9158-0a7afa2bd950,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-404df1b6-cb35-43c6-a926-df436cc9acc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-82b322f1-00e3-4137-90ac-89cab2fd1718,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-8d9c25eb-d471-4185-9632-31b604738ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312426809-172.17.0.9-1595700780879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-4d891efb-71b9-4aad-8ca3-be4f2fd6dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-2f0cabe4-b16f-4f6a-8d01-2a9aee25bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-5d0eb8aa-466f-439c-896e-c11ded1851e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-69ab8f7f-9313-400b-83b1-5ec32c3fa978,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-68875796-2833-45fd-95a3-547e1b09f04c,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-51fc41c8-294e-4565-97ef-f471b8cac00e,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-9f200365-65ee-4b52-a5d6-86e2c67324e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-8d648f40-1f1c-4e9b-835b-cc3080a27cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312426809-172.17.0.9-1595700780879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-4d891efb-71b9-4aad-8ca3-be4f2fd6dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-2f0cabe4-b16f-4f6a-8d01-2a9aee25bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-5d0eb8aa-466f-439c-896e-c11ded1851e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-69ab8f7f-9313-400b-83b1-5ec32c3fa978,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-68875796-2833-45fd-95a3-547e1b09f04c,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-51fc41c8-294e-4565-97ef-f471b8cac00e,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-9f200365-65ee-4b52-a5d6-86e2c67324e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-8d648f40-1f1c-4e9b-835b-cc3080a27cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676682144-172.17.0.9-1595700815533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36072,DS-96130e05-a3bb-4842-a9fe-72a479a8d9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-372b5ab6-6fa8-48ec-ad85-5b40d56d57aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-4fce0e35-e78b-4a12-8740-303d5f2617c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-35afd1a4-3a19-4089-9788-6baf0a8e7de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-54e7c574-6c77-48b3-a766-377e44bb8c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-7665c6d9-2f4a-4b0c-806e-43500a413178,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-e3829e47-6f2d-4a47-9845-55138af69f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-4dc35127-4ce9-4c57-9ade-56dad0d9df43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676682144-172.17.0.9-1595700815533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36072,DS-96130e05-a3bb-4842-a9fe-72a479a8d9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-372b5ab6-6fa8-48ec-ad85-5b40d56d57aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-4fce0e35-e78b-4a12-8740-303d5f2617c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-35afd1a4-3a19-4089-9788-6baf0a8e7de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-54e7c574-6c77-48b3-a766-377e44bb8c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-7665c6d9-2f4a-4b0c-806e-43500a413178,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-e3829e47-6f2d-4a47-9845-55138af69f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-4dc35127-4ce9-4c57-9ade-56dad0d9df43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145153024-172.17.0.9-1595700927647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33406,DS-a51c8f40-c351-4154-beb5-316d34040a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-cff40fd8-049a-4727-bfef-3a888ccc39af,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-341b937c-9f1a-480d-bec6-97a33ca8bc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-914f17a0-2e00-4fc0-ac3e-b0b6f6e8a0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-e90277cc-0ae8-47ad-b14c-4ed2e0d32bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-a14923c2-1db5-4d6e-9cae-5b2ca20c8e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-7319354c-e585-4288-98c2-53646408b71d,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-52b64be9-fce1-4289-9a77-0bf284734d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145153024-172.17.0.9-1595700927647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33406,DS-a51c8f40-c351-4154-beb5-316d34040a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-cff40fd8-049a-4727-bfef-3a888ccc39af,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-341b937c-9f1a-480d-bec6-97a33ca8bc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-914f17a0-2e00-4fc0-ac3e-b0b6f6e8a0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-e90277cc-0ae8-47ad-b14c-4ed2e0d32bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-a14923c2-1db5-4d6e-9cae-5b2ca20c8e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-7319354c-e585-4288-98c2-53646408b71d,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-52b64be9-fce1-4289-9a77-0bf284734d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766289103-172.17.0.9-1595701213859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37948,DS-50d08797-7e54-46e8-a663-aa596dc911e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-dac671ce-fb17-48d7-8fd3-fcd868da1dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-f9592439-e563-44be-8d93-af5b74bfac65,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-5abafa55-a958-425f-87e2-607b822beaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-9ce6851a-b6aa-45d1-a5d2-5be2472b7121,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-ff9dd604-c6be-46ed-a3e0-c94a880a1bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-6d7ba2d9-5fd1-4810-89f3-b633aff2891b,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-19567116-df79-4e53-9e58-73422b5841aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766289103-172.17.0.9-1595701213859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37948,DS-50d08797-7e54-46e8-a663-aa596dc911e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-dac671ce-fb17-48d7-8fd3-fcd868da1dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-f9592439-e563-44be-8d93-af5b74bfac65,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-5abafa55-a958-425f-87e2-607b822beaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-9ce6851a-b6aa-45d1-a5d2-5be2472b7121,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-ff9dd604-c6be-46ed-a3e0-c94a880a1bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-6d7ba2d9-5fd1-4810-89f3-b633aff2891b,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-19567116-df79-4e53-9e58-73422b5841aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558091170-172.17.0.9-1595701430012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-c0bcef21-dd2b-4839-9c48-a85075a28346,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-eafb6724-257b-4afa-9932-84c2c5d5186d,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-f63345ef-d72d-4159-81f3-a3e7e0a067ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-8dcfd24d-f69f-44e0-9d59-90fce2600494,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-0d515a02-3556-4cc5-a1c1-e33ee44db99a,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-a81dff79-d3e4-45c7-bf47-b1a9f8f48e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-91fdade2-cb6d-42f4-bba0-8b7e4386495b,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-34fb13b0-3336-467d-b40f-7e1579c03ab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558091170-172.17.0.9-1595701430012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-c0bcef21-dd2b-4839-9c48-a85075a28346,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-eafb6724-257b-4afa-9932-84c2c5d5186d,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-f63345ef-d72d-4159-81f3-a3e7e0a067ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-8dcfd24d-f69f-44e0-9d59-90fce2600494,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-0d515a02-3556-4cc5-a1c1-e33ee44db99a,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-a81dff79-d3e4-45c7-bf47-b1a9f8f48e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-91fdade2-cb6d-42f4-bba0-8b7e4386495b,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-34fb13b0-3336-467d-b40f-7e1579c03ab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062352835-172.17.0.9-1595701645585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39591,DS-8e81fea3-37ff-4654-bf64-3641b64da1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-8f2b5c1c-65ea-451d-a1d1-a9ce13026a05,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-4d9cb7c0-163c-418c-b60b-c36e72ec67e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-0e6c862c-ef47-4a5d-80c3-5453ff28111f,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-a7766f59-098c-4031-b784-eee3e8a87386,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-d4226897-bcac-4716-9a74-dba615a8a48c,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-3d590ae3-8dd2-4874-8a75-e8d2f047c655,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-c61bbd86-d775-4f99-9da5-f04c0124239b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062352835-172.17.0.9-1595701645585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39591,DS-8e81fea3-37ff-4654-bf64-3641b64da1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-8f2b5c1c-65ea-451d-a1d1-a9ce13026a05,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-4d9cb7c0-163c-418c-b60b-c36e72ec67e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-0e6c862c-ef47-4a5d-80c3-5453ff28111f,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-a7766f59-098c-4031-b784-eee3e8a87386,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-d4226897-bcac-4716-9a74-dba615a8a48c,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-3d590ae3-8dd2-4874-8a75-e8d2f047c655,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-c61bbd86-d775-4f99-9da5-f04c0124239b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118533001-172.17.0.9-1595701724495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39102,DS-64cff281-e914-4634-b824-599585aad6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-18cb29a2-020f-4077-9174-ea371aec5d13,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-561abdf6-ba02-4455-a30f-b74679998475,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-be70a591-99ff-40b9-9166-ea95d46cea06,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-bf99f0d3-1dd3-43af-aa18-5c0166480d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-027b2759-78dc-4e85-b36e-6663f161aa75,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-37f799db-9424-4715-9b8e-eab21115c9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-1db4d0a5-ce47-4593-8b9b-148b90b77768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118533001-172.17.0.9-1595701724495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39102,DS-64cff281-e914-4634-b824-599585aad6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-18cb29a2-020f-4077-9174-ea371aec5d13,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-561abdf6-ba02-4455-a30f-b74679998475,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-be70a591-99ff-40b9-9166-ea95d46cea06,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-bf99f0d3-1dd3-43af-aa18-5c0166480d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-027b2759-78dc-4e85-b36e-6663f161aa75,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-37f799db-9424-4715-9b8e-eab21115c9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-1db4d0a5-ce47-4593-8b9b-148b90b77768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731322900-172.17.0.9-1595701899587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36620,DS-62944b14-62cb-49de-aed4-43e16a22793b,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-662d3341-b7ed-420f-bf64-f78babf3f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-6e69e1a8-dbb2-46b5-9063-457bc35ef1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-bd182adf-10ef-4f3e-882e-1d86e63443ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-d0118dc1-8f73-43e2-bc00-aecf351ec650,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-99295402-0075-4b0c-933c-e6a2534bbe65,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-eab398cf-b86b-4fd2-b3ee-240087b12981,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-deb1bd81-1ae3-4725-b52c-631b08c3607d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731322900-172.17.0.9-1595701899587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36620,DS-62944b14-62cb-49de-aed4-43e16a22793b,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-662d3341-b7ed-420f-bf64-f78babf3f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-6e69e1a8-dbb2-46b5-9063-457bc35ef1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-bd182adf-10ef-4f3e-882e-1d86e63443ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-d0118dc1-8f73-43e2-bc00-aecf351ec650,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-99295402-0075-4b0c-933c-e6a2534bbe65,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-eab398cf-b86b-4fd2-b3ee-240087b12981,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-deb1bd81-1ae3-4725-b52c-631b08c3607d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97811322-172.17.0.9-1595701941503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37746,DS-6fa2ec3a-3319-47e0-a3b6-c089d98e3bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-9034432d-315b-479c-b4a3-a2d4087ebd73,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-b07f0758-4d03-4357-a7bf-5cb35355bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-512885e8-be7f-43a4-8f03-908642059367,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-95f59187-9740-4c78-8965-a31fe38789aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-0f270a4d-3c4a-4fcf-b140-3d308dfe9da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-45de9e14-6d7f-4c24-949e-f053fed7bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-3b4ec635-754f-4f4f-9688-80b822f990c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97811322-172.17.0.9-1595701941503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37746,DS-6fa2ec3a-3319-47e0-a3b6-c089d98e3bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-9034432d-315b-479c-b4a3-a2d4087ebd73,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-b07f0758-4d03-4357-a7bf-5cb35355bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-512885e8-be7f-43a4-8f03-908642059367,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-95f59187-9740-4c78-8965-a31fe38789aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-0f270a4d-3c4a-4fcf-b140-3d308dfe9da5,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-45de9e14-6d7f-4c24-949e-f053fed7bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-3b4ec635-754f-4f4f-9688-80b822f990c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59809055-172.17.0.9-1595702018495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-11e94802-3042-4195-8f2e-63b72b9834d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-a9646b86-a463-45e5-ba76-b0b462a0b34b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-a31e8640-1b70-4d6e-aec2-93262506ab07,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-87119b42-1491-42c2-a12b-efa7de774b60,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-8e9d9f9d-38b2-4fcd-bdad-d3bee54abd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-d45258ba-1777-4975-b657-e4c664a53357,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-81ee320e-1d71-42ad-97e6-cdefd876af18,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-d6276666-a7d8-4006-87a1-731e49e62c36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59809055-172.17.0.9-1595702018495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-11e94802-3042-4195-8f2e-63b72b9834d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-a9646b86-a463-45e5-ba76-b0b462a0b34b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-a31e8640-1b70-4d6e-aec2-93262506ab07,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-87119b42-1491-42c2-a12b-efa7de774b60,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-8e9d9f9d-38b2-4fcd-bdad-d3bee54abd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-d45258ba-1777-4975-b657-e4c664a53357,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-81ee320e-1d71-42ad-97e6-cdefd876af18,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-d6276666-a7d8-4006-87a1-731e49e62c36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245344541-172.17.0.9-1595702286892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46163,DS-6a4ba5c4-1eaf-4151-9971-962e0f84f540,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-cdb58b6e-0c03-4759-83fb-12c3d70f8083,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-338ddb72-5ecd-4371-9722-f4b75c288dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-f24ee01b-5280-4114-b6b2-24d28b429832,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-aa78f7af-8ea8-4226-b26c-ee10ec44816c,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-b3c40df8-b423-4a03-9ea4-375fe8648598,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-84d2066a-e173-426d-b6b2-fb3f02f84677,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-c806f055-2b83-44e5-b9ae-b2d47b64e8da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245344541-172.17.0.9-1595702286892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46163,DS-6a4ba5c4-1eaf-4151-9971-962e0f84f540,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-cdb58b6e-0c03-4759-83fb-12c3d70f8083,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-338ddb72-5ecd-4371-9722-f4b75c288dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-f24ee01b-5280-4114-b6b2-24d28b429832,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-aa78f7af-8ea8-4226-b26c-ee10ec44816c,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-b3c40df8-b423-4a03-9ea4-375fe8648598,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-84d2066a-e173-426d-b6b2-fb3f02f84677,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-c806f055-2b83-44e5-b9ae-b2d47b64e8da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5513
