reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712826207-172.17.0.3-1595523628122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-fa7ddac0-14ea-4e5f-982a-cb40d42d01ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-479e74e5-6fd5-45c7-a203-ea0e858e7f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-5bd23c40-2893-41b9-bbc9-90ec205f0333,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-244f5628-531e-4a7d-afd3-877391454085,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-bddbb45a-ad9d-4fcd-9ce2-c499bbff2acd,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-38c009de-eea4-485e-9d8d-38e87fedb875,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-679d4c89-b5d9-4c7f-8e00-3299aaf78738,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-c09702e1-a77a-45a1-92b8-b695d02bb40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712826207-172.17.0.3-1595523628122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-fa7ddac0-14ea-4e5f-982a-cb40d42d01ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-479e74e5-6fd5-45c7-a203-ea0e858e7f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-5bd23c40-2893-41b9-bbc9-90ec205f0333,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-244f5628-531e-4a7d-afd3-877391454085,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-bddbb45a-ad9d-4fcd-9ce2-c499bbff2acd,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-38c009de-eea4-485e-9d8d-38e87fedb875,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-679d4c89-b5d9-4c7f-8e00-3299aaf78738,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-c09702e1-a77a-45a1-92b8-b695d02bb40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439911888-172.17.0.3-1595523923307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43459,DS-05d5559f-f57f-4f56-b930-69537e5e7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-f6c3f585-c4f8-4121-bdff-f3cadb73a673,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-f4d4e4ed-94e3-4b9f-b975-3ddfc6ae0d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-1c87a53a-e9c5-4635-b1c4-f6ef0d6fbfed,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-f07fa7ea-d605-4369-b5b1-6815485db738,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-aee5e606-9473-432e-8412-d8cc165c233e,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-a29d42fe-119d-4ecc-8dec-466fed9cd417,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-7d294449-106f-43a0-a287-efcda07432af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439911888-172.17.0.3-1595523923307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43459,DS-05d5559f-f57f-4f56-b930-69537e5e7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-f6c3f585-c4f8-4121-bdff-f3cadb73a673,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-f4d4e4ed-94e3-4b9f-b975-3ddfc6ae0d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-1c87a53a-e9c5-4635-b1c4-f6ef0d6fbfed,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-f07fa7ea-d605-4369-b5b1-6815485db738,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-aee5e606-9473-432e-8412-d8cc165c233e,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-a29d42fe-119d-4ecc-8dec-466fed9cd417,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-7d294449-106f-43a0-a287-efcda07432af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344640135-172.17.0.3-1595523960824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33324,DS-4cc9f39c-fd66-468b-a96c-fd2263123789,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-06eaa605-9cdc-45ec-bb52-4983c4ef5044,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-aaed7126-0c13-4e23-bc19-ff991b91d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-eb5d01d5-8ede-4a41-80de-8d26d485108f,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-3f944100-c9bd-4b5f-8be6-534ab776e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-b9972f79-644f-475b-b7dd-8da93609bc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-94415fe0-4c21-4f99-b375-0be359671e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-01c28c68-e1c4-40d1-b698-1274d3deda41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344640135-172.17.0.3-1595523960824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33324,DS-4cc9f39c-fd66-468b-a96c-fd2263123789,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-06eaa605-9cdc-45ec-bb52-4983c4ef5044,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-aaed7126-0c13-4e23-bc19-ff991b91d5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-eb5d01d5-8ede-4a41-80de-8d26d485108f,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-3f944100-c9bd-4b5f-8be6-534ab776e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-b9972f79-644f-475b-b7dd-8da93609bc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-94415fe0-4c21-4f99-b375-0be359671e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-01c28c68-e1c4-40d1-b698-1274d3deda41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341762213-172.17.0.3-1595525002434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-3fd6996b-e21f-416b-bddd-a6cd9ca9bdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-9c816e46-f426-44c5-b102-265528a77157,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-afa8ea28-77d0-43b0-bc6d-a1d4779b22ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-3558dc46-ec22-4e09-a537-3e908bfe9edb,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-d19f4d84-f0da-4153-86e6-1def50a64764,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-0110a212-03d8-4176-8cb9-2dbc9b4f6e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-a876f86d-d60b-4e1e-87fb-9cc97fc92706,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-ab872cf9-692d-4dc8-a50c-6ddd517de691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341762213-172.17.0.3-1595525002434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-3fd6996b-e21f-416b-bddd-a6cd9ca9bdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-9c816e46-f426-44c5-b102-265528a77157,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-afa8ea28-77d0-43b0-bc6d-a1d4779b22ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-3558dc46-ec22-4e09-a537-3e908bfe9edb,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-d19f4d84-f0da-4153-86e6-1def50a64764,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-0110a212-03d8-4176-8cb9-2dbc9b4f6e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-a876f86d-d60b-4e1e-87fb-9cc97fc92706,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-ab872cf9-692d-4dc8-a50c-6ddd517de691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826856338-172.17.0.3-1595525077825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46726,DS-37f3b1f6-3d28-45f3-ab6a-de4868b8bab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-e0f5f2c8-cf62-4965-a0f1-8e33a2571baa,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-72b5361c-deb5-48a4-b4c9-018ef8274a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-f2e7ce26-7229-425a-9053-25754204f2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-76bdfdaf-90da-4412-85f1-9028cde691a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-b433c153-5026-41c8-b9cd-71ef69503433,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-d562f087-7099-4d28-8d9f-fce81b4caf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-24f19229-ac3e-4bce-b2b0-257939eafaae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826856338-172.17.0.3-1595525077825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46726,DS-37f3b1f6-3d28-45f3-ab6a-de4868b8bab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-e0f5f2c8-cf62-4965-a0f1-8e33a2571baa,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-72b5361c-deb5-48a4-b4c9-018ef8274a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-f2e7ce26-7229-425a-9053-25754204f2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-76bdfdaf-90da-4412-85f1-9028cde691a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-b433c153-5026-41c8-b9cd-71ef69503433,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-d562f087-7099-4d28-8d9f-fce81b4caf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-24f19229-ac3e-4bce-b2b0-257939eafaae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173731462-172.17.0.3-1595525265243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41052,DS-23b8f74c-db22-4746-95c5-d8e1665f0064,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-d96fb956-85ad-4aa1-bf10-c2d7a11f76d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-f34dab35-c68b-4624-8b2b-d8e00c00aa83,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-49c18a0c-e726-473b-bb42-1c622e1c54ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-1aefab8f-d842-4322-9197-049882e52e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-c66cfa8b-4f85-48a6-987a-3fc41ffa953d,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-a8935929-1b60-488f-b8b4-43605d5a0846,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-1ad5b64e-7464-4aa1-b9a3-02f6ce8c8b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173731462-172.17.0.3-1595525265243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41052,DS-23b8f74c-db22-4746-95c5-d8e1665f0064,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-d96fb956-85ad-4aa1-bf10-c2d7a11f76d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-f34dab35-c68b-4624-8b2b-d8e00c00aa83,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-49c18a0c-e726-473b-bb42-1c622e1c54ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-1aefab8f-d842-4322-9197-049882e52e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-c66cfa8b-4f85-48a6-987a-3fc41ffa953d,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-a8935929-1b60-488f-b8b4-43605d5a0846,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-1ad5b64e-7464-4aa1-b9a3-02f6ce8c8b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014484741-172.17.0.3-1595525955227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-08f03c58-fdc0-4af2-a1a5-b0114c53b283,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-c129fc10-f39e-4fd6-ba7e-e30f7787ef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-6daac372-e71f-473c-b588-7b8156f4cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-61402561-64ac-4536-a9cd-47da4728e418,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-e1852674-09e3-43ee-840f-88e5a305a235,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-5f1dcb6c-8cac-44d7-8daf-a81afc9aeea7,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-f3c0dce4-43c5-4cba-a904-48a530ec8245,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-751b0aaa-3b08-4e81-bab6-3c43a83b53d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014484741-172.17.0.3-1595525955227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-08f03c58-fdc0-4af2-a1a5-b0114c53b283,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-c129fc10-f39e-4fd6-ba7e-e30f7787ef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-6daac372-e71f-473c-b588-7b8156f4cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-61402561-64ac-4536-a9cd-47da4728e418,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-e1852674-09e3-43ee-840f-88e5a305a235,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-5f1dcb6c-8cac-44d7-8daf-a81afc9aeea7,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-f3c0dce4-43c5-4cba-a904-48a530ec8245,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-751b0aaa-3b08-4e81-bab6-3c43a83b53d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354261239-172.17.0.3-1595526102302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-d8e7058a-b067-4089-a579-800809e37ded,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-53a4790d-0665-404f-b5ac-bb68e61066f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-885df489-e6bc-4214-a18b-300a5e652c95,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-4119066a-e230-43e6-8dd5-e0d9145a532a,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-67a20952-8557-4231-a5a9-05ad67b9b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-49eead4f-8ca8-4f2b-b85b-7fe14a4470eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-2bab50a2-e8bc-44c2-a33a-e4d094af396b,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-6d8e6875-caeb-41ff-9e6d-dc180177350e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354261239-172.17.0.3-1595526102302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-d8e7058a-b067-4089-a579-800809e37ded,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-53a4790d-0665-404f-b5ac-bb68e61066f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-885df489-e6bc-4214-a18b-300a5e652c95,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-4119066a-e230-43e6-8dd5-e0d9145a532a,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-67a20952-8557-4231-a5a9-05ad67b9b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-49eead4f-8ca8-4f2b-b85b-7fe14a4470eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-2bab50a2-e8bc-44c2-a33a-e4d094af396b,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-6d8e6875-caeb-41ff-9e6d-dc180177350e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537200180-172.17.0.3-1595526359718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-3cc56391-74de-4b21-9180-8d678a4292b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-8cf58b2f-5da1-48b2-8b9a-229b9bf9f41f,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-0bd1b124-4bad-47ff-9f77-0f24f364deff,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-9518a164-56c5-4513-aded-b60e013d8632,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-e0320fa3-92f6-4c40-81e8-40e950498cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-0f186173-4472-43b9-9dfd-d4ef215c0233,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-9514bc27-535f-4b4f-8ce2-aba2dda22913,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-e9a23b78-b097-4b7b-a170-5f3bcc072203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537200180-172.17.0.3-1595526359718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-3cc56391-74de-4b21-9180-8d678a4292b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-8cf58b2f-5da1-48b2-8b9a-229b9bf9f41f,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-0bd1b124-4bad-47ff-9f77-0f24f364deff,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-9518a164-56c5-4513-aded-b60e013d8632,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-e0320fa3-92f6-4c40-81e8-40e950498cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-0f186173-4472-43b9-9dfd-d4ef215c0233,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-9514bc27-535f-4b4f-8ce2-aba2dda22913,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-e9a23b78-b097-4b7b-a170-5f3bcc072203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657544268-172.17.0.3-1595526399404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-2ad45768-38c8-4eac-866a-e5161ae1c408,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-ca2fb86c-d13b-4e74-81c4-b76c3dee8f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-d3825762-e90d-49a1-b9d6-4f99b76c5cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-2128570d-f2fb-43dc-987e-dcab308b9181,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-150ec5aa-84c4-46f8-a7d2-cbe4af47b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-32567c4d-3996-4e76-bff4-a244154a75ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-ada369d8-3984-44b0-b103-3ea6c0a50b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-73898b34-90c3-4735-b4e9-edf788a9f01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657544268-172.17.0.3-1595526399404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-2ad45768-38c8-4eac-866a-e5161ae1c408,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-ca2fb86c-d13b-4e74-81c4-b76c3dee8f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-d3825762-e90d-49a1-b9d6-4f99b76c5cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-2128570d-f2fb-43dc-987e-dcab308b9181,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-150ec5aa-84c4-46f8-a7d2-cbe4af47b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-32567c4d-3996-4e76-bff4-a244154a75ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-ada369d8-3984-44b0-b103-3ea6c0a50b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-73898b34-90c3-4735-b4e9-edf788a9f01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807569823-172.17.0.3-1595526570518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42257,DS-756d3651-0e4c-460e-86c2-04b52493c1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-59087ffa-0a09-4df7-9046-c2c53bf2f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-4cb8542d-b36f-4f5b-b204-f3653ff59660,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-dd3b7942-26ca-4c13-a96a-32fcb0d0f5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-284a5392-5055-44dd-be63-59c02f598e27,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-955e5ccd-e7b3-4bc1-90a5-0082ba9bf6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-d4302b59-9ab9-4b5a-a377-a091f4a67f86,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-85b7442d-50b8-4070-bd9f-32347cb146bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807569823-172.17.0.3-1595526570518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42257,DS-756d3651-0e4c-460e-86c2-04b52493c1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-59087ffa-0a09-4df7-9046-c2c53bf2f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-4cb8542d-b36f-4f5b-b204-f3653ff59660,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-dd3b7942-26ca-4c13-a96a-32fcb0d0f5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-284a5392-5055-44dd-be63-59c02f598e27,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-955e5ccd-e7b3-4bc1-90a5-0082ba9bf6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-d4302b59-9ab9-4b5a-a377-a091f4a67f86,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-85b7442d-50b8-4070-bd9f-32347cb146bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066484144-172.17.0.3-1595527185814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-27d9cb14-a1a2-49eb-ad53-f4de24654ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-396ff522-7b3b-427d-9536-474101e01944,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-edea704b-ad19-4a39-96cf-4d40aa444154,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-6a3a2b1c-9402-481e-877a-d518eb34c260,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-2f6b2e37-94c0-4c51-ba05-50ed20f42a04,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-428bbe56-1dd7-4ac5-8719-744fdb416e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-25f612e3-1811-422f-b77d-dd48fb6d6536,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-9499f26f-8b00-4c9b-9936-4aec554e68ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066484144-172.17.0.3-1595527185814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-27d9cb14-a1a2-49eb-ad53-f4de24654ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-396ff522-7b3b-427d-9536-474101e01944,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-edea704b-ad19-4a39-96cf-4d40aa444154,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-6a3a2b1c-9402-481e-877a-d518eb34c260,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-2f6b2e37-94c0-4c51-ba05-50ed20f42a04,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-428bbe56-1dd7-4ac5-8719-744fdb416e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-25f612e3-1811-422f-b77d-dd48fb6d6536,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-9499f26f-8b00-4c9b-9936-4aec554e68ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579447596-172.17.0.3-1595527608893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38820,DS-187f0383-ac7a-4b70-a542-ab5b48180fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-cfa3d3ba-7846-465c-ac18-43ff55579f98,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-52502b07-0e5f-413a-88dd-ea979cb0d378,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-93faf5fd-ad11-45ce-a28b-14a5a3e291ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-fb52da0e-2db4-4153-9b7b-29dfda3bde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e61f035d-0ee7-422e-88a6-78ed878bcd63,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-795f0b11-45d2-40d0-b69f-9573c104a365,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-be7eae3e-fd71-49d5-8832-78e738acc910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579447596-172.17.0.3-1595527608893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38820,DS-187f0383-ac7a-4b70-a542-ab5b48180fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-cfa3d3ba-7846-465c-ac18-43ff55579f98,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-52502b07-0e5f-413a-88dd-ea979cb0d378,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-93faf5fd-ad11-45ce-a28b-14a5a3e291ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-fb52da0e-2db4-4153-9b7b-29dfda3bde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-e61f035d-0ee7-422e-88a6-78ed878bcd63,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-795f0b11-45d2-40d0-b69f-9573c104a365,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-be7eae3e-fd71-49d5-8832-78e738acc910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231869877-172.17.0.3-1595527872303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-7db6762e-80e4-4178-98a2-b8ae889995e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-b9308a30-ed95-40e7-a8e1-53d0ce20918e,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-95bc7a7d-5539-4d66-aa4d-43e8d39ba471,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-d3ba04ad-ce86-4e83-bbbb-1be6c99cb2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-73468f21-7117-4e22-b2fe-de562a7fc672,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-70ed45e5-41a0-4141-a69c-97194193f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-227b440c-f301-43dd-a7a8-c881eeede7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-60017a5c-77bb-4759-9d89-627e4c0edc1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231869877-172.17.0.3-1595527872303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-7db6762e-80e4-4178-98a2-b8ae889995e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-b9308a30-ed95-40e7-a8e1-53d0ce20918e,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-95bc7a7d-5539-4d66-aa4d-43e8d39ba471,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-d3ba04ad-ce86-4e83-bbbb-1be6c99cb2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-73468f21-7117-4e22-b2fe-de562a7fc672,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-70ed45e5-41a0-4141-a69c-97194193f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-227b440c-f301-43dd-a7a8-c881eeede7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-60017a5c-77bb-4759-9d89-627e4c0edc1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980681701-172.17.0.3-1595527907675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-b060199e-4eb7-40f6-883b-871c1e960609,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-18a385eb-9747-4237-9b52-a332eef56ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-b461639c-efe0-4676-b08a-914c22ca0f78,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-78d79f61-38a1-474c-92ce-18edb9a7cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-3b378ee8-c4f7-487f-b342-7e8fd9b04375,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-b8ce5b6e-3b3d-40be-9345-2a2f8fce7e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-8c168d72-6484-48ad-82ab-bc45ef898173,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-619e234c-fda6-40d0-b069-d3ad45635df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980681701-172.17.0.3-1595527907675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-b060199e-4eb7-40f6-883b-871c1e960609,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-18a385eb-9747-4237-9b52-a332eef56ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-b461639c-efe0-4676-b08a-914c22ca0f78,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-78d79f61-38a1-474c-92ce-18edb9a7cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-3b378ee8-c4f7-487f-b342-7e8fd9b04375,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-b8ce5b6e-3b3d-40be-9345-2a2f8fce7e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-8c168d72-6484-48ad-82ab-bc45ef898173,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-619e234c-fda6-40d0-b069-d3ad45635df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 2097152
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064830325-172.17.0.3-1595528403520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-43610b9e-73fa-46b2-bd15-4dd5f5be40ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-32da0543-ed46-4043-ba45-4afa719cfb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-80a41f23-1181-4ce6-a731-128052e85af2,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-3f328a8f-5df5-462d-8815-07cfd0745092,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-deaacbd8-d727-470f-b89a-1bade5d6a57d,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-9f9b6cec-a25e-4879-9014-dbad5ede87ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-04037eb9-4784-4f44-b2e7-8d64da3636c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-1f4246fb-2f43-4d5c-9130-4a613ab0cb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064830325-172.17.0.3-1595528403520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-43610b9e-73fa-46b2-bd15-4dd5f5be40ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-32da0543-ed46-4043-ba45-4afa719cfb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-80a41f23-1181-4ce6-a731-128052e85af2,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-3f328a8f-5df5-462d-8815-07cfd0745092,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-deaacbd8-d727-470f-b89a-1bade5d6a57d,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-9f9b6cec-a25e-4879-9014-dbad5ede87ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-04037eb9-4784-4f44-b2e7-8d64da3636c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-1f4246fb-2f43-4d5c-9130-4a613ab0cb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5515
