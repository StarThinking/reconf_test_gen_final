reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654406693-172.17.0.3-1595567177427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37091,DS-65931afb-e717-4f7f-a2ed-94d7a2f24c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-fcbd9271-ea40-4d43-be2f-1c139804f09a,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-92f7d5bf-2112-48ef-940a-3cac698f321b,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-601f525d-8416-4564-9bb3-bd7769af7ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-65772b01-8598-475f-8cc1-1965a94a31e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-01fdd53f-ae76-4254-a8fa-0ecba6d8c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-f20dcd74-efac-49b7-b9b4-32df776d66bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-a327a1cf-cc61-4f68-8a4f-5f63f4e09bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654406693-172.17.0.3-1595567177427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37091,DS-65931afb-e717-4f7f-a2ed-94d7a2f24c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-fcbd9271-ea40-4d43-be2f-1c139804f09a,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-92f7d5bf-2112-48ef-940a-3cac698f321b,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-601f525d-8416-4564-9bb3-bd7769af7ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-65772b01-8598-475f-8cc1-1965a94a31e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-01fdd53f-ae76-4254-a8fa-0ecba6d8c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-f20dcd74-efac-49b7-b9b4-32df776d66bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-a327a1cf-cc61-4f68-8a4f-5f63f4e09bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673821897-172.17.0.3-1595567399025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44481,DS-ed52df67-e186-4f35-ae2d-177872a1a081,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-5b9a86a3-62b5-44e8-ab9a-44b0cacae7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-9b746759-401f-4ab0-8b85-b053f811f8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-3d66f7a5-cc71-46f9-bd7a-843655f1178c,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-8fc90197-4216-4b15-979b-d952220d91b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-d6d398fa-b110-4a8c-b8eb-0f75c07219f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-c80af5fd-033d-454b-9848-a1fe416ce2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-17b0d6fe-869f-4c29-be51-6356e192c4d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673821897-172.17.0.3-1595567399025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44481,DS-ed52df67-e186-4f35-ae2d-177872a1a081,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-5b9a86a3-62b5-44e8-ab9a-44b0cacae7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-9b746759-401f-4ab0-8b85-b053f811f8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-3d66f7a5-cc71-46f9-bd7a-843655f1178c,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-8fc90197-4216-4b15-979b-d952220d91b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-d6d398fa-b110-4a8c-b8eb-0f75c07219f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-c80af5fd-033d-454b-9848-a1fe416ce2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-17b0d6fe-869f-4c29-be51-6356e192c4d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570141910-172.17.0.3-1595567535259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-3486a9d2-0506-453b-8a75-dfbdb24eec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-a14f59fc-8273-4352-9705-40a15b4b8ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-1926343e-ee33-40b7-b68e-559d77aa13e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-eca921f3-6a1d-4230-8ade-25369dd08975,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-19393dff-04eb-4285-844c-b9cf53697a32,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-502e103a-a221-40d1-9759-110d21d9f413,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-3ea2a4c1-e9c2-4d73-8caa-5060e20d9cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-3da05163-9c9e-4c57-887f-d0baee6eaf49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570141910-172.17.0.3-1595567535259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-3486a9d2-0506-453b-8a75-dfbdb24eec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-a14f59fc-8273-4352-9705-40a15b4b8ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-1926343e-ee33-40b7-b68e-559d77aa13e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-eca921f3-6a1d-4230-8ade-25369dd08975,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-19393dff-04eb-4285-844c-b9cf53697a32,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-502e103a-a221-40d1-9759-110d21d9f413,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-3ea2a4c1-e9c2-4d73-8caa-5060e20d9cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-3da05163-9c9e-4c57-887f-d0baee6eaf49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038100818-172.17.0.3-1595567817811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33009,DS-85504ccf-fd95-4762-8e28-6195b8e7a1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-ee92819f-43a2-4fa3-92aa-c037dd34b653,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-32784443-2ad5-41f4-8031-4e5603f871f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-80087764-c50e-4010-9097-d0fabb9e2fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-ea592ccd-ba3c-4491-b2d9-407961dd2225,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-dee2e7c0-a0d3-4fbd-be81-ee0ae07a2f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-b61bd463-93e9-47f4-8efb-0bd69a461ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-ceb4d1e8-ba29-47a9-9571-25a8f53502a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038100818-172.17.0.3-1595567817811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33009,DS-85504ccf-fd95-4762-8e28-6195b8e7a1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-ee92819f-43a2-4fa3-92aa-c037dd34b653,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-32784443-2ad5-41f4-8031-4e5603f871f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-80087764-c50e-4010-9097-d0fabb9e2fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-ea592ccd-ba3c-4491-b2d9-407961dd2225,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-dee2e7c0-a0d3-4fbd-be81-ee0ae07a2f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-b61bd463-93e9-47f4-8efb-0bd69a461ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-ceb4d1e8-ba29-47a9-9571-25a8f53502a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963033414-172.17.0.3-1595571150864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-f293c9ac-52ed-4f3c-95b0-5e88d230eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-6f548fca-480e-4c40-b7e2-b659e17021f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-be939e72-942d-4294-b08c-f20f5a7f0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-c5f7fc43-e81f-4cd5-ac3f-2f30617dc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-a4be3f5e-3d86-4a78-a956-a779a673572c,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-735312da-c6db-4dd2-b589-f389cae8ff9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-cf5d04f3-5a34-4dd4-b397-a94228074060,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-03a0c69f-fe11-4123-86fc-e835063a1c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963033414-172.17.0.3-1595571150864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-f293c9ac-52ed-4f3c-95b0-5e88d230eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-6f548fca-480e-4c40-b7e2-b659e17021f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-be939e72-942d-4294-b08c-f20f5a7f0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-c5f7fc43-e81f-4cd5-ac3f-2f30617dc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-a4be3f5e-3d86-4a78-a956-a779a673572c,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-735312da-c6db-4dd2-b589-f389cae8ff9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-cf5d04f3-5a34-4dd4-b397-a94228074060,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-03a0c69f-fe11-4123-86fc-e835063a1c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596276154-172.17.0.3-1595571215920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33523,DS-20442106-8ace-4b91-b0aa-b692b47c95dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-e264fbc6-990d-4fcf-ae63-8d62d52a8895,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-c25c9eab-bdc3-42f8-b694-ad699623489b,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-6d91daf1-f463-4856-b71c-95c7ac0c99f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-a247ce11-1d66-4f34-8243-933ab145c8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-fc3a4252-31fb-441d-aedf-5549ddd635f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-988ee76f-fafa-4ec1-b090-90ba4cfde047,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-41cd5201-dfac-4591-ae65-4c3b927c0bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596276154-172.17.0.3-1595571215920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33523,DS-20442106-8ace-4b91-b0aa-b692b47c95dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-e264fbc6-990d-4fcf-ae63-8d62d52a8895,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-c25c9eab-bdc3-42f8-b694-ad699623489b,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-6d91daf1-f463-4856-b71c-95c7ac0c99f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-a247ce11-1d66-4f34-8243-933ab145c8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-fc3a4252-31fb-441d-aedf-5549ddd635f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-988ee76f-fafa-4ec1-b090-90ba4cfde047,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-41cd5201-dfac-4591-ae65-4c3b927c0bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524223087-172.17.0.3-1595571285901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32933,DS-b5e01985-00a1-496c-b452-e1403c1f94f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-a7a0586e-e402-4ba5-ae83-fc2256042368,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-595a577f-2ee7-4e0c-ab88-2da44f6c1805,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-41c02785-edf6-439e-b1d8-9a4fafd2da1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-7324e58d-068c-4253-bbbe-1233bb97f9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-94ae7b61-3e20-45b8-a9e7-1c442470e809,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-69072676-f311-478a-88c0-3fc19264bfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-bae772fc-e36a-4410-975c-b341fa69fbb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524223087-172.17.0.3-1595571285901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32933,DS-b5e01985-00a1-496c-b452-e1403c1f94f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-a7a0586e-e402-4ba5-ae83-fc2256042368,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-595a577f-2ee7-4e0c-ab88-2da44f6c1805,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-41c02785-edf6-439e-b1d8-9a4fafd2da1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-7324e58d-068c-4253-bbbe-1233bb97f9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-94ae7b61-3e20-45b8-a9e7-1c442470e809,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-69072676-f311-478a-88c0-3fc19264bfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-bae772fc-e36a-4410-975c-b341fa69fbb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297414528-172.17.0.3-1595571790591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32804,DS-d8fe88bf-a2c8-4d83-aace-65074a8ac47f,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-fb2f041a-f719-4e97-9fe8-7c5db8f14942,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-08037abd-74ed-48af-bb1d-2bb866a00644,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-5a30e045-2e0d-48e0-9b16-be6bc3b3fdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-6be4612d-975d-45de-80e9-c5deefe3f433,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-38ba2d99-f535-4c6b-bb8f-1cc5204e7733,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-32fd3913-b13b-4e05-9335-6bf3c82aed38,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-adc1aa6f-f0af-4afa-ba6b-a530d7965c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297414528-172.17.0.3-1595571790591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32804,DS-d8fe88bf-a2c8-4d83-aace-65074a8ac47f,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-fb2f041a-f719-4e97-9fe8-7c5db8f14942,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-08037abd-74ed-48af-bb1d-2bb866a00644,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-5a30e045-2e0d-48e0-9b16-be6bc3b3fdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-6be4612d-975d-45de-80e9-c5deefe3f433,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-38ba2d99-f535-4c6b-bb8f-1cc5204e7733,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-32fd3913-b13b-4e05-9335-6bf3c82aed38,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-adc1aa6f-f0af-4afa-ba6b-a530d7965c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369017918-172.17.0.3-1595571893655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36676,DS-1a59ea02-ce05-4c6b-af71-0e47c133b3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-78221f98-478e-4bff-a0e0-354f4950597f,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-80c3092a-36a6-4d0f-a8da-debacad286fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-84586b1e-7ffc-4b9a-bbc2-8ef253a1c4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-1737f497-7787-46bb-a273-51fd0d6779dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-b70ae373-d759-4ea9-b5c0-6d055f48dbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-b7277a21-7679-4fcb-934e-18192b4876e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-a400aa6f-2a03-4127-8778-913309685a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369017918-172.17.0.3-1595571893655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36676,DS-1a59ea02-ce05-4c6b-af71-0e47c133b3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-78221f98-478e-4bff-a0e0-354f4950597f,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-80c3092a-36a6-4d0f-a8da-debacad286fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-84586b1e-7ffc-4b9a-bbc2-8ef253a1c4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-1737f497-7787-46bb-a273-51fd0d6779dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-b70ae373-d759-4ea9-b5c0-6d055f48dbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-b7277a21-7679-4fcb-934e-18192b4876e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-a400aa6f-2a03-4127-8778-913309685a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socketcache.capacity
component: hdfs:NameNode
v1: 16
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481326525-172.17.0.3-1595571961100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45690,DS-1f723039-c48d-4795-84cf-02aa09b5d712,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-a47659de-ed89-4e55-b222-971bec358dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-771c2fa4-8ae7-4f6f-9771-496630f07ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-3b78d35d-152e-4d8e-9301-22b09aae3d15,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-f71a25a2-3c63-4cad-aa22-cd997f2159f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-d6e81ad6-814d-4ffe-a1b2-6e972dea578d,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-eefddf58-a0e8-4299-89ac-8d1145d6c521,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-06cd4ab2-e6e2-4fd1-b10d-8aa1c2f813fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481326525-172.17.0.3-1595571961100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45690,DS-1f723039-c48d-4795-84cf-02aa09b5d712,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-a47659de-ed89-4e55-b222-971bec358dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-771c2fa4-8ae7-4f6f-9771-496630f07ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-3b78d35d-152e-4d8e-9301-22b09aae3d15,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-f71a25a2-3c63-4cad-aa22-cd997f2159f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-d6e81ad6-814d-4ffe-a1b2-6e972dea578d,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-eefddf58-a0e8-4299-89ac-8d1145d6c521,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-06cd4ab2-e6e2-4fd1-b10d-8aa1c2f813fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5348
