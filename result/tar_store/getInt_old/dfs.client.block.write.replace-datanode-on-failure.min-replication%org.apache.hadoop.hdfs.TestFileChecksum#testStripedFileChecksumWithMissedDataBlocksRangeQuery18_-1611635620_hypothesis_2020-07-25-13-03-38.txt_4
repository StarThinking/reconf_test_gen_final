reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569242689-172.17.0.13-1595682611024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45328,DS-a74ec67c-3b5a-4368-b2c9-d7c5c047975d,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-19b1e4b5-8621-4082-a77a-68db97cf383f,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-05d8be43-cb79-445e-b54a-dfbdf0e4ff88,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-a147194b-401c-478d-b600-5b1a88a0acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-9970b986-bc87-4335-be41-308591743427,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-39f2a795-f0ad-4b56-bb6b-f530104977e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-2aef582d-1418-42d5-96e6-f1ae1287005f,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-bcee0fb0-d969-4919-b46e-f0cc4e3bbfa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569242689-172.17.0.13-1595682611024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45328,DS-a74ec67c-3b5a-4368-b2c9-d7c5c047975d,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-19b1e4b5-8621-4082-a77a-68db97cf383f,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-05d8be43-cb79-445e-b54a-dfbdf0e4ff88,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-a147194b-401c-478d-b600-5b1a88a0acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-9970b986-bc87-4335-be41-308591743427,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-39f2a795-f0ad-4b56-bb6b-f530104977e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-2aef582d-1418-42d5-96e6-f1ae1287005f,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-bcee0fb0-d969-4919-b46e-f0cc4e3bbfa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253905740-172.17.0.13-1595683586731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46033,DS-dae38632-8960-449f-bd15-aefba2ad61d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-a6c2f3c9-b987-4614-a470-94f9069d8500,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-afeaa70c-6c84-4a99-b766-bb8577e4d62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-9065e469-4042-4f81-a999-7c160c5722bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-946318d0-5a71-499d-a8f7-e1b3e6ddd027,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-f5e1e294-c486-4bd6-915e-8f4c9d847a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-5e02fede-e0c9-4469-8634-4c793a8a755f,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-fb3e138a-35ee-4195-a84c-a902014f2c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253905740-172.17.0.13-1595683586731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46033,DS-dae38632-8960-449f-bd15-aefba2ad61d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-a6c2f3c9-b987-4614-a470-94f9069d8500,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-afeaa70c-6c84-4a99-b766-bb8577e4d62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-9065e469-4042-4f81-a999-7c160c5722bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-946318d0-5a71-499d-a8f7-e1b3e6ddd027,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-f5e1e294-c486-4bd6-915e-8f4c9d847a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-5e02fede-e0c9-4469-8634-4c793a8a755f,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-fb3e138a-35ee-4195-a84c-a902014f2c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956181741-172.17.0.13-1595684794252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41697,DS-6706d943-e7b3-4a53-9ce1-14c6e5c81362,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-59775a97-d690-464d-9d8a-541a72bf46f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-d1b8ff62-10a0-4ddf-b11d-fce51ab75490,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-5d35d761-0314-4ac1-af32-6ec35cff9807,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-d38b6182-6840-4fa3-a146-22e01e0b1f61,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-2a743a5e-3d04-49d4-8496-588e51c30bca,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-a2aa0999-97e5-45f5-a8b7-b108b129288c,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-90cc954e-4c0a-47ed-82c5-6d17a9d1944a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956181741-172.17.0.13-1595684794252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41697,DS-6706d943-e7b3-4a53-9ce1-14c6e5c81362,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-59775a97-d690-464d-9d8a-541a72bf46f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-d1b8ff62-10a0-4ddf-b11d-fce51ab75490,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-5d35d761-0314-4ac1-af32-6ec35cff9807,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-d38b6182-6840-4fa3-a146-22e01e0b1f61,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-2a743a5e-3d04-49d4-8496-588e51c30bca,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-a2aa0999-97e5-45f5-a8b7-b108b129288c,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-90cc954e-4c0a-47ed-82c5-6d17a9d1944a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313118298-172.17.0.13-1595684832908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38959,DS-edce8dc3-e603-4777-a02f-e4abfd672184,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-799a14be-f8e2-43f4-8f4b-555b717cb15d,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-1da80d31-420f-487d-af12-66fa1da34ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-82e0e421-6e9f-4e20-872b-38590b8e8fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-de186d57-161c-43d5-a5b2-619c332d9712,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-0027cac4-9757-4866-8408-d4eb68c56c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-b54ac9c0-7d7d-4bc4-852a-fa6ea67f0123,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-a91b772e-a7af-424d-8e02-73930a85f8b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313118298-172.17.0.13-1595684832908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38959,DS-edce8dc3-e603-4777-a02f-e4abfd672184,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-799a14be-f8e2-43f4-8f4b-555b717cb15d,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-1da80d31-420f-487d-af12-66fa1da34ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-82e0e421-6e9f-4e20-872b-38590b8e8fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-de186d57-161c-43d5-a5b2-619c332d9712,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-0027cac4-9757-4866-8408-d4eb68c56c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-b54ac9c0-7d7d-4bc4-852a-fa6ea67f0123,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-a91b772e-a7af-424d-8e02-73930a85f8b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952470957-172.17.0.13-1595685218879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-bc4aac4f-0e72-4072-95f4-859a68bac6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-5b3b0b5b-8eac-4c83-801a-8fa89534b514,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-f78dc585-0f2d-41bb-b7c7-4507c0b2684d,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-a7478fed-c482-4a67-a3be-c997b680f759,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-ae00b430-c3c9-4fc3-84d5-3ad8c3cff6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-d0fe78aa-2f55-4a4b-b204-7776f6746f76,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-91b67c28-a176-453e-97ae-0d6a3afafe37,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-da408491-477e-4443-a072-ad27a79f1d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952470957-172.17.0.13-1595685218879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-bc4aac4f-0e72-4072-95f4-859a68bac6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-5b3b0b5b-8eac-4c83-801a-8fa89534b514,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-f78dc585-0f2d-41bb-b7c7-4507c0b2684d,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-a7478fed-c482-4a67-a3be-c997b680f759,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-ae00b430-c3c9-4fc3-84d5-3ad8c3cff6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-d0fe78aa-2f55-4a4b-b204-7776f6746f76,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-91b67c28-a176-453e-97ae-0d6a3afafe37,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-da408491-477e-4443-a072-ad27a79f1d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171256390-172.17.0.13-1595685747595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-a4770212-4996-4a1b-a21e-229dd2660de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-03169c84-0d1e-4e3e-bd9a-61273a9c33fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-364c57d0-574e-455c-81a5-b34017440a22,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-91668326-cbf7-4f3d-b048-20e0f5f5f841,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-4f22470e-0d55-4ca7-a32e-c7af21f6357b,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-80813286-e3a3-47d9-98cc-a4c7e40f04be,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-8ffdaf06-500a-4e1c-b172-f5b47e1a72bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-dd29bde5-b688-4251-8152-b2f2a48c36b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171256390-172.17.0.13-1595685747595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-a4770212-4996-4a1b-a21e-229dd2660de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-03169c84-0d1e-4e3e-bd9a-61273a9c33fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-364c57d0-574e-455c-81a5-b34017440a22,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-91668326-cbf7-4f3d-b048-20e0f5f5f841,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-4f22470e-0d55-4ca7-a32e-c7af21f6357b,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-80813286-e3a3-47d9-98cc-a4c7e40f04be,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-8ffdaf06-500a-4e1c-b172-f5b47e1a72bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-dd29bde5-b688-4251-8152-b2f2a48c36b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188579674-172.17.0.13-1595686538452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41916,DS-36d264e2-f31e-4876-a30b-8090abc06531,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-3ae0f026-49b5-4d26-8e75-e5dacd183458,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-849a3c84-61ec-4a10-b14d-a515be22b9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-aafa51f7-3667-46c8-82bb-a35226b7e536,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-b8908061-ae9b-4552-8947-471739241592,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-b7ed26fd-9581-403b-a255-f7408c37442d,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-870b1ca8-11b9-4b0b-8cff-861bf03be01f,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-cc3be7e8-f9ae-4f10-b9ed-dfcd028ef5ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188579674-172.17.0.13-1595686538452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41916,DS-36d264e2-f31e-4876-a30b-8090abc06531,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-3ae0f026-49b5-4d26-8e75-e5dacd183458,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-849a3c84-61ec-4a10-b14d-a515be22b9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-aafa51f7-3667-46c8-82bb-a35226b7e536,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-b8908061-ae9b-4552-8947-471739241592,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-b7ed26fd-9581-403b-a255-f7408c37442d,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-870b1ca8-11b9-4b0b-8cff-861bf03be01f,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-cc3be7e8-f9ae-4f10-b9ed-dfcd028ef5ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167346030-172.17.0.13-1595686569351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-5ac26ad4-a32b-4388-87ba-80260419b60a,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-f69a6689-b27d-4f84-ab26-e525eb23059a,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-8fbdaf15-bcdc-4ff7-b28f-f2f6881219d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-e12a3f1a-e42e-408f-88ba-59cb34089bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-cbec367a-a13c-428f-b020-ab1c4fcdd144,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-29e755c5-bf24-4b95-9c61-5fe12ba8c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-ffcb3531-f1b3-44b9-9ae2-6be6e95e4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-37f7368d-8188-45a8-adf4-d357c3c85a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167346030-172.17.0.13-1595686569351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-5ac26ad4-a32b-4388-87ba-80260419b60a,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-f69a6689-b27d-4f84-ab26-e525eb23059a,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-8fbdaf15-bcdc-4ff7-b28f-f2f6881219d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-e12a3f1a-e42e-408f-88ba-59cb34089bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-cbec367a-a13c-428f-b020-ab1c4fcdd144,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-29e755c5-bf24-4b95-9c61-5fe12ba8c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-ffcb3531-f1b3-44b9-9ae2-6be6e95e4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-37f7368d-8188-45a8-adf4-d357c3c85a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444464306-172.17.0.13-1595687619546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-ddff4017-91fc-45bf-923a-acdeeb3f79a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-09c81dc9-e887-4860-ae72-1b10c6f668f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-1175ed6f-3294-4973-8d72-a119a789ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-861ed178-c886-425b-8976-8aa1685bd358,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-93a94e71-4d0a-40bc-bdd5-d5931c6903ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-2f5893ba-479f-4e7b-9023-9dd10e8a92c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-035b852e-04e2-4c23-a137-285247c9bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-b17aa5b7-48a7-4cc4-875b-dae148764225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444464306-172.17.0.13-1595687619546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-ddff4017-91fc-45bf-923a-acdeeb3f79a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-09c81dc9-e887-4860-ae72-1b10c6f668f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-1175ed6f-3294-4973-8d72-a119a789ba3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-861ed178-c886-425b-8976-8aa1685bd358,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-93a94e71-4d0a-40bc-bdd5-d5931c6903ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-2f5893ba-479f-4e7b-9023-9dd10e8a92c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-035b852e-04e2-4c23-a137-285247c9bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-b17aa5b7-48a7-4cc4-875b-dae148764225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: false positive !!!
Total execution time in seconds : 5425
