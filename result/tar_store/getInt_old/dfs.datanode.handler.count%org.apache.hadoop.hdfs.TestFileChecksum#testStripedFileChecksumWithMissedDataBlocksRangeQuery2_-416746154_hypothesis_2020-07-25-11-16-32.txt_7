reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991226906-172.17.0.5-1595676280849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-e2e74b8f-06f8-4d68-a409-a144e685ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-7b502745-213b-4a17-88d0-0e5a8e794aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-1f15bc65-da8c-4079-aa68-940f0ced218e,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-961de732-22f6-4ef7-9912-0d240d4b1016,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-6d1e04fe-3710-414c-8728-d2acd4243ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-9cade29c-f934-4954-98a7-498dd328651b,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-6bffaa3a-bce4-48b6-b08f-6d2c00f5afc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-b990e817-4fc9-489e-baa7-d7783dcd9357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991226906-172.17.0.5-1595676280849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-e2e74b8f-06f8-4d68-a409-a144e685ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-7b502745-213b-4a17-88d0-0e5a8e794aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-1f15bc65-da8c-4079-aa68-940f0ced218e,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-961de732-22f6-4ef7-9912-0d240d4b1016,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-6d1e04fe-3710-414c-8728-d2acd4243ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-9cade29c-f934-4954-98a7-498dd328651b,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-6bffaa3a-bce4-48b6-b08f-6d2c00f5afc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-b990e817-4fc9-489e-baa7-d7783dcd9357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811256373-172.17.0.5-1595676415147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45808,DS-50ac31a2-f076-4cf5-bdf1-b54a904cb695,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-04680ad1-8a76-4d24-b4c0-210533d8bbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-fe0ca0e7-62fa-43ee-9226-8c939080d66c,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-63e0eea5-7462-404d-96b8-d87c9d39bad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-47f1a96e-266b-4173-8de7-596cafdb0d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-d60d2b28-dff7-4d9c-8161-6de77eb58499,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-61d9caf2-58d1-46da-8127-416884ca2685,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-49258b15-4f99-4b9a-969c-f55f3d92b27b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811256373-172.17.0.5-1595676415147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45808,DS-50ac31a2-f076-4cf5-bdf1-b54a904cb695,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-04680ad1-8a76-4d24-b4c0-210533d8bbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-fe0ca0e7-62fa-43ee-9226-8c939080d66c,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-63e0eea5-7462-404d-96b8-d87c9d39bad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-47f1a96e-266b-4173-8de7-596cafdb0d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-d60d2b28-dff7-4d9c-8161-6de77eb58499,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-61d9caf2-58d1-46da-8127-416884ca2685,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-49258b15-4f99-4b9a-969c-f55f3d92b27b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690702737-172.17.0.5-1595676541992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-cf113ca5-d601-403a-a1cf-3a94a6e2c792,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-9f035b17-b0f5-4b67-8f10-ceededa11311,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-abde3b1a-4306-4243-9c42-2efe7234d782,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-10fd7335-4ab9-472b-a25c-d349639f6d27,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-1e36d8be-489b-4477-8def-a3ae74c7af27,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-2769e442-90a6-422d-b97c-3b7e4804c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-552b1f63-a24e-418c-afe4-7c333b5abd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-c854ce8c-4aa2-4566-b04d-99e5b6917bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690702737-172.17.0.5-1595676541992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-cf113ca5-d601-403a-a1cf-3a94a6e2c792,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-9f035b17-b0f5-4b67-8f10-ceededa11311,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-abde3b1a-4306-4243-9c42-2efe7234d782,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-10fd7335-4ab9-472b-a25c-d349639f6d27,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-1e36d8be-489b-4477-8def-a3ae74c7af27,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-2769e442-90a6-422d-b97c-3b7e4804c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-552b1f63-a24e-418c-afe4-7c333b5abd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-c854ce8c-4aa2-4566-b04d-99e5b6917bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159385999-172.17.0.5-1595676639885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35170,DS-19d34d9a-053f-4665-8beb-0b3997285b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-88b22483-9744-4e65-b890-3ed89a40c271,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-c518dc4a-490f-41a4-9d9b-8f61a5c2d884,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-b333d431-eab9-47f0-89d5-726110a7b503,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-840a5a11-1d99-40ec-a01d-737703a2f3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-f1a41f3d-f981-41fb-9ce6-9e1ceafa0476,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-fbe8527a-ef7d-40f3-b770-93ab3f24dfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-f231e31f-1467-4b35-af5c-e263e3f4282c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159385999-172.17.0.5-1595676639885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35170,DS-19d34d9a-053f-4665-8beb-0b3997285b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-88b22483-9744-4e65-b890-3ed89a40c271,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-c518dc4a-490f-41a4-9d9b-8f61a5c2d884,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-b333d431-eab9-47f0-89d5-726110a7b503,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-840a5a11-1d99-40ec-a01d-737703a2f3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-f1a41f3d-f981-41fb-9ce6-9e1ceafa0476,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-fbe8527a-ef7d-40f3-b770-93ab3f24dfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-f231e31f-1467-4b35-af5c-e263e3f4282c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846954038-172.17.0.5-1595676716291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37403,DS-f699fcf3-ca35-4a89-8d39-15ca37f34b91,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-76cd3343-601d-4fcc-b6c1-ad054af07caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-dd146dde-722e-4c89-8d07-356a1aa97e80,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-12e4e3ff-9e56-4c7d-9cf0-49d321a400ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-5c2f73f3-a4e5-4f2f-abc0-4a5f74afd9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-016ab0ff-2142-41f3-928c-7cf87e8029b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-7ca2858b-dcaa-4a3b-aca5-bf4cdeabca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-67c2f2b8-06cc-46dc-beda-6ab46c5cad34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846954038-172.17.0.5-1595676716291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37403,DS-f699fcf3-ca35-4a89-8d39-15ca37f34b91,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-76cd3343-601d-4fcc-b6c1-ad054af07caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-dd146dde-722e-4c89-8d07-356a1aa97e80,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-12e4e3ff-9e56-4c7d-9cf0-49d321a400ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-5c2f73f3-a4e5-4f2f-abc0-4a5f74afd9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-016ab0ff-2142-41f3-928c-7cf87e8029b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-7ca2858b-dcaa-4a3b-aca5-bf4cdeabca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-67c2f2b8-06cc-46dc-beda-6ab46c5cad34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948197330-172.17.0.5-1595677186415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-636e1b23-ab17-416c-82f3-9396d8dad16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-6719543f-409c-4995-acbd-6894c7441c85,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-7c531706-5d82-4f96-b05f-32bac680a20e,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-a55a2c1f-ccc4-46e1-8a6e-d83abb8844b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-d37e9a41-357f-44dd-a086-cb398460211c,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-25cb4260-397d-4b6c-8483-f1d9686aed87,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-e20e131e-2cb5-463a-b44e-c42566be8293,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-64ef3507-97ac-4da7-9f67-78018ab25416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948197330-172.17.0.5-1595677186415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-636e1b23-ab17-416c-82f3-9396d8dad16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-6719543f-409c-4995-acbd-6894c7441c85,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-7c531706-5d82-4f96-b05f-32bac680a20e,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-a55a2c1f-ccc4-46e1-8a6e-d83abb8844b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-d37e9a41-357f-44dd-a086-cb398460211c,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-25cb4260-397d-4b6c-8483-f1d9686aed87,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-e20e131e-2cb5-463a-b44e-c42566be8293,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-64ef3507-97ac-4da7-9f67-78018ab25416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317055314-172.17.0.5-1595677492060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45412,DS-fa1e0cbf-66e5-448f-b781-2b9cd7b53eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-b5a90315-6c9e-430d-a700-d2bed7417312,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-1e5b1e21-9c31-4867-839d-26677a0402a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-c401e077-2509-4573-9615-9c4a90c083bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-b80b45b0-642b-4b55-bcc7-20fdfbc604ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-5c6b781d-ff56-4a70-b367-d5ebfafe44b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-80600c72-7942-430f-85f7-144a8c125dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-635a30b2-ffc2-465a-b68c-eb6c090dc102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317055314-172.17.0.5-1595677492060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45412,DS-fa1e0cbf-66e5-448f-b781-2b9cd7b53eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-b5a90315-6c9e-430d-a700-d2bed7417312,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-1e5b1e21-9c31-4867-839d-26677a0402a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-c401e077-2509-4573-9615-9c4a90c083bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-b80b45b0-642b-4b55-bcc7-20fdfbc604ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-5c6b781d-ff56-4a70-b367-d5ebfafe44b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-80600c72-7942-430f-85f7-144a8c125dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-635a30b2-ffc2-465a-b68c-eb6c090dc102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154163540-172.17.0.5-1595677921098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-f82ef350-b949-41a4-81cd-e7f42d592a32,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-e0b67bbc-8f2c-4aaa-8200-27644e61bcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-9dd0e7f9-4d08-4e72-8db2-a2a2cc3df617,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-d3503409-520f-4a98-b19b-617571ee0d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-7cd7d8e3-eeed-420a-8d4e-de204569da2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-557290e0-8a32-4694-b30a-4757095876a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-1d27324c-d028-4f96-a81e-ebc58e402bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-5d92e96c-8c43-4d1f-b7ff-a11061106aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154163540-172.17.0.5-1595677921098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-f82ef350-b949-41a4-81cd-e7f42d592a32,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-e0b67bbc-8f2c-4aaa-8200-27644e61bcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-9dd0e7f9-4d08-4e72-8db2-a2a2cc3df617,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-d3503409-520f-4a98-b19b-617571ee0d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-7cd7d8e3-eeed-420a-8d4e-de204569da2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-557290e0-8a32-4694-b30a-4757095876a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-1d27324c-d028-4f96-a81e-ebc58e402bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-5d92e96c-8c43-4d1f-b7ff-a11061106aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530712042-172.17.0.5-1595677955366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-491e5934-0fb0-4831-ad7f-bb37be536698,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-58f74546-92d9-4997-941b-79cdac80a39e,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-05986c23-b732-4215-b6cc-e9932717c6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-ae578caa-fca1-4d90-b675-3d683d07168d,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-f40b6dbf-8222-4e1e-9990-36689585b76a,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-48de051c-bf36-471c-87d4-481d67f5bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-928a0350-9e28-4722-b6a3-9bd7f26a3d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-61035ef6-ae91-40ba-8731-e8031090f608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530712042-172.17.0.5-1595677955366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-491e5934-0fb0-4831-ad7f-bb37be536698,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-58f74546-92d9-4997-941b-79cdac80a39e,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-05986c23-b732-4215-b6cc-e9932717c6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-ae578caa-fca1-4d90-b675-3d683d07168d,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-f40b6dbf-8222-4e1e-9990-36689585b76a,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-48de051c-bf36-471c-87d4-481d67f5bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-928a0350-9e28-4722-b6a3-9bd7f26a3d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-61035ef6-ae91-40ba-8731-e8031090f608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035183226-172.17.0.5-1595679155238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-1eacd11a-fb78-4099-ab5e-ba2ee61d59d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-9585abf6-0151-4eba-a8b1-fa7f00b61c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-2768f765-572b-4856-9147-9e60f20a7c36,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-e6cd1fc5-5baa-48ba-995e-95e03fd6b79a,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-05d976bb-d7c8-4420-99ae-f950a5839f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-a61f859a-1968-43e3-ae77-06c1b22c572f,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-e548395d-7f13-40a9-a3a9-880a492c253b,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-55df3fd5-264c-4e1a-818f-2c79d74a7c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035183226-172.17.0.5-1595679155238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-1eacd11a-fb78-4099-ab5e-ba2ee61d59d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-9585abf6-0151-4eba-a8b1-fa7f00b61c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-2768f765-572b-4856-9147-9e60f20a7c36,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-e6cd1fc5-5baa-48ba-995e-95e03fd6b79a,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-05d976bb-d7c8-4420-99ae-f950a5839f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-a61f859a-1968-43e3-ae77-06c1b22c572f,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-e548395d-7f13-40a9-a3a9-880a492c253b,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-55df3fd5-264c-4e1a-818f-2c79d74a7c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869559191-172.17.0.5-1595679298359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43862,DS-7b6f21d1-7d49-4ad4-8a6f-792b51f46b77,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-849e53eb-2164-46f6-ae3b-40b8b2d9e355,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-c134d2b9-f03a-44b1-9811-9cf1fe621a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-57321d5c-10b8-4ed6-8306-7f5f98dbdc39,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-9e3d3538-4282-477d-b67d-ca81eb66ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-b44676e1-1d48-4c48-b98c-60d414f5bd85,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-02fbcc87-e1ea-4b55-8fb2-089e12bd0934,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-dc5d162a-b6d5-4100-b0d5-6f7bcda689d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869559191-172.17.0.5-1595679298359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43862,DS-7b6f21d1-7d49-4ad4-8a6f-792b51f46b77,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-849e53eb-2164-46f6-ae3b-40b8b2d9e355,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-c134d2b9-f03a-44b1-9811-9cf1fe621a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-57321d5c-10b8-4ed6-8306-7f5f98dbdc39,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-9e3d3538-4282-477d-b67d-ca81eb66ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-b44676e1-1d48-4c48-b98c-60d414f5bd85,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-02fbcc87-e1ea-4b55-8fb2-089e12bd0934,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-dc5d162a-b6d5-4100-b0d5-6f7bcda689d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155869725-172.17.0.5-1595679369685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35698,DS-103a9ef0-e4d1-449d-895e-cf27ce07d535,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-f3e0ee1c-6d88-463f-922d-1a18120781b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-e864db1f-4b45-45ad-9668-7618519a9a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-77771a58-1eda-4076-8a7b-c8a3db03bbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-07c95032-e0d4-451a-9206-f28e2f070907,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-7f065cb2-4771-471c-ba6e-28893a10b498,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-376ea234-d131-4a49-afea-6eafcf5960bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-8b076240-30eb-4301-b301-8081d743fdbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155869725-172.17.0.5-1595679369685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35698,DS-103a9ef0-e4d1-449d-895e-cf27ce07d535,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-f3e0ee1c-6d88-463f-922d-1a18120781b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-e864db1f-4b45-45ad-9668-7618519a9a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-77771a58-1eda-4076-8a7b-c8a3db03bbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-07c95032-e0d4-451a-9206-f28e2f070907,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-7f065cb2-4771-471c-ba6e-28893a10b498,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-376ea234-d131-4a49-afea-6eafcf5960bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-8b076240-30eb-4301-b301-8081d743fdbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764202040-172.17.0.5-1595679441513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-1974ae73-e90a-497c-b6ea-cfad53228dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-06f22544-d587-40ad-a1df-d9c7108b5d44,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-5eb188a3-761a-4cd5-8854-1190c1e948cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-cbf6fda2-20ef-468c-80ac-5e048b8839ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-f04a68b8-3096-4bbb-b57a-69249c710615,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-d01752fc-19eb-477a-ba8a-0f0bab0f0089,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-04124eed-05d5-4c0a-bada-583f8a28243d,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-c67e9976-82cf-4ac5-af85-0797f076c42b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764202040-172.17.0.5-1595679441513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-1974ae73-e90a-497c-b6ea-cfad53228dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-06f22544-d587-40ad-a1df-d9c7108b5d44,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-5eb188a3-761a-4cd5-8854-1190c1e948cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-cbf6fda2-20ef-468c-80ac-5e048b8839ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-f04a68b8-3096-4bbb-b57a-69249c710615,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-d01752fc-19eb-477a-ba8a-0f0bab0f0089,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-04124eed-05d5-4c0a-bada-583f8a28243d,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-c67e9976-82cf-4ac5-af85-0797f076c42b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121771702-172.17.0.5-1595679778051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36924,DS-23f2bba9-9ef2-419a-9646-b471c2be56b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-e35e79bb-fd53-4588-854c-1d17cbf8ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-db6b419d-9a28-46a3-b4cc-cf246aef8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-c36e637b-3010-45a3-a0a2-7965297feab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-b4ff8e5e-ef61-4ed3-ba3c-dce1fa960a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-4a7945e5-fa28-4670-86ec-c3842ae92a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-6a83d752-73e5-42ce-bcc2-0c5c788a0d93,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-f89cd43b-ea34-4842-94d5-dee1c3a603ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121771702-172.17.0.5-1595679778051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36924,DS-23f2bba9-9ef2-419a-9646-b471c2be56b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-e35e79bb-fd53-4588-854c-1d17cbf8ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-db6b419d-9a28-46a3-b4cc-cf246aef8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-c36e637b-3010-45a3-a0a2-7965297feab0,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-b4ff8e5e-ef61-4ed3-ba3c-dce1fa960a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-4a7945e5-fa28-4670-86ec-c3842ae92a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-6a83d752-73e5-42ce-bcc2-0c5c788a0d93,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-f89cd43b-ea34-4842-94d5-dee1c3a603ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437313101-172.17.0.5-1595679854053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33099,DS-e91b7bd9-1212-499f-b4cd-625b4276c7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-01b51b14-db6a-4bf7-b706-55631fa89c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-90fdd3ff-c5c2-4c24-a7a5-39d6a31a1fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-d4411842-d80e-46b9-b5c9-541c0dda6203,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-d180bfaf-0ffd-4598-8f20-3d93667cf24d,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-8ef5bdbb-f75f-4ebe-b684-f80d14acde6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-58b946f7-6aef-4154-afba-71c62764f02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-f8601e37-414a-49f0-aad1-5970ec54b204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437313101-172.17.0.5-1595679854053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33099,DS-e91b7bd9-1212-499f-b4cd-625b4276c7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-01b51b14-db6a-4bf7-b706-55631fa89c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-90fdd3ff-c5c2-4c24-a7a5-39d6a31a1fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-d4411842-d80e-46b9-b5c9-541c0dda6203,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-d180bfaf-0ffd-4598-8f20-3d93667cf24d,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-8ef5bdbb-f75f-4ebe-b684-f80d14acde6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-58b946f7-6aef-4154-afba-71c62764f02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-f8601e37-414a-49f0-aad1-5970ec54b204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382411012-172.17.0.5-1595679922840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-a34d7938-2ce3-42f6-acbd-b84fd3009f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-ff2a0a24-b74a-4136-ad39-122d8ca4ddf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-08102491-58e1-4ccf-ba75-0da39e7e9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-9d118d06-b73f-4ac7-89bc-9bec89588e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-aef18a7d-36a1-4fed-b809-84851b72fca0,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-69864c9f-f370-4b84-a82a-5f53d9c1667b,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-0e271c10-30f9-42ec-ae19-75403551c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-2ba49933-6add-47f1-bfc9-c564ad6d9464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382411012-172.17.0.5-1595679922840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-a34d7938-2ce3-42f6-acbd-b84fd3009f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-ff2a0a24-b74a-4136-ad39-122d8ca4ddf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-08102491-58e1-4ccf-ba75-0da39e7e9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-9d118d06-b73f-4ac7-89bc-9bec89588e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-aef18a7d-36a1-4fed-b809-84851b72fca0,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-69864c9f-f370-4b84-a82a-5f53d9c1667b,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-0e271c10-30f9-42ec-ae19-75403551c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-2ba49933-6add-47f1-bfc9-c564ad6d9464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120126853-172.17.0.5-1595680335245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-0b486693-0588-428d-8bb7-65beb1db591b,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-ca8b212e-a053-41b1-b27d-35b486934474,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-bfe62ac6-c0ba-4940-bfe4-0062e369fa12,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-ba27cc3a-a561-4bbf-95c5-b92578c1385f,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-d5a1a6ee-0362-4baf-af03-14e6552d2860,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-12033dce-344f-40eb-a955-77b1084eab32,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-757c090a-32ea-40bd-807d-d936c3c413d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-906ca580-387a-4302-83bc-e8bbe138f988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120126853-172.17.0.5-1595680335245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-0b486693-0588-428d-8bb7-65beb1db591b,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-ca8b212e-a053-41b1-b27d-35b486934474,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-bfe62ac6-c0ba-4940-bfe4-0062e369fa12,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-ba27cc3a-a561-4bbf-95c5-b92578c1385f,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-d5a1a6ee-0362-4baf-af03-14e6552d2860,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-12033dce-344f-40eb-a955-77b1084eab32,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-757c090a-32ea-40bd-807d-d936c3c413d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-906ca580-387a-4302-83bc-e8bbe138f988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730075739-172.17.0.5-1595680659450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37810,DS-935c5a81-b058-4f27-84af-5a6b2d25edc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-ebb20f5f-b044-4fa1-a6d7-b61ef06bbbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-a028943f-7b56-4dbe-870c-95de8a03c211,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-b7a0b27d-6e5b-4411-81fb-e1652fd8d13b,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-77812879-2847-4f0e-add4-9c87def6714b,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-fcd3c3c7-f234-4b94-81f4-1c69642a4d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4d6cf3ba-bb91-4217-904f-1d47fd59144c,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-2dcc16b5-957f-46ea-bff2-242c3abcf0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730075739-172.17.0.5-1595680659450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37810,DS-935c5a81-b058-4f27-84af-5a6b2d25edc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-ebb20f5f-b044-4fa1-a6d7-b61ef06bbbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-a028943f-7b56-4dbe-870c-95de8a03c211,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-b7a0b27d-6e5b-4411-81fb-e1652fd8d13b,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-77812879-2847-4f0e-add4-9c87def6714b,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-fcd3c3c7-f234-4b94-81f4-1c69642a4d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4d6cf3ba-bb91-4217-904f-1d47fd59144c,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-2dcc16b5-957f-46ea-bff2-242c3abcf0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520058170-172.17.0.5-1595680884153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42920,DS-7a5af0c4-e78f-45c5-8419-8270affd478f,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-3ee9041f-efa1-4518-8c4f-e75a2642bbda,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-1bbe2a10-cec4-4bba-b562-b6eb06c653bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-0719745f-944a-44a8-bc4d-fdeb805bbb42,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-e8eb97c0-4cfe-44bd-bdb5-aecab57c69de,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-09ca476e-6e51-4920-b75d-53123fa2f037,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-490e4a08-87ac-44e5-a7c7-8906ab397c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-b90ecca0-5a9e-48eb-a234-a5a1bc086ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520058170-172.17.0.5-1595680884153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42920,DS-7a5af0c4-e78f-45c5-8419-8270affd478f,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-3ee9041f-efa1-4518-8c4f-e75a2642bbda,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-1bbe2a10-cec4-4bba-b562-b6eb06c653bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-0719745f-944a-44a8-bc4d-fdeb805bbb42,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-e8eb97c0-4cfe-44bd-bdb5-aecab57c69de,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-09ca476e-6e51-4920-b75d-53123fa2f037,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-490e4a08-87ac-44e5-a7c7-8906ab397c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-b90ecca0-5a9e-48eb-a234-a5a1bc086ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5462
