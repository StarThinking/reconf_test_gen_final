reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-187203834-172.17.0.6-1595618626819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-cf86338f-9ebd-48bc-b39b-f4d3d2e5d5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-94b4b362-d082-40a0-8255-632fcf9234e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-17e70f94-a7c6-4dab-bc76-7e656cb54196,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-0d3e08e0-e3e0-4405-8cdb-1e9209c1e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-4bf4d831-df49-4b32-969f-95dd9d6a3116,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-f1ef91d1-e94a-4d78-a0b9-5a773b15dfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-b8af541e-200b-492b-90dc-41a49575bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-a93bed79-3cec-4ee9-8dce-94a1f32d83d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-187203834-172.17.0.6-1595618626819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-cf86338f-9ebd-48bc-b39b-f4d3d2e5d5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-94b4b362-d082-40a0-8255-632fcf9234e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-17e70f94-a7c6-4dab-bc76-7e656cb54196,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-0d3e08e0-e3e0-4405-8cdb-1e9209c1e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-4bf4d831-df49-4b32-969f-95dd9d6a3116,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-f1ef91d1-e94a-4d78-a0b9-5a773b15dfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-b8af541e-200b-492b-90dc-41a49575bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-a93bed79-3cec-4ee9-8dce-94a1f32d83d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473360354-172.17.0.6-1595619064402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-05c84551-1ce4-4003-b49a-65e440f94c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-e269ee29-86c9-49c5-af25-b08d569b28f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-325748e8-daf0-427d-a448-3d2e2fda2f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-42f321cd-4c63-41e3-869b-e9bd2eaa9b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-d117c0d2-a265-4256-82b5-a92f696634f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e42e9219-dd7f-4b0b-8348-897d54cd7a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-3772cd95-b49d-4c4b-a99c-25cf5133a084,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-0e235bc3-23a5-4059-982a-ca4c15345273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473360354-172.17.0.6-1595619064402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-05c84551-1ce4-4003-b49a-65e440f94c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-e269ee29-86c9-49c5-af25-b08d569b28f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-325748e8-daf0-427d-a448-3d2e2fda2f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-42f321cd-4c63-41e3-869b-e9bd2eaa9b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-d117c0d2-a265-4256-82b5-a92f696634f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e42e9219-dd7f-4b0b-8348-897d54cd7a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-3772cd95-b49d-4c4b-a99c-25cf5133a084,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-0e235bc3-23a5-4059-982a-ca4c15345273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454775827-172.17.0.6-1595619142904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-5e063c26-a44e-4ad8-9b9a-15fcd7c1bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-8399f52c-e31c-445d-8584-496483bab107,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-1fb251b7-55d6-4194-9989-66ae4a1755bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-ec61c515-18d3-4cd8-8302-8a5b0223b71d,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-5db3e730-52b3-41e0-9f01-86c058edd9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-a2562a40-85d2-4335-a3d2-df1ece2b1d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-8f433929-0ebc-4f9e-b473-7f41e3b31ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-67ef37cd-be36-45b2-86f5-2620c93ba74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454775827-172.17.0.6-1595619142904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-5e063c26-a44e-4ad8-9b9a-15fcd7c1bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-8399f52c-e31c-445d-8584-496483bab107,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-1fb251b7-55d6-4194-9989-66ae4a1755bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-ec61c515-18d3-4cd8-8302-8a5b0223b71d,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-5db3e730-52b3-41e0-9f01-86c058edd9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-a2562a40-85d2-4335-a3d2-df1ece2b1d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-8f433929-0ebc-4f9e-b473-7f41e3b31ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-67ef37cd-be36-45b2-86f5-2620c93ba74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219747203-172.17.0.6-1595619177341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-4d080832-156e-431c-931d-6e3815073839,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-b2be3de7-2f77-4602-8a04-35fde8a2fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-2504cb85-330e-49d7-9311-e9dce62f09d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-97072963-e87d-4eef-b33b-f518e7f4200b,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-f88493d1-3608-4f2f-ac2e-cc03028fafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-55cce9ec-ef43-45d6-baf5-2242317a9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-6c315967-71ff-4d7b-9171-f92ec93b4de6,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-a394818a-ce8c-49a1-a42a-dcefa9eabbdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219747203-172.17.0.6-1595619177341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-4d080832-156e-431c-931d-6e3815073839,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-b2be3de7-2f77-4602-8a04-35fde8a2fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-2504cb85-330e-49d7-9311-e9dce62f09d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-97072963-e87d-4eef-b33b-f518e7f4200b,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-f88493d1-3608-4f2f-ac2e-cc03028fafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-55cce9ec-ef43-45d6-baf5-2242317a9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-6c315967-71ff-4d7b-9171-f92ec93b4de6,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-a394818a-ce8c-49a1-a42a-dcefa9eabbdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900159845-172.17.0.6-1595619736090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45654,DS-557cd990-86a8-49aa-bda1-029652dbb8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-4a699ae0-acf6-4a40-8181-f456571110ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-af554803-3188-40a6-8361-c1dc81e274f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-70a179ff-3f07-4a65-945b-6233dfb07479,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-8eca1b84-007e-42e4-8234-9c174f39ec99,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-a7fde8b8-16a3-4904-8145-0a4f32003f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-d6d619bb-d58d-4e83-9a88-0443c394b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-2b8ead8d-ae27-485a-97b1-c34aab219a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900159845-172.17.0.6-1595619736090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45654,DS-557cd990-86a8-49aa-bda1-029652dbb8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-4a699ae0-acf6-4a40-8181-f456571110ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-af554803-3188-40a6-8361-c1dc81e274f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-70a179ff-3f07-4a65-945b-6233dfb07479,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-8eca1b84-007e-42e4-8234-9c174f39ec99,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-a7fde8b8-16a3-4904-8145-0a4f32003f71,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-d6d619bb-d58d-4e83-9a88-0443c394b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-2b8ead8d-ae27-485a-97b1-c34aab219a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219438019-172.17.0.6-1595619831310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46017,DS-359f93cb-eba5-4aa7-924a-81bbceb6c150,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-4f6c6ca8-d720-4072-921b-74cf40d00a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-4386b47a-f4c3-4fa4-bb88-7414de1b1693,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-e4da85c8-b517-41a7-98ff-dff1c54a2b72,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-85692c46-d5cb-4a94-8869-51c477d2d566,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-7f4b45d1-aea0-49d7-b757-f2ce29fe9064,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-bd189caf-2e8f-4c3a-a87b-51efb00f4ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-b0102d81-2155-4f2e-9c8d-7248ca47bf36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219438019-172.17.0.6-1595619831310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46017,DS-359f93cb-eba5-4aa7-924a-81bbceb6c150,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-4f6c6ca8-d720-4072-921b-74cf40d00a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-4386b47a-f4c3-4fa4-bb88-7414de1b1693,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-e4da85c8-b517-41a7-98ff-dff1c54a2b72,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-85692c46-d5cb-4a94-8869-51c477d2d566,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-7f4b45d1-aea0-49d7-b757-f2ce29fe9064,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-bd189caf-2e8f-4c3a-a87b-51efb00f4ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-b0102d81-2155-4f2e-9c8d-7248ca47bf36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701396188-172.17.0.6-1595619909388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-d3cd2b8b-9eaf-413e-9026-c9b6aa260ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-aa463923-6a68-4d6f-9d3d-b2cdee13b716,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-c566d83c-ee70-49e5-80c7-6a4c8e2c3852,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-812c6bfa-3770-4805-9335-6a38f4f896d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-deb4d449-b6dd-4a79-8e55-617a7b1a8643,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-ea9b61b5-ddb7-49d2-8a95-975ff79a03c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-1360c39e-9f70-404a-838d-e4e8ec9e178d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-eac3d8c0-e929-4c32-9a35-02d069832cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701396188-172.17.0.6-1595619909388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-d3cd2b8b-9eaf-413e-9026-c9b6aa260ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-aa463923-6a68-4d6f-9d3d-b2cdee13b716,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-c566d83c-ee70-49e5-80c7-6a4c8e2c3852,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-812c6bfa-3770-4805-9335-6a38f4f896d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-deb4d449-b6dd-4a79-8e55-617a7b1a8643,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-ea9b61b5-ddb7-49d2-8a95-975ff79a03c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-1360c39e-9f70-404a-838d-e4e8ec9e178d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-eac3d8c0-e929-4c32-9a35-02d069832cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519152557-172.17.0.6-1595620038824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-935afb6f-7596-4c24-afcf-5dad3940a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-5a0cf75e-705a-4489-ab42-807b4833331c,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-2d89e944-c1ed-47a2-8bd6-4e424fa3ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-b0dddce0-1527-4d56-aa2f-41b46e3800b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-f302fb20-3e9c-419e-b95a-937cbc72862b,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-44672a3e-b437-49cd-8009-edb6af818d34,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-9a07b4dc-f6ac-492c-8c55-0cefc8cc37fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-4225be4a-132e-40d1-9219-3ed571a78e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519152557-172.17.0.6-1595620038824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-935afb6f-7596-4c24-afcf-5dad3940a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-5a0cf75e-705a-4489-ab42-807b4833331c,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-2d89e944-c1ed-47a2-8bd6-4e424fa3ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-b0dddce0-1527-4d56-aa2f-41b46e3800b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-f302fb20-3e9c-419e-b95a-937cbc72862b,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-44672a3e-b437-49cd-8009-edb6af818d34,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-9a07b4dc-f6ac-492c-8c55-0cefc8cc37fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-4225be4a-132e-40d1-9219-3ed571a78e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397794240-172.17.0.6-1595620262737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37259,DS-51cc5f18-579a-4ae9-9281-cdb502056013,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-2ae259fc-b93f-40c5-93d7-bec6bfc33052,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-34f426fe-1ccd-4eb5-9141-75ea2a081881,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-674e2ddd-a9a6-4308-9c06-f91979685f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-b67562b9-aaed-4f35-be09-e98f47e67524,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-c794bbe4-051d-493e-b9cc-d9438df5f8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-82446e79-91ad-44b4-a03e-e0984cc3db66,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-70b84489-3ec9-489c-b255-6e8fcaf840ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397794240-172.17.0.6-1595620262737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37259,DS-51cc5f18-579a-4ae9-9281-cdb502056013,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-2ae259fc-b93f-40c5-93d7-bec6bfc33052,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-34f426fe-1ccd-4eb5-9141-75ea2a081881,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-674e2ddd-a9a6-4308-9c06-f91979685f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-b67562b9-aaed-4f35-be09-e98f47e67524,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-c794bbe4-051d-493e-b9cc-d9438df5f8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-82446e79-91ad-44b4-a03e-e0984cc3db66,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-70b84489-3ec9-489c-b255-6e8fcaf840ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856134708-172.17.0.6-1595621163954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40989,DS-e70a7fee-943d-4602-9fa3-7d2c4c15a11e,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-a6f2d01a-65fe-417b-a2f8-d2c367a53daa,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-e3635a55-047c-4f03-8116-cc0e9e303ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-2b35fa5e-a9b0-482c-90ad-0de642af8959,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-7b4cafd6-567a-4b58-b182-7d22c596ea21,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-29e7a94a-f215-4264-9e35-07572e676429,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-b846b5e1-3638-4994-98fb-1c5277746f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-3c33d2b0-134d-442d-b932-779a9716a196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856134708-172.17.0.6-1595621163954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40989,DS-e70a7fee-943d-4602-9fa3-7d2c4c15a11e,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-a6f2d01a-65fe-417b-a2f8-d2c367a53daa,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-e3635a55-047c-4f03-8116-cc0e9e303ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-2b35fa5e-a9b0-482c-90ad-0de642af8959,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-7b4cafd6-567a-4b58-b182-7d22c596ea21,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-29e7a94a-f215-4264-9e35-07572e676429,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-b846b5e1-3638-4994-98fb-1c5277746f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-3c33d2b0-134d-442d-b932-779a9716a196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861577418-172.17.0.6-1595621828420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-2a0c13cb-efa8-4da9-aa59-ea6287bc7868,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-18b41757-7678-40fc-a67c-29fb6cc4fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-1452e57c-e49b-4171-bb17-00091f6e09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-0fcaa997-06c4-4004-aa7d-41ed2a961f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-32114129-67a1-4be7-89f2-3304813b846e,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-de619ca7-d40d-4e78-b879-bf45ddfd346a,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-fbdfa347-fa1f-46ab-8563-f447f8100f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-ced42e11-9d2c-4be0-96a4-189d00feb421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861577418-172.17.0.6-1595621828420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-2a0c13cb-efa8-4da9-aa59-ea6287bc7868,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-18b41757-7678-40fc-a67c-29fb6cc4fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-1452e57c-e49b-4171-bb17-00091f6e09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-0fcaa997-06c4-4004-aa7d-41ed2a961f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-32114129-67a1-4be7-89f2-3304813b846e,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-de619ca7-d40d-4e78-b879-bf45ddfd346a,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-fbdfa347-fa1f-46ab-8563-f447f8100f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-ced42e11-9d2c-4be0-96a4-189d00feb421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680323896-172.17.0.6-1595622260295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-8891e7d7-a429-4267-951f-b380534441f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-574bed3b-f95c-4eed-948f-2cd1c4078157,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-13683b95-8d17-4c94-8738-7fce5f6c2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-e39d4f82-a33e-4a0b-9ab5-f1041e426f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-42548818-9870-4150-a66b-2d828efab61f,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-ca34c03f-032a-4f46-a9ec-7fbdf143db72,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-5149d984-1e93-49c0-9e30-3dbd9e4ab340,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-e1964c0f-6bbb-4370-8f40-974b29d76949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680323896-172.17.0.6-1595622260295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44799,DS-8891e7d7-a429-4267-951f-b380534441f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-574bed3b-f95c-4eed-948f-2cd1c4078157,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-13683b95-8d17-4c94-8738-7fce5f6c2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-e39d4f82-a33e-4a0b-9ab5-f1041e426f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-42548818-9870-4150-a66b-2d828efab61f,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-ca34c03f-032a-4f46-a9ec-7fbdf143db72,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-5149d984-1e93-49c0-9e30-3dbd9e4ab340,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-e1964c0f-6bbb-4370-8f40-974b29d76949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978571541-172.17.0.6-1595622293988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39692,DS-482b41e3-3a21-4b4f-aec1-42029324079e,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-8d084613-c7c0-4bca-af18-cb1875424dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-7d2d652c-3fab-4ae7-9629-da5b6b399649,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-1c25758f-323d-4d26-bdb6-d4b2e3a26d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-6917e071-27c4-43dc-bae8-113f101a29fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-ad3ead10-f189-40c6-94d0-9d61956e86f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-c892dbcb-2832-45ce-ad01-55ef3fb9b80b,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-09d2a66c-228a-4032-bfd0-946724dd1647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978571541-172.17.0.6-1595622293988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39692,DS-482b41e3-3a21-4b4f-aec1-42029324079e,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-8d084613-c7c0-4bca-af18-cb1875424dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-7d2d652c-3fab-4ae7-9629-da5b6b399649,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-1c25758f-323d-4d26-bdb6-d4b2e3a26d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-6917e071-27c4-43dc-bae8-113f101a29fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-ad3ead10-f189-40c6-94d0-9d61956e86f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-c892dbcb-2832-45ce-ad01-55ef3fb9b80b,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-09d2a66c-228a-4032-bfd0-946724dd1647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865769397-172.17.0.6-1595622384732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-aa7a2db7-19cc-49f2-bffe-ed26a78f0812,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-44a8adf5-dc93-49ad-bb08-7d1f58232097,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-afd834d6-5e9c-4705-b7a2-135d8789ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-25792336-a985-4724-9144-54c43cea0ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-9aa25fba-0003-43c9-a5ce-39fa312fde21,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-428e08b7-1381-494b-b7a6-80043721a1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-42dd59fb-2ec2-44c0-bd10-c362784abfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-c47ba555-d458-4586-8251-15e097c261cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865769397-172.17.0.6-1595622384732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-aa7a2db7-19cc-49f2-bffe-ed26a78f0812,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-44a8adf5-dc93-49ad-bb08-7d1f58232097,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-afd834d6-5e9c-4705-b7a2-135d8789ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-25792336-a985-4724-9144-54c43cea0ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-9aa25fba-0003-43c9-a5ce-39fa312fde21,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-428e08b7-1381-494b-b7a6-80043721a1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-42dd59fb-2ec2-44c0-bd10-c362784abfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-c47ba555-d458-4586-8251-15e097c261cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669264756-172.17.0.6-1595622633772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43490,DS-449111fb-f5f4-4c1c-bdfe-099139ea28cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-c4a05fa5-607a-4996-a7dd-529918535aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-0c6c3e08-6efc-456c-8368-f17eabff070a,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-5b89fa18-45d6-4e1c-be25-cd4c4e2c8c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-09ae3c6d-84f1-4d41-ac5f-1a7348b18790,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-586a69bc-3a04-478c-8a92-4256dd20eb51,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-b5e298ef-2b70-469a-b2d2-e8239509365b,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-2fa553db-768d-4079-ae53-73dc53b74ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669264756-172.17.0.6-1595622633772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43490,DS-449111fb-f5f4-4c1c-bdfe-099139ea28cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-c4a05fa5-607a-4996-a7dd-529918535aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-0c6c3e08-6efc-456c-8368-f17eabff070a,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-5b89fa18-45d6-4e1c-be25-cd4c4e2c8c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-09ae3c6d-84f1-4d41-ac5f-1a7348b18790,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-586a69bc-3a04-478c-8a92-4256dd20eb51,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-b5e298ef-2b70-469a-b2d2-e8239509365b,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-2fa553db-768d-4079-ae53-73dc53b74ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926446273-172.17.0.6-1595623107092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-6ae7f584-7d94-4767-988e-c4b8b7a4dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-03eccff6-dc5d-4424-8513-550a17dd3384,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-534083b0-6040-45bd-bddc-01d61e94399e,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-eab518a4-7237-4874-ae48-b7201b056a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-a1c512f8-d1bc-4d96-aaa1-8523ef2e810e,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-8a029833-e9c6-4938-a515-7ba985a9e211,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-f7b3898c-12d0-4e34-a9b6-fad60c26ce57,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-c896a92e-2a8d-4e64-83bc-0cc39234daef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926446273-172.17.0.6-1595623107092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-6ae7f584-7d94-4767-988e-c4b8b7a4dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-03eccff6-dc5d-4424-8513-550a17dd3384,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-534083b0-6040-45bd-bddc-01d61e94399e,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-eab518a4-7237-4874-ae48-b7201b056a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-a1c512f8-d1bc-4d96-aaa1-8523ef2e810e,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-8a029833-e9c6-4938-a515-7ba985a9e211,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-f7b3898c-12d0-4e34-a9b6-fad60c26ce57,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-c896a92e-2a8d-4e64-83bc-0cc39234daef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349183014-172.17.0.6-1595623227638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-f1dae78a-120d-47a2-9cc0-384490393708,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-1864fce2-a237-496d-bf3d-3974be2a7b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-2ad76a94-2607-477a-b3f9-55e54b38a0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-98af291d-09a5-45d5-a768-4704bc523850,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-6a84e1b4-77e1-467b-a3ea-5bd6e94dad35,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-28d88dd0-4316-40f9-aa28-e790897ef343,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-83be4f49-2b33-4724-8a3a-50d446ea60e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-263beaab-26ee-4657-91c4-a6d2671f3476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349183014-172.17.0.6-1595623227638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-f1dae78a-120d-47a2-9cc0-384490393708,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-1864fce2-a237-496d-bf3d-3974be2a7b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-2ad76a94-2607-477a-b3f9-55e54b38a0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-98af291d-09a5-45d5-a768-4704bc523850,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-6a84e1b4-77e1-467b-a3ea-5bd6e94dad35,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-28d88dd0-4316-40f9-aa28-e790897ef343,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-83be4f49-2b33-4724-8a3a-50d446ea60e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-263beaab-26ee-4657-91c4-a6d2671f3476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261229514-172.17.0.6-1595623264786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-0f8857e2-d94c-41a7-a799-023ab82c4f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-b47b904a-d7db-4516-b5b2-079338703a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-80d81561-88da-40e1-be8a-c0694ed93438,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-661f9d71-3dfd-44b7-9918-1b6723043d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-64ba28d8-2f1f-48ae-a61d-543ad6d79c05,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-97fa3c17-2ac4-4462-b036-69b84ebf8cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-41514f47-1d6b-420c-8c93-ca2fec8d2d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-ae87e85c-a243-452e-bddd-1c0ab1d7e5de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261229514-172.17.0.6-1595623264786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-0f8857e2-d94c-41a7-a799-023ab82c4f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-b47b904a-d7db-4516-b5b2-079338703a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-80d81561-88da-40e1-be8a-c0694ed93438,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-661f9d71-3dfd-44b7-9918-1b6723043d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-64ba28d8-2f1f-48ae-a61d-543ad6d79c05,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-97fa3c17-2ac4-4462-b036-69b84ebf8cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-41514f47-1d6b-420c-8c93-ca2fec8d2d35,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-ae87e85c-a243-452e-bddd-1c0ab1d7e5de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395201392-172.17.0.6-1595624091194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38290,DS-47715e62-b83f-4483-a17e-b7c2a85d1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-10de66f3-b892-4eb5-b0c9-70e07148da47,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-b10442f8-1794-4daa-bedf-f6fe4fbe763b,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-cbcc0816-1815-4a50-a1e5-c840b5d4ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-035d88c1-17c0-43cc-ba7e-55763616a470,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-f1186307-fcd3-4359-b204-8f519fe1a366,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-1a96475a-d374-44cb-a834-89f6cfab6f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-9c6926ce-fa53-4b9f-a7f5-798d7ac06246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395201392-172.17.0.6-1595624091194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38290,DS-47715e62-b83f-4483-a17e-b7c2a85d1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-10de66f3-b892-4eb5-b0c9-70e07148da47,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-b10442f8-1794-4daa-bedf-f6fe4fbe763b,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-cbcc0816-1815-4a50-a1e5-c840b5d4ace0,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-035d88c1-17c0-43cc-ba7e-55763616a470,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-f1186307-fcd3-4359-b204-8f519fe1a366,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-1a96475a-d374-44cb-a834-89f6cfab6f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-9c6926ce-fa53-4b9f-a7f5-798d7ac06246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910572641-172.17.0.6-1595624688557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36530,DS-1f17ed00-966e-4752-bd3f-184fd893ed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-ac7eaa5b-3546-4e6c-9e74-691541454569,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-67c128a9-e0c8-4cf3-99aa-63e37040209b,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-7fd4469b-01af-4e8f-9dab-ad6dfef6dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-da0a06e6-0991-45dc-8639-6d46ee2f04a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-48580cf7-ef31-4114-8ae4-0fd74f4e3839,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-f453c493-5ea5-454e-a2ed-62b4bb97f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-20fcc12a-32c3-44a9-814f-b82fe42bfb86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910572641-172.17.0.6-1595624688557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36530,DS-1f17ed00-966e-4752-bd3f-184fd893ed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-ac7eaa5b-3546-4e6c-9e74-691541454569,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-67c128a9-e0c8-4cf3-99aa-63e37040209b,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-7fd4469b-01af-4e8f-9dab-ad6dfef6dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-da0a06e6-0991-45dc-8639-6d46ee2f04a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-48580cf7-ef31-4114-8ae4-0fd74f4e3839,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-f453c493-5ea5-454e-a2ed-62b4bb97f9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-20fcc12a-32c3-44a9-814f-b82fe42bfb86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6528
