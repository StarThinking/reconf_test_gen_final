reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473576784-172.17.0.12-1595674727513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46011,DS-61834018-ee79-4954-9fc1-1a1730f777e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-9750ff69-ed91-45bd-abc0-5960eaac74d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-ed8eab90-00c7-4f50-bb08-3db3e514a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-3bce9042-e382-4796-aae7-82a739eb00cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-4eb0345c-7336-40ea-bafd-4c99db3aaed3,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-5418c66a-c502-431b-9141-f12b72f2a814,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-aae6fd57-445c-4c70-aba6-20860e48b3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-08fdb667-e738-42a1-b85a-405f80c55441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473576784-172.17.0.12-1595674727513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46011,DS-61834018-ee79-4954-9fc1-1a1730f777e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-9750ff69-ed91-45bd-abc0-5960eaac74d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-ed8eab90-00c7-4f50-bb08-3db3e514a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-3bce9042-e382-4796-aae7-82a739eb00cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-4eb0345c-7336-40ea-bafd-4c99db3aaed3,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-5418c66a-c502-431b-9141-f12b72f2a814,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-aae6fd57-445c-4c70-aba6-20860e48b3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-08fdb667-e738-42a1-b85a-405f80c55441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707072802-172.17.0.12-1595675633770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32831,DS-84bb8ef8-92b0-4f45-be2b-ab80bb81079d,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-4b6d1acf-b58a-4a3a-a478-143cdc6e4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-ee113e98-4032-41c7-98d8-4f68dce964a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-fe97ec04-444f-4089-b1c8-3f67e85da904,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-60c72127-ee10-4310-abd6-48ac42d066cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-e60eacfa-36b5-4ee2-8bf0-3e5a36bb097d,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-93599c55-feb7-463f-9ec6-d26faab74ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-9511ffc1-5db3-4f21-8220-1d526b21cb06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707072802-172.17.0.12-1595675633770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32831,DS-84bb8ef8-92b0-4f45-be2b-ab80bb81079d,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-4b6d1acf-b58a-4a3a-a478-143cdc6e4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-ee113e98-4032-41c7-98d8-4f68dce964a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-fe97ec04-444f-4089-b1c8-3f67e85da904,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-60c72127-ee10-4310-abd6-48ac42d066cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-e60eacfa-36b5-4ee2-8bf0-3e5a36bb097d,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-93599c55-feb7-463f-9ec6-d26faab74ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-9511ffc1-5db3-4f21-8220-1d526b21cb06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137680418-172.17.0.12-1595676008806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-fa373755-15d7-42f3-8ae1-860fed51ca0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-4c703e2e-67e6-40ff-abbb-a2dbe88dde49,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-8d1f1e35-a516-435d-b4fe-775ab2b0d502,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-58b79ca8-23ad-495e-ada6-2c1f3a445e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-fe23a8d6-28b6-45b8-b549-6ac125c75ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-56c70d71-d56f-4dc2-82c7-07a6981fcb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-f3c27cc7-ccd3-478e-9a3f-b5ffe73e5fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-e2be7cef-4bfb-4fd4-b3cf-6e8341aac9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137680418-172.17.0.12-1595676008806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-fa373755-15d7-42f3-8ae1-860fed51ca0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-4c703e2e-67e6-40ff-abbb-a2dbe88dde49,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-8d1f1e35-a516-435d-b4fe-775ab2b0d502,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-58b79ca8-23ad-495e-ada6-2c1f3a445e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-fe23a8d6-28b6-45b8-b549-6ac125c75ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-56c70d71-d56f-4dc2-82c7-07a6981fcb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-f3c27cc7-ccd3-478e-9a3f-b5ffe73e5fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-e2be7cef-4bfb-4fd4-b3cf-6e8341aac9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960107872-172.17.0.12-1595676855006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-8f24b38c-c838-47d3-bc17-d0d18dbda50c,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-aa674e8f-564e-4bd8-8fbf-d5f9f2fcc489,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-f791589d-2d7f-4bd6-bf61-0b628e15c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-cf327255-7e6a-4060-82ac-1a9a10e18657,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-f686e63d-86f3-40ae-b1ee-b0cd36775d93,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-42205d36-52cb-4289-9b3b-54ec7515c4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-bf50eb53-304b-46d2-808c-791805bf651b,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-4a6db781-8c41-4174-bf4e-f8a794e71023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960107872-172.17.0.12-1595676855006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-8f24b38c-c838-47d3-bc17-d0d18dbda50c,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-aa674e8f-564e-4bd8-8fbf-d5f9f2fcc489,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-f791589d-2d7f-4bd6-bf61-0b628e15c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-cf327255-7e6a-4060-82ac-1a9a10e18657,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-f686e63d-86f3-40ae-b1ee-b0cd36775d93,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-42205d36-52cb-4289-9b3b-54ec7515c4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-bf50eb53-304b-46d2-808c-791805bf651b,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-4a6db781-8c41-4174-bf4e-f8a794e71023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725746859-172.17.0.12-1595677119799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-96238270-3b79-4ffb-b8ba-b9280a6de73f,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-d6b62d00-3250-42db-af56-c47075475e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-6b249b2b-f4e6-413e-a668-6f47a4cb2e85,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-3437b339-e137-4c40-8587-8ecacc508499,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-3b942ea8-0083-46b6-a1b6-ba02e123f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-6e4b28c8-2b46-45cf-a38a-140962ae2862,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-f9c1e49d-bf28-4b26-b146-4213fbe1eb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-b74ca3fc-0fc3-48a1-9612-8a2401d0ed53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725746859-172.17.0.12-1595677119799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-96238270-3b79-4ffb-b8ba-b9280a6de73f,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-d6b62d00-3250-42db-af56-c47075475e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-6b249b2b-f4e6-413e-a668-6f47a4cb2e85,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-3437b339-e137-4c40-8587-8ecacc508499,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-3b942ea8-0083-46b6-a1b6-ba02e123f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-6e4b28c8-2b46-45cf-a38a-140962ae2862,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-f9c1e49d-bf28-4b26-b146-4213fbe1eb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-b74ca3fc-0fc3-48a1-9612-8a2401d0ed53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052799042-172.17.0.12-1595677160039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45675,DS-38ad34e4-8417-417f-9733-b310923ac5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-22da1825-cd7b-4002-9dcb-dc51c0741764,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-801987ca-58d9-4d88-b18a-d653072744a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-49a8d6ad-48b7-4dd6-b50b-c9d39342365f,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-5a3319e4-0de3-48af-a5a8-5935d9cd69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-cb184efb-9820-4361-bd0c-58cd167e4557,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-262055ed-e44a-4706-a1ef-4a3911bca0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-702252b4-6f32-4713-a2eb-3f82ef1f2361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052799042-172.17.0.12-1595677160039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45675,DS-38ad34e4-8417-417f-9733-b310923ac5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-22da1825-cd7b-4002-9dcb-dc51c0741764,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-801987ca-58d9-4d88-b18a-d653072744a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-49a8d6ad-48b7-4dd6-b50b-c9d39342365f,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-5a3319e4-0de3-48af-a5a8-5935d9cd69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-cb184efb-9820-4361-bd0c-58cd167e4557,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-262055ed-e44a-4706-a1ef-4a3911bca0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-702252b4-6f32-4713-a2eb-3f82ef1f2361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402004495-172.17.0.12-1595677405578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45596,DS-b3e6be59-89bf-4b8c-bdce-72601c23ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-6f2b54a1-2e44-4c22-acd5-c76223975b44,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-8d23771e-f647-47b8-b6e0-244be7d84b40,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-d2852b71-a5d0-43a7-b1fd-f8cd295e0471,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-06e42a22-6a0b-451c-965e-d562518e9779,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-f86766cf-20d8-42f6-8f28-d5c666773e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-3798f86a-f3fa-4eec-a483-ab0171a74336,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-b1f9b442-5d3e-4853-81fc-d3430c8e94f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402004495-172.17.0.12-1595677405578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45596,DS-b3e6be59-89bf-4b8c-bdce-72601c23ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-6f2b54a1-2e44-4c22-acd5-c76223975b44,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-8d23771e-f647-47b8-b6e0-244be7d84b40,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-d2852b71-a5d0-43a7-b1fd-f8cd295e0471,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-06e42a22-6a0b-451c-965e-d562518e9779,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-f86766cf-20d8-42f6-8f28-d5c666773e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-3798f86a-f3fa-4eec-a483-ab0171a74336,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-b1f9b442-5d3e-4853-81fc-d3430c8e94f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322033854-172.17.0.12-1595677564640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40154,DS-45c91fe6-e7cb-420b-b01f-0b3d7ac07a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-13bb433c-12ac-4379-a074-f904eee8efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-77972497-fc50-4b1c-a37d-4cc8053c6711,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-25831979-f666-40de-90a5-616ebb8d3fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-92ae7a6c-5e60-47b3-be33-c79ab12c9aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-6405abf6-df04-43e2-8dba-a4d9aa0de648,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-1d3e8a4b-f965-40d8-ad19-351459a342ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-652e2e73-ff90-4b21-b1ad-9f4f43dd5fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322033854-172.17.0.12-1595677564640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40154,DS-45c91fe6-e7cb-420b-b01f-0b3d7ac07a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-13bb433c-12ac-4379-a074-f904eee8efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-77972497-fc50-4b1c-a37d-4cc8053c6711,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-25831979-f666-40de-90a5-616ebb8d3fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-92ae7a6c-5e60-47b3-be33-c79ab12c9aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-6405abf6-df04-43e2-8dba-a4d9aa0de648,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-1d3e8a4b-f965-40d8-ad19-351459a342ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-652e2e73-ff90-4b21-b1ad-9f4f43dd5fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619286309-172.17.0.12-1595677602582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-6ad3b2f5-a25f-4e12-8335-dcdd2a725966,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-6048a094-bcca-403d-9753-180e0877503a,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-c273ff72-2e8c-4a66-9250-8b0e8ff5d138,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-a237b339-25fa-4e72-9d78-59a53f4e2bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-f42f3e30-55e7-41f7-a91f-b85c46888b77,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-ff9d1f17-8bd8-4c01-a1bf-befd1921413d,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-05059015-450d-43dd-a2bb-ac1e8e7e3f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-27b68d0d-11b6-487e-b7d4-ea19e485f2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619286309-172.17.0.12-1595677602582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-6ad3b2f5-a25f-4e12-8335-dcdd2a725966,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-6048a094-bcca-403d-9753-180e0877503a,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-c273ff72-2e8c-4a66-9250-8b0e8ff5d138,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-a237b339-25fa-4e72-9d78-59a53f4e2bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-f42f3e30-55e7-41f7-a91f-b85c46888b77,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-ff9d1f17-8bd8-4c01-a1bf-befd1921413d,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-05059015-450d-43dd-a2bb-ac1e8e7e3f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-27b68d0d-11b6-487e-b7d4-ea19e485f2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964256955-172.17.0.12-1595677952179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45657,DS-90a81233-29b2-420b-a714-3de62640f2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-9307a7ae-c2ce-4efc-9380-8b5a3c15f2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-bff1632f-f022-4e81-8781-26d34bfa1ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-dbf9ede6-e92d-4e7e-b8be-cd6e116c72a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-0ac7fc0e-e10d-4b93-8880-119316fe047b,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-d7073d49-4d39-4794-ae1b-10c525ad2b93,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-850952e1-495a-4f80-b6c0-469e0e14e446,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-770129f5-401f-4ada-8c33-429e8efeaa4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964256955-172.17.0.12-1595677952179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45657,DS-90a81233-29b2-420b-a714-3de62640f2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-9307a7ae-c2ce-4efc-9380-8b5a3c15f2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-bff1632f-f022-4e81-8781-26d34bfa1ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-dbf9ede6-e92d-4e7e-b8be-cd6e116c72a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-0ac7fc0e-e10d-4b93-8880-119316fe047b,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-d7073d49-4d39-4794-ae1b-10c525ad2b93,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-850952e1-495a-4f80-b6c0-469e0e14e446,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-770129f5-401f-4ada-8c33-429e8efeaa4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777963863-172.17.0.12-1595678915615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34307,DS-cbe6cc03-16de-4880-86a8-a19c1d6feaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-490d5c09-aaa0-4bf3-ac56-c6110ac565b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-6db37b9a-ce28-4a5f-ae55-378abb8e57d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-803d6775-6842-4d8e-b94c-680089ff3d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-01a11fec-f05e-4017-875b-1d9616c1ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-02de012f-c554-40a0-947c-bf8e63e3a34c,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-61c383e5-7d41-4a0d-883f-ebe04c40413e,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-ef4137aa-54e4-4e01-ac77-f945eb915b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777963863-172.17.0.12-1595678915615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34307,DS-cbe6cc03-16de-4880-86a8-a19c1d6feaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-490d5c09-aaa0-4bf3-ac56-c6110ac565b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-6db37b9a-ce28-4a5f-ae55-378abb8e57d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-803d6775-6842-4d8e-b94c-680089ff3d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-01a11fec-f05e-4017-875b-1d9616c1ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-02de012f-c554-40a0-947c-bf8e63e3a34c,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-61c383e5-7d41-4a0d-883f-ebe04c40413e,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-ef4137aa-54e4-4e01-ac77-f945eb915b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869391320-172.17.0.12-1595679654556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-8d51bd09-51bd-4ee1-9eac-e87a4c61d8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-c6c0788e-e00d-4882-afea-9fb22baa52f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-9226ac6a-6609-46ad-8510-8d048ee634d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-40a65083-813c-4152-8b21-5bdce592b742,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-d5120598-b880-4ae5-bdd6-ad2ddf0fb267,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-54fba67f-f8a7-4398-a54f-eb227598e2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-bfb6aeaf-d6a3-4042-b16b-57b9496e736a,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-76d60b49-f9db-49f6-b9a8-102d27189a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869391320-172.17.0.12-1595679654556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-8d51bd09-51bd-4ee1-9eac-e87a4c61d8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-c6c0788e-e00d-4882-afea-9fb22baa52f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-9226ac6a-6609-46ad-8510-8d048ee634d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-40a65083-813c-4152-8b21-5bdce592b742,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-d5120598-b880-4ae5-bdd6-ad2ddf0fb267,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-54fba67f-f8a7-4398-a54f-eb227598e2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-bfb6aeaf-d6a3-4042-b16b-57b9496e736a,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-76d60b49-f9db-49f6-b9a8-102d27189a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69160781-172.17.0.12-1595679739219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35545,DS-20928df1-752d-4794-a6b6-c441c8469068,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-53bedcbd-d75d-472b-b8fc-62aac4aae506,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-ec55dcc3-1c9e-4484-a667-2d68361d5bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-8b019432-a6b9-403b-a616-2e2a924c631c,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-0a27cf4c-1b93-42ca-b9fa-7f0b301bd08c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-245f3a4a-5a4b-4d0d-9844-dbbfe944cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-b0e69411-59d2-4766-9a9b-2013b5ceaa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-879d0c79-eb4f-4eb9-bc82-8a44454cb619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69160781-172.17.0.12-1595679739219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35545,DS-20928df1-752d-4794-a6b6-c441c8469068,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-53bedcbd-d75d-472b-b8fc-62aac4aae506,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-ec55dcc3-1c9e-4484-a667-2d68361d5bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-8b019432-a6b9-403b-a616-2e2a924c631c,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-0a27cf4c-1b93-42ca-b9fa-7f0b301bd08c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-245f3a4a-5a4b-4d0d-9844-dbbfe944cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-b0e69411-59d2-4766-9a9b-2013b5ceaa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-879d0c79-eb4f-4eb9-bc82-8a44454cb619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304799478-172.17.0.12-1595679778237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-0dbdbc64-1121-4b7b-9fb5-9d85dcd0b6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-adb7f3cc-3a81-4fe0-a12b-1a9b07753c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-09c10b7e-c47f-4cd5-86b4-6bf1ad4a6758,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-bc49c295-a985-4129-bccd-68175e60c24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-f109b59b-f93b-498e-add7-3acf9ef3fa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-c468985c-b3bd-4404-b9a4-7fc15f2d4902,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-c73d4c16-cd49-4922-ac20-67c016351bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7f13b5a6-720c-4093-94d5-11a69712e19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304799478-172.17.0.12-1595679778237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-0dbdbc64-1121-4b7b-9fb5-9d85dcd0b6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-adb7f3cc-3a81-4fe0-a12b-1a9b07753c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-09c10b7e-c47f-4cd5-86b4-6bf1ad4a6758,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-bc49c295-a985-4129-bccd-68175e60c24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-f109b59b-f93b-498e-add7-3acf9ef3fa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-c468985c-b3bd-4404-b9a4-7fc15f2d4902,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-c73d4c16-cd49-4922-ac20-67c016351bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7f13b5a6-720c-4093-94d5-11a69712e19a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5675
