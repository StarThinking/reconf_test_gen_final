reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273809281-172.17.0.14-1595609121963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44914,DS-828d3ca8-2681-45bf-8794-c52f2a4dfce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-d4f68d91-b813-4bf6-adcd-62e45e2c337b,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-f3b705d3-0983-42b9-8bd3-2f656c67e525,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-39b7bc79-c4da-4c18-a520-3c74254e769e,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-6b8264ec-44c2-48f8-ba1c-c5ef1e9699ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-65e5c3f1-74c5-4253-bc79-e4d816c37608,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-d879ed5f-8a30-4fad-afd4-d6edaf4d7add,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-cb60754e-eeba-40ec-9e0e-4a32fa47198c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273809281-172.17.0.14-1595609121963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44914,DS-828d3ca8-2681-45bf-8794-c52f2a4dfce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-d4f68d91-b813-4bf6-adcd-62e45e2c337b,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-f3b705d3-0983-42b9-8bd3-2f656c67e525,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-39b7bc79-c4da-4c18-a520-3c74254e769e,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-6b8264ec-44c2-48f8-ba1c-c5ef1e9699ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-65e5c3f1-74c5-4253-bc79-e4d816c37608,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-d879ed5f-8a30-4fad-afd4-d6edaf4d7add,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-cb60754e-eeba-40ec-9e0e-4a32fa47198c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458535842-172.17.0.14-1595609685812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-6d6a8e4a-aed0-447c-b56e-5ff3f133ed95,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-b3632bf3-acbd-4442-a519-eb3eeaf64c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-af62df22-ca80-4961-b9cf-53ded0c9113e,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-f3afa299-345e-418e-b455-54b702ab7849,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-3f294498-0ee7-4f4f-8559-ff3c9e1ed5df,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-249d2211-9d82-4ca0-89d0-4339d380c322,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-da5b3f9d-19db-409d-a68c-9d2ebbd6bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-7b94218e-2833-485f-9990-3ffc51e91855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458535842-172.17.0.14-1595609685812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-6d6a8e4a-aed0-447c-b56e-5ff3f133ed95,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-b3632bf3-acbd-4442-a519-eb3eeaf64c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-af62df22-ca80-4961-b9cf-53ded0c9113e,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-f3afa299-345e-418e-b455-54b702ab7849,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-3f294498-0ee7-4f4f-8559-ff3c9e1ed5df,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-249d2211-9d82-4ca0-89d0-4339d380c322,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-da5b3f9d-19db-409d-a68c-9d2ebbd6bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-7b94218e-2833-485f-9990-3ffc51e91855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925746379-172.17.0.14-1595609755378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33350,DS-96ff8675-a0f5-4980-98e7-33dd2b0fac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-cddc7058-c8ab-4d62-bb0e-2e567ef24309,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-049d51e4-38b1-4d77-bdf8-724bf228ab1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-963df40e-2dc3-4b27-8888-f81655f8dff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-bc40a57b-c3af-4afb-999b-a5b0e4c8e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-fbd00bc1-3543-4a77-99fa-23c2129b843a,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-29f7d837-43c5-4351-9612-c884822c4147,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-1f99b050-46a2-45e7-9320-296bf9c9a2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925746379-172.17.0.14-1595609755378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33350,DS-96ff8675-a0f5-4980-98e7-33dd2b0fac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-cddc7058-c8ab-4d62-bb0e-2e567ef24309,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-049d51e4-38b1-4d77-bdf8-724bf228ab1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-963df40e-2dc3-4b27-8888-f81655f8dff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-bc40a57b-c3af-4afb-999b-a5b0e4c8e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-fbd00bc1-3543-4a77-99fa-23c2129b843a,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-29f7d837-43c5-4351-9612-c884822c4147,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-1f99b050-46a2-45e7-9320-296bf9c9a2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770647855-172.17.0.14-1595610417028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-8546f511-b038-44bb-82b5-c28d8fa34bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-968d1a75-e06b-4b74-9471-46855509f618,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-313ea34a-94d8-4ace-8033-32f6e4a7f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-cf2679aa-c735-4bb8-8816-389b130d9c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-544461c2-63da-4bd8-8bec-13a166d7063f,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-64e2eb17-a2c6-47a4-8022-a94de1c4e788,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-340c3f63-a2d2-4063-8f1d-78511d0c5f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-327b0af4-0374-4b4f-a2ef-ce0a13e92a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770647855-172.17.0.14-1595610417028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-8546f511-b038-44bb-82b5-c28d8fa34bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-968d1a75-e06b-4b74-9471-46855509f618,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-313ea34a-94d8-4ace-8033-32f6e4a7f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-cf2679aa-c735-4bb8-8816-389b130d9c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-544461c2-63da-4bd8-8bec-13a166d7063f,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-64e2eb17-a2c6-47a4-8022-a94de1c4e788,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-340c3f63-a2d2-4063-8f1d-78511d0c5f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-327b0af4-0374-4b4f-a2ef-ce0a13e92a3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592009693-172.17.0.14-1595610706718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-a1fd29ad-4a98-4386-8fbe-85d30c91123a,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-f48372f6-8bad-4de4-b3e5-d1de8d101d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-4b3a171f-5ccb-45aa-95c7-84483e21cdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-0ae82685-9b58-4ed1-8d11-db8ec236f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-27a900d4-2432-40c6-ab39-bebbd95476ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-c2597477-b174-4fe3-9824-e0e8e9276b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-57d22624-5185-40d1-9c29-3d1a385681ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-bbe315be-4cff-404d-b110-66d054e89778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592009693-172.17.0.14-1595610706718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-a1fd29ad-4a98-4386-8fbe-85d30c91123a,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-f48372f6-8bad-4de4-b3e5-d1de8d101d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-4b3a171f-5ccb-45aa-95c7-84483e21cdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-0ae82685-9b58-4ed1-8d11-db8ec236f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-27a900d4-2432-40c6-ab39-bebbd95476ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-c2597477-b174-4fe3-9824-e0e8e9276b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-57d22624-5185-40d1-9c29-3d1a385681ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-bbe315be-4cff-404d-b110-66d054e89778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458820754-172.17.0.14-1595611062217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34516,DS-44bc7ed9-e470-4f9f-83f9-a504eaf99a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-c8a6d5c5-4f6c-434c-99cf-faf0c587eb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-8b411b6b-7411-442b-b208-d8ebead6ad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-c6210d13-439e-4a3b-ad53-27f1beab93c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-d5529283-7d2d-4b4c-9a51-9d2589e5cc52,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-b16988f2-b7e5-4225-94d8-a5dd45c0a118,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-0eb20ace-11b7-4acc-b86a-d3510b99041d,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-d69b6d58-d7f0-4ae6-886b-09d7844d2d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458820754-172.17.0.14-1595611062217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34516,DS-44bc7ed9-e470-4f9f-83f9-a504eaf99a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-c8a6d5c5-4f6c-434c-99cf-faf0c587eb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-8b411b6b-7411-442b-b208-d8ebead6ad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-c6210d13-439e-4a3b-ad53-27f1beab93c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-d5529283-7d2d-4b4c-9a51-9d2589e5cc52,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-b16988f2-b7e5-4225-94d8-a5dd45c0a118,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-0eb20ace-11b7-4acc-b86a-d3510b99041d,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-d69b6d58-d7f0-4ae6-886b-09d7844d2d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829010780-172.17.0.14-1595611102221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39307,DS-620a297d-fe50-4698-a332-6873730c18c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-955feaf2-f62e-4f63-9694-1cbe17271721,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-3adf4f1c-3da4-4a11-adaf-fbaec89da90e,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-ea06d4ad-6eec-485b-b9b9-e546b4519d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-c155c6e4-b47b-4005-9db6-e8b650599616,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-f59efc65-91f4-493e-863e-015d9637e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-3ed920c9-b5b0-4322-8bf2-a1eda2233450,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-8e2ddf66-9bbc-4871-bb64-86d18eae7acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829010780-172.17.0.14-1595611102221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39307,DS-620a297d-fe50-4698-a332-6873730c18c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-955feaf2-f62e-4f63-9694-1cbe17271721,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-3adf4f1c-3da4-4a11-adaf-fbaec89da90e,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-ea06d4ad-6eec-485b-b9b9-e546b4519d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-c155c6e4-b47b-4005-9db6-e8b650599616,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-f59efc65-91f4-493e-863e-015d9637e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-3ed920c9-b5b0-4322-8bf2-a1eda2233450,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-8e2ddf66-9bbc-4871-bb64-86d18eae7acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239704666-172.17.0.14-1595611233173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45399,DS-e876495b-de37-4548-8e75-576f7c483fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-32c54bfe-3cff-482e-9094-dabf9810c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-7ef5ea95-0a51-44bc-8ce6-0d702f1735d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-515e330a-b48a-45a7-958a-1f9329fd6abf,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-e61dc1bc-3cd8-4159-a021-7ba520e1b726,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-26061c77-3f55-4b5e-8d2d-d94a114dcaee,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-4021189a-8a26-4613-98ef-b45b97f550a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-40eca514-d78c-4385-a068-e264a1ff9644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239704666-172.17.0.14-1595611233173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45399,DS-e876495b-de37-4548-8e75-576f7c483fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-32c54bfe-3cff-482e-9094-dabf9810c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-7ef5ea95-0a51-44bc-8ce6-0d702f1735d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-515e330a-b48a-45a7-958a-1f9329fd6abf,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-e61dc1bc-3cd8-4159-a021-7ba520e1b726,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-26061c77-3f55-4b5e-8d2d-d94a114dcaee,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-4021189a-8a26-4613-98ef-b45b97f550a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-40eca514-d78c-4385-a068-e264a1ff9644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13362391-172.17.0.14-1595611629375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-b30e4f8b-8a8e-4854-91f3-38117492953e,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-e18b0358-ade4-4c8a-8a8a-855a51865dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-98ec8c15-3a06-461b-a2d8-3af3e6af0be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-8f728d09-6e22-4751-87a8-f674d0c758fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-3ee93611-9a6e-42cc-9bd5-043456a169ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-af720c82-1a0f-427c-a2d2-a35e43dbf251,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-27795ef6-ba61-41af-a8a4-ba889bbbbb07,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-1389fbe0-c055-455e-aea0-0e5bb84ad36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13362391-172.17.0.14-1595611629375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-b30e4f8b-8a8e-4854-91f3-38117492953e,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-e18b0358-ade4-4c8a-8a8a-855a51865dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-98ec8c15-3a06-461b-a2d8-3af3e6af0be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-8f728d09-6e22-4751-87a8-f674d0c758fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-3ee93611-9a6e-42cc-9bd5-043456a169ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-af720c82-1a0f-427c-a2d2-a35e43dbf251,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-27795ef6-ba61-41af-a8a4-ba889bbbbb07,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-1389fbe0-c055-455e-aea0-0e5bb84ad36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332906263-172.17.0.14-1595611763531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-1d097013-8e06-47a2-8bf0-37a1e11c8b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-dfa3f88a-d521-4812-9f35-a2dc18c1f8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-c783d544-6562-4e84-82c9-b622e374c012,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-317b27db-b11f-4e29-adb1-f3930f666457,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-ee8a6ff1-4692-4a39-a204-9d29cdba4709,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-58fe890d-d336-49ef-b3df-dd748b6daebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-52146f75-d86d-4a15-81a8-4a4030df2ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-e044e9e8-3856-4868-97e8-bf8756169096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332906263-172.17.0.14-1595611763531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-1d097013-8e06-47a2-8bf0-37a1e11c8b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-dfa3f88a-d521-4812-9f35-a2dc18c1f8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-c783d544-6562-4e84-82c9-b622e374c012,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-317b27db-b11f-4e29-adb1-f3930f666457,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-ee8a6ff1-4692-4a39-a204-9d29cdba4709,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-58fe890d-d336-49ef-b3df-dd748b6daebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-52146f75-d86d-4a15-81a8-4a4030df2ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-e044e9e8-3856-4868-97e8-bf8756169096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730930720-172.17.0.14-1595612275143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43401,DS-d2a1f388-fe96-41ee-ac05-b1818e90b40d,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-1c88b799-3fd8-4191-ac01-0fffd1c43460,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-598fad9b-0a8d-4b90-a203-e0097ac037d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-61925f4d-98ce-4a6f-8bb5-db474fb38220,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-333c3ce6-9e86-4931-acd8-d14c1e8888ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-ac4cae85-0c4a-45e7-adf7-678165442e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-802d4f88-4786-4be3-bebf-3e83da57d5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-d5b8992b-4092-4f22-ba9b-6c3073e285bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730930720-172.17.0.14-1595612275143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43401,DS-d2a1f388-fe96-41ee-ac05-b1818e90b40d,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-1c88b799-3fd8-4191-ac01-0fffd1c43460,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-598fad9b-0a8d-4b90-a203-e0097ac037d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-61925f4d-98ce-4a6f-8bb5-db474fb38220,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-333c3ce6-9e86-4931-acd8-d14c1e8888ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-ac4cae85-0c4a-45e7-adf7-678165442e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-802d4f88-4786-4be3-bebf-3e83da57d5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-d5b8992b-4092-4f22-ba9b-6c3073e285bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939767780-172.17.0.14-1595612379778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34175,DS-ea793d37-7db3-41e7-9f6b-cf37b4d3eb69,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-648fe739-fc5b-4e12-a524-027c824d8b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-c87abe35-e963-4b71-b778-43b1e7a07896,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-06b31966-9f75-46e5-a04c-3ff82c1fed21,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-761ac5d6-5fbd-4688-bf03-f4cb3aee71a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-b81032f5-5826-4dc8-8e78-a311ea212c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-bcf03a9e-1192-48e5-b1db-0fde87853160,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-307130bd-7ae4-457e-8535-c1610ef1aac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939767780-172.17.0.14-1595612379778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34175,DS-ea793d37-7db3-41e7-9f6b-cf37b4d3eb69,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-648fe739-fc5b-4e12-a524-027c824d8b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-c87abe35-e963-4b71-b778-43b1e7a07896,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-06b31966-9f75-46e5-a04c-3ff82c1fed21,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-761ac5d6-5fbd-4688-bf03-f4cb3aee71a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-b81032f5-5826-4dc8-8e78-a311ea212c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-bcf03a9e-1192-48e5-b1db-0fde87853160,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-307130bd-7ae4-457e-8535-c1610ef1aac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763201901-172.17.0.14-1595612518168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-6f604d30-bf57-424d-b93b-4368c15787f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-e960c263-7b96-486d-acbb-6d188577ff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-4467b59c-2c34-4084-bc50-1a8de82404ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-d5bf6235-6617-44e0-9153-a71bb3a3243d,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-3af82119-4f2e-4464-a0e2-c230103b5445,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-dd7d5ecc-2a4d-4e55-ad31-d53c322225ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-ce2e76f8-6753-4cd6-8d5b-cf32986d0cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-e486201b-d08a-4c70-8ca6-de17b9f58589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763201901-172.17.0.14-1595612518168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-6f604d30-bf57-424d-b93b-4368c15787f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-e960c263-7b96-486d-acbb-6d188577ff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-4467b59c-2c34-4084-bc50-1a8de82404ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-d5bf6235-6617-44e0-9153-a71bb3a3243d,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-3af82119-4f2e-4464-a0e2-c230103b5445,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-dd7d5ecc-2a4d-4e55-ad31-d53c322225ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-ce2e76f8-6753-4cd6-8d5b-cf32986d0cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-e486201b-d08a-4c70-8ca6-de17b9f58589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393481628-172.17.0.14-1595613058957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38075,DS-0a22cc35-b2ef-4ef3-836d-e3f7881f43a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-badd1c8d-e877-49d0-893b-c574b61d7630,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-ff1526fe-9825-4bb2-9fb0-564afcdcb4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-94d84afe-2d01-426e-882b-11527c1b39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-bb26f609-4862-4c66-87b5-d11f8a3df319,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-f3be477a-e68c-415d-b9d4-5008c5bd32b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-9343443f-75b5-4ac4-9a84-aafeec3ea579,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-9ae30f2e-6ca3-4595-80e3-1e0762e03ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393481628-172.17.0.14-1595613058957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38075,DS-0a22cc35-b2ef-4ef3-836d-e3f7881f43a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-badd1c8d-e877-49d0-893b-c574b61d7630,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-ff1526fe-9825-4bb2-9fb0-564afcdcb4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-94d84afe-2d01-426e-882b-11527c1b39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-bb26f609-4862-4c66-87b5-d11f8a3df319,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-f3be477a-e68c-415d-b9d4-5008c5bd32b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-9343443f-75b5-4ac4-9a84-aafeec3ea579,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-9ae30f2e-6ca3-4595-80e3-1e0762e03ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955556219-172.17.0.14-1595613123750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-b5afb54e-feed-43c5-8b70-0be3817b5504,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-aec23ecc-03b4-44c1-bd11-fdf1eef34762,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-2132b33a-8859-4155-a45e-8c2512d44e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-8c0bbc68-4290-412a-86d1-6af3671385d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-253839e5-a85c-4f58-be4a-5449245106b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-84b0a7fa-b0a0-4cc2-a5be-1bec9959d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-2e4be052-7928-4d62-a381-dd74358ae01c,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-d014b0ff-282a-4a03-8729-3d58085ea16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955556219-172.17.0.14-1595613123750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-b5afb54e-feed-43c5-8b70-0be3817b5504,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-aec23ecc-03b4-44c1-bd11-fdf1eef34762,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-2132b33a-8859-4155-a45e-8c2512d44e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-8c0bbc68-4290-412a-86d1-6af3671385d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-253839e5-a85c-4f58-be4a-5449245106b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-84b0a7fa-b0a0-4cc2-a5be-1bec9959d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-2e4be052-7928-4d62-a381-dd74358ae01c,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-d014b0ff-282a-4a03-8729-3d58085ea16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544803348-172.17.0.14-1595613628242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-cd3959fb-2b4a-4599-8d75-b82b62522628,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-70f1ed61-d8a8-436a-be77-e49918b73b49,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-c5d81063-d0ae-4e55-92bd-996bfad1c372,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-e44d66fa-4928-4d79-a86b-8463bf94eb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-444266a1-176b-4aad-8614-b69ef0e63af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-51c8de51-bc24-495e-a09a-c3b619a39e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-669be64d-3dc5-4df0-b5ee-98023daf9d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-b7e55567-af73-4ab4-8250-21c0cbc4daf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544803348-172.17.0.14-1595613628242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-cd3959fb-2b4a-4599-8d75-b82b62522628,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-70f1ed61-d8a8-436a-be77-e49918b73b49,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-c5d81063-d0ae-4e55-92bd-996bfad1c372,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-e44d66fa-4928-4d79-a86b-8463bf94eb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-444266a1-176b-4aad-8614-b69ef0e63af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-51c8de51-bc24-495e-a09a-c3b619a39e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-669be64d-3dc5-4df0-b5ee-98023daf9d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-b7e55567-af73-4ab4-8250-21c0cbc4daf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487484690-172.17.0.14-1595613764031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-5f02ac81-7b77-4033-850e-6a41c1de01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-ea9a4f6c-d399-4adc-8c09-795971e07067,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-49411624-3894-43c3-a959-ae8d0e507af7,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-194bbe89-a5ee-4caf-93e2-a58e245a9098,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-9a68449b-4460-47f0-823d-bafe85cd265e,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-f58a99e3-ddfe-4d03-8cc3-8a183f8f86b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-8520cd87-c593-4f96-b298-b897fada1794,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-cdaa08d3-9caf-49f0-9b45-48069e5c7b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487484690-172.17.0.14-1595613764031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-5f02ac81-7b77-4033-850e-6a41c1de01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-ea9a4f6c-d399-4adc-8c09-795971e07067,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-49411624-3894-43c3-a959-ae8d0e507af7,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-194bbe89-a5ee-4caf-93e2-a58e245a9098,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-9a68449b-4460-47f0-823d-bafe85cd265e,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-f58a99e3-ddfe-4d03-8cc3-8a183f8f86b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-8520cd87-c593-4f96-b298-b897fada1794,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-cdaa08d3-9caf-49f0-9b45-48069e5c7b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818135860-172.17.0.14-1595614101503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40414,DS-a576c5b1-f3af-4794-bce3-7c69cc76edf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-dd7c8a8f-0c06-4604-8d41-8273aced1cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-24b56040-668c-42e0-bb0b-d8a80d517bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-bf925364-36b8-4970-943d-572b90b7555a,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-d5f418fe-12c6-438c-bc35-1b5d6a892a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-782ebb79-e5f5-43c2-9093-1ed4f7044a76,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-59cd163f-5810-490f-85ef-01a76dfdd31d,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-f1e1a7b4-ca78-43ae-b5ad-e0c3bf31819f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818135860-172.17.0.14-1595614101503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40414,DS-a576c5b1-f3af-4794-bce3-7c69cc76edf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-dd7c8a8f-0c06-4604-8d41-8273aced1cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-24b56040-668c-42e0-bb0b-d8a80d517bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-bf925364-36b8-4970-943d-572b90b7555a,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-d5f418fe-12c6-438c-bc35-1b5d6a892a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-782ebb79-e5f5-43c2-9093-1ed4f7044a76,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-59cd163f-5810-490f-85ef-01a76dfdd31d,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-f1e1a7b4-ca78-43ae-b5ad-e0c3bf31819f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472994408-172.17.0.14-1595614254891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-4f67f067-5a7d-4740-8c3e-62f8a8d3f382,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-6ac87977-f4c9-4932-ab67-af8b5fdbc469,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-2e27a192-697a-4082-bfd0-c17e51683629,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-2914a138-9abc-4841-976a-defa16c2bd30,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-e10dfdb8-16e6-4eb2-9ed2-dbbd6afbebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-b944ed17-493e-45f1-868d-f3541dcc7f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-eb4f1682-d2fa-48fc-84a4-66d3acc4f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7ead554c-1a78-476b-a5bd-cd4051997608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472994408-172.17.0.14-1595614254891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-4f67f067-5a7d-4740-8c3e-62f8a8d3f382,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-6ac87977-f4c9-4932-ab67-af8b5fdbc469,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-2e27a192-697a-4082-bfd0-c17e51683629,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-2914a138-9abc-4841-976a-defa16c2bd30,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-e10dfdb8-16e6-4eb2-9ed2-dbbd6afbebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-b944ed17-493e-45f1-868d-f3541dcc7f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-eb4f1682-d2fa-48fc-84a4-66d3acc4f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7ead554c-1a78-476b-a5bd-cd4051997608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5199
