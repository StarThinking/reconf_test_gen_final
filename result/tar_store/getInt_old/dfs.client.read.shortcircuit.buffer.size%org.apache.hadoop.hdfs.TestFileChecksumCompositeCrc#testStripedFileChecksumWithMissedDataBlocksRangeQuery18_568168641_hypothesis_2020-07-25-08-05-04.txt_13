reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813053866-172.17.0.3-1595664315796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37040,DS-cd22f1e5-37c1-416e-ab72-621e45ca8120,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-4f1f1969-79ae-4fe8-a6d8-f7d73e35fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-27bfe97b-c00f-40c7-9463-9e7b331c6b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-50ddf2eb-084d-40fe-a6f4-611f73d61746,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-9275ba0d-17d7-41ae-aa07-3943dda64eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-a589ef33-8382-4e3b-948d-8a3c1a0962b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-f8e585ef-eabc-463d-a948-483e7acd1a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-ae7d5624-256a-4381-ac82-0207789c1b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813053866-172.17.0.3-1595664315796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37040,DS-cd22f1e5-37c1-416e-ab72-621e45ca8120,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-4f1f1969-79ae-4fe8-a6d8-f7d73e35fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-27bfe97b-c00f-40c7-9463-9e7b331c6b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-50ddf2eb-084d-40fe-a6f4-611f73d61746,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-9275ba0d-17d7-41ae-aa07-3943dda64eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-a589ef33-8382-4e3b-948d-8a3c1a0962b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-f8e585ef-eabc-463d-a948-483e7acd1a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-ae7d5624-256a-4381-ac82-0207789c1b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363175219-172.17.0.3-1595665061213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46673,DS-8a9264d7-7ce1-48b6-9e13-968e8fff3148,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-e4b7e53d-3a88-4e99-9d62-0a69ed2fb862,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-deafc443-2052-4930-9157-55a7001e5691,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-680dfd7b-860b-477f-b7e9-0a6aef9c52ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-cf336b7b-2d8c-44e1-995b-43478071e0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-6ad8a1c3-9b8f-418e-b020-e150748e8484,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-925ab199-8e8c-421b-978f-e80635937603,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-4cdfe9d5-450a-4ffa-9bbd-5f66daf1de53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363175219-172.17.0.3-1595665061213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46673,DS-8a9264d7-7ce1-48b6-9e13-968e8fff3148,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-e4b7e53d-3a88-4e99-9d62-0a69ed2fb862,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-deafc443-2052-4930-9157-55a7001e5691,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-680dfd7b-860b-477f-b7e9-0a6aef9c52ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-cf336b7b-2d8c-44e1-995b-43478071e0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-6ad8a1c3-9b8f-418e-b020-e150748e8484,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-925ab199-8e8c-421b-978f-e80635937603,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-4cdfe9d5-450a-4ffa-9bbd-5f66daf1de53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558906702-172.17.0.3-1595665103735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-570b37c2-c345-4c36-9964-1f06a24aac56,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-426385f1-6b81-4ae7-9438-adad363561b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-2c289256-f09f-4360-98dc-08d1cb4f3b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-0917a01a-bf4b-4721-adab-c76b7c9f20fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-ae9c5c79-58b0-4d91-8552-93d9122deffc,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-a0a654ce-2e8b-4fda-ab90-af615d727257,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-58814aee-7327-4d43-948e-11f549a4cb18,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-1a10b3a5-9adf-47d7-a9e7-0c9052363f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558906702-172.17.0.3-1595665103735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-570b37c2-c345-4c36-9964-1f06a24aac56,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-426385f1-6b81-4ae7-9438-adad363561b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-2c289256-f09f-4360-98dc-08d1cb4f3b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-0917a01a-bf4b-4721-adab-c76b7c9f20fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-ae9c5c79-58b0-4d91-8552-93d9122deffc,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-a0a654ce-2e8b-4fda-ab90-af615d727257,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-58814aee-7327-4d43-948e-11f549a4cb18,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-1a10b3a5-9adf-47d7-a9e7-0c9052363f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314134352-172.17.0.3-1595665362072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-d98acf22-d6f9-4485-bd54-bc9bde4cf228,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-45632236-583b-4f73-be34-5ab389a78e86,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-351de8d7-310a-4509-a921-c7f00ad04a57,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-28b3f809-5263-42aa-bc6b-0f682b2475f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-708c4b59-3379-4f88-807d-7236659c11b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-2a32f371-e434-4901-a1f2-6f7b4043dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-ace9f3bc-8209-4f18-ba4c-b9250d073396,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-e110bb34-9ee3-4087-a92b-914c17ee809a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314134352-172.17.0.3-1595665362072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-d98acf22-d6f9-4485-bd54-bc9bde4cf228,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-45632236-583b-4f73-be34-5ab389a78e86,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-351de8d7-310a-4509-a921-c7f00ad04a57,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-28b3f809-5263-42aa-bc6b-0f682b2475f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-708c4b59-3379-4f88-807d-7236659c11b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-2a32f371-e434-4901-a1f2-6f7b4043dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-ace9f3bc-8209-4f18-ba4c-b9250d073396,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-e110bb34-9ee3-4087-a92b-914c17ee809a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761642379-172.17.0.3-1595666402893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44715,DS-dc530d5a-9f23-4192-93ce-7b0a145a291f,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-af3d4dc1-f5e1-44ae-977d-b9d57505aef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-f4dcb544-1926-48fd-8e9b-f4cc7fbcdaff,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-fc919a48-bcdf-4c7b-b532-170f8e887cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-231d3e88-04a3-4b98-90ed-8085207a32ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-0955410b-4fac-4416-84ca-a4e9769eb479,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-741e8cae-261e-4aab-a42e-7124537e0a55,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-67d42e6f-606d-45c7-bfc1-890b25787d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761642379-172.17.0.3-1595666402893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44715,DS-dc530d5a-9f23-4192-93ce-7b0a145a291f,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-af3d4dc1-f5e1-44ae-977d-b9d57505aef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-f4dcb544-1926-48fd-8e9b-f4cc7fbcdaff,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-fc919a48-bcdf-4c7b-b532-170f8e887cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-231d3e88-04a3-4b98-90ed-8085207a32ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-0955410b-4fac-4416-84ca-a4e9769eb479,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-741e8cae-261e-4aab-a42e-7124537e0a55,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-67d42e6f-606d-45c7-bfc1-890b25787d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607231081-172.17.0.3-1595666442598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44198,DS-587ddfe3-e69b-4710-9fb8-93fee19fc917,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-9369be88-cc7d-4a22-9998-3e7bb86dbb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-fcd66136-8a00-4801-8c80-be55bb219df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-8b7a56f4-b04e-4f07-9bd3-c2b378326511,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-a2a41548-43e9-4b68-96e2-34f08693d49e,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-b1da9a79-13b5-4a02-88ee-fb9226419f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-d03bd831-319a-4ffd-98a3-5768b86be841,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-1071b6a8-d059-4861-a22a-6b972e77ecfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607231081-172.17.0.3-1595666442598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44198,DS-587ddfe3-e69b-4710-9fb8-93fee19fc917,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-9369be88-cc7d-4a22-9998-3e7bb86dbb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-fcd66136-8a00-4801-8c80-be55bb219df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-8b7a56f4-b04e-4f07-9bd3-c2b378326511,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-a2a41548-43e9-4b68-96e2-34f08693d49e,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-b1da9a79-13b5-4a02-88ee-fb9226419f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-d03bd831-319a-4ffd-98a3-5768b86be841,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-1071b6a8-d059-4861-a22a-6b972e77ecfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50564088-172.17.0.3-1595666921919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45183,DS-1e7ece98-7796-4485-a2c5-e5d531b5152d,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-5c19a422-4f09-4177-a6ba-2a7654a985cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-408f1757-4c11-487c-aa2c-a7df79454e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-011bc996-5a53-4691-8a06-3a1132e3b834,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-aaa0097e-e6a2-4e25-80bd-40d08597d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-2142b3d2-70cb-4164-8a45-e48a6a5f7caf,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-f7fcd385-2bed-405c-ad3c-72ffee85aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-eec826c6-5210-4a2f-b1d9-a5d1693219d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50564088-172.17.0.3-1595666921919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45183,DS-1e7ece98-7796-4485-a2c5-e5d531b5152d,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-5c19a422-4f09-4177-a6ba-2a7654a985cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-408f1757-4c11-487c-aa2c-a7df79454e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-011bc996-5a53-4691-8a06-3a1132e3b834,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-aaa0097e-e6a2-4e25-80bd-40d08597d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-2142b3d2-70cb-4164-8a45-e48a6a5f7caf,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-f7fcd385-2bed-405c-ad3c-72ffee85aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-eec826c6-5210-4a2f-b1d9-a5d1693219d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933491025-172.17.0.3-1595667431055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-5758a294-9eba-417c-b77a-eb0dbb165354,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-8fafae3f-2942-4508-b8fc-27735081f555,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-6f811dad-1733-423d-aacf-1e4c00ef6b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-adcd92a5-6d12-4046-935d-49fbadf18757,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-17f69040-69b5-47d0-8d03-f33339a130f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-1f2becaa-f6a4-414e-acea-77d5d0a6e318,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-1cb4d73a-174c-4963-9c48-abe4a4d4b536,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-2f6bfe2f-d266-419f-b393-02df012b2a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933491025-172.17.0.3-1595667431055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-5758a294-9eba-417c-b77a-eb0dbb165354,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-8fafae3f-2942-4508-b8fc-27735081f555,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-6f811dad-1733-423d-aacf-1e4c00ef6b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-adcd92a5-6d12-4046-935d-49fbadf18757,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-17f69040-69b5-47d0-8d03-f33339a130f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-1f2becaa-f6a4-414e-acea-77d5d0a6e318,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-1cb4d73a-174c-4963-9c48-abe4a4d4b536,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-2f6bfe2f-d266-419f-b393-02df012b2a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226085073-172.17.0.3-1595668019496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37321,DS-855d5463-aa8e-4737-82c2-e9b7f2b96aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-45b20b0a-d692-441a-bc44-27f616cb972b,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-085055d9-3602-44f3-9154-a7c7ebe06859,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-ae8c2a06-29ee-4331-a875-633c35ea9023,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-dfd3789e-64a5-472d-b81c-2eea4dc2c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-8df454bf-570c-4fc7-9499-eca68f41cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-f5e31e16-c898-49c5-9d81-fed253f992f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-170e7f87-2870-4dda-9937-89af050624d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226085073-172.17.0.3-1595668019496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37321,DS-855d5463-aa8e-4737-82c2-e9b7f2b96aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-45b20b0a-d692-441a-bc44-27f616cb972b,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-085055d9-3602-44f3-9154-a7c7ebe06859,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-ae8c2a06-29ee-4331-a875-633c35ea9023,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-dfd3789e-64a5-472d-b81c-2eea4dc2c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-8df454bf-570c-4fc7-9499-eca68f41cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-f5e31e16-c898-49c5-9d81-fed253f992f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-170e7f87-2870-4dda-9937-89af050624d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162918289-172.17.0.3-1595668076255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39049,DS-87ec88c1-9743-4c32-a702-bb0ba7dc091c,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-ae67e09c-ec0a-4da3-85d2-1b6b74ca1d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-da3d7195-88af-4408-81dc-b9d2cb89ce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-a7bcbdb0-19ea-431c-b467-b8e14c17fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-b5e3a813-98bd-41fd-a231-d530ba2a3adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-631648c2-a927-4063-b90a-84a25fb67760,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-2d216260-7132-478b-8aed-8406df67dbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-4de3e8c7-48d3-47f2-930b-b17ed65e3827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162918289-172.17.0.3-1595668076255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39049,DS-87ec88c1-9743-4c32-a702-bb0ba7dc091c,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-ae67e09c-ec0a-4da3-85d2-1b6b74ca1d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-da3d7195-88af-4408-81dc-b9d2cb89ce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-a7bcbdb0-19ea-431c-b467-b8e14c17fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-b5e3a813-98bd-41fd-a231-d530ba2a3adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-631648c2-a927-4063-b90a-84a25fb67760,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-2d216260-7132-478b-8aed-8406df67dbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-4de3e8c7-48d3-47f2-930b-b17ed65e3827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954848430-172.17.0.3-1595668107559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43990,DS-2d3aa1ad-49e1-4d0f-8e15-9fd142cba6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-b1e93ce2-8be4-46f5-9061-84b512ce0657,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-62b6ae7c-9889-4bda-8618-b92cd0061259,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-017a5431-44fd-4c86-82b8-a47ce44d0ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-b8254810-f64d-4831-8a31-f24935888685,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-988bfab8-ec35-4f95-9846-bad0ed0a2715,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-001b60c0-672c-4ebf-9e40-b2389ab09c38,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-6b9b8150-9ba6-4bdd-8303-f507e68ed28c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954848430-172.17.0.3-1595668107559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43990,DS-2d3aa1ad-49e1-4d0f-8e15-9fd142cba6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-b1e93ce2-8be4-46f5-9061-84b512ce0657,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-62b6ae7c-9889-4bda-8618-b92cd0061259,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-017a5431-44fd-4c86-82b8-a47ce44d0ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-b8254810-f64d-4831-8a31-f24935888685,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-988bfab8-ec35-4f95-9846-bad0ed0a2715,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-001b60c0-672c-4ebf-9e40-b2389ab09c38,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-6b9b8150-9ba6-4bdd-8303-f507e68ed28c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936190642-172.17.0.3-1595668528301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-37b0d9c5-eb0a-4b51-8146-d393898ede47,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-4ea5eb19-0145-477f-8b6f-8efc4248a274,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-c2dca80a-b7a5-480a-80b0-930a49c385c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-7d2460a3-c681-41c0-8283-fb387b2d3aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-5236a55c-0f53-43b2-a7f5-e5d55d12773f,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-97045de2-4c85-4229-b2ea-9e6b64584cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-1facda65-3471-499c-90c3-7590c5c36260,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-bef42763-ffb0-4291-a316-4d32f8837e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936190642-172.17.0.3-1595668528301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-37b0d9c5-eb0a-4b51-8146-d393898ede47,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-4ea5eb19-0145-477f-8b6f-8efc4248a274,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-c2dca80a-b7a5-480a-80b0-930a49c385c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-7d2460a3-c681-41c0-8283-fb387b2d3aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-5236a55c-0f53-43b2-a7f5-e5d55d12773f,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-97045de2-4c85-4229-b2ea-9e6b64584cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-1facda65-3471-499c-90c3-7590c5c36260,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-bef42763-ffb0-4291-a316-4d32f8837e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736709618-172.17.0.3-1595668727904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-f4e8a0c2-2fb3-4461-aa8f-214d765e99cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-47b6ce6d-b6d5-475e-96da-9143bee488ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-6301f60c-7bef-4e2e-a2cf-c3b1f3c464c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-6ce42e98-bbf3-495c-a9d5-b6f163c176e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-3023663f-f6b2-49ef-bbf1-9f3a74277761,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-e971ffe9-7c4c-4142-9737-777f14a42078,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-13bf06e5-b748-4024-86c9-b5f86fcf6616,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-63d0e2b6-e498-4fc1-827f-fccf12e2c9b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736709618-172.17.0.3-1595668727904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-f4e8a0c2-2fb3-4461-aa8f-214d765e99cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-47b6ce6d-b6d5-475e-96da-9143bee488ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-6301f60c-7bef-4e2e-a2cf-c3b1f3c464c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-6ce42e98-bbf3-495c-a9d5-b6f163c176e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-3023663f-f6b2-49ef-bbf1-9f3a74277761,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-e971ffe9-7c4c-4142-9737-777f14a42078,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-13bf06e5-b748-4024-86c9-b5f86fcf6616,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-63d0e2b6-e498-4fc1-827f-fccf12e2c9b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5300
