reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766874473-172.17.0.21-1595705694857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-af108065-1590-479a-b0d0-459699d73e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-ada46e74-ad3f-4c54-9205-648bf0cf0d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-9fcd738a-e27a-4020-a915-05957c488e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-ac550b5b-b511-4677-81c9-831765b8b8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-2c807169-89af-4a2d-8ee5-6b3878a34eec,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-2d4c79be-2946-40b9-af0f-970996ca68e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-a58ff2c3-19ac-4179-accc-ebe003adc63a,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-9f0800d9-5984-4da9-9297-9817194da464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766874473-172.17.0.21-1595705694857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-af108065-1590-479a-b0d0-459699d73e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-ada46e74-ad3f-4c54-9205-648bf0cf0d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-9fcd738a-e27a-4020-a915-05957c488e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-ac550b5b-b511-4677-81c9-831765b8b8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-2c807169-89af-4a2d-8ee5-6b3878a34eec,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-2d4c79be-2946-40b9-af0f-970996ca68e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-a58ff2c3-19ac-4179-accc-ebe003adc63a,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-9f0800d9-5984-4da9-9297-9817194da464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555334171-172.17.0.21-1595705868145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44782,DS-865d60b8-eece-4c43-8192-94de42ae5cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-da415f82-4a65-4521-916f-b238d46fd85c,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-d2faa543-24d9-44ee-b869-d502a9d3d6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-f7464293-4bc8-40a5-bb31-8295eb0bf6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-46af346c-fd58-4e9e-b12b-b395f4d103a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-104defd3-d5a9-4c05-ab85-71c15b18ff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-b2c6a61a-ad0f-4852-829d-4a6cd680ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-fb71ac57-2d43-4db9-b920-33b5286d1f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555334171-172.17.0.21-1595705868145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44782,DS-865d60b8-eece-4c43-8192-94de42ae5cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-da415f82-4a65-4521-916f-b238d46fd85c,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-d2faa543-24d9-44ee-b869-d502a9d3d6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-f7464293-4bc8-40a5-bb31-8295eb0bf6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-46af346c-fd58-4e9e-b12b-b395f4d103a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-104defd3-d5a9-4c05-ab85-71c15b18ff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-b2c6a61a-ad0f-4852-829d-4a6cd680ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-fb71ac57-2d43-4db9-b920-33b5286d1f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648531010-172.17.0.21-1595706084272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-e81ab4fc-8b2c-4028-bf34-341de96756cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-19cab305-264b-403f-a316-9e58a655e39c,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-ebd316b3-5c3c-4d4e-861e-25497712696e,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-c4025649-ba23-40f8-8e88-9b3596341267,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-da0b33f1-ed5b-4ff7-b3aa-699742cc4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-1ebc5bc0-7904-410c-8a08-644ae284fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-1792054b-c1e8-4979-87e0-19c34a48642d,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-dcf277fc-fe69-4026-a239-5a138977ff79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648531010-172.17.0.21-1595706084272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-e81ab4fc-8b2c-4028-bf34-341de96756cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-19cab305-264b-403f-a316-9e58a655e39c,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-ebd316b3-5c3c-4d4e-861e-25497712696e,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-c4025649-ba23-40f8-8e88-9b3596341267,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-da0b33f1-ed5b-4ff7-b3aa-699742cc4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-1ebc5bc0-7904-410c-8a08-644ae284fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-1792054b-c1e8-4979-87e0-19c34a48642d,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-dcf277fc-fe69-4026-a239-5a138977ff79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98825690-172.17.0.21-1595706159738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40372,DS-1272385e-ad87-49da-a334-7a5c1ac4a72c,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-9f86766e-8455-40e8-a5bd-786b92c9f73d,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-abac60fb-3934-46c3-b5d0-3e18cf36cc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-1bb6c50f-04f3-499a-8823-f009c783023d,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-da8a3b38-a08d-4896-8ddc-81aec9c82588,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-a5529172-80e7-4bd3-be9a-438187ecfb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-5a45f512-e6d8-4096-8a28-72498ab6e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e6cd5756-af40-4518-a23d-812189cac948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98825690-172.17.0.21-1595706159738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40372,DS-1272385e-ad87-49da-a334-7a5c1ac4a72c,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-9f86766e-8455-40e8-a5bd-786b92c9f73d,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-abac60fb-3934-46c3-b5d0-3e18cf36cc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-1bb6c50f-04f3-499a-8823-f009c783023d,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-da8a3b38-a08d-4896-8ddc-81aec9c82588,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-a5529172-80e7-4bd3-be9a-438187ecfb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-5a45f512-e6d8-4096-8a28-72498ab6e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e6cd5756-af40-4518-a23d-812189cac948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005647648-172.17.0.21-1595706282061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-382fab57-916d-493d-ba57-580c3cf98198,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-7fb0be9a-a95f-49cc-a62b-727d6ecfe862,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-0e8f055d-1773-4ffc-bfaf-3d017297de0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-1d3ef5e2-52bd-4aea-a99d-7074898d520e,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-fabc3771-4abd-4382-8184-778116da0859,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-5711e033-8914-4d12-8067-481e26fa9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-4ee15e07-765c-4ba8-bb7d-9a913ba24871,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-c6d2f647-903e-4b41-996b-6d7f2d192017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005647648-172.17.0.21-1595706282061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-382fab57-916d-493d-ba57-580c3cf98198,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-7fb0be9a-a95f-49cc-a62b-727d6ecfe862,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-0e8f055d-1773-4ffc-bfaf-3d017297de0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-1d3ef5e2-52bd-4aea-a99d-7074898d520e,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-fabc3771-4abd-4382-8184-778116da0859,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-5711e033-8914-4d12-8067-481e26fa9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-4ee15e07-765c-4ba8-bb7d-9a913ba24871,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-c6d2f647-903e-4b41-996b-6d7f2d192017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480794802-172.17.0.21-1595707172839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32985,DS-0739ab1a-c750-4cf0-b0d9-6dd7a8fb3535,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-484773de-3e57-4461-974d-5c40f3592546,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-5ed67d0b-1ef8-4207-95dd-482d0ebcda02,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-dee724eb-dfac-4f85-a94c-e6b1a4f97e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-3cf29bef-2816-4346-b154-a20bd81f9679,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-b6244d6d-3dae-4df6-87bf-f7eed80d2515,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-50b83a35-56cf-44e8-a2e0-4cbbf349ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-f36ca23e-9695-4715-897a-90c65cab0f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480794802-172.17.0.21-1595707172839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32985,DS-0739ab1a-c750-4cf0-b0d9-6dd7a8fb3535,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-484773de-3e57-4461-974d-5c40f3592546,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-5ed67d0b-1ef8-4207-95dd-482d0ebcda02,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-dee724eb-dfac-4f85-a94c-e6b1a4f97e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-3cf29bef-2816-4346-b154-a20bd81f9679,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-b6244d6d-3dae-4df6-87bf-f7eed80d2515,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-50b83a35-56cf-44e8-a2e0-4cbbf349ab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-f36ca23e-9695-4715-897a-90c65cab0f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479261857-172.17.0.21-1595707876085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-382ef35a-2ca0-4d27-b602-9694936bc098,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-ff347920-c6fb-4387-bb36-2a4e78e983d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-114c5bbe-bb5f-499f-810f-d61fad081b23,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-bd3d2d7c-a394-4f21-ae5c-b61ea1f76adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-e7dd6404-9523-4dd9-8b78-1521e88014fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-dc7dd697-17c1-4b16-8cd2-d08ecbdcead8,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-111e1e38-3a49-4e7f-883d-4c267ce0bb92,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-22e0df59-6962-47de-a5d4-c9a723afae7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479261857-172.17.0.21-1595707876085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-382ef35a-2ca0-4d27-b602-9694936bc098,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-ff347920-c6fb-4387-bb36-2a4e78e983d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-114c5bbe-bb5f-499f-810f-d61fad081b23,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-bd3d2d7c-a394-4f21-ae5c-b61ea1f76adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-e7dd6404-9523-4dd9-8b78-1521e88014fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-dc7dd697-17c1-4b16-8cd2-d08ecbdcead8,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-111e1e38-3a49-4e7f-883d-4c267ce0bb92,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-22e0df59-6962-47de-a5d4-c9a723afae7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845131076-172.17.0.21-1595708134681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38520,DS-9c9f704f-f1a1-4912-82b2-c342e08999b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-1db1d440-4d0b-4e00-86ce-9ff32e93dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-2819f007-0242-4a7e-95f5-15c6840c6115,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-046091f5-eb03-4306-923b-e91cfdee6a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-22deef57-ac4c-4530-9104-fee1ee3ba0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-5ca21620-e0d3-4e23-9a4b-6a11872c78cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-941479fd-7c41-47d4-800f-677c5b5d0f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-2972fe98-25a3-42f0-99e3-dcf4144343fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845131076-172.17.0.21-1595708134681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38520,DS-9c9f704f-f1a1-4912-82b2-c342e08999b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-1db1d440-4d0b-4e00-86ce-9ff32e93dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-2819f007-0242-4a7e-95f5-15c6840c6115,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-046091f5-eb03-4306-923b-e91cfdee6a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-22deef57-ac4c-4530-9104-fee1ee3ba0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-5ca21620-e0d3-4e23-9a4b-6a11872c78cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-941479fd-7c41-47d4-800f-677c5b5d0f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-2972fe98-25a3-42f0-99e3-dcf4144343fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078542312-172.17.0.21-1595708592363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42163,DS-fac8a358-fb53-4274-88e8-83d2c06c6873,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-fced34af-b597-40dc-ad44-8d3254a5fde6,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-b8e02ad3-d6c3-4de7-9db2-bfd50a9189d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-7054d642-a5da-40c0-88db-ac723792bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-c7c11aee-ba0f-4ab2-aaef-2eff5454c9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-64bba9a8-9da7-4aaf-af5e-e506b4542a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-520a0876-692d-4d94-8488-7d6c639bcd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-f5c0a706-9000-4e2b-9ab4-0d56df95b7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078542312-172.17.0.21-1595708592363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42163,DS-fac8a358-fb53-4274-88e8-83d2c06c6873,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-fced34af-b597-40dc-ad44-8d3254a5fde6,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-b8e02ad3-d6c3-4de7-9db2-bfd50a9189d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-7054d642-a5da-40c0-88db-ac723792bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-c7c11aee-ba0f-4ab2-aaef-2eff5454c9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-64bba9a8-9da7-4aaf-af5e-e506b4542a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-520a0876-692d-4d94-8488-7d6c639bcd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-f5c0a706-9000-4e2b-9ab4-0d56df95b7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609949456-172.17.0.21-1595708630787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33057,DS-431ae81d-b32b-4699-a757-b404b7007a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-d6015b98-f48a-40b5-8a03-07cdb5d2c814,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-b6578805-3d21-4203-aff0-421f1bd1820b,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-cb8fbe9b-a619-4e77-bfac-fe08ad0740e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-3db465c8-6aea-4233-abe0-26f0ce015b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-bcac1419-ffce-442a-8388-bb215420c068,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-c3d3fdbd-8935-4ea5-a740-8c9cfa42dc03,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-9946a387-8fea-4591-81b5-4694e2a1b979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609949456-172.17.0.21-1595708630787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33057,DS-431ae81d-b32b-4699-a757-b404b7007a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-d6015b98-f48a-40b5-8a03-07cdb5d2c814,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-b6578805-3d21-4203-aff0-421f1bd1820b,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-cb8fbe9b-a619-4e77-bfac-fe08ad0740e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-3db465c8-6aea-4233-abe0-26f0ce015b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-bcac1419-ffce-442a-8388-bb215420c068,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-c3d3fdbd-8935-4ea5-a740-8c9cfa42dc03,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-9946a387-8fea-4591-81b5-4694e2a1b979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233785969-172.17.0.21-1595709578073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-f0b3dd41-3751-4452-b83a-7d0e790512c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-14dd50f7-db92-4338-bbbb-a66fd1fa4558,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-9e0c1506-bffe-4c38-b8b3-22f105e0d453,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-1bb38484-3519-4ac0-971a-6784299a93da,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-7c67eb6f-dcd8-42da-ac0f-99c997b00b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-15d211ae-17bc-44d0-b6dd-95640dfb3a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-9c944954-d53d-4817-9ed5-fc836f53b5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-137a4570-d6fb-4863-9197-7d7f476059e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233785969-172.17.0.21-1595709578073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-f0b3dd41-3751-4452-b83a-7d0e790512c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-14dd50f7-db92-4338-bbbb-a66fd1fa4558,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-9e0c1506-bffe-4c38-b8b3-22f105e0d453,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-1bb38484-3519-4ac0-971a-6784299a93da,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-7c67eb6f-dcd8-42da-ac0f-99c997b00b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-15d211ae-17bc-44d0-b6dd-95640dfb3a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-9c944954-d53d-4817-9ed5-fc836f53b5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-137a4570-d6fb-4863-9197-7d7f476059e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574257317-172.17.0.21-1595709900473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-1782872e-43b3-4e81-844c-b5f44cefbe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-d6ede19a-eaf8-4f4d-9973-8c67764f6ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-3b4f716f-6f9e-46d7-b7b1-70a76f51cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-1c3f2462-3325-4fed-bdd5-79d7878466d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-36b05673-621e-445f-b366-c7c2e78d3197,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-34f475e6-3f9b-4dc8-ac1b-fcef5c1fe6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-b32b1207-83f3-4e03-9786-26d093567157,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-4b238634-527a-4cb7-99d9-729a5b196fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574257317-172.17.0.21-1595709900473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-1782872e-43b3-4e81-844c-b5f44cefbe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-d6ede19a-eaf8-4f4d-9973-8c67764f6ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-3b4f716f-6f9e-46d7-b7b1-70a76f51cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-1c3f2462-3325-4fed-bdd5-79d7878466d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-36b05673-621e-445f-b366-c7c2e78d3197,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-34f475e6-3f9b-4dc8-ac1b-fcef5c1fe6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-b32b1207-83f3-4e03-9786-26d093567157,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-4b238634-527a-4cb7-99d9-729a5b196fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474322522-172.17.0.21-1595710033214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-ee7ee958-b859-47d2-8f2f-837fb3821932,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-b9661e85-8ca2-43fd-9b07-8b3f0c194567,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-baa3ec3c-da88-41a3-abb4-625be57aa5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-d95c6d46-e720-4bed-afc0-c34d9832f702,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-be5119dd-ba6c-4447-baf4-a9321f708cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-f8624ebc-ebc9-42ab-ae2c-e9655e7d7189,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-70e7c56e-cc71-4ada-8df1-6dd7abcbffc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-c3934394-305f-482d-be25-25c8c5fb9b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474322522-172.17.0.21-1595710033214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-ee7ee958-b859-47d2-8f2f-837fb3821932,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-b9661e85-8ca2-43fd-9b07-8b3f0c194567,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-baa3ec3c-da88-41a3-abb4-625be57aa5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-d95c6d46-e720-4bed-afc0-c34d9832f702,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-be5119dd-ba6c-4447-baf4-a9321f708cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-f8624ebc-ebc9-42ab-ae2c-e9655e7d7189,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-70e7c56e-cc71-4ada-8df1-6dd7abcbffc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-c3934394-305f-482d-be25-25c8c5fb9b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370028759-172.17.0.21-1595710321487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35820,DS-7e3b1631-c2b1-4f38-b6f9-b0432037bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-bd59cb69-1f80-4fcb-a3d4-ce1b49f3a009,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-218af1ff-8bf5-4ffd-aa43-f7adb75681ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-a9d90097-2024-41ce-b9df-d162f9f1af81,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-da6ff6d7-b9a7-4d77-8134-3b37e41ac009,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-d049d499-9319-45c2-b74b-0eb04d3168d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-7bcb332d-1d06-4d37-bd94-a887ebf9edbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-95f22b9a-eb71-4256-aae9-8bf5786afcc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370028759-172.17.0.21-1595710321487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35820,DS-7e3b1631-c2b1-4f38-b6f9-b0432037bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-bd59cb69-1f80-4fcb-a3d4-ce1b49f3a009,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-218af1ff-8bf5-4ffd-aa43-f7adb75681ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-a9d90097-2024-41ce-b9df-d162f9f1af81,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-da6ff6d7-b9a7-4d77-8134-3b37e41ac009,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-d049d499-9319-45c2-b74b-0eb04d3168d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-7bcb332d-1d06-4d37-bd94-a887ebf9edbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-95f22b9a-eb71-4256-aae9-8bf5786afcc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813530049-172.17.0.21-1595711431017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43839,DS-b572d21d-54e2-44fe-88bc-742747ae22bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-0fb6653d-2d75-48a4-adea-1f1bc90a09ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-404b3b1c-b2e1-4ea2-8be7-40127136a7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-6ae70e7f-93c4-4966-b6d8-4c7f243bc124,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-12363afc-0643-44c3-aee0-bce1cac2baf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-86d932a8-557c-4a01-b41c-576e5b513af2,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-bc12f45d-0c1e-4915-8796-73204475de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-ed35eec0-7cd0-41bf-9702-f52b60e26f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813530049-172.17.0.21-1595711431017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43839,DS-b572d21d-54e2-44fe-88bc-742747ae22bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-0fb6653d-2d75-48a4-adea-1f1bc90a09ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-404b3b1c-b2e1-4ea2-8be7-40127136a7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-6ae70e7f-93c4-4966-b6d8-4c7f243bc124,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-12363afc-0643-44c3-aee0-bce1cac2baf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-86d932a8-557c-4a01-b41c-576e5b513af2,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-bc12f45d-0c1e-4915-8796-73204475de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-ed35eec0-7cd0-41bf-9702-f52b60e26f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502229936-172.17.0.21-1595711518385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-51aa8f64-62f5-4abf-b19a-605e18503abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-29a60042-59c4-4f40-9343-2d9e79741d67,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-359fe175-6d87-441f-84e3-be8e9ed0b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-31a2bedc-2f1c-4efe-a18d-df1a4886f931,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-b00b9b80-c0f6-4206-b8ef-44be4ff74d61,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-565f6815-116a-48cf-88e6-2e9d4f238e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-6d8c0f62-dba5-44ea-bd49-40c06b0c45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-6dfc7e07-68bb-49ac-8fdd-47af996f482e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502229936-172.17.0.21-1595711518385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-51aa8f64-62f5-4abf-b19a-605e18503abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-29a60042-59c4-4f40-9343-2d9e79741d67,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-359fe175-6d87-441f-84e3-be8e9ed0b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-31a2bedc-2f1c-4efe-a18d-df1a4886f931,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-b00b9b80-c0f6-4206-b8ef-44be4ff74d61,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-565f6815-116a-48cf-88e6-2e9d4f238e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-6d8c0f62-dba5-44ea-bd49-40c06b0c45f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-6dfc7e07-68bb-49ac-8fdd-47af996f482e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665652530-172.17.0.21-1595711570411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-a0dee9f1-f6fa-4590-9223-2ccb4b63bbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-d88e3823-9f1f-4852-a828-f8e0be6dee53,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-677c570d-e865-4b06-b4b7-2b22fce28248,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-0004fcac-badc-430e-9aa9-63eb5bf67f39,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-b5822b79-6602-4fa6-8838-e64df8d4614a,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-f60ce7ca-d89f-42c5-924a-0cebac2d8bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-9986bca9-59de-4612-a0e3-1f7a07994c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-38c55b9d-9cef-4baa-8c97-9afbdbf414d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665652530-172.17.0.21-1595711570411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-a0dee9f1-f6fa-4590-9223-2ccb4b63bbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-d88e3823-9f1f-4852-a828-f8e0be6dee53,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-677c570d-e865-4b06-b4b7-2b22fce28248,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-0004fcac-badc-430e-9aa9-63eb5bf67f39,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-b5822b79-6602-4fa6-8838-e64df8d4614a,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-f60ce7ca-d89f-42c5-924a-0cebac2d8bab,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-9986bca9-59de-4612-a0e3-1f7a07994c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-38c55b9d-9cef-4baa-8c97-9afbdbf414d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382827080-172.17.0.21-1595711689273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37686,DS-233933e8-f81c-4afd-965a-f68875101d72,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-ca61f5e9-2b1b-456a-95b1-ee40a2aaa8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-339ff761-dbc7-45e3-be2d-2f7699a8a685,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-3a6866fb-0c96-4a73-a3d2-83e188e5b5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-fa8beae5-07d5-4c31-8fae-203b74dbb0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-f9a66889-c300-449a-b07c-f7909371e440,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-53967cd8-06c7-4044-8618-d48c76dd2a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-22090879-58f0-4f0d-8304-c78f91c28a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382827080-172.17.0.21-1595711689273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37686,DS-233933e8-f81c-4afd-965a-f68875101d72,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-ca61f5e9-2b1b-456a-95b1-ee40a2aaa8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-339ff761-dbc7-45e3-be2d-2f7699a8a685,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-3a6866fb-0c96-4a73-a3d2-83e188e5b5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-fa8beae5-07d5-4c31-8fae-203b74dbb0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-f9a66889-c300-449a-b07c-f7909371e440,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-53967cd8-06c7-4044-8618-d48c76dd2a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-22090879-58f0-4f0d-8304-c78f91c28a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6555
