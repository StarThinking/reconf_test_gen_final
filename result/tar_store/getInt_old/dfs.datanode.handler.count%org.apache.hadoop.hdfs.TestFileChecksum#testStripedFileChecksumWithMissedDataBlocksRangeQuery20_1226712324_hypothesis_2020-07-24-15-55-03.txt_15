reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368664353-172.17.0.7-1595606205074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-ac3d2263-8d07-4f11-ba5c-025534d50613,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-0e3d2771-2c0b-4e58-bd28-d41ee2a72a73,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-1c4cfea3-1d50-436b-9859-52b3384cceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-e1494179-b8e6-4983-a420-849e425f8f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-e0af88f9-e934-474c-b211-7521374a0daa,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-b6c5b471-8ce0-4378-bc62-1a1661b58a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-0fdc77d0-543a-4d90-a20a-f78a76032ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-06427e93-5f82-40b3-a4e6-483b145d416d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368664353-172.17.0.7-1595606205074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39362,DS-ac3d2263-8d07-4f11-ba5c-025534d50613,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-0e3d2771-2c0b-4e58-bd28-d41ee2a72a73,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-1c4cfea3-1d50-436b-9859-52b3384cceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-e1494179-b8e6-4983-a420-849e425f8f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-e0af88f9-e934-474c-b211-7521374a0daa,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-b6c5b471-8ce0-4378-bc62-1a1661b58a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-0fdc77d0-543a-4d90-a20a-f78a76032ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-06427e93-5f82-40b3-a4e6-483b145d416d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597628124-172.17.0.7-1595606637132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40066,DS-4e333067-38a4-42c1-946e-212ecf8a6fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-13ee8431-49f7-406d-86c1-7bedc721ca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-d98487ad-d180-4ffd-ac7a-f8e632b73fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-49089548-3f8e-4d2e-ae98-1e39fe36b59e,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-87c41f74-53fd-4fed-b204-eec0c1e0ec8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-a34a9f41-1645-4175-9676-dfc115e87eef,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-421a1ee2-0b79-4eb6-9d85-1fb3fd63cb60,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-11c01546-0dd6-40ca-a831-8aa66228a1f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597628124-172.17.0.7-1595606637132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40066,DS-4e333067-38a4-42c1-946e-212ecf8a6fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-13ee8431-49f7-406d-86c1-7bedc721ca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-d98487ad-d180-4ffd-ac7a-f8e632b73fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-49089548-3f8e-4d2e-ae98-1e39fe36b59e,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-87c41f74-53fd-4fed-b204-eec0c1e0ec8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-a34a9f41-1645-4175-9676-dfc115e87eef,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-421a1ee2-0b79-4eb6-9d85-1fb3fd63cb60,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-11c01546-0dd6-40ca-a831-8aa66228a1f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208331209-172.17.0.7-1595606884047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-004aa9b6-10fd-4567-b2af-3b9391f9f390,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-ab2262a3-3a32-498a-9322-8960f8fb8420,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-aec8c5a5-6eca-4cce-b740-c7b1d7657a03,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-7eef9295-cb31-40c7-9b0d-33906a804d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-783521f3-58f7-4530-8dff-cb965781c6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-7ffc438d-be4e-4bd3-83fd-2648312594f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-e50585bb-ccfa-4a15-a0f7-0d48a354f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-22142a25-c35a-4364-8b94-e71bc6cacaef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208331209-172.17.0.7-1595606884047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-004aa9b6-10fd-4567-b2af-3b9391f9f390,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-ab2262a3-3a32-498a-9322-8960f8fb8420,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-aec8c5a5-6eca-4cce-b740-c7b1d7657a03,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-7eef9295-cb31-40c7-9b0d-33906a804d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-783521f3-58f7-4530-8dff-cb965781c6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-7ffc438d-be4e-4bd3-83fd-2648312594f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-e50585bb-ccfa-4a15-a0f7-0d48a354f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-22142a25-c35a-4364-8b94-e71bc6cacaef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025329920-172.17.0.7-1595606955747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-5b75ff8a-8600-4ea3-ab04-7219bb65b4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-498d7c64-74eb-4e88-aea1-6e7cb5726f51,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-06ecc023-2883-41af-be7c-49ab65f9f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-87234a16-cd67-4129-89bf-bd0a57432e71,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-f374db0c-3fcf-4e9e-982e-7e59648cb559,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-72b25e9a-618a-4519-87c0-cf7b9715723a,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-b82375df-8378-4eba-a168-f47005286379,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-437bf4ee-3e6e-4591-8942-46de0d72232e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025329920-172.17.0.7-1595606955747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38172,DS-5b75ff8a-8600-4ea3-ab04-7219bb65b4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-498d7c64-74eb-4e88-aea1-6e7cb5726f51,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-06ecc023-2883-41af-be7c-49ab65f9f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-87234a16-cd67-4129-89bf-bd0a57432e71,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-f374db0c-3fcf-4e9e-982e-7e59648cb559,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-72b25e9a-618a-4519-87c0-cf7b9715723a,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-b82375df-8378-4eba-a168-f47005286379,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-437bf4ee-3e6e-4591-8942-46de0d72232e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569647626-172.17.0.7-1595607269501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-ffa70ecc-96df-4acc-8a1d-867e234245d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-c764eed1-1227-4af4-ae1b-f413e68ec90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-4e0528b3-5055-4c9a-bd13-0723ef720357,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-6ae2b109-d9e5-4b98-a6ad-fbc5413737c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-77ee505c-c30e-4ff2-9042-1a6300edeeec,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-3be4ecfa-06a2-49c0-9e4b-da20375f0b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-1db5c1ce-899e-4a12-acf3-8903208c1257,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-cd940a61-cbe8-4e39-b738-e04354fe0f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569647626-172.17.0.7-1595607269501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-ffa70ecc-96df-4acc-8a1d-867e234245d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-c764eed1-1227-4af4-ae1b-f413e68ec90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-4e0528b3-5055-4c9a-bd13-0723ef720357,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-6ae2b109-d9e5-4b98-a6ad-fbc5413737c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-77ee505c-c30e-4ff2-9042-1a6300edeeec,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-3be4ecfa-06a2-49c0-9e4b-da20375f0b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-1db5c1ce-899e-4a12-acf3-8903208c1257,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-cd940a61-cbe8-4e39-b738-e04354fe0f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226985944-172.17.0.7-1595607313406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-027dc91e-d78b-44c9-a92f-669f8f23560c,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-a606aee2-5acb-43ad-893f-b84cd6ee8598,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-855a9960-73d2-4a8a-927e-9d0d739b1c47,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-02015f3d-c387-44cb-bd3d-44190a5a0b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-04f913c5-7805-4636-8d10-1c9a582dbf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-cbd8586f-4603-46c6-8db8-718164aa29a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-8549a155-b28e-4c90-ad64-c4ab44b87156,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-58cee654-56fe-4867-a7ad-0c09e90dc61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226985944-172.17.0.7-1595607313406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-027dc91e-d78b-44c9-a92f-669f8f23560c,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-a606aee2-5acb-43ad-893f-b84cd6ee8598,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-855a9960-73d2-4a8a-927e-9d0d739b1c47,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-02015f3d-c387-44cb-bd3d-44190a5a0b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-04f913c5-7805-4636-8d10-1c9a582dbf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-cbd8586f-4603-46c6-8db8-718164aa29a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-8549a155-b28e-4c90-ad64-c4ab44b87156,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-58cee654-56fe-4867-a7ad-0c09e90dc61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209634805-172.17.0.7-1595607441189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-4b8ba2a9-d411-4c55-9ff5-ef59c3638b15,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-dca91096-eff3-422d-9c7a-ed9ff866ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-fc9bd41e-a4dc-4082-8a84-218cdd5dc694,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-aa902e2d-744f-420a-82c0-a90587343baa,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-9c84939f-7c0c-4727-beae-ba3887915f58,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-c93d9a13-787f-4bd3-922f-4214f1e876d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-2553ba59-8773-45f1-96c6-da823e217ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-1f665761-a6a1-45a1-b7c8-fec51ce4cc6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209634805-172.17.0.7-1595607441189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-4b8ba2a9-d411-4c55-9ff5-ef59c3638b15,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-dca91096-eff3-422d-9c7a-ed9ff866ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-fc9bd41e-a4dc-4082-8a84-218cdd5dc694,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-aa902e2d-744f-420a-82c0-a90587343baa,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-9c84939f-7c0c-4727-beae-ba3887915f58,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-c93d9a13-787f-4bd3-922f-4214f1e876d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-2553ba59-8773-45f1-96c6-da823e217ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-1f665761-a6a1-45a1-b7c8-fec51ce4cc6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724670302-172.17.0.7-1595607671800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39983,DS-ad30638a-0402-4258-a27f-97be831bf5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-1d8fe336-67a9-474e-a186-6b8a5aa83145,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-e25f18bc-08d9-49c7-99a2-3a5955955807,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-ba23bb3a-6321-4ac6-b1c8-b3b7b3a8a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c58a9da9-9b36-4d59-878b-b991502b2781,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-dc797ae9-fb1b-44ae-850a-f45c6fccd62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-2fe5eb34-5082-469e-9c6c-c98d6a1c2d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-78ab1673-88ef-452a-bc18-74e5d9842e05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724670302-172.17.0.7-1595607671800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39983,DS-ad30638a-0402-4258-a27f-97be831bf5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-1d8fe336-67a9-474e-a186-6b8a5aa83145,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-e25f18bc-08d9-49c7-99a2-3a5955955807,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-ba23bb3a-6321-4ac6-b1c8-b3b7b3a8a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c58a9da9-9b36-4d59-878b-b991502b2781,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-dc797ae9-fb1b-44ae-850a-f45c6fccd62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-2fe5eb34-5082-469e-9c6c-c98d6a1c2d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-78ab1673-88ef-452a-bc18-74e5d9842e05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271615225-172.17.0.7-1595607800459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44706,DS-30644208-07e0-4929-b043-9fbd15b0d7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-2d184d3e-675f-483b-ad9a-52b8a1a76270,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-edf8db28-b2f8-428b-8be1-faf4ffd81cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-d437a87d-607b-4342-b864-c32ac46ea421,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-5e4ce800-a628-409a-83f8-ab1ecdbd30e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-f266afc1-8bf6-49d4-9851-195f590ddff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-b571cdc4-122f-4342-ad4f-21ef5ae79a15,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-be3cd2fc-f48b-4f3d-bb6d-3fdf38d34fb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271615225-172.17.0.7-1595607800459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44706,DS-30644208-07e0-4929-b043-9fbd15b0d7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-2d184d3e-675f-483b-ad9a-52b8a1a76270,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-edf8db28-b2f8-428b-8be1-faf4ffd81cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-d437a87d-607b-4342-b864-c32ac46ea421,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-5e4ce800-a628-409a-83f8-ab1ecdbd30e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-f266afc1-8bf6-49d4-9851-195f590ddff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-b571cdc4-122f-4342-ad4f-21ef5ae79a15,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-be3cd2fc-f48b-4f3d-bb6d-3fdf38d34fb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985330245-172.17.0.7-1595608193541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-933ccba1-1d71-44c3-8955-0dd63dda657d,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-bfe222d5-3bfe-494b-bc2a-525fef37b011,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e7a69708-6178-4c76-bd20-a92b9ed7a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c15a0745-480e-4a0c-8a05-5e9212f4ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-5ca11e6a-d122-43bc-ab3c-bea36bd31a71,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-0454a9d7-0c2d-45a8-b480-f0b51b46f585,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-11ae7db2-885a-496d-97be-c1be31fbca61,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-8922549b-6f3d-4b0f-92fa-87965ffa577b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985330245-172.17.0.7-1595608193541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-933ccba1-1d71-44c3-8955-0dd63dda657d,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-bfe222d5-3bfe-494b-bc2a-525fef37b011,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e7a69708-6178-4c76-bd20-a92b9ed7a4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c15a0745-480e-4a0c-8a05-5e9212f4ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-5ca11e6a-d122-43bc-ab3c-bea36bd31a71,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-0454a9d7-0c2d-45a8-b480-f0b51b46f585,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-11ae7db2-885a-496d-97be-c1be31fbca61,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-8922549b-6f3d-4b0f-92fa-87965ffa577b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000041880-172.17.0.7-1595608523941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40592,DS-b6b0c583-953e-4a92-8493-2c4f5e3f60c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-1936ae16-1481-49ba-894e-f4a7145a1587,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-3f368c9b-f0b5-40e4-854d-d6a7b03109ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-873c9a99-f990-4a2f-9ab6-bb6a94e69b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-de90482c-8b06-47d3-a84a-be6195b96e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-9447e8bf-210f-4aac-a46b-562398d73d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-078ddfef-1a2e-4fe1-91a4-2263fbb80f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-4cf2042e-3ab6-4975-8ad7-3590737f73e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000041880-172.17.0.7-1595608523941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40592,DS-b6b0c583-953e-4a92-8493-2c4f5e3f60c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-1936ae16-1481-49ba-894e-f4a7145a1587,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-3f368c9b-f0b5-40e4-854d-d6a7b03109ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-873c9a99-f990-4a2f-9ab6-bb6a94e69b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-de90482c-8b06-47d3-a84a-be6195b96e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-9447e8bf-210f-4aac-a46b-562398d73d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-078ddfef-1a2e-4fe1-91a4-2263fbb80f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-4cf2042e-3ab6-4975-8ad7-3590737f73e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-604065481-172.17.0.7-1595608675626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40698,DS-93434096-2bee-49f9-a41d-1065ad877d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-0ed2c60e-437f-4db7-b30c-1c98f3efd95b,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-0cbee6c6-1e9a-4fda-8909-25d105e89666,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-f17dafc5-ba76-474b-a82a-130db4239012,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-e21c25bb-c442-43b2-a8ce-86154f3f8383,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-01197f56-a5b3-45e4-bcbb-e32708e5aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-144dac54-d4e1-4b87-a9d7-6f7ab02ac52d,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-da4cb8f9-3969-4e29-8fd5-f8ed8e455040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-604065481-172.17.0.7-1595608675626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40698,DS-93434096-2bee-49f9-a41d-1065ad877d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-0ed2c60e-437f-4db7-b30c-1c98f3efd95b,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-0cbee6c6-1e9a-4fda-8909-25d105e89666,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-f17dafc5-ba76-474b-a82a-130db4239012,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-e21c25bb-c442-43b2-a8ce-86154f3f8383,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-01197f56-a5b3-45e4-bcbb-e32708e5aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-144dac54-d4e1-4b87-a9d7-6f7ab02ac52d,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-da4cb8f9-3969-4e29-8fd5-f8ed8e455040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941540760-172.17.0.7-1595609071430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-059f1002-2f86-45d5-95be-d662d74fda1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-05063fa6-6c2e-4a59-857f-baa136064340,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-ade76b53-c6c3-4c90-b66c-35655fb92967,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-268e8e5a-e650-4b97-89d8-6dfa013e0a61,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-33bc327d-7ecc-4cf8-90d1-f2e649072a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-235a749a-ebeb-4d88-8886-ab81c68adad3,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-979794c9-f0a9-4c0a-bcba-4a0ac3edcbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-edd20066-9077-4eef-88ed-cc7316cd85b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941540760-172.17.0.7-1595609071430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-059f1002-2f86-45d5-95be-d662d74fda1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-05063fa6-6c2e-4a59-857f-baa136064340,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-ade76b53-c6c3-4c90-b66c-35655fb92967,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-268e8e5a-e650-4b97-89d8-6dfa013e0a61,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-33bc327d-7ecc-4cf8-90d1-f2e649072a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-235a749a-ebeb-4d88-8886-ab81c68adad3,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-979794c9-f0a9-4c0a-bcba-4a0ac3edcbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-edd20066-9077-4eef-88ed-cc7316cd85b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041723400-172.17.0.7-1595610434134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43931,DS-c59d1c60-f6d5-49d2-a081-f30a706d61f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-ce98a8ce-0019-4a68-938b-cd3ee430736f,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-57eb6dc4-dfd0-464f-97ab-b23f5c90dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-458c334d-8f89-4d37-9f40-48f84bf16158,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-12573520-e0ae-4f22-ab5e-72ab0942c49b,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-87577ed2-b4ff-4aa7-98a6-90d91ba8d691,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-3ea2f0c3-c07f-4fae-8b77-5c997af835e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-472403fa-86f6-45c4-9aff-54da89e13fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041723400-172.17.0.7-1595610434134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43931,DS-c59d1c60-f6d5-49d2-a081-f30a706d61f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-ce98a8ce-0019-4a68-938b-cd3ee430736f,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-57eb6dc4-dfd0-464f-97ab-b23f5c90dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-458c334d-8f89-4d37-9f40-48f84bf16158,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-12573520-e0ae-4f22-ab5e-72ab0942c49b,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-87577ed2-b4ff-4aa7-98a6-90d91ba8d691,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-3ea2f0c3-c07f-4fae-8b77-5c997af835e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-472403fa-86f6-45c4-9aff-54da89e13fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583406763-172.17.0.7-1595610925760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39301,DS-71a68a4f-31bf-46ef-be19-a284dab02c14,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-2bae7840-dbbc-4846-8737-16717eba7e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-05e5402c-42e6-48a2-a728-2e77f8c665e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-3e8a6d79-a077-4096-90a6-9caef07f23c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-fde39e3d-664d-4f93-b5ff-8776a7403fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-b25ecf4a-552f-403b-8f96-ef140add3d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-50547115-7306-4960-8852-d3f293fa674d,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-a4806320-7318-4861-b9ea-d3268748edfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583406763-172.17.0.7-1595610925760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39301,DS-71a68a4f-31bf-46ef-be19-a284dab02c14,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-2bae7840-dbbc-4846-8737-16717eba7e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-05e5402c-42e6-48a2-a728-2e77f8c665e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-3e8a6d79-a077-4096-90a6-9caef07f23c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-fde39e3d-664d-4f93-b5ff-8776a7403fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-b25ecf4a-552f-403b-8f96-ef140add3d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-50547115-7306-4960-8852-d3f293fa674d,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-a4806320-7318-4861-b9ea-d3268748edfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369491429-172.17.0.7-1595611787749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40274,DS-1674f836-4ea3-49cf-ba70-db11cce9320b,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-d29515e6-c955-4707-8a52-3318f01a5215,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-7ab3655b-8df9-41f5-b0cc-283b2da2a6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-9cd28d27-e4b3-4395-b5b4-a76a399ecbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-4065fcf2-147e-4d6f-bfda-2624775157fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-da764c79-4edf-45cc-95ed-4fd88f864d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-07bad2d1-7673-4d7e-98d7-b66cfe938886,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-57b6a146-daf4-4e03-b805-f609ac77b54b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369491429-172.17.0.7-1595611787749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40274,DS-1674f836-4ea3-49cf-ba70-db11cce9320b,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-d29515e6-c955-4707-8a52-3318f01a5215,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-7ab3655b-8df9-41f5-b0cc-283b2da2a6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-9cd28d27-e4b3-4395-b5b4-a76a399ecbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-4065fcf2-147e-4d6f-bfda-2624775157fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-da764c79-4edf-45cc-95ed-4fd88f864d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-07bad2d1-7673-4d7e-98d7-b66cfe938886,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-57b6a146-daf4-4e03-b805-f609ac77b54b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310159881-172.17.0.7-1595611828954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37549,DS-9000b4de-a379-4fd4-8286-fd7dface6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-9d9bae54-8f04-48ff-bb1c-9d5174cbf1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-57f6200c-920d-42f3-99be-893ebe2a0c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-97cb5f51-f79f-4a22-81ed-12782a9c1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-988ed5c9-0238-4603-83b5-b06acd5fb30c,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-5cecd6a8-4cf1-42f0-88f9-7eba3bfd2769,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-fdcce74a-162d-482a-a0c4-13360e38b970,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-8021d92b-f6a9-457d-9dcc-e55915c63f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310159881-172.17.0.7-1595611828954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37549,DS-9000b4de-a379-4fd4-8286-fd7dface6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-9d9bae54-8f04-48ff-bb1c-9d5174cbf1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-57f6200c-920d-42f3-99be-893ebe2a0c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-97cb5f51-f79f-4a22-81ed-12782a9c1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-988ed5c9-0238-4603-83b5-b06acd5fb30c,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-5cecd6a8-4cf1-42f0-88f9-7eba3bfd2769,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-fdcce74a-162d-482a-a0c4-13360e38b970,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-8021d92b-f6a9-457d-9dcc-e55915c63f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 3
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645603593-172.17.0.7-1595612140310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-4123f01e-6ea0-424d-b406-64289315ea9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-43cd923c-0dc7-4b29-b5b2-e8e875c6fb86,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-3b86cd3a-8bed-489d-a45c-dece6d235554,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-90d12a41-735a-4f08-b6b6-5bc8594f0159,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-9665d6a0-caca-4c7a-8b86-7333329bf22c,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-7c49a351-d131-48d7-93e4-ec8c753e81ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-9f7d2cab-0577-4b67-affa-7d8bb2837517,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-e23f7b96-37c8-4807-b6b3-aeec6e2b98f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645603593-172.17.0.7-1595612140310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-4123f01e-6ea0-424d-b406-64289315ea9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-43cd923c-0dc7-4b29-b5b2-e8e875c6fb86,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-3b86cd3a-8bed-489d-a45c-dece6d235554,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-90d12a41-735a-4f08-b6b6-5bc8594f0159,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-9665d6a0-caca-4c7a-8b86-7333329bf22c,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-7c49a351-d131-48d7-93e4-ec8c753e81ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-9f7d2cab-0577-4b67-affa-7d8bb2837517,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-e23f7b96-37c8-4807-b6b3-aeec6e2b98f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6094
