reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339641593-172.17.0.5-1595497076978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39695,DS-72890593-d79b-4fc9-b142-8a53d4ae8286,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-ccc022b0-ef73-48fc-87b5-82db6750aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-30e6e7c9-19cf-414e-84f4-e6c9107a7da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-aa42d3f1-188c-4b25-a2cc-bedb9d2b32d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-977cd5fb-ffb4-4271-9b54-4d141b6615a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-d8b1e1bb-d7e1-45b4-9139-29f1e0abd8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-ef06bf26-db6c-42d2-9dfc-16c5c3ffc645,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-19d21a00-855e-411c-b4a5-2b2948d35e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339641593-172.17.0.5-1595497076978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39695,DS-72890593-d79b-4fc9-b142-8a53d4ae8286,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-ccc022b0-ef73-48fc-87b5-82db6750aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-30e6e7c9-19cf-414e-84f4-e6c9107a7da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-aa42d3f1-188c-4b25-a2cc-bedb9d2b32d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-977cd5fb-ffb4-4271-9b54-4d141b6615a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-d8b1e1bb-d7e1-45b4-9139-29f1e0abd8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-ef06bf26-db6c-42d2-9dfc-16c5c3ffc645,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-19d21a00-855e-411c-b4a5-2b2948d35e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616461731-172.17.0.5-1595497228774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-48273dc3-d51f-45e2-a1d7-c0a26d0112f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-e18da8a3-7980-4634-8c34-a45dbb1e924f,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-a93be31a-2099-439a-bed7-b9ca6ca8e3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-4ebe3439-6aec-4e22-bfc4-d34766f3d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-fd92a6f1-3086-4ecf-8fea-5ad4c3d6ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-f98032b9-c546-423a-a9c0-fad848ba8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-ae377e8a-4a54-4708-a145-88637b027a86,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-f4e8b159-94fc-4969-a872-f93f8f71d3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616461731-172.17.0.5-1595497228774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-48273dc3-d51f-45e2-a1d7-c0a26d0112f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-e18da8a3-7980-4634-8c34-a45dbb1e924f,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-a93be31a-2099-439a-bed7-b9ca6ca8e3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-4ebe3439-6aec-4e22-bfc4-d34766f3d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-fd92a6f1-3086-4ecf-8fea-5ad4c3d6ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-f98032b9-c546-423a-a9c0-fad848ba8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-ae377e8a-4a54-4708-a145-88637b027a86,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-f4e8b159-94fc-4969-a872-f93f8f71d3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6686963-172.17.0.5-1595497261272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-4962b959-900b-4688-a4e3-75200d4fe1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-20288643-5caa-448e-a6cb-223011a4005c,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-ec18663f-dd67-4ec6-b7fe-aaf8a42e2ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-b22ed101-aab2-4b6c-a16d-679357c53ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-ccd4d381-d264-485a-ae8c-b2f10bac9cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-2ce9449b-b024-4494-9f42-83819e4032f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-29ec17b3-3e48-4f68-843f-00c1477dfda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-eccc349f-3815-4e8c-b0d5-48a47d017b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6686963-172.17.0.5-1595497261272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-4962b959-900b-4688-a4e3-75200d4fe1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-20288643-5caa-448e-a6cb-223011a4005c,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-ec18663f-dd67-4ec6-b7fe-aaf8a42e2ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-b22ed101-aab2-4b6c-a16d-679357c53ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-ccd4d381-d264-485a-ae8c-b2f10bac9cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-2ce9449b-b024-4494-9f42-83819e4032f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-29ec17b3-3e48-4f68-843f-00c1477dfda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-eccc349f-3815-4e8c-b0d5-48a47d017b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054257152-172.17.0.5-1595497610500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37089,DS-e91e14b3-015a-4aa3-b616-1bd13ea31711,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-2749aba5-f329-4d20-8bef-0833650ff29d,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-52bbc98d-fb97-46b2-a4fa-8c19a5e685e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-4e21e7b5-b6aa-4e8a-a1ce-c71158187575,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-b86835ed-82ee-4934-b947-ec1d911351ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-fc6ba067-5418-4e53-858a-adb5e5920ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-e72f7a03-94fe-4161-8582-a122e3096922,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-850d7df1-a271-4f12-a430-849467543b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054257152-172.17.0.5-1595497610500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37089,DS-e91e14b3-015a-4aa3-b616-1bd13ea31711,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-2749aba5-f329-4d20-8bef-0833650ff29d,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-52bbc98d-fb97-46b2-a4fa-8c19a5e685e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-4e21e7b5-b6aa-4e8a-a1ce-c71158187575,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-b86835ed-82ee-4934-b947-ec1d911351ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-fc6ba067-5418-4e53-858a-adb5e5920ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-e72f7a03-94fe-4161-8582-a122e3096922,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-850d7df1-a271-4f12-a430-849467543b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494731495-172.17.0.5-1595497865096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37998,DS-5f633d1b-fb26-42d4-ab42-d39f5171e297,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-11b1e638-5a56-44ce-b0b3-d960033fbf34,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-d415773f-5b63-44ef-801c-0559b915cd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-a685ca34-afb8-4f51-a5e6-1f299f34dfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-547672eb-028e-4130-9aa3-29d6ab150c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-5d39161a-5965-42fb-9393-3ad804135807,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-36d897a4-ba0a-433f-b95f-1a6a516bcb00,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-db033695-0628-42f8-b34f-9d80384eb727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494731495-172.17.0.5-1595497865096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37998,DS-5f633d1b-fb26-42d4-ab42-d39f5171e297,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-11b1e638-5a56-44ce-b0b3-d960033fbf34,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-d415773f-5b63-44ef-801c-0559b915cd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-a685ca34-afb8-4f51-a5e6-1f299f34dfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-547672eb-028e-4130-9aa3-29d6ab150c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-5d39161a-5965-42fb-9393-3ad804135807,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-36d897a4-ba0a-433f-b95f-1a6a516bcb00,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-db033695-0628-42f8-b34f-9d80384eb727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197671082-172.17.0.5-1595498208452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39674,DS-0facedcd-0965-4fee-acc8-5333a2cf1cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-81e16e0e-fdea-4585-9777-d9dd83634945,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-15ba0976-3761-4d93-9d25-2b55173bb19d,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-752ce19c-e088-41e3-a72d-2f95fbdae422,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-98193685-09be-4e4a-9585-76ff50ccac8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-f20304f9-cd94-4704-8464-a4c3f16a2005,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-b8f63fd7-9e0a-44b7-a87d-0f8ec6f5b3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-d6250403-7e90-47e1-b8ae-f08638ab7653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197671082-172.17.0.5-1595498208452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39674,DS-0facedcd-0965-4fee-acc8-5333a2cf1cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-81e16e0e-fdea-4585-9777-d9dd83634945,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-15ba0976-3761-4d93-9d25-2b55173bb19d,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-752ce19c-e088-41e3-a72d-2f95fbdae422,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-98193685-09be-4e4a-9585-76ff50ccac8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-f20304f9-cd94-4704-8464-a4c3f16a2005,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-b8f63fd7-9e0a-44b7-a87d-0f8ec6f5b3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-d6250403-7e90-47e1-b8ae-f08638ab7653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247267071-172.17.0.5-1595498431250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-9fc4590f-186a-4690-96d1-f75d87b21b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-991605d6-7d12-4164-99f9-bc9cfbe8bb04,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-7c766a8f-3999-4786-bb33-6b20a205b345,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-9f30a184-f5e9-4616-935c-dd8ba20c131d,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-7601328b-db33-46bb-bf25-282b3bfe5909,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-9ab60a09-56b1-426d-9c1a-098bda29a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-42760198-1eb1-49bc-80e4-45909d83f852,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-9885ccd0-6dee-45ec-b9e3-3642fac9177a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247267071-172.17.0.5-1595498431250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-9fc4590f-186a-4690-96d1-f75d87b21b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-991605d6-7d12-4164-99f9-bc9cfbe8bb04,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-7c766a8f-3999-4786-bb33-6b20a205b345,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-9f30a184-f5e9-4616-935c-dd8ba20c131d,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-7601328b-db33-46bb-bf25-282b3bfe5909,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-9ab60a09-56b1-426d-9c1a-098bda29a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-42760198-1eb1-49bc-80e4-45909d83f852,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-9885ccd0-6dee-45ec-b9e3-3642fac9177a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1304615859-172.17.0.5-1595498866870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43143,DS-5b35c054-af10-4932-bcbe-3023c7dbbc76,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-ba941f8e-5e03-47f7-8aad-20da1ba7f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-13862014-a11c-4adb-9548-a1bbd882068f,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-afa9cdbc-0db9-4c4a-a727-30e24981b344,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-e5116430-3c5e-406f-a251-5e291a060eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-6475e7e3-7d70-4fc8-b972-fb9a5ec8baa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-6e69a04c-b4bf-4267-b68b-53b4e70f298d,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-622fc056-0d89-42ce-be25-e29419294aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1304615859-172.17.0.5-1595498866870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43143,DS-5b35c054-af10-4932-bcbe-3023c7dbbc76,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-ba941f8e-5e03-47f7-8aad-20da1ba7f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-13862014-a11c-4adb-9548-a1bbd882068f,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-afa9cdbc-0db9-4c4a-a727-30e24981b344,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-e5116430-3c5e-406f-a251-5e291a060eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-6475e7e3-7d70-4fc8-b972-fb9a5ec8baa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-6e69a04c-b4bf-4267-b68b-53b4e70f298d,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-622fc056-0d89-42ce-be25-e29419294aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52615860-172.17.0.5-1595499199939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38002,DS-3cd8399c-5562-42fd-95a4-f5a856fb1810,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-9eb18995-2f15-43cb-a672-1658d7f7ce46,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-b091f2de-ec05-47f8-ac53-bb1c1a04cfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-99aaec9e-d970-406a-ba81-bfad71ef197c,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-7181fee8-9108-4b62-aa05-b695b0efad31,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-6f7ae406-80f6-47a5-ae4b-0afab155c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-92e8d62f-b928-4f27-b6e5-f0bbcf180a44,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-8d5aea09-320c-4fab-ab1e-2cdcb8490638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52615860-172.17.0.5-1595499199939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38002,DS-3cd8399c-5562-42fd-95a4-f5a856fb1810,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-9eb18995-2f15-43cb-a672-1658d7f7ce46,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-b091f2de-ec05-47f8-ac53-bb1c1a04cfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-99aaec9e-d970-406a-ba81-bfad71ef197c,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-7181fee8-9108-4b62-aa05-b695b0efad31,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-6f7ae406-80f6-47a5-ae4b-0afab155c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-92e8d62f-b928-4f27-b6e5-f0bbcf180a44,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-8d5aea09-320c-4fab-ab1e-2cdcb8490638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566807470-172.17.0.5-1595499390934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33537,DS-7c3c1789-fc0b-4e66-9ab6-75642d3583a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-38444787-817f-44a4-9b36-befbdb4ae235,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-6834bbcc-ccab-4091-9fa0-aa8eaa297ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-71b67286-e487-4749-8822-7fce44bb9ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-152121d2-f699-49c3-90f7-f39ba80ac779,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-c50f805d-1787-4dd2-81d5-0bff0c102203,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-099355b1-8ab3-4c92-982f-b5432b4edf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-58c47efa-e2b1-4517-9efc-cd2e9f4ca34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566807470-172.17.0.5-1595499390934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33537,DS-7c3c1789-fc0b-4e66-9ab6-75642d3583a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-38444787-817f-44a4-9b36-befbdb4ae235,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-6834bbcc-ccab-4091-9fa0-aa8eaa297ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-71b67286-e487-4749-8822-7fce44bb9ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-152121d2-f699-49c3-90f7-f39ba80ac779,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-c50f805d-1787-4dd2-81d5-0bff0c102203,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-099355b1-8ab3-4c92-982f-b5432b4edf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-58c47efa-e2b1-4517-9efc-cd2e9f4ca34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751455841-172.17.0.5-1595499793857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42269,DS-32d8302b-c6a1-48b7-8dda-8326f93273e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-5148a7ba-a1a7-40aa-8b55-d522d555d50b,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-32edbf89-fd4a-4339-8619-14ac89b6767d,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-55aad119-1692-4b93-8865-3ad00621cd85,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-7244ecea-b208-4d86-bd6f-5a08b57e96f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-b54d3553-1245-4a04-8c26-d7cec1ea2230,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-c70190f8-9acb-4706-be94-a5519e5ab8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-e2e7e553-f278-433d-927f-33923d4ebc97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751455841-172.17.0.5-1595499793857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42269,DS-32d8302b-c6a1-48b7-8dda-8326f93273e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-5148a7ba-a1a7-40aa-8b55-d522d555d50b,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-32edbf89-fd4a-4339-8619-14ac89b6767d,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-55aad119-1692-4b93-8865-3ad00621cd85,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-7244ecea-b208-4d86-bd6f-5a08b57e96f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-b54d3553-1245-4a04-8c26-d7cec1ea2230,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-c70190f8-9acb-4706-be94-a5519e5ab8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-e2e7e553-f278-433d-927f-33923d4ebc97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928699195-172.17.0.5-1595500291583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-afb8c4ba-20e8-47ff-8115-5464482ca2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-54c894f3-c7e6-4286-9228-b544f62a7ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-4e72d173-4af4-42e0-bb98-0b45ab2164eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-d3b2e727-d941-4778-9cee-66591722cadd,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-93feafec-1095-43ef-9fe2-ecc4e0f6340f,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-c3e93d2b-f1de-4bfb-9115-f50e777b661f,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-aa8b0a69-0233-4a34-9e3b-112c75154239,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-540b88c8-76cd-4fa0-b250-acd75e1db303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928699195-172.17.0.5-1595500291583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-afb8c4ba-20e8-47ff-8115-5464482ca2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-54c894f3-c7e6-4286-9228-b544f62a7ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-4e72d173-4af4-42e0-bb98-0b45ab2164eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-d3b2e727-d941-4778-9cee-66591722cadd,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-93feafec-1095-43ef-9fe2-ecc4e0f6340f,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-c3e93d2b-f1de-4bfb-9115-f50e777b661f,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-aa8b0a69-0233-4a34-9e3b-112c75154239,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-540b88c8-76cd-4fa0-b250-acd75e1db303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860580253-172.17.0.5-1595501133335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-39ba32b5-44cc-40f6-a343-a5a9bbbe20dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-b8131519-6c54-402a-8836-eea54659381b,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-382007c8-c5e9-49f8-9254-021db216516a,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-abe94bab-6a86-46db-9604-dffea30428ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-04b14a66-07d9-447d-be97-c9ab0b607032,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-524301c3-967d-4c50-b58e-82d35dc111b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-140a71f9-fddc-4636-8963-d56411d9dae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-de6e3e76-c48b-4715-ae74-df396620696f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860580253-172.17.0.5-1595501133335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-39ba32b5-44cc-40f6-a343-a5a9bbbe20dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-b8131519-6c54-402a-8836-eea54659381b,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-382007c8-c5e9-49f8-9254-021db216516a,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-abe94bab-6a86-46db-9604-dffea30428ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-04b14a66-07d9-447d-be97-c9ab0b607032,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-524301c3-967d-4c50-b58e-82d35dc111b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-140a71f9-fddc-4636-8963-d56411d9dae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-de6e3e76-c48b-4715-ae74-df396620696f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5497
