reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812167062-172.17.0.6-1595499387605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-3f852fdb-6ecd-46fe-9d73-470067bfa29d,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-4c76cc1a-0a23-4d76-81e9-04488372db8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-4775321f-c0f5-4c7e-899e-f443c77a93d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-4b4bade2-7b67-472f-a4b7-4ad7c3d998ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-49ae3b4e-e308-40c8-9f27-70a94d544679,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-005792a7-57bf-433f-99e4-9b6c47b93bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-32d83d55-b151-4147-8b13-783e05a6fb31,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-98b4bcfa-9690-4c80-9888-4f86bffbfb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812167062-172.17.0.6-1595499387605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-3f852fdb-6ecd-46fe-9d73-470067bfa29d,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-4c76cc1a-0a23-4d76-81e9-04488372db8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-4775321f-c0f5-4c7e-899e-f443c77a93d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-4b4bade2-7b67-472f-a4b7-4ad7c3d998ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-49ae3b4e-e308-40c8-9f27-70a94d544679,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-005792a7-57bf-433f-99e4-9b6c47b93bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-32d83d55-b151-4147-8b13-783e05a6fb31,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-98b4bcfa-9690-4c80-9888-4f86bffbfb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340724099-172.17.0.6-1595499552792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-e3c830a2-2df0-45e7-94fe-042a67de09aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-6537092b-8897-47e5-b6a6-b4b0acd5117e,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-04ed1dcd-bb14-4d98-8a45-da77db59efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-1cd5a66a-dd16-4d7d-9a3e-d8dc9582daac,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-09d93ba9-c42a-4759-9bad-7a2d787c1635,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-60b8377b-be0d-4d66-a0cc-991c547cd4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-4145deb4-0be2-4edf-9e1d-f4afa3b84dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-7b83f105-9a56-4436-a7cf-64617458fefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340724099-172.17.0.6-1595499552792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42049,DS-e3c830a2-2df0-45e7-94fe-042a67de09aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-6537092b-8897-47e5-b6a6-b4b0acd5117e,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-04ed1dcd-bb14-4d98-8a45-da77db59efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-1cd5a66a-dd16-4d7d-9a3e-d8dc9582daac,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-09d93ba9-c42a-4759-9bad-7a2d787c1635,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-60b8377b-be0d-4d66-a0cc-991c547cd4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-4145deb4-0be2-4edf-9e1d-f4afa3b84dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-7b83f105-9a56-4436-a7cf-64617458fefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972580204-172.17.0.6-1595499825401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45825,DS-d402ac36-554a-403f-9bf4-b348bfbee736,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-257ecdbe-6397-46ed-b4f2-82000b08ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-ec69c8b3-7b61-4a17-91e8-519b16e9ba00,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-d99221af-c5d8-483d-824a-28deb4fc3f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-c3b20866-350f-409d-ba48-e062e27fe495,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-8bc83bb8-41f7-49ee-95fe-19f6c7ae4f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-3a54f8e3-c9c4-43be-bdf5-0a316117d321,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-c2e8125d-b8f1-403a-bd7d-ef622a2bc874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972580204-172.17.0.6-1595499825401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45825,DS-d402ac36-554a-403f-9bf4-b348bfbee736,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-257ecdbe-6397-46ed-b4f2-82000b08ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-ec69c8b3-7b61-4a17-91e8-519b16e9ba00,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-d99221af-c5d8-483d-824a-28deb4fc3f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-c3b20866-350f-409d-ba48-e062e27fe495,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-8bc83bb8-41f7-49ee-95fe-19f6c7ae4f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-3a54f8e3-c9c4-43be-bdf5-0a316117d321,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-c2e8125d-b8f1-403a-bd7d-ef622a2bc874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489386168-172.17.0.6-1595499946550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40268,DS-4fd8fd24-d54d-4b26-aa9e-9379b15fb44f,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-994b90ba-513a-4c76-9499-dc15c7f4d754,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-d0ab3f1c-15b8-49fd-83ff-85c65793b15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-0c6c3888-b63b-4d97-866a-834117361b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-6c121742-e49d-41ff-bf67-78ef2e1d8a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-c44d5b1a-ed74-4453-ad50-e9e29a251a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-2aabb0d4-a27e-429e-99fc-9b79050eae77,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-13b5c1f8-87ad-4874-9612-0d5473dc611f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489386168-172.17.0.6-1595499946550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40268,DS-4fd8fd24-d54d-4b26-aa9e-9379b15fb44f,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-994b90ba-513a-4c76-9499-dc15c7f4d754,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-d0ab3f1c-15b8-49fd-83ff-85c65793b15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-0c6c3888-b63b-4d97-866a-834117361b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-6c121742-e49d-41ff-bf67-78ef2e1d8a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-c44d5b1a-ed74-4453-ad50-e9e29a251a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-2aabb0d4-a27e-429e-99fc-9b79050eae77,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-13b5c1f8-87ad-4874-9612-0d5473dc611f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983479872-172.17.0.6-1595500160427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42545,DS-06f0b4ae-7e54-4007-86a5-f95c6bb47c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-2c3ad4f7-f4d6-449a-916f-39e7730afac9,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-3506d988-d308-46f1-ad7a-6cd4deeace5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-17785d2c-2894-4a84-9645-89cd33b06f22,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-1e765cf4-852d-4346-80cf-a717a2311e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-7267ae47-aa45-4499-abcd-1db7aa7e8126,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-3f912bda-b000-4a10-b73f-75ca38bf36af,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-13bc3d4d-b7d0-40c6-a2e1-7d4c2ea7e512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983479872-172.17.0.6-1595500160427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42545,DS-06f0b4ae-7e54-4007-86a5-f95c6bb47c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-2c3ad4f7-f4d6-449a-916f-39e7730afac9,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-3506d988-d308-46f1-ad7a-6cd4deeace5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-17785d2c-2894-4a84-9645-89cd33b06f22,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-1e765cf4-852d-4346-80cf-a717a2311e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-7267ae47-aa45-4499-abcd-1db7aa7e8126,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-3f912bda-b000-4a10-b73f-75ca38bf36af,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-13bc3d4d-b7d0-40c6-a2e1-7d4c2ea7e512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123058231-172.17.0.6-1595500313561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-efd187d6-3092-460e-9f65-bb57c041b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-46705412-c6a8-4ae9-b0fa-eeb89153214d,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-014d1bc7-6b94-45ad-94aa-48ecffa1f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-922e3726-e3fd-40fe-acde-b74093a9ad29,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-147b0c00-e636-4c4c-8e87-f191430a6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-3219c221-036c-438b-9a3c-78dca7461383,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-65c20500-5f85-4d64-9ad7-98e5a5afa248,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-ae0b9cd5-0a47-4052-b38e-ffabe9426e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123058231-172.17.0.6-1595500313561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-efd187d6-3092-460e-9f65-bb57c041b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-46705412-c6a8-4ae9-b0fa-eeb89153214d,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-014d1bc7-6b94-45ad-94aa-48ecffa1f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-922e3726-e3fd-40fe-acde-b74093a9ad29,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-147b0c00-e636-4c4c-8e87-f191430a6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-3219c221-036c-438b-9a3c-78dca7461383,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-65c20500-5f85-4d64-9ad7-98e5a5afa248,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-ae0b9cd5-0a47-4052-b38e-ffabe9426e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082965106-172.17.0.6-1595501022300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-3afd80a8-329c-437c-b428-1c810817caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-2abcf463-c6e1-4111-bfcd-3b92f581dcee,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-3d660d47-a781-423c-9f1e-ec59431dce53,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-590487d2-ea5d-4408-9724-9cebf4fc3380,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-8bfb4da9-b35e-49e4-90b6-60368d440e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-b689d087-5af7-4e3b-bf4f-82a178e0b1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-e92e4b87-ad10-4863-ab8a-0445ee22bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-891d069a-2bf0-41fb-bc9f-b8034d631c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082965106-172.17.0.6-1595501022300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-3afd80a8-329c-437c-b428-1c810817caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-2abcf463-c6e1-4111-bfcd-3b92f581dcee,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-3d660d47-a781-423c-9f1e-ec59431dce53,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-590487d2-ea5d-4408-9724-9cebf4fc3380,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-8bfb4da9-b35e-49e4-90b6-60368d440e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-b689d087-5af7-4e3b-bf4f-82a178e0b1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-e92e4b87-ad10-4863-ab8a-0445ee22bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-891d069a-2bf0-41fb-bc9f-b8034d631c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934791077-172.17.0.6-1595501178912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-f542d6f9-36af-47fc-adca-c45ab07bc169,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-fed5f4c2-4f55-4056-a4d9-2ac0a258921a,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-cac89e79-41af-43c6-bfce-11530224bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-2b03015b-e978-40a2-a0e2-50d98dc3d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-aaf5ce8b-0a61-4e4f-a363-196088ab59a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-18380ec7-af59-4578-bbaa-a0c36e30f173,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-c4b9ea7f-de8f-4bab-8edc-ba0077947f20,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-1a8c53e0-8d62-4797-87b3-09f5872e5a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934791077-172.17.0.6-1595501178912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-f542d6f9-36af-47fc-adca-c45ab07bc169,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-fed5f4c2-4f55-4056-a4d9-2ac0a258921a,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-cac89e79-41af-43c6-bfce-11530224bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-2b03015b-e978-40a2-a0e2-50d98dc3d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-aaf5ce8b-0a61-4e4f-a363-196088ab59a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-18380ec7-af59-4578-bbaa-a0c36e30f173,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-c4b9ea7f-de8f-4bab-8edc-ba0077947f20,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-1a8c53e0-8d62-4797-87b3-09f5872e5a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620613639-172.17.0.6-1595501252135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-6c3df778-a017-4662-ae31-ca54d21f1890,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-4e8dbe66-42f7-4ea5-9a81-8d72e945b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-864cc1f2-484d-4af9-b018-b0240be93ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-558f535d-c46a-4432-9229-840eef17588a,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-536953b7-7075-4ca5-b3ec-97bb29572fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-1b45dbb5-75b2-4824-905e-04ecc1e95fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-8f6a4161-bbfc-4a86-a6c0-4d5e8042a05a,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-49f5345b-98e1-4000-92ed-d4fc2a4efbc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620613639-172.17.0.6-1595501252135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-6c3df778-a017-4662-ae31-ca54d21f1890,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-4e8dbe66-42f7-4ea5-9a81-8d72e945b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-864cc1f2-484d-4af9-b018-b0240be93ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-558f535d-c46a-4432-9229-840eef17588a,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-536953b7-7075-4ca5-b3ec-97bb29572fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-1b45dbb5-75b2-4824-905e-04ecc1e95fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-8f6a4161-bbfc-4a86-a6c0-4d5e8042a05a,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-49f5345b-98e1-4000-92ed-d4fc2a4efbc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48663500-172.17.0.6-1595501997375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32875,DS-70fc1f57-43e7-435d-8236-984d42b04031,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-f1871bb6-eb6e-480e-ab3d-2ca29ac7c2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-d547a546-b69c-44c1-8521-751380b13dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-c78b6fef-3ed7-4ec8-bda9-ef96b821a029,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-34902143-32c4-4b66-a342-d7c21dcc79b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-810049b9-35ec-4790-8ed4-56155b9aa369,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-f51b13dc-1c3d-4c07-bcd4-e98fd995f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-971ab38d-0228-4f0d-859e-36eda32e899a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48663500-172.17.0.6-1595501997375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32875,DS-70fc1f57-43e7-435d-8236-984d42b04031,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-f1871bb6-eb6e-480e-ab3d-2ca29ac7c2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-d547a546-b69c-44c1-8521-751380b13dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-c78b6fef-3ed7-4ec8-bda9-ef96b821a029,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-34902143-32c4-4b66-a342-d7c21dcc79b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-810049b9-35ec-4790-8ed4-56155b9aa369,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-f51b13dc-1c3d-4c07-bcd4-e98fd995f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-971ab38d-0228-4f0d-859e-36eda32e899a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093385964-172.17.0.6-1595502539702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-84348e5b-7204-4fea-94a1-37c68b37b76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-fb772a84-8e3e-4b5d-b1b0-d0d919ae64d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-aef92adb-1276-4b98-b186-5714a96d41ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-d09a2610-cbd2-4fe0-96aa-74b74850a650,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-4ce699b7-1c3b-48c9-b79e-d7c20f9fb05a,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-b719fd7a-5858-467a-b421-640c93ea8c33,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-30f031a7-64ad-4f81-9dd2-ecc9bb7c3fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-7829ae5a-9cfb-406b-b70b-5ed687fc9f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093385964-172.17.0.6-1595502539702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35957,DS-84348e5b-7204-4fea-94a1-37c68b37b76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-fb772a84-8e3e-4b5d-b1b0-d0d919ae64d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-aef92adb-1276-4b98-b186-5714a96d41ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-d09a2610-cbd2-4fe0-96aa-74b74850a650,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-4ce699b7-1c3b-48c9-b79e-d7c20f9fb05a,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-b719fd7a-5858-467a-b421-640c93ea8c33,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-30f031a7-64ad-4f81-9dd2-ecc9bb7c3fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-7829ae5a-9cfb-406b-b70b-5ed687fc9f07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244508695-172.17.0.6-1595502623291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-7b96ec8e-0a5c-46be-ad8c-c9fd2934d91b,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-2e1eb44e-58b9-4dcf-9eb2-0c887a7a5783,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-ae94428d-7ceb-4439-b750-b351a518a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-f36b2821-6b30-49c3-92af-7d1c317b325c,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-a88c8b51-6513-40dd-89f6-c8d769065789,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-b0b1ae50-81c0-4fa7-adf9-a6105a3c144a,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-488d2f11-5d14-4af0-ae86-65108c0ae111,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-64a3cb8b-d594-45b8-9bc9-8d1bb9c93381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244508695-172.17.0.6-1595502623291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-7b96ec8e-0a5c-46be-ad8c-c9fd2934d91b,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-2e1eb44e-58b9-4dcf-9eb2-0c887a7a5783,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-ae94428d-7ceb-4439-b750-b351a518a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-f36b2821-6b30-49c3-92af-7d1c317b325c,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-a88c8b51-6513-40dd-89f6-c8d769065789,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-b0b1ae50-81c0-4fa7-adf9-a6105a3c144a,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-488d2f11-5d14-4af0-ae86-65108c0ae111,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-64a3cb8b-d594-45b8-9bc9-8d1bb9c93381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163731095-172.17.0.6-1595504055066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43536,DS-59bb6d19-c51b-4a82-8d33-7bcc7f3a5468,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-d575b530-3595-4896-ac16-148df59b1a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-e1451d2d-17e8-47e6-a63d-351ee5a64c23,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-a997d814-751a-4b70-be72-08dc14055b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-4d0d0aa6-7f32-4e05-941f-d6a3280482a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-fc1b85c7-d442-4d4d-b5af-c8d2525e153a,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-3f68f2a9-146a-4a8e-a01b-d34a1c03b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-2b165388-2483-43d0-a498-4dbe0cd717d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163731095-172.17.0.6-1595504055066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43536,DS-59bb6d19-c51b-4a82-8d33-7bcc7f3a5468,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-d575b530-3595-4896-ac16-148df59b1a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-e1451d2d-17e8-47e6-a63d-351ee5a64c23,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-a997d814-751a-4b70-be72-08dc14055b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-4d0d0aa6-7f32-4e05-941f-d6a3280482a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-fc1b85c7-d442-4d4d-b5af-c8d2525e153a,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-3f68f2a9-146a-4a8e-a01b-d34a1c03b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-2b165388-2483-43d0-a498-4dbe0cd717d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322835987-172.17.0.6-1595504305784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36245,DS-8caaae11-7057-4006-b2de-3053c626b7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7324cdfd-4ca9-4077-8c4f-d2d0c69dbe86,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-2234d99b-8c60-4fd0-86dd-0e63d69c5b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-432406ef-5267-4562-8237-989e8a114e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-2c9c7e42-1da5-4033-ae9e-ed236c4bc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-4cc67d86-5453-4cee-bcc9-e75690c47ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-f0707acb-2874-420a-8909-893dcaf36adf,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-12e5abcb-e9c4-426b-a983-fa2973a6c8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322835987-172.17.0.6-1595504305784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36245,DS-8caaae11-7057-4006-b2de-3053c626b7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7324cdfd-4ca9-4077-8c4f-d2d0c69dbe86,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-2234d99b-8c60-4fd0-86dd-0e63d69c5b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-432406ef-5267-4562-8237-989e8a114e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-2c9c7e42-1da5-4033-ae9e-ed236c4bc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-4cc67d86-5453-4cee-bcc9-e75690c47ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-f0707acb-2874-420a-8909-893dcaf36adf,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-12e5abcb-e9c4-426b-a983-fa2973a6c8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628589819-172.17.0.6-1595504473440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46145,DS-c2a7ef88-63fe-43c4-8dd1-7bbc7d77c47c,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-4cbee582-2216-4a37-90d3-e1dd12191260,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-e432a592-c3d5-4b33-9460-e04b0bef01b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-227698bd-7add-40a4-b7c9-09ac1bf5ba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-ec80466b-69a8-4ad8-9cf3-0b7e07d8d372,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-dbc54fad-fc00-4db3-a3f1-d006fd7f3930,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-99720079-37da-4ceb-ae65-5dd05fd8ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-ccd76c9c-5272-4cc8-9690-87286169d05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628589819-172.17.0.6-1595504473440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46145,DS-c2a7ef88-63fe-43c4-8dd1-7bbc7d77c47c,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-4cbee582-2216-4a37-90d3-e1dd12191260,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-e432a592-c3d5-4b33-9460-e04b0bef01b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-227698bd-7add-40a4-b7c9-09ac1bf5ba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-ec80466b-69a8-4ad8-9cf3-0b7e07d8d372,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-dbc54fad-fc00-4db3-a3f1-d006fd7f3930,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-99720079-37da-4ceb-ae65-5dd05fd8ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-ccd76c9c-5272-4cc8-9690-87286169d05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 3000000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38137040-172.17.0.6-1595504501687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43628,DS-a1315c1f-36d0-46f8-a6e8-e6cc1e6c83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-ae30090c-7c0b-4e24-bdc5-91cb62fb5c30,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-a7a76c03-ac21-49d1-9d82-ba532b5c7fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-034fde14-13ab-4760-a760-e38c0b2e9110,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-5c3333fc-4f2f-4678-b11c-a5eab8b1d601,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-48e8ca61-5ba9-4818-95d0-176093998b59,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-5f0c21a2-6fda-4428-aa43-62ce28d7587e,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-1f4c954a-8d15-4cba-b718-d43828a3cdba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38137040-172.17.0.6-1595504501687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43628,DS-a1315c1f-36d0-46f8-a6e8-e6cc1e6c83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-ae30090c-7c0b-4e24-bdc5-91cb62fb5c30,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-a7a76c03-ac21-49d1-9d82-ba532b5c7fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-034fde14-13ab-4760-a760-e38c0b2e9110,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-5c3333fc-4f2f-4678-b11c-a5eab8b1d601,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-48e8ca61-5ba9-4818-95d0-176093998b59,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-5f0c21a2-6fda-4428-aa43-62ce28d7587e,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-1f4c954a-8d15-4cba-b718-d43828a3cdba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5584
