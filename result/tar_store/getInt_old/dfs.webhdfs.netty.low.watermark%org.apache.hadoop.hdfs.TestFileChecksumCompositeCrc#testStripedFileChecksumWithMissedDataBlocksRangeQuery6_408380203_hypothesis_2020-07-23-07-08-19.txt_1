reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882595265-172.17.0.9-1595488114302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37065,DS-dc787455-f924-4fd3-a6e3-7e32d98791a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-9f48837e-7664-43e4-9a05-c7ccd664626e,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-5fa29407-2dd9-4a3d-9ca3-a858f5968665,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-aa522234-c834-466b-b4cc-84e1c5eea0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-6340a277-9b7c-475d-955b-4630db72c554,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-73839efc-0b59-40e6-9ac3-3e8ff42a369e,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-829b9eec-b76d-4162-8d0b-ac0e896a7349,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-909e2c2e-2c80-4920-b91b-2d9790ea2025,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882595265-172.17.0.9-1595488114302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37065,DS-dc787455-f924-4fd3-a6e3-7e32d98791a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-9f48837e-7664-43e4-9a05-c7ccd664626e,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-5fa29407-2dd9-4a3d-9ca3-a858f5968665,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-aa522234-c834-466b-b4cc-84e1c5eea0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-6340a277-9b7c-475d-955b-4630db72c554,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-73839efc-0b59-40e6-9ac3-3e8ff42a369e,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-829b9eec-b76d-4162-8d0b-ac0e896a7349,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-909e2c2e-2c80-4920-b91b-2d9790ea2025,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727268162-172.17.0.9-1595488407338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-72bc61fa-e74e-4b27-bcc4-8cb95804a2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-095d97bb-19f4-4c57-aa91-c3a967f395f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-19f65d1d-d296-4bdb-a0a6-e885b1a68223,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-3051d19e-79be-47ae-852e-65e6415ed3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-41f59ec4-cde1-4b20-b362-4554f49bdf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-1dbd14ef-6ccd-4009-8cb8-8a731f6cd6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-13d8b4d2-d61e-45bc-bd4c-9aab26733c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-c8c16b02-979a-4668-b91c-a072f8180cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727268162-172.17.0.9-1595488407338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-72bc61fa-e74e-4b27-bcc4-8cb95804a2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-095d97bb-19f4-4c57-aa91-c3a967f395f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-19f65d1d-d296-4bdb-a0a6-e885b1a68223,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-3051d19e-79be-47ae-852e-65e6415ed3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-41f59ec4-cde1-4b20-b362-4554f49bdf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-1dbd14ef-6ccd-4009-8cb8-8a731f6cd6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-13d8b4d2-d61e-45bc-bd4c-9aab26733c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-c8c16b02-979a-4668-b91c-a072f8180cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703190666-172.17.0.9-1595488535373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38374,DS-3ccf92c6-361b-4805-a427-6682fdacc044,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-065f6193-854d-435e-8d9e-83f73cdb0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-650169ea-0271-4198-a2d9-423a8eba0b48,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-ff29dbcd-1517-4d14-ab99-cee3f80e1a05,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-29050e6e-d6a0-4833-9aa0-cdc4ce3546ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-68dd647e-3b0a-4256-8106-36b1938e7d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-8dad1842-da35-435c-8e1e-ddfb3d294bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-5fc55361-09e6-4fdc-97fb-c71a2a6f4aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703190666-172.17.0.9-1595488535373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38374,DS-3ccf92c6-361b-4805-a427-6682fdacc044,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-065f6193-854d-435e-8d9e-83f73cdb0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-650169ea-0271-4198-a2d9-423a8eba0b48,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-ff29dbcd-1517-4d14-ab99-cee3f80e1a05,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-29050e6e-d6a0-4833-9aa0-cdc4ce3546ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-68dd647e-3b0a-4256-8106-36b1938e7d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-8dad1842-da35-435c-8e1e-ddfb3d294bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-5fc55361-09e6-4fdc-97fb-c71a2a6f4aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146855227-172.17.0.9-1595488572892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-e0b233a3-3a44-4265-a2ed-2888e1e9ed86,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-0256f974-ce53-435c-ba36-9d8e3eedc186,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-dcbfb50e-5363-4464-abd2-40a5291d25f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-f45dbe84-5734-4ca9-bdfb-14b5a0ec2f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-2b08aa7a-1797-498c-8b55-3586d109e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-08bf1522-0f99-4e49-a6d0-3e7bf04614ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-37facc82-8f8a-402b-bd5b-be6940086aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-610bb0cd-032b-43bd-88f2-7d48d2b53a83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146855227-172.17.0.9-1595488572892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-e0b233a3-3a44-4265-a2ed-2888e1e9ed86,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-0256f974-ce53-435c-ba36-9d8e3eedc186,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-dcbfb50e-5363-4464-abd2-40a5291d25f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-f45dbe84-5734-4ca9-bdfb-14b5a0ec2f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-2b08aa7a-1797-498c-8b55-3586d109e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-08bf1522-0f99-4e49-a6d0-3e7bf04614ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-37facc82-8f8a-402b-bd5b-be6940086aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-610bb0cd-032b-43bd-88f2-7d48d2b53a83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361670885-172.17.0.9-1595488607161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-78a697fd-a2de-4a7b-b518-e2edcee3e574,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-dd2aa992-12ca-4531-8c24-19ae3c660dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-9fa6747e-573a-423d-a1d3-4735fcb8df96,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-3f2ffa88-7a35-4347-a3dc-0d1ba1213780,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-d4219403-dfee-4a4a-a981-e4c371c87b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-320609b7-95ba-4d40-adfd-aad6022d0a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-80e3f59a-88de-421e-9a80-a2f2d3bbbdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-bf2cbe3e-47af-48c2-8f02-f9c0b3fe6cff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361670885-172.17.0.9-1595488607161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-78a697fd-a2de-4a7b-b518-e2edcee3e574,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-dd2aa992-12ca-4531-8c24-19ae3c660dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-9fa6747e-573a-423d-a1d3-4735fcb8df96,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-3f2ffa88-7a35-4347-a3dc-0d1ba1213780,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-d4219403-dfee-4a4a-a981-e4c371c87b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-320609b7-95ba-4d40-adfd-aad6022d0a31,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-80e3f59a-88de-421e-9a80-a2f2d3bbbdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-bf2cbe3e-47af-48c2-8f02-f9c0b3fe6cff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538237796-172.17.0.9-1595488670071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-cced4392-1e32-41c2-bf72-52cc1f33518a,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-519adb2b-46b3-492f-a986-5bfede69d33a,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-a41f641c-0e84-4ccf-aa31-ab049bedfc56,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-1ea8356b-3c69-4a3c-ab02-25e9f5bd5830,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-3067f48c-bc3a-4412-93fb-cb1ad36633cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-0f87d7d4-709f-439d-bd95-5e9f505d5a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-b6b9de3a-f2bf-4e73-9896-7ce756b0c9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-3613535e-0cec-48bf-aa2c-ac45338e82dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538237796-172.17.0.9-1595488670071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-cced4392-1e32-41c2-bf72-52cc1f33518a,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-519adb2b-46b3-492f-a986-5bfede69d33a,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-a41f641c-0e84-4ccf-aa31-ab049bedfc56,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-1ea8356b-3c69-4a3c-ab02-25e9f5bd5830,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-3067f48c-bc3a-4412-93fb-cb1ad36633cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-0f87d7d4-709f-439d-bd95-5e9f505d5a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-b6b9de3a-f2bf-4e73-9896-7ce756b0c9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-3613535e-0cec-48bf-aa2c-ac45338e82dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465348398-172.17.0.9-1595488961188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42932,DS-3608681e-92bf-403b-81b4-9807b61026e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-54c00c72-b5ef-41cd-881c-0cd7c8fbee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-af179701-b7da-4a61-bac9-e881489029b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-507a88c8-80aa-4944-a66d-38e598bd81c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-846a826e-845f-4d34-82da-099252b4dca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-0e781ab8-8953-4059-a4a1-2365a590d7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-209ab9fa-80e5-470e-9eb8-79bf0293cc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-90666ba1-a2d9-4bf3-9321-517a2f0c6e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465348398-172.17.0.9-1595488961188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42932,DS-3608681e-92bf-403b-81b4-9807b61026e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-54c00c72-b5ef-41cd-881c-0cd7c8fbee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-af179701-b7da-4a61-bac9-e881489029b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-507a88c8-80aa-4944-a66d-38e598bd81c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-846a826e-845f-4d34-82da-099252b4dca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-0e781ab8-8953-4059-a4a1-2365a590d7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-209ab9fa-80e5-470e-9eb8-79bf0293cc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-90666ba1-a2d9-4bf3-9321-517a2f0c6e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094784220-172.17.0.9-1595489006252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-26776842-c925-4ee0-be7a-a8c15403c298,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-a5319436-85e9-45a2-aa2c-4ec077cacd71,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-485ea83e-247a-44e6-85b6-6ba5d58b9673,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-abc19f7d-bb66-4c76-9295-bd8db6725be1,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-25b50af6-c2cc-4c4c-b753-fdf2348ddd56,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-89edc4ce-b777-4ead-8c22-132438ac5fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-33538081-3850-4002-89ce-34b9d2126951,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-3c580fbe-f928-4317-afd6-b0ce5393d037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094784220-172.17.0.9-1595489006252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-26776842-c925-4ee0-be7a-a8c15403c298,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-a5319436-85e9-45a2-aa2c-4ec077cacd71,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-485ea83e-247a-44e6-85b6-6ba5d58b9673,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-abc19f7d-bb66-4c76-9295-bd8db6725be1,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-25b50af6-c2cc-4c4c-b753-fdf2348ddd56,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-89edc4ce-b777-4ead-8c22-132438ac5fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-33538081-3850-4002-89ce-34b9d2126951,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-3c580fbe-f928-4317-afd6-b0ce5393d037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276808250-172.17.0.9-1595489150752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44409,DS-2ed27ac9-91b2-4048-a918-0a1f2d6badbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-c84883b2-844c-4099-8275-96cd917adef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-ed187247-9ccd-4a03-a58a-2a19c18fca96,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-ecebbaf0-eccd-4b11-9019-8e9ec965665a,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-416c97df-4c52-4c60-8e46-dc1dd21f2289,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-e1c6e977-4fb4-4ff5-97a2-a8599f47cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-cca74b9d-0bdf-419c-bdd5-1b6447e3d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-5685efa0-43f6-423b-8ef8-032cf2acb368,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1276808250-172.17.0.9-1595489150752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44409,DS-2ed27ac9-91b2-4048-a918-0a1f2d6badbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-c84883b2-844c-4099-8275-96cd917adef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-ed187247-9ccd-4a03-a58a-2a19c18fca96,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-ecebbaf0-eccd-4b11-9019-8e9ec965665a,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-416c97df-4c52-4c60-8e46-dc1dd21f2289,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-e1c6e977-4fb4-4ff5-97a2-a8599f47cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-cca74b9d-0bdf-419c-bdd5-1b6447e3d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-5685efa0-43f6-423b-8ef8-032cf2acb368,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139990578-172.17.0.9-1595489299440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41547,DS-345581a1-813a-454c-bd03-3a262e824d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-791b0cff-2fc4-4d38-bc81-b2a3f77c5de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-b013d546-99e7-4113-8737-6a0d7c4c64d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-b1ac3abb-5a39-4511-9528-329d070aef10,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-32459a50-3f32-4825-8855-acce229cbff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-67d217cf-c90b-4ebc-87c7-6b37107aa022,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-d1875c34-6311-499b-9c09-caa1e4243582,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-da2128fc-7ef1-46dc-b9a7-4fb6e818c390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139990578-172.17.0.9-1595489299440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41547,DS-345581a1-813a-454c-bd03-3a262e824d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-791b0cff-2fc4-4d38-bc81-b2a3f77c5de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-b013d546-99e7-4113-8737-6a0d7c4c64d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-b1ac3abb-5a39-4511-9528-329d070aef10,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-32459a50-3f32-4825-8855-acce229cbff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-67d217cf-c90b-4ebc-87c7-6b37107aa022,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-d1875c34-6311-499b-9c09-caa1e4243582,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-da2128fc-7ef1-46dc-b9a7-4fb6e818c390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524319325-172.17.0.9-1595489438263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33551,DS-0866af25-1ce6-4243-b216-fd41dbf05481,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-8ae273c2-d92b-43d9-a99c-12db029a889d,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-7235d3a8-9c91-4589-8d36-1f61bcdb615e,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-0513253d-6696-4cd1-8147-5a6db9d78e24,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-794c37d9-335b-4184-ba7d-4c98d15f88c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-d961e89e-9222-4101-8d54-9e7a1a52565e,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-301de065-f825-4345-a119-d44210c2e6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-39408a90-1983-45bb-b146-514c9794f0da,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524319325-172.17.0.9-1595489438263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33551,DS-0866af25-1ce6-4243-b216-fd41dbf05481,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-8ae273c2-d92b-43d9-a99c-12db029a889d,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-7235d3a8-9c91-4589-8d36-1f61bcdb615e,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-0513253d-6696-4cd1-8147-5a6db9d78e24,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-794c37d9-335b-4184-ba7d-4c98d15f88c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-d961e89e-9222-4101-8d54-9e7a1a52565e,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-301de065-f825-4345-a119-d44210c2e6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-39408a90-1983-45bb-b146-514c9794f0da,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023250115-172.17.0.9-1595489652668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42109,DS-8a27d6e6-1227-4144-8fb1-0399765a928a,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-978e3b1b-74b6-4914-869e-ab9ebd44fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-4cbd4643-42e3-44a1-b179-47f446d812da,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-e60600fe-6f76-4fff-9419-47a1be18edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-20b69469-4d31-4290-ab43-0a9070ed1ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-704de2fd-529c-46a2-bc26-3224930aa84b,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-c1953e15-59e0-4319-9c66-fee174192054,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-0cb14243-d404-41e6-8f65-2c625286d75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023250115-172.17.0.9-1595489652668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42109,DS-8a27d6e6-1227-4144-8fb1-0399765a928a,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-978e3b1b-74b6-4914-869e-ab9ebd44fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-4cbd4643-42e3-44a1-b179-47f446d812da,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-e60600fe-6f76-4fff-9419-47a1be18edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-20b69469-4d31-4290-ab43-0a9070ed1ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-704de2fd-529c-46a2-bc26-3224930aa84b,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-c1953e15-59e0-4319-9c66-fee174192054,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-0cb14243-d404-41e6-8f65-2c625286d75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689054965-172.17.0.9-1595489984257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-bbd364cd-ebfc-4c0a-bb30-f368a8a7e826,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-8c7d9d19-af21-4580-800d-eb33ed2daafe,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-2a049b97-d53b-471f-a255-bdc79eed7343,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-5fb1bdd6-ee97-4f3e-993a-d8d5e4875485,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-0c9a2453-5d3e-45c2-9be1-8a2c1778fead,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-279477f6-26a6-4323-bb45-8b1359c1fde0,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-ea980b48-c797-4b09-b9f3-c4d8f25d0248,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-5fcc5339-94da-42e7-9c01-117cb83075ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689054965-172.17.0.9-1595489984257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-bbd364cd-ebfc-4c0a-bb30-f368a8a7e826,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-8c7d9d19-af21-4580-800d-eb33ed2daafe,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-2a049b97-d53b-471f-a255-bdc79eed7343,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-5fb1bdd6-ee97-4f3e-993a-d8d5e4875485,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-0c9a2453-5d3e-45c2-9be1-8a2c1778fead,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-279477f6-26a6-4323-bb45-8b1359c1fde0,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-ea980b48-c797-4b09-b9f3-c4d8f25d0248,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-5fcc5339-94da-42e7-9c01-117cb83075ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012938426-172.17.0.9-1595490100837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-aecb25e1-9058-4182-b5a8-f41dff44f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-7200ba82-fd25-4f1e-975b-43194ab2833c,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-13963e30-8e37-40b1-8587-64734c467cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-6c41b5ad-2545-4801-8b74-eb8959b2502f,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-17bfbfa5-ff65-4a77-9abc-138bd46ee818,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-e20982f1-8395-4f93-a898-069f77482972,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-11162ba7-6c8f-4216-92f7-60ea4f68fa91,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-f9b189a8-a85c-450b-a23e-968d199143c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012938426-172.17.0.9-1595490100837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-aecb25e1-9058-4182-b5a8-f41dff44f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-7200ba82-fd25-4f1e-975b-43194ab2833c,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-13963e30-8e37-40b1-8587-64734c467cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-6c41b5ad-2545-4801-8b74-eb8959b2502f,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-17bfbfa5-ff65-4a77-9abc-138bd46ee818,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-e20982f1-8395-4f93-a898-069f77482972,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-11162ba7-6c8f-4216-92f7-60ea4f68fa91,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-f9b189a8-a85c-450b-a23e-968d199143c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922891522-172.17.0.9-1595490303373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-c37ad70e-79f5-4eb7-b201-1e8a3ee9b531,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-32c9adad-1d8c-4718-b23c-b937da1782a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-55ae93d4-ca67-4b2c-b299-04123e4c924c,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-627da0d3-1ce3-4f1a-98f1-f22b1b18943e,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-0aa4c1a4-9bca-470f-bae0-777892769462,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-4ae49b53-a436-47d1-b4ea-df5e0986ef24,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-3ca8ff45-6582-45cd-85c4-e3c2d7d6898d,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-a0681a2d-8fda-41c7-ac91-fd204240d541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922891522-172.17.0.9-1595490303373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-c37ad70e-79f5-4eb7-b201-1e8a3ee9b531,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-32c9adad-1d8c-4718-b23c-b937da1782a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-55ae93d4-ca67-4b2c-b299-04123e4c924c,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-627da0d3-1ce3-4f1a-98f1-f22b1b18943e,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-0aa4c1a4-9bca-470f-bae0-777892769462,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-4ae49b53-a436-47d1-b4ea-df5e0986ef24,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-3ca8ff45-6582-45cd-85c4-e3c2d7d6898d,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-a0681a2d-8fda-41c7-ac91-fd204240d541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138941851-172.17.0.9-1595490617950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-d8f543d9-ad28-4e7f-9a1a-88758aef1be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-f9338d39-0e94-409d-9b94-9cbbc27bd952,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-86dacf0a-0e36-4a74-8d2c-d185a594ee77,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-789fc665-2375-49f0-a441-097d69541a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-731f0a06-a0f8-43ad-801c-c61b856661d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-9f787f2c-0dde-4e41-9b89-e41f8fa6a9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-998fc45b-1cf4-433d-baa4-0edeb3d3747d,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-9e1dd75d-5c1f-49b6-980e-3c68913e5b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138941851-172.17.0.9-1595490617950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-d8f543d9-ad28-4e7f-9a1a-88758aef1be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-f9338d39-0e94-409d-9b94-9cbbc27bd952,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-86dacf0a-0e36-4a74-8d2c-d185a594ee77,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-789fc665-2375-49f0-a441-097d69541a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-731f0a06-a0f8-43ad-801c-c61b856661d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-9f787f2c-0dde-4e41-9b89-e41f8fa6a9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-998fc45b-1cf4-433d-baa4-0edeb3d3747d,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-9e1dd75d-5c1f-49b6-980e-3c68913e5b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723084889-172.17.0.9-1595490777625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-eecf3f28-91e1-41c1-8992-dd3998457612,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-87fa81ba-a701-4693-a9dd-2cb59f4af581,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-a85ceaa6-ff49-41f8-bd10-2a2fff1ad591,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-29e5eda4-e334-42b5-98b9-60e141103dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-4014f119-111e-4488-af8d-79f2130a43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-28dac690-fb86-41b8-ac6e-fd962d4b67a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-ccee3207-8bde-4f92-becd-86c5e2a2846e,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-4938e8e5-fa63-46b7-8ce5-bcda85018a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723084889-172.17.0.9-1595490777625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-eecf3f28-91e1-41c1-8992-dd3998457612,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-87fa81ba-a701-4693-a9dd-2cb59f4af581,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-a85ceaa6-ff49-41f8-bd10-2a2fff1ad591,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-29e5eda4-e334-42b5-98b9-60e141103dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-4014f119-111e-4488-af8d-79f2130a43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-28dac690-fb86-41b8-ac6e-fd962d4b67a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-ccee3207-8bde-4f92-becd-86c5e2a2846e,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-4938e8e5-fa63-46b7-8ce5-bcda85018a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71130082-172.17.0.9-1595490806643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-b4727d0f-c630-490d-9604-784d0f6d6971,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-4ccab8c2-25b2-4671-ac8d-fe5e498d195c,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-9caf91a5-6307-4948-a913-5496e6cbd3df,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-8686b4d3-5633-4b9e-85ff-ca7e4c1bc11f,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-ae85f4b6-bc81-4114-b6ab-dabb00529ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-df614cb8-7441-4758-b54b-c205d81ad6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-e744f027-3a8b-4c94-afb6-4f19a7545e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-b9ee9de6-e74d-40de-96dd-d1b265ca1970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71130082-172.17.0.9-1595490806643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-b4727d0f-c630-490d-9604-784d0f6d6971,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-4ccab8c2-25b2-4671-ac8d-fe5e498d195c,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-9caf91a5-6307-4948-a913-5496e6cbd3df,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-8686b4d3-5633-4b9e-85ff-ca7e4c1bc11f,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-ae85f4b6-bc81-4114-b6ab-dabb00529ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-df614cb8-7441-4758-b54b-c205d81ad6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-e744f027-3a8b-4c94-afb6-4f19a7545e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-b9ee9de6-e74d-40de-96dd-d1b265ca1970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649678798-172.17.0.9-1595490886979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33113,DS-962864c0-6bc8-46a6-b425-580000f54131,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-8cb0b9bd-9c1d-4536-a25c-cc67ec878797,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-37d97289-d0e5-4ba3-9ee9-4b05193eeb34,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-09116689-39f7-45e1-83c1-dcca25d5f544,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-82c5426d-2c95-43f4-950e-853864734980,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-283dc7ff-e7fe-42da-85bc-37eb2610985d,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-0b10d7a6-f79f-4b4d-aa4e-cf1ef638465c,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-d8ec1f38-56bd-4c09-b69c-b044518d0673,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649678798-172.17.0.9-1595490886979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33113,DS-962864c0-6bc8-46a6-b425-580000f54131,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-8cb0b9bd-9c1d-4536-a25c-cc67ec878797,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-37d97289-d0e5-4ba3-9ee9-4b05193eeb34,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-09116689-39f7-45e1-83c1-dcca25d5f544,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-82c5426d-2c95-43f4-950e-853864734980,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-283dc7ff-e7fe-42da-85bc-37eb2610985d,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-0b10d7a6-f79f-4b4d-aa4e-cf1ef638465c,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-d8ec1f38-56bd-4c09-b69c-b044518d0673,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936990523-172.17.0.9-1595491222636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34218,DS-626895f8-7ecc-477b-bdb8-4610ffd2a993,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-9de86668-47d1-42ab-9340-b14565f9ad04,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-5c15c131-a28b-4f69-b340-9c29b89c1a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-1b47eb01-d16a-4679-adb1-eea0986959d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-32911fe3-14e0-44ab-bc28-bd27ad2096ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-ee998c32-d353-44f7-b18a-84fa15fb3eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-857ce4e6-c216-4041-b704-c1431f85f04e,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-ee1c336e-1b4a-407c-819f-99b309e61bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936990523-172.17.0.9-1595491222636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34218,DS-626895f8-7ecc-477b-bdb8-4610ffd2a993,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-9de86668-47d1-42ab-9340-b14565f9ad04,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-5c15c131-a28b-4f69-b340-9c29b89c1a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-1b47eb01-d16a-4679-adb1-eea0986959d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-32911fe3-14e0-44ab-bc28-bd27ad2096ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-ee998c32-d353-44f7-b18a-84fa15fb3eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-857ce4e6-c216-4041-b704-c1431f85f04e,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-ee1c336e-1b4a-407c-819f-99b309e61bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715390049-172.17.0.9-1595491302158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35543,DS-517d6454-096b-4c86-b73d-c9d44fbc1f97,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-fa6e6a88-7bb1-4827-a939-66dc96e354d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-6ed10d2c-5f64-4934-bba2-e6b917da136a,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-8daeb72e-ff42-47e9-883d-f37fc3a93521,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-b8866a53-91e6-4415-8689-73e874ee9551,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-062f7bd3-c8dd-425c-bf22-725b25dcd934,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-7b7fe15a-187b-4fee-8377-3e15f0c6163d,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-1d3f0272-89a0-4d76-97b7-8715f2cf7f40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715390049-172.17.0.9-1595491302158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35543,DS-517d6454-096b-4c86-b73d-c9d44fbc1f97,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-fa6e6a88-7bb1-4827-a939-66dc96e354d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-6ed10d2c-5f64-4934-bba2-e6b917da136a,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-8daeb72e-ff42-47e9-883d-f37fc3a93521,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-b8866a53-91e6-4415-8689-73e874ee9551,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-062f7bd3-c8dd-425c-bf22-725b25dcd934,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-7b7fe15a-187b-4fee-8377-3e15f0c6163d,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-1d3f0272-89a0-4d76-97b7-8715f2cf7f40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809507720-172.17.0.9-1595491378217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-e9ddff73-a7a3-4f81-9bfc-4d99fcbf87e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-6887cc35-f65a-4ee7-bfd6-b9cc13fadfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-508377a1-ac39-4498-ba9d-3fc8c51c530f,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-5e0a4212-715b-4a93-a51b-1c27b7a0d8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-5c3559ae-de60-4161-b6da-0453366439de,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-41fbbb69-ec5c-4588-821f-6e007ec7ea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-bf207cf6-6ec1-4168-b076-ccc00b74f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-01180570-3735-4246-8dab-f33c611a3876,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809507720-172.17.0.9-1595491378217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-e9ddff73-a7a3-4f81-9bfc-4d99fcbf87e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-6887cc35-f65a-4ee7-bfd6-b9cc13fadfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-508377a1-ac39-4498-ba9d-3fc8c51c530f,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-5e0a4212-715b-4a93-a51b-1c27b7a0d8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-5c3559ae-de60-4161-b6da-0453366439de,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-41fbbb69-ec5c-4588-821f-6e007ec7ea1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-bf207cf6-6ec1-4168-b076-ccc00b74f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-01180570-3735-4246-8dab-f33c611a3876,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372617649-172.17.0.9-1595491421481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35032,DS-e32873dc-c066-4b42-be44-e08cd60e4d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-b8ea6e70-0ca1-4e66-866b-98e4d8c710e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-049da807-2a2b-42be-893c-569e1e57433a,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-616af008-3840-4da8-98e9-a3a929b2280d,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-41ec7011-10ff-4dbe-8d2a-89fa0b0ba7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-bc5e032f-096c-4144-b2f1-8ad3224d8216,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-399b0165-a992-4eb4-880f-7d371c78e7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-de336055-509e-4ee3-9743-7e6f534b048f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372617649-172.17.0.9-1595491421481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35032,DS-e32873dc-c066-4b42-be44-e08cd60e4d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-b8ea6e70-0ca1-4e66-866b-98e4d8c710e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-049da807-2a2b-42be-893c-569e1e57433a,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-616af008-3840-4da8-98e9-a3a929b2280d,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-41ec7011-10ff-4dbe-8d2a-89fa0b0ba7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-bc5e032f-096c-4144-b2f1-8ad3224d8216,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-399b0165-a992-4eb4-880f-7d371c78e7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-de336055-509e-4ee3-9743-7e6f534b048f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809924617-172.17.0.9-1595491553012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-841d48c7-ff76-4977-a629-cd79b88abfac,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-f2090029-1b16-4dca-9e14-66c3752945c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-e4eae5f5-8326-432c-a1ba-38f45715e5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-d294e0ac-2459-4761-ab2a-f6b19b944150,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-4f360d6d-7e9a-46d8-849c-1961004a385a,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-2e21b35f-7ff1-4336-a538-36167769c170,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-3efc40c6-2f64-42ea-bf1b-10fbb0c651a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-3315b6f7-0e1f-4eaf-a1f1-ef8a6d03207e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809924617-172.17.0.9-1595491553012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-841d48c7-ff76-4977-a629-cd79b88abfac,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-f2090029-1b16-4dca-9e14-66c3752945c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-e4eae5f5-8326-432c-a1ba-38f45715e5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-d294e0ac-2459-4761-ab2a-f6b19b944150,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-4f360d6d-7e9a-46d8-849c-1961004a385a,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-2e21b35f-7ff1-4336-a538-36167769c170,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-3efc40c6-2f64-42ea-bf1b-10fbb0c651a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-3315b6f7-0e1f-4eaf-a1f1-ef8a6d03207e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408307942-172.17.0.9-1595491592705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35155,DS-07552f62-49d6-4846-9e51-096cbdf9422c,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-fa64dc15-36c6-4732-959e-851d965206b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-c4a1546e-a31a-49cd-823a-a0ee826624f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-88cac984-ddfc-448d-a826-98752c670ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-15e5bfa8-b3f2-4487-83ca-1ec715fdcd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f7320286-ba76-4bf1-879a-1ed4699c685e,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-83155c76-fd5e-434b-bc16-12c24c605893,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-f0558162-8f9a-4975-8b43-bced9704f9f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408307942-172.17.0.9-1595491592705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35155,DS-07552f62-49d6-4846-9e51-096cbdf9422c,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-fa64dc15-36c6-4732-959e-851d965206b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-c4a1546e-a31a-49cd-823a-a0ee826624f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-88cac984-ddfc-448d-a826-98752c670ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-15e5bfa8-b3f2-4487-83ca-1ec715fdcd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f7320286-ba76-4bf1-879a-1ed4699c685e,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-83155c76-fd5e-434b-bc16-12c24c605893,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-f0558162-8f9a-4975-8b43-bced9704f9f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858831277-172.17.0.9-1595491838278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-20bfca80-934c-4bf0-8f27-fcf6aa50aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-dba52dd9-cb8c-4d41-9613-89d76b10add2,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-eccddbec-ed7b-428a-b722-fabcd6327efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-9d5dec69-65e0-4658-a708-bf24862fc32c,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-563f1c4c-c23e-4e45-bb30-890dd32c3dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-dfdfce47-1374-4d24-857e-c1f2e91cfc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-0bdd2362-cc40-4f07-b21b-3eb8a47b37bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-259fed53-4e81-4072-a2b3-40629238a701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858831277-172.17.0.9-1595491838278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-20bfca80-934c-4bf0-8f27-fcf6aa50aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-dba52dd9-cb8c-4d41-9613-89d76b10add2,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-eccddbec-ed7b-428a-b722-fabcd6327efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-9d5dec69-65e0-4658-a708-bf24862fc32c,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-563f1c4c-c23e-4e45-bb30-890dd32c3dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-dfdfce47-1374-4d24-857e-c1f2e91cfc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-0bdd2362-cc40-4f07-b21b-3eb8a47b37bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-259fed53-4e81-4072-a2b3-40629238a701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268278537-172.17.0.9-1595492083448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-f2efc975-22fb-41c4-a93f-c6c15d2af4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-7f5a754b-37b7-4ebc-9ea7-429182421e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-58db0a8f-a6e9-4f33-8372-e16e08d69317,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-859e339c-69ec-4205-9175-0906790667b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-87d448f5-db02-4270-94a4-c66d70d437cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-86866714-9d17-4ac1-a334-836042007097,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-386108cc-32cc-46c6-b6f0-1647e6fd2047,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-d3b1fe74-7c21-4f0d-b180-50dd233fb975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268278537-172.17.0.9-1595492083448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-f2efc975-22fb-41c4-a93f-c6c15d2af4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-7f5a754b-37b7-4ebc-9ea7-429182421e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-58db0a8f-a6e9-4f33-8372-e16e08d69317,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-859e339c-69ec-4205-9175-0906790667b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-87d448f5-db02-4270-94a4-c66d70d437cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-86866714-9d17-4ac1-a334-836042007097,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-386108cc-32cc-46c6-b6f0-1647e6fd2047,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-d3b1fe74-7c21-4f0d-b180-50dd233fb975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902173358-172.17.0.9-1595492410852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-ee2438fb-d88e-481a-87ea-99b50ef67773,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-97547958-4a06-4999-8275-1de6421954b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-8a9cc2d7-2095-4b00-beab-705d7b081a17,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-0ef90eeb-99c5-427a-94e7-b5a653845daa,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-2aee62db-75f8-457a-8a8e-05d3463bdd22,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-8a3b5b33-cf4e-4172-a510-ee3c4355baf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-bd14aea3-dec8-4b9c-b212-6a94ca053387,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-f97d3db9-b1c5-4bb8-9abc-f94f264b88f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902173358-172.17.0.9-1595492410852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-ee2438fb-d88e-481a-87ea-99b50ef67773,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-97547958-4a06-4999-8275-1de6421954b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-8a9cc2d7-2095-4b00-beab-705d7b081a17,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-0ef90eeb-99c5-427a-94e7-b5a653845daa,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-2aee62db-75f8-457a-8a8e-05d3463bdd22,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-8a3b5b33-cf4e-4172-a510-ee3c4355baf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-bd14aea3-dec8-4b9c-b212-6a94ca053387,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-f97d3db9-b1c5-4bb8-9abc-f94f264b88f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687010615-172.17.0.9-1595492679327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-2c246859-e962-4d0d-a844-065094f0fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-c8227862-d7be-435d-86a4-a903985682c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-713ceb06-7e99-45f2-9004-14d0b9ae522f,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-e3fd8ad8-5923-4977-87c2-00b1f4f0571b,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-e3331964-f5ac-45a0-914c-54f89c12fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-1ad7ffa6-43ec-4522-825e-78ec039343d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-6ef745df-e960-4e41-95a5-5ad996000b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-8396b96d-5b30-49d0-aa3e-39fde579ad90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687010615-172.17.0.9-1595492679327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-2c246859-e962-4d0d-a844-065094f0fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-c8227862-d7be-435d-86a4-a903985682c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-713ceb06-7e99-45f2-9004-14d0b9ae522f,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-e3fd8ad8-5923-4977-87c2-00b1f4f0571b,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-e3331964-f5ac-45a0-914c-54f89c12fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-1ad7ffa6-43ec-4522-825e-78ec039343d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-6ef745df-e960-4e41-95a5-5ad996000b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-8396b96d-5b30-49d0-aa3e-39fde579ad90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435911264-172.17.0.9-1595492754041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44157,DS-87df10f4-88d8-435b-8596-f0191f4459ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-2d2de0c1-6a0e-43aa-905b-986e325b4bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-3fc659c5-a3fb-457b-bc9d-b6ca6a6964b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-b8e95fbc-828e-4efe-83c1-6537a615e369,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-c086dd77-2a34-400e-8172-9cfd874a9c01,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-63e8463d-80e2-4869-a97d-279f45e460d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-026fb639-99da-4da6-bb4e-e4b7911e3342,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-01c01646-91c1-4d01-8afa-1b786e244451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435911264-172.17.0.9-1595492754041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44157,DS-87df10f4-88d8-435b-8596-f0191f4459ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-2d2de0c1-6a0e-43aa-905b-986e325b4bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-3fc659c5-a3fb-457b-bc9d-b6ca6a6964b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-b8e95fbc-828e-4efe-83c1-6537a615e369,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-c086dd77-2a34-400e-8172-9cfd874a9c01,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-63e8463d-80e2-4869-a97d-279f45e460d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-026fb639-99da-4da6-bb4e-e4b7911e3342,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-01c01646-91c1-4d01-8afa-1b786e244451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028653031-172.17.0.9-1595493252038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38033,DS-db14ba84-49eb-4862-8397-ed099270fac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-961754ef-87b1-4b4f-b6df-2c56fb429a81,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-dc21f87a-0002-46d4-a6e1-101480b0eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-398c00e4-dd65-4713-963c-ee270f9a84db,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-90823799-a129-4601-afa1-a15a6fc69cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-0d94c296-a0e3-4772-82f5-827ec41d0820,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-b1fa0363-2e2c-436c-8a76-80ffa2ef28c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-01d04df4-ed76-4d98-9fa9-64b18b65c829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028653031-172.17.0.9-1595493252038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38033,DS-db14ba84-49eb-4862-8397-ed099270fac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-961754ef-87b1-4b4f-b6df-2c56fb429a81,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-dc21f87a-0002-46d4-a6e1-101480b0eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-398c00e4-dd65-4713-963c-ee270f9a84db,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-90823799-a129-4601-afa1-a15a6fc69cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-0d94c296-a0e3-4772-82f5-827ec41d0820,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-b1fa0363-2e2c-436c-8a76-80ffa2ef28c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-01d04df4-ed76-4d98-9fa9-64b18b65c829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644436930-172.17.0.9-1595493286623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44463,DS-5fe4648d-d3ee-4488-bc47-5bf5e7fef86c,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-9fe21bae-f4ac-4cd7-9feb-448c8a1a2afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-425dee16-6abe-4aa3-9b62-1474ac702a89,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-4c625120-336b-4bb6-b1dc-2ce92d49b239,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-35caba59-169d-4a4d-bb27-84fc40683e48,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-ed2e9353-715b-45b6-b6aa-0d93999186be,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-26ee8e33-9160-42c2-8ca4-4bdf40580547,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-6f93e9a4-60db-4316-a809-829af1cc0bc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644436930-172.17.0.9-1595493286623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44463,DS-5fe4648d-d3ee-4488-bc47-5bf5e7fef86c,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-9fe21bae-f4ac-4cd7-9feb-448c8a1a2afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-425dee16-6abe-4aa3-9b62-1474ac702a89,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-4c625120-336b-4bb6-b1dc-2ce92d49b239,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-35caba59-169d-4a4d-bb27-84fc40683e48,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-ed2e9353-715b-45b6-b6aa-0d93999186be,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-26ee8e33-9160-42c2-8ca4-4bdf40580547,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-6f93e9a4-60db-4316-a809-829af1cc0bc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494710280-172.17.0.9-1595493327306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-687b3a15-cfbd-4432-ae4b-c5f0e22f7d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-a78971a5-8b0d-49ef-ba89-27a00e902143,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-ef62f939-bbe0-451e-8404-b6cfc251849e,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-4035cfaf-bdda-49cd-80a7-d26859c10fff,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-51d8dd3a-611f-40e1-9332-571a183657f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-af0ba463-7e44-4536-ba8d-f0faa4574dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-c969b8f0-3e2b-41be-ba86-e3e8385e6fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-9c3dbfff-f9ac-495f-9b4a-92a60f93e273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494710280-172.17.0.9-1595493327306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-687b3a15-cfbd-4432-ae4b-c5f0e22f7d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-a78971a5-8b0d-49ef-ba89-27a00e902143,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-ef62f939-bbe0-451e-8404-b6cfc251849e,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-4035cfaf-bdda-49cd-80a7-d26859c10fff,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-51d8dd3a-611f-40e1-9332-571a183657f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-af0ba463-7e44-4536-ba8d-f0faa4574dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-c969b8f0-3e2b-41be-ba86-e3e8385e6fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-9c3dbfff-f9ac-495f-9b4a-92a60f93e273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039696673-172.17.0.9-1595493666392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-e6aee71d-5f55-46c6-a86c-6aa23ae0d0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-4ba1efbc-4f43-4e81-bb81-07a21779cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-8fcef9aa-23ba-4660-9009-3526150922a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-9770f96e-fb57-4a99-b146-efe0bf419278,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-1d3eae3d-f0b6-4c71-93bd-e25d1abb46dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-cacae837-4263-47f2-9107-39435e2a0848,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-98d6a46f-1a8c-423e-83af-89a38e9f49df,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-4c7e28c6-c464-4646-b8dc-c04fb53de433,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1039696673-172.17.0.9-1595493666392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-e6aee71d-5f55-46c6-a86c-6aa23ae0d0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-4ba1efbc-4f43-4e81-bb81-07a21779cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-8fcef9aa-23ba-4660-9009-3526150922a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-9770f96e-fb57-4a99-b146-efe0bf419278,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-1d3eae3d-f0b6-4c71-93bd-e25d1abb46dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-cacae837-4263-47f2-9107-39435e2a0848,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-98d6a46f-1a8c-423e-83af-89a38e9f49df,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-4c7e28c6-c464-4646-b8dc-c04fb53de433,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736961956-172.17.0.9-1595493746192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45145,DS-5d889177-cef0-4226-b79a-70201ee26f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-212b3d98-5ee4-4f30-93fa-7c9ec80cb020,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-37bd4052-fbc3-46bc-84bb-9bd58c8fe221,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-a0cf6670-a849-4cf9-b0c8-7f42f189c6df,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-851e3e86-ed5d-47ce-8081-356bee954e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-83745617-e525-4bc3-b1ea-8ae40b377771,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-14620a6f-f1b9-4bc5-a29b-5e950d37fd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-8ba2876f-72fd-4eb8-a35f-f5cffb553a74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736961956-172.17.0.9-1595493746192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45145,DS-5d889177-cef0-4226-b79a-70201ee26f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-212b3d98-5ee4-4f30-93fa-7c9ec80cb020,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-37bd4052-fbc3-46bc-84bb-9bd58c8fe221,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-a0cf6670-a849-4cf9-b0c8-7f42f189c6df,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-851e3e86-ed5d-47ce-8081-356bee954e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-83745617-e525-4bc3-b1ea-8ae40b377771,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-14620a6f-f1b9-4bc5-a29b-5e950d37fd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-8ba2876f-72fd-4eb8-a35f-f5cffb553a74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5666
