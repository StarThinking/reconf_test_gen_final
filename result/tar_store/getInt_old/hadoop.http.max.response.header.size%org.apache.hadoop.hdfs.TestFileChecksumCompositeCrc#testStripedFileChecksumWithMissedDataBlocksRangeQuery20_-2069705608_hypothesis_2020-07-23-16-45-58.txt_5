reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731337079-172.17.0.16-1595522961745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-864d718a-fc22-4eab-99a1-680a07d647f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-5a33c4bf-e3cf-4a87-94bf-3b0de44bc529,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-bbfac143-dba0-46ba-96bc-825e90fb8306,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-0ae1d503-490a-4835-beee-763d3ab85664,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-03a70fb8-d430-4947-a970-d09271787fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-0ae7a4d5-231c-4ebd-b634-a8ee4ad262c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-bd0d4f41-a15a-417e-8048-b148bfd74b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-102f902f-6890-4f8a-8499-6a6676c53b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731337079-172.17.0.16-1595522961745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-864d718a-fc22-4eab-99a1-680a07d647f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-5a33c4bf-e3cf-4a87-94bf-3b0de44bc529,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-bbfac143-dba0-46ba-96bc-825e90fb8306,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-0ae1d503-490a-4835-beee-763d3ab85664,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-03a70fb8-d430-4947-a970-d09271787fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-0ae7a4d5-231c-4ebd-b634-a8ee4ad262c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-bd0d4f41-a15a-417e-8048-b148bfd74b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-102f902f-6890-4f8a-8499-6a6676c53b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773409269-172.17.0.16-1595525442862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-534998da-5eb9-4cfa-82a5-ee05da5f38f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-704fa08f-552b-4869-83c9-4d4c96f0ed53,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-2ab4ce01-58c8-4415-a27d-f07ad6ca1e06,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-f29b8da8-8666-4fb5-af71-c27818470a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-0832f647-ceff-4e8f-bb1c-1e2994461fae,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-45090eb1-802f-4dd3-8537-de434320a697,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-db3fbab5-e771-4d57-a7d5-22a69ac7cd50,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-c873f21a-62c9-4d86-aaf0-c44d97f1bd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773409269-172.17.0.16-1595525442862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-534998da-5eb9-4cfa-82a5-ee05da5f38f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-704fa08f-552b-4869-83c9-4d4c96f0ed53,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-2ab4ce01-58c8-4415-a27d-f07ad6ca1e06,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-f29b8da8-8666-4fb5-af71-c27818470a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-0832f647-ceff-4e8f-bb1c-1e2994461fae,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-45090eb1-802f-4dd3-8537-de434320a697,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-db3fbab5-e771-4d57-a7d5-22a69ac7cd50,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-c873f21a-62c9-4d86-aaf0-c44d97f1bd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427255385-172.17.0.16-1595525709014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-49f735ec-4bfc-4dd0-b9b7-640b37cb4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-84348385-99b3-4297-84f8-d1f9e087931e,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-e069b101-cf90-4a0c-90b2-bca1b1bc041b,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-46dec9e4-e0ad-430d-a743-58c54760b33b,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-f7d214f0-ba1c-4a1b-8dc6-82fb4911c3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-5a81ddcd-12db-468f-be11-6eb6981a8175,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-964d2117-5ce6-4215-a2c1-9e76e120587e,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-0db45da5-a234-4fb3-a737-ffbfa74fdf78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427255385-172.17.0.16-1595525709014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-49f735ec-4bfc-4dd0-b9b7-640b37cb4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-84348385-99b3-4297-84f8-d1f9e087931e,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-e069b101-cf90-4a0c-90b2-bca1b1bc041b,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-46dec9e4-e0ad-430d-a743-58c54760b33b,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-f7d214f0-ba1c-4a1b-8dc6-82fb4911c3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-5a81ddcd-12db-468f-be11-6eb6981a8175,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-964d2117-5ce6-4215-a2c1-9e76e120587e,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-0db45da5-a234-4fb3-a737-ffbfa74fdf78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937916997-172.17.0.16-1595525747710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-7a07c04b-077c-4f92-b9c4-80e50f458395,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-ed525b74-9fc9-4e3a-a813-d5c02437acca,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-e23a78c5-bf5e-4369-979b-089457782712,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-e6286aaf-8a60-4f4e-9545-0140751cc01a,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-0a30d39b-230f-404a-9869-235f3487d54d,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-a61ddee0-6371-47f7-bace-3e29997e4dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-86824b49-67e9-4458-b3bb-d0dcad67637a,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-b6918bc1-54e3-4f69-8989-e7eb497bb9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937916997-172.17.0.16-1595525747710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-7a07c04b-077c-4f92-b9c4-80e50f458395,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-ed525b74-9fc9-4e3a-a813-d5c02437acca,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-e23a78c5-bf5e-4369-979b-089457782712,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-e6286aaf-8a60-4f4e-9545-0140751cc01a,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-0a30d39b-230f-404a-9869-235f3487d54d,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-a61ddee0-6371-47f7-bace-3e29997e4dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-86824b49-67e9-4458-b3bb-d0dcad67637a,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-b6918bc1-54e3-4f69-8989-e7eb497bb9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056109125-172.17.0.16-1595526112197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35450,DS-aa13301b-57c7-44a9-83d6-90b88dd18170,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-fa7ed382-295f-46ea-aee0-77cb7725155f,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-68c48914-e16a-439c-a933-06add8d4f51b,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-7b5581f2-5e03-4530-9b6b-18ed553f8a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-368fbdaa-f4a9-4f98-ab10-c637c253a7db,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-5b8c1e54-be43-4c81-af06-e6757986f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-48460381-5f3d-4f06-a75d-bbebf044d7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-8a612275-6dba-46e4-992f-5c7c9299736e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056109125-172.17.0.16-1595526112197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35450,DS-aa13301b-57c7-44a9-83d6-90b88dd18170,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-fa7ed382-295f-46ea-aee0-77cb7725155f,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-68c48914-e16a-439c-a933-06add8d4f51b,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-7b5581f2-5e03-4530-9b6b-18ed553f8a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-368fbdaa-f4a9-4f98-ab10-c637c253a7db,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-5b8c1e54-be43-4c81-af06-e6757986f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-48460381-5f3d-4f06-a75d-bbebf044d7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-8a612275-6dba-46e4-992f-5c7c9299736e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205772617-172.17.0.16-1595526505892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34334,DS-a62a42c6-4e9b-4e27-8296-c78797e926df,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-dcbb4521-6af5-4e1e-a310-a8db843c02e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-ba9a0cef-44dc-4a88-bae4-0c81def7d238,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-560772d1-173c-4544-96bc-80e269807bea,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-bcc508ca-f5f0-4af3-9b64-c294ec7d820c,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-27df711f-7481-40d4-ae4b-4a29f9fb8d32,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a21f3cc1-d7f9-4462-b44b-54d531d7036c,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-7f1dbe4c-7545-42f5-a186-3c84e5e4e9c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205772617-172.17.0.16-1595526505892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34334,DS-a62a42c6-4e9b-4e27-8296-c78797e926df,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-dcbb4521-6af5-4e1e-a310-a8db843c02e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-ba9a0cef-44dc-4a88-bae4-0c81def7d238,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-560772d1-173c-4544-96bc-80e269807bea,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-bcc508ca-f5f0-4af3-9b64-c294ec7d820c,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-27df711f-7481-40d4-ae4b-4a29f9fb8d32,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a21f3cc1-d7f9-4462-b44b-54d531d7036c,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-7f1dbe4c-7545-42f5-a186-3c84e5e4e9c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940162546-172.17.0.16-1595526802517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-99cd7ad6-faa6-4866-8967-2c7ecdcf5e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-a6fb774d-4826-49de-917b-676ee28a12bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-e39ce532-1278-47fa-87b2-5d39382b57af,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-89fdeeb5-c3d3-46be-ac44-1fd3c183e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-9ffaf323-2ef7-4180-933a-3f5e97211e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-5b10fbe4-c732-4f10-9516-ddb5d8993e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-74a32bbc-db07-4dd7-a19a-7a835f8ac49c,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-abee420d-06b7-4942-91a0-131f29e03580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940162546-172.17.0.16-1595526802517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-99cd7ad6-faa6-4866-8967-2c7ecdcf5e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-a6fb774d-4826-49de-917b-676ee28a12bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-e39ce532-1278-47fa-87b2-5d39382b57af,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-89fdeeb5-c3d3-46be-ac44-1fd3c183e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-9ffaf323-2ef7-4180-933a-3f5e97211e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-5b10fbe4-c732-4f10-9516-ddb5d8993e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-74a32bbc-db07-4dd7-a19a-7a835f8ac49c,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-abee420d-06b7-4942-91a0-131f29e03580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898028109-172.17.0.16-1595527616246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-0f4a3ef8-b869-4593-a23f-a296c4c924a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-e95aa77a-e4e1-4a51-b421-fe9a0b5b9fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-8f1fa687-e212-4ccb-bfaf-fce1b5d95e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-e909014c-8b62-469d-a483-25f33feb6e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-9c817662-ba7c-4f09-b048-70c0e51967b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-fb5f4ccf-2687-48fe-8310-68a16adaf2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-b743b190-3769-4cca-9bae-a52d18698c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-b32c23c6-ed51-4c99-a356-30157d9bd896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898028109-172.17.0.16-1595527616246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-0f4a3ef8-b869-4593-a23f-a296c4c924a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-e95aa77a-e4e1-4a51-b421-fe9a0b5b9fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-8f1fa687-e212-4ccb-bfaf-fce1b5d95e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-e909014c-8b62-469d-a483-25f33feb6e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-9c817662-ba7c-4f09-b048-70c0e51967b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-fb5f4ccf-2687-48fe-8310-68a16adaf2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-b743b190-3769-4cca-9bae-a52d18698c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-b32c23c6-ed51-4c99-a356-30157d9bd896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631057952-172.17.0.16-1595528122849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-2b5c6d22-ee5b-42af-a23c-3ef93cc312b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-4fb57e48-caef-4c9b-be51-78e4d63313bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-e9393523-037e-43f3-afb1-74c92dbc74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-dbfcca3d-a185-4b4b-b0b2-cc338ac1c8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-34ca0c99-fb17-4582-92ab-788c8d0f2393,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-31b2e8b1-0541-46ba-b6ab-fc9187a5bb09,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-12adebdb-365f-4080-a6a2-d4f659d707ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-a255c9d2-e3ab-4e2b-a9ce-aa29c158d671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631057952-172.17.0.16-1595528122849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-2b5c6d22-ee5b-42af-a23c-3ef93cc312b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-4fb57e48-caef-4c9b-be51-78e4d63313bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-e9393523-037e-43f3-afb1-74c92dbc74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-dbfcca3d-a185-4b4b-b0b2-cc338ac1c8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-34ca0c99-fb17-4582-92ab-788c8d0f2393,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-31b2e8b1-0541-46ba-b6ab-fc9187a5bb09,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-12adebdb-365f-4080-a6a2-d4f659d707ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-a255c9d2-e3ab-4e2b-a9ce-aa29c158d671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5489
