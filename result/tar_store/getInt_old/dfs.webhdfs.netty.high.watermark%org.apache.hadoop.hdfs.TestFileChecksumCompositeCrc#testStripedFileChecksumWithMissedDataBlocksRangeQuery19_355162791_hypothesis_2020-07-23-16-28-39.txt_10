reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312450243-172.17.0.6-1595522144238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44134,DS-979c7a52-bf0b-40a1-90f3-4dfb9697fbed,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-68d23261-a3ba-421a-9d13-9104377cfdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-48cb221a-3eca-4777-b489-e70867b3fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-d6eabca2-c03c-484c-b2e6-2e1212d1aac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-483184db-cbbc-4609-a106-d41eb943b9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-1575f2c7-f278-4cae-b492-aab0bd3fc528,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-f1b93fbc-e862-43b5-af45-46a87f6b8751,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-2ace6146-778b-4056-b015-fdf7f3887f5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312450243-172.17.0.6-1595522144238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44134,DS-979c7a52-bf0b-40a1-90f3-4dfb9697fbed,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-68d23261-a3ba-421a-9d13-9104377cfdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-48cb221a-3eca-4777-b489-e70867b3fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-d6eabca2-c03c-484c-b2e6-2e1212d1aac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-483184db-cbbc-4609-a106-d41eb943b9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-1575f2c7-f278-4cae-b492-aab0bd3fc528,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-f1b93fbc-e862-43b5-af45-46a87f6b8751,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-2ace6146-778b-4056-b015-fdf7f3887f5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247683194-172.17.0.6-1595522211701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42057,DS-b34e6b79-67a2-486e-8997-abb1e0ca6c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-89030bc8-dd96-4b4e-a75a-527f27d12709,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-b385f16d-4c51-493e-86f6-2f8f50c3cdda,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-eb0ec81e-6242-4ff9-a839-22712c6bca03,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-25c30733-22d6-4e98-8026-f652fafa68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-04cc66dc-2bb5-4a21-bc31-42fb01f3b626,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-8d58f05f-48c9-48cf-9042-35d30097c54e,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-74ec5c35-0d16-4d89-8fea-852bb37304bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247683194-172.17.0.6-1595522211701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42057,DS-b34e6b79-67a2-486e-8997-abb1e0ca6c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-89030bc8-dd96-4b4e-a75a-527f27d12709,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-b385f16d-4c51-493e-86f6-2f8f50c3cdda,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-eb0ec81e-6242-4ff9-a839-22712c6bca03,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-25c30733-22d6-4e98-8026-f652fafa68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-04cc66dc-2bb5-4a21-bc31-42fb01f3b626,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-8d58f05f-48c9-48cf-9042-35d30097c54e,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-74ec5c35-0d16-4d89-8fea-852bb37304bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766021384-172.17.0.6-1595522281100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-21e0a92f-0edc-49db-99a0-4a9c69c80210,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-d8c06197-b09f-4078-9bbe-6eb399b403e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-72546251-ea92-4ac4-bf2c-b6bf55e7f4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-aa70569c-f0a2-49aa-b1c8-bfb57760dd88,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-ce2f7d03-dfe4-404b-b076-105789a82499,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-dbc263a7-0fc3-4a0e-91df-e7301f878588,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-2b273680-b967-4836-8ece-95026a70ed73,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-1223d061-b4de-42ce-895a-96721b0721c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766021384-172.17.0.6-1595522281100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-21e0a92f-0edc-49db-99a0-4a9c69c80210,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-d8c06197-b09f-4078-9bbe-6eb399b403e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-72546251-ea92-4ac4-bf2c-b6bf55e7f4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-aa70569c-f0a2-49aa-b1c8-bfb57760dd88,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-ce2f7d03-dfe4-404b-b076-105789a82499,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-dbc263a7-0fc3-4a0e-91df-e7301f878588,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-2b273680-b967-4836-8ece-95026a70ed73,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-1223d061-b4de-42ce-895a-96721b0721c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646184297-172.17.0.6-1595522639900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-28437f25-659c-4bcd-be69-5ab53d5b0970,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-82667acf-b63a-4dad-8a3f-059bfb152d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-4484e41a-ee97-418d-a156-3b170a6ca0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-5668fc31-9234-469f-9963-2c74691d3dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-f4bfce53-df0c-4c4a-8a09-273277fa43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-7e923ac4-36e5-4cf7-9342-bec9eb1c9b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-4d10c366-e216-4194-b261-9e0ef3aac25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-6d50fbf5-a110-4f52-802a-8667c62fcce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646184297-172.17.0.6-1595522639900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-28437f25-659c-4bcd-be69-5ab53d5b0970,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-82667acf-b63a-4dad-8a3f-059bfb152d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-4484e41a-ee97-418d-a156-3b170a6ca0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-5668fc31-9234-469f-9963-2c74691d3dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-f4bfce53-df0c-4c4a-8a09-273277fa43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-7e923ac4-36e5-4cf7-9342-bec9eb1c9b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-4d10c366-e216-4194-b261-9e0ef3aac25a,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-6d50fbf5-a110-4f52-802a-8667c62fcce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20765200-172.17.0.6-1595522712841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42528,DS-47aa6281-1b9b-4560-bfa1-c622f4773031,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-bfcbc9ae-6008-41ec-92d2-ccd1a4dae5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-993ae558-62d5-4654-a1bf-57be1646d333,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-3f1add94-969b-4ab8-8bb5-fbb0b3007064,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-d716c7c3-478c-4817-835a-66be1b538dee,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-bf6748c7-7efe-4a69-a04f-f936b3b3c38d,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-23bc64c4-074c-4787-9e22-01d2f63e866c,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-851c353a-127f-4d15-bf93-d5ae61227814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20765200-172.17.0.6-1595522712841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42528,DS-47aa6281-1b9b-4560-bfa1-c622f4773031,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-bfcbc9ae-6008-41ec-92d2-ccd1a4dae5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-993ae558-62d5-4654-a1bf-57be1646d333,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-3f1add94-969b-4ab8-8bb5-fbb0b3007064,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-d716c7c3-478c-4817-835a-66be1b538dee,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-bf6748c7-7efe-4a69-a04f-f936b3b3c38d,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-23bc64c4-074c-4787-9e22-01d2f63e866c,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-851c353a-127f-4d15-bf93-d5ae61227814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768944662-172.17.0.6-1595522844155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34036,DS-dc8efde9-9432-4b4f-a40a-9d490e0614a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-d9435fd5-3f40-45ab-95f8-06c726c56a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-4d80b699-8112-4f4e-bb26-64855e85da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-3b71e38c-d619-4bfe-a27e-08c159d9d3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-4d05a68a-5001-4607-bf7d-8276aa65ede0,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-63492ca5-fabe-47d1-b0b0-db7e884d4844,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-41a8d21f-8961-477e-b38d-8fb0948ca660,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-49583c9c-37c9-42c7-b6af-8b0982ba1d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768944662-172.17.0.6-1595522844155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34036,DS-dc8efde9-9432-4b4f-a40a-9d490e0614a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-d9435fd5-3f40-45ab-95f8-06c726c56a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-4d80b699-8112-4f4e-bb26-64855e85da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-3b71e38c-d619-4bfe-a27e-08c159d9d3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-4d05a68a-5001-4607-bf7d-8276aa65ede0,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-63492ca5-fabe-47d1-b0b0-db7e884d4844,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-41a8d21f-8961-477e-b38d-8fb0948ca660,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-49583c9c-37c9-42c7-b6af-8b0982ba1d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218857196-172.17.0.6-1595523115185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35862,DS-8d7c3771-09ef-4556-87b2-983239923b80,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-38e6ec3d-c592-48e1-8d12-911eb3161b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-570963fc-a4ce-46d3-b12b-0b631459ca53,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-9d20031e-9166-4618-8405-79dfb1d83061,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-8a58130d-58d5-4ccc-8fba-f43211ad46e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-a16b4307-ba68-4a7b-8ff4-cba2085318c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-ba918293-96d6-40df-8d50-f95e363c6935,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-3893ef0c-3a4a-4068-9be2-28ee56eb5afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218857196-172.17.0.6-1595523115185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35862,DS-8d7c3771-09ef-4556-87b2-983239923b80,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-38e6ec3d-c592-48e1-8d12-911eb3161b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-570963fc-a4ce-46d3-b12b-0b631459ca53,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-9d20031e-9166-4618-8405-79dfb1d83061,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-8a58130d-58d5-4ccc-8fba-f43211ad46e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-a16b4307-ba68-4a7b-8ff4-cba2085318c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-ba918293-96d6-40df-8d50-f95e363c6935,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-3893ef0c-3a4a-4068-9be2-28ee56eb5afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033048531-172.17.0.6-1595523741123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44526,DS-b2f44733-4492-42d5-8d90-c8ef9d4eae64,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-5f8dac73-9690-4c10-8ba1-08c420c0e852,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-6bdc5c9e-085b-49ec-9ac0-6a85ba76620d,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-3f6653d1-ca35-43f7-af6d-e67a414d2621,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-2eb4e720-4e9a-4ae7-8f62-7554ac5d28bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-216e2372-afc9-424f-a555-d361d079a3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-6196cf88-3e45-4b1f-8cae-eb1bf1a17778,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-e0f280a0-9361-48ad-9dcc-49985798b9c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033048531-172.17.0.6-1595523741123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44526,DS-b2f44733-4492-42d5-8d90-c8ef9d4eae64,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-5f8dac73-9690-4c10-8ba1-08c420c0e852,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-6bdc5c9e-085b-49ec-9ac0-6a85ba76620d,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-3f6653d1-ca35-43f7-af6d-e67a414d2621,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-2eb4e720-4e9a-4ae7-8f62-7554ac5d28bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-216e2372-afc9-424f-a555-d361d079a3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-6196cf88-3e45-4b1f-8cae-eb1bf1a17778,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-e0f280a0-9361-48ad-9dcc-49985798b9c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252616860-172.17.0.6-1595524021491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44251,DS-da54c3d7-c3ec-43f8-b226-b2981c832d92,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-0d7bdc69-c6d8-4168-8609-9f012aa494b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-53544196-633c-42aa-b415-d32a11d4c04e,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-6b584e53-440f-4b68-987b-ebdaeeac6a16,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-a2e9522c-8a1a-48d3-9274-e94c66442de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-8ef2bd45-dcd3-408a-a72b-f0d0e6f58bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-a8c2bbe1-289e-4585-b42f-39ae99eee06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-2a988b71-175e-495f-9ff7-4ed2c45226fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252616860-172.17.0.6-1595524021491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44251,DS-da54c3d7-c3ec-43f8-b226-b2981c832d92,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-0d7bdc69-c6d8-4168-8609-9f012aa494b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-53544196-633c-42aa-b415-d32a11d4c04e,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-6b584e53-440f-4b68-987b-ebdaeeac6a16,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-a2e9522c-8a1a-48d3-9274-e94c66442de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-8ef2bd45-dcd3-408a-a72b-f0d0e6f58bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-a8c2bbe1-289e-4585-b42f-39ae99eee06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-2a988b71-175e-495f-9ff7-4ed2c45226fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271736758-172.17.0.6-1595524174286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45374,DS-bfb05d35-7331-4c98-8aea-0a430f723f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-e09878b5-37d2-4ca3-9756-c115db981247,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-fd0722b5-5974-481d-bf20-f130d33b1aff,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-0cb30ae6-d70a-409b-ab3b-79aa124b4976,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-fdfc1c69-b302-41ab-bfb5-a5a187cb6959,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-fcdfbd34-be5a-4f27-957e-0bc12b0a6cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-def61698-6d81-4aa4-a29f-a21cb73011ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-1853f12a-c38d-46b0-9a4d-7f3cd0001c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271736758-172.17.0.6-1595524174286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45374,DS-bfb05d35-7331-4c98-8aea-0a430f723f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-e09878b5-37d2-4ca3-9756-c115db981247,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-fd0722b5-5974-481d-bf20-f130d33b1aff,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-0cb30ae6-d70a-409b-ab3b-79aa124b4976,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-fdfc1c69-b302-41ab-bfb5-a5a187cb6959,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-fcdfbd34-be5a-4f27-957e-0bc12b0a6cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-def61698-6d81-4aa4-a29f-a21cb73011ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-1853f12a-c38d-46b0-9a4d-7f3cd0001c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795569811-172.17.0.6-1595524831106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37467,DS-b6a4f929-c50e-442b-8402-27fe9e9d2730,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-5715f2ce-ae6d-4bfc-99f3-2e469a0bb125,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-aa392b42-eefd-4894-9943-656f0f6e6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-b4b461cd-a010-463c-b537-cb9bea867936,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-80823836-1392-43f5-b993-0d17978d91c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-d120e96d-9721-4f9d-b33c-aca90e1a3abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-f8317510-2331-4f21-9157-77f3cfbe38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-7b2c541b-01c9-4d9c-9383-bc9feac155ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795569811-172.17.0.6-1595524831106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37467,DS-b6a4f929-c50e-442b-8402-27fe9e9d2730,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-5715f2ce-ae6d-4bfc-99f3-2e469a0bb125,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-aa392b42-eefd-4894-9943-656f0f6e6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-b4b461cd-a010-463c-b537-cb9bea867936,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-80823836-1392-43f5-b993-0d17978d91c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-d120e96d-9721-4f9d-b33c-aca90e1a3abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-f8317510-2331-4f21-9157-77f3cfbe38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-7b2c541b-01c9-4d9c-9383-bc9feac155ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479158768-172.17.0.6-1595524981160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38293,DS-fa55e4d5-4afb-4a25-9152-e8b5816c0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-511fe4bc-a74a-495d-bfdd-7b018cc957b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-3320f86e-99f3-4c01-a06d-b5bb8572e0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-d6752e05-1f9a-43a4-9af3-79c4771f5b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-60cf1c94-d1b0-4b06-b1b2-3bcffe39b410,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-a5797d6c-f731-4f8b-a5fb-e084ec2f70f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-ffb625e5-7fa8-4a6c-b702-fac722dbb7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-a6ef449a-7a07-49eb-a0a1-04207f76fdd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479158768-172.17.0.6-1595524981160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38293,DS-fa55e4d5-4afb-4a25-9152-e8b5816c0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-511fe4bc-a74a-495d-bfdd-7b018cc957b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-3320f86e-99f3-4c01-a06d-b5bb8572e0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-d6752e05-1f9a-43a4-9af3-79c4771f5b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-60cf1c94-d1b0-4b06-b1b2-3bcffe39b410,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-a5797d6c-f731-4f8b-a5fb-e084ec2f70f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-ffb625e5-7fa8-4a6c-b702-fac722dbb7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-a6ef449a-7a07-49eb-a0a1-04207f76fdd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607248651-172.17.0.6-1595525526232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-d228289b-d04c-4f5f-afe5-6887dd6331fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-5a554227-5d23-4353-84e2-c7a07c8bf63d,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-04075a5f-2b8c-4d2f-bd3f-604e269cf2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-b7073577-2f74-488d-b836-90e6484baf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-daf7002e-15be-4615-adcc-7595e4bd32f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-6bd2067b-f08f-43dd-b10d-ace182b79139,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-dfb874ff-949c-4a83-958f-9c078285054d,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-bf871b01-e374-4e94-bcb4-10a2d7a22d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607248651-172.17.0.6-1595525526232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-d228289b-d04c-4f5f-afe5-6887dd6331fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-5a554227-5d23-4353-84e2-c7a07c8bf63d,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-04075a5f-2b8c-4d2f-bd3f-604e269cf2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-b7073577-2f74-488d-b836-90e6484baf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-daf7002e-15be-4615-adcc-7595e4bd32f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-6bd2067b-f08f-43dd-b10d-ace182b79139,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-dfb874ff-949c-4a83-958f-9c078285054d,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-bf871b01-e374-4e94-bcb4-10a2d7a22d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465180450-172.17.0.6-1595525566256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-64293087-3f6e-4e0d-bbff-db6229db30f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-cabdb294-e233-48d6-ac89-7d61bd135569,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-d1de10f3-21b6-4a55-9a60-005812773177,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-699b3c07-2761-48a0-860a-4a6d0bce8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-480b39df-13e8-4f29-8828-4b7bbe83404f,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-e05e0f55-94d5-4cd9-8472-5d10f7639549,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-c666f2f1-12e3-492e-a7e8-73e312038db1,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-0904aedc-6d27-435c-98bc-2947d2c75942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465180450-172.17.0.6-1595525566256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-64293087-3f6e-4e0d-bbff-db6229db30f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-cabdb294-e233-48d6-ac89-7d61bd135569,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-d1de10f3-21b6-4a55-9a60-005812773177,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-699b3c07-2761-48a0-860a-4a6d0bce8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-480b39df-13e8-4f29-8828-4b7bbe83404f,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-e05e0f55-94d5-4cd9-8472-5d10f7639549,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-c666f2f1-12e3-492e-a7e8-73e312038db1,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-0904aedc-6d27-435c-98bc-2947d2c75942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671886614-172.17.0.6-1595526153460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42321,DS-4639f54b-35c7-4fbf-b530-99f37447a4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-2b23eeb0-987b-40cd-bb46-a20848b7fc81,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-52d6bd98-edb5-45b9-bb1e-832106b287cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-b188a23c-0ed4-42d6-b748-1232264f56d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-4ccf182c-231e-40da-8d5b-09568256f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-93bf3ed5-02ac-4cb3-8531-de22423f836f,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-e0fec79e-085a-4d1d-8e0e-659b0ccda833,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-fefdcc70-8dd5-44b0-96d4-dd7e9c1cb529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671886614-172.17.0.6-1595526153460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42321,DS-4639f54b-35c7-4fbf-b530-99f37447a4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-2b23eeb0-987b-40cd-bb46-a20848b7fc81,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-52d6bd98-edb5-45b9-bb1e-832106b287cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-b188a23c-0ed4-42d6-b748-1232264f56d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-4ccf182c-231e-40da-8d5b-09568256f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-93bf3ed5-02ac-4cb3-8531-de22423f836f,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-e0fec79e-085a-4d1d-8e0e-659b0ccda833,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-fefdcc70-8dd5-44b0-96d4-dd7e9c1cb529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15951252-172.17.0.6-1595526365739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36344,DS-bc56e43a-84fb-4bc4-8901-87c2526d5df1,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-f56563ca-b595-45cf-aebc-f7748eb61b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-4ba6b0e3-4699-4610-9af8-aa129f4e3c16,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-0587a058-3ed8-41d5-bd62-ddd0e8ea5a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-e9bf29ce-5f15-438d-a41d-8117ae339e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-2a49364b-64ec-430b-bb9b-53707fb0499c,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-83719c16-e9f6-4098-a2e3-8f149e3fa8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-758bcb1f-a038-40ea-959f-f6e3c6512fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15951252-172.17.0.6-1595526365739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36344,DS-bc56e43a-84fb-4bc4-8901-87c2526d5df1,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-f56563ca-b595-45cf-aebc-f7748eb61b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-4ba6b0e3-4699-4610-9af8-aa129f4e3c16,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-0587a058-3ed8-41d5-bd62-ddd0e8ea5a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-e9bf29ce-5f15-438d-a41d-8117ae339e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-2a49364b-64ec-430b-bb9b-53707fb0499c,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-83719c16-e9f6-4098-a2e3-8f149e3fa8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-758bcb1f-a038-40ea-959f-f6e3c6512fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223213335-172.17.0.6-1595526802757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33191,DS-63dcf904-755c-4ac1-a408-1352749d933b,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-04940749-4bf6-46f6-84c1-17369f79d163,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-d913a70c-d3b0-4ac3-bb44-7a6dce87e789,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-b32d3ccb-adc4-4b75-b743-da8b85106fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-36dd6d59-58b8-4f64-b0e6-42e9c59a6fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-532ff475-6b1b-41a6-aada-54961dd1017a,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-616e41fb-174d-47e7-92b9-5e50ceab87e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-64239dc1-3edf-4e4d-8bc2-8128f1d1454f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223213335-172.17.0.6-1595526802757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33191,DS-63dcf904-755c-4ac1-a408-1352749d933b,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-04940749-4bf6-46f6-84c1-17369f79d163,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-d913a70c-d3b0-4ac3-bb44-7a6dce87e789,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-b32d3ccb-adc4-4b75-b743-da8b85106fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-36dd6d59-58b8-4f64-b0e6-42e9c59a6fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-532ff475-6b1b-41a6-aada-54961dd1017a,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-616e41fb-174d-47e7-92b9-5e50ceab87e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-64239dc1-3edf-4e4d-8bc2-8128f1d1454f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351851183-172.17.0.6-1595526838982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-f26f3114-a6c1-4485-8fef-11be23891981,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-ffe30183-6346-4eb1-abf3-dd5d280cf12d,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-4d2078c1-12ed-4115-9b1c-89a6811f998d,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ab0d05f1-a2bd-445a-a2b2-5f5180c135cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-c29c4eb4-7742-41e3-9294-90e2744804ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-5910b215-9e8b-4d9f-ace4-9f8b57bcf711,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-cca9c652-94d4-4c6a-9379-970fe5dfa9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-6498e5b5-e895-4237-a261-21cc885b0ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351851183-172.17.0.6-1595526838982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-f26f3114-a6c1-4485-8fef-11be23891981,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-ffe30183-6346-4eb1-abf3-dd5d280cf12d,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-4d2078c1-12ed-4115-9b1c-89a6811f998d,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ab0d05f1-a2bd-445a-a2b2-5f5180c135cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-c29c4eb4-7742-41e3-9294-90e2744804ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-5910b215-9e8b-4d9f-ace4-9f8b57bcf711,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-cca9c652-94d4-4c6a-9379-970fe5dfa9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-6498e5b5-e895-4237-a261-21cc885b0ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321666948-172.17.0.6-1595526911857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45825,DS-90dee286-0eff-492e-bf94-b4587750ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-aeeb5a4a-20e0-4285-8c2e-ee2fb1e1135c,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-18df4350-99f5-47cd-9fca-3f431a232983,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-374efa62-a4ee-4d61-bda0-a0d71e13c2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-09d6caab-59a0-419a-addc-e5618a8eca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-c514133e-4407-4975-b166-282492fd0912,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-b6d678f3-2664-4afc-baf4-7989628d5ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-30e6f399-ae0f-4cfd-bcbc-d9747012f6c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321666948-172.17.0.6-1595526911857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45825,DS-90dee286-0eff-492e-bf94-b4587750ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-aeeb5a4a-20e0-4285-8c2e-ee2fb1e1135c,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-18df4350-99f5-47cd-9fca-3f431a232983,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-374efa62-a4ee-4d61-bda0-a0d71e13c2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-09d6caab-59a0-419a-addc-e5618a8eca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-c514133e-4407-4975-b166-282492fd0912,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-b6d678f3-2664-4afc-baf4-7989628d5ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-30e6f399-ae0f-4cfd-bcbc-d9747012f6c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354234687-172.17.0.6-1595527044046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-c2361935-fdfa-4c81-a767-907e242353e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-0337a98f-ffdf-4c87-8e48-a9720b225d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-02073e6e-e6ad-4e4d-afaa-b2544835322c,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-b797073c-fdd0-4774-a5c6-37adb521e9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-a43ad77e-d225-460f-9955-a321f1d1996e,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-b4d8948f-1ee8-4e88-83d3-34991eedba48,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-310ac1ad-ed47-4840-98b6-91ea10fe3138,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-2068e0f8-fecd-4363-8416-871f9597c5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354234687-172.17.0.6-1595527044046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-c2361935-fdfa-4c81-a767-907e242353e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-0337a98f-ffdf-4c87-8e48-a9720b225d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-02073e6e-e6ad-4e4d-afaa-b2544835322c,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-b797073c-fdd0-4774-a5c6-37adb521e9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-a43ad77e-d225-460f-9955-a321f1d1996e,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-b4d8948f-1ee8-4e88-83d3-34991eedba48,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-310ac1ad-ed47-4840-98b6-91ea10fe3138,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-2068e0f8-fecd-4363-8416-871f9597c5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5342
