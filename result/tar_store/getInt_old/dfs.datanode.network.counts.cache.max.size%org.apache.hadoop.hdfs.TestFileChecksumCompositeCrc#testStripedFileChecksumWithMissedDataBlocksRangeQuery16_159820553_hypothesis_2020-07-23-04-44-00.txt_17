reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644979966-172.17.0.21-1595479456600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35657,DS-07478206-0903-4e40-8b24-7d5f8ca93a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-64e48b4a-441d-4e00-9509-c824e9d19328,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-37774941-dd2e-4507-8723-e48beceaccda,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-ac381230-605f-41c3-8f2b-8f05dae9ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-55b31e2f-85ab-4802-88d3-50f09a862d01,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-19ede2bf-545b-4d8a-a575-5c60c97f9737,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-f047417f-183c-43f7-8b1d-82efb73819da,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4088234d-5575-4d01-9e24-9f55784cad85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644979966-172.17.0.21-1595479456600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35657,DS-07478206-0903-4e40-8b24-7d5f8ca93a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-64e48b4a-441d-4e00-9509-c824e9d19328,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-37774941-dd2e-4507-8723-e48beceaccda,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-ac381230-605f-41c3-8f2b-8f05dae9ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-55b31e2f-85ab-4802-88d3-50f09a862d01,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-19ede2bf-545b-4d8a-a575-5c60c97f9737,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-f047417f-183c-43f7-8b1d-82efb73819da,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4088234d-5575-4d01-9e24-9f55784cad85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9759955-172.17.0.21-1595479728477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41921,DS-4d28c1ec-9129-4a00-87a6-b3a88faadf14,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-92b39096-3eee-41b6-8664-c986806c0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-43a23684-7c1e-4e54-bcab-97d2732e30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-4100cdae-8ba0-406e-bd7e-fb0fc6829fad,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-564210ea-8e93-4ced-aa84-b183d966635e,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-539a5e91-0d5e-46f2-a697-b67d2fc5a6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-414fff4d-012b-4517-81eb-89af830fe70b,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-439ba10f-ed5a-4cc1-afb8-eb8e61cf87c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9759955-172.17.0.21-1595479728477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41921,DS-4d28c1ec-9129-4a00-87a6-b3a88faadf14,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-92b39096-3eee-41b6-8664-c986806c0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-43a23684-7c1e-4e54-bcab-97d2732e30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-4100cdae-8ba0-406e-bd7e-fb0fc6829fad,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-564210ea-8e93-4ced-aa84-b183d966635e,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-539a5e91-0d5e-46f2-a697-b67d2fc5a6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-414fff4d-012b-4517-81eb-89af830fe70b,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-439ba10f-ed5a-4cc1-afb8-eb8e61cf87c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841275009-172.17.0.21-1595479883660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-5514730f-1a82-42fc-8c9d-805c90b372fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-009dbb9f-5855-4241-9f58-5a4dfc79e3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-358858e3-688a-4d31-88e7-24dc07e0aa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-ff8dffc6-40a7-4c73-b26a-2dbd597e3172,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-a48f940c-3e49-4242-b27a-896c0780ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-07eb1300-2c78-46a7-86c9-6e030515f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-0b64b89b-5ae1-4469-9492-a586b695ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-04862103-8fdd-4d48-ba5a-0ac6d5261fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841275009-172.17.0.21-1595479883660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-5514730f-1a82-42fc-8c9d-805c90b372fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-009dbb9f-5855-4241-9f58-5a4dfc79e3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-358858e3-688a-4d31-88e7-24dc07e0aa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-ff8dffc6-40a7-4c73-b26a-2dbd597e3172,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-a48f940c-3e49-4242-b27a-896c0780ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-07eb1300-2c78-46a7-86c9-6e030515f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-0b64b89b-5ae1-4469-9492-a586b695ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-04862103-8fdd-4d48-ba5a-0ac6d5261fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290478119-172.17.0.21-1595480218376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-efd87146-06aa-4844-8423-401678362cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-cecc43c8-4fcd-4268-b150-0831efddc49e,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-97f6495b-1b72-4e8f-af1a-68a0105585fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-cf9d8841-787b-4ef1-8618-5bd0679b700e,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-0654941a-f689-4df7-bfb3-bcb905fba221,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-3c9266a0-8909-42d8-9c04-a1784ca210a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-5c8bc7f9-d91c-4f4b-9137-4548db468d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-2d5b52e9-5206-4abf-a08f-87feea12fb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290478119-172.17.0.21-1595480218376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-efd87146-06aa-4844-8423-401678362cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-cecc43c8-4fcd-4268-b150-0831efddc49e,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-97f6495b-1b72-4e8f-af1a-68a0105585fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-cf9d8841-787b-4ef1-8618-5bd0679b700e,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-0654941a-f689-4df7-bfb3-bcb905fba221,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-3c9266a0-8909-42d8-9c04-a1784ca210a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-5c8bc7f9-d91c-4f4b-9137-4548db468d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-2d5b52e9-5206-4abf-a08f-87feea12fb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069689892-172.17.0.21-1595480292354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-c5741b18-cbcc-4b18-ae2a-a586913c9a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-eb7e372c-cac5-42d6-b7df-46e6525246e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-ad1909fa-1feb-4ef8-8eb7-972396c9f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-e25d61df-973c-4f91-bf02-c3834835662a,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-967b6a99-731d-4209-af4f-2c1004ace8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-8c943d62-7654-4eb1-9928-b49fa14cc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-813245f0-16a8-433b-b4f5-caaf4d1c562a,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-056cea96-9607-4307-bc3b-9cbef73fb9ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069689892-172.17.0.21-1595480292354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-c5741b18-cbcc-4b18-ae2a-a586913c9a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-eb7e372c-cac5-42d6-b7df-46e6525246e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-ad1909fa-1feb-4ef8-8eb7-972396c9f76b,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-e25d61df-973c-4f91-bf02-c3834835662a,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-967b6a99-731d-4209-af4f-2c1004ace8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-8c943d62-7654-4eb1-9928-b49fa14cc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-813245f0-16a8-433b-b4f5-caaf4d1c562a,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-056cea96-9607-4307-bc3b-9cbef73fb9ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244731061-172.17.0.21-1595480580061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35580,DS-cd852c10-668b-4812-bffc-ebc99b0a51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-0257ee0c-cb9e-4429-95a4-774e4774ad50,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-eab01a55-1df6-457d-ae68-3987a5c6ead2,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-4357adb1-3a96-4493-bedb-087e1a744e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-b68ce0f5-3a29-4788-808f-a324aaf90af0,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-802a2d64-19ec-4db9-97a9-5a405e2788de,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-78c76419-d20c-42d1-968e-3645d0c538a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-1c173fce-3d8b-47cc-b228-f2448dccddaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244731061-172.17.0.21-1595480580061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35580,DS-cd852c10-668b-4812-bffc-ebc99b0a51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-0257ee0c-cb9e-4429-95a4-774e4774ad50,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-eab01a55-1df6-457d-ae68-3987a5c6ead2,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-4357adb1-3a96-4493-bedb-087e1a744e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-b68ce0f5-3a29-4788-808f-a324aaf90af0,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-802a2d64-19ec-4db9-97a9-5a405e2788de,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-78c76419-d20c-42d1-968e-3645d0c538a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-1c173fce-3d8b-47cc-b228-f2448dccddaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993344323-172.17.0.21-1595480724435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45198,DS-c0989697-6d9d-4db3-8322-e07b8fecf4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-d3675e0b-935c-4e38-a720-ce7b8f0bc615,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-5e610916-2992-4bec-ae05-51434270bb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-fd66a34c-3ca7-428c-9369-825df3080185,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-9a9de73a-9430-4627-9b39-26d782d0abd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-b27533c2-8243-4886-9ffc-3ce7a1eb8f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-8e464b96-e5f8-436d-9527-6d54b7c89394,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-78465c4a-fc3a-46fe-baa2-326430285248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993344323-172.17.0.21-1595480724435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45198,DS-c0989697-6d9d-4db3-8322-e07b8fecf4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-d3675e0b-935c-4e38-a720-ce7b8f0bc615,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-5e610916-2992-4bec-ae05-51434270bb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-fd66a34c-3ca7-428c-9369-825df3080185,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-9a9de73a-9430-4627-9b39-26d782d0abd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-b27533c2-8243-4886-9ffc-3ce7a1eb8f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-8e464b96-e5f8-436d-9527-6d54b7c89394,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-78465c4a-fc3a-46fe-baa2-326430285248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100406596-172.17.0.21-1595481144609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41002,DS-4bd651fe-e0e5-4704-9294-4e69bac6c7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-4bb6cafa-aaf4-455a-9b3a-03c44fdfe2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-49b03ded-0849-4a3c-b610-7a805cee8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-1294e1f0-be23-41bc-9dc3-0121b91eebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-9a793537-54f7-47df-a77b-017ec2a9bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-9d52007d-ad79-4a5f-93ad-67c8a239b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-7dfdf411-6760-48be-8c4d-e895737c6d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-c4bb835b-2179-496c-aaf7-77f4e999f519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100406596-172.17.0.21-1595481144609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41002,DS-4bd651fe-e0e5-4704-9294-4e69bac6c7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-4bb6cafa-aaf4-455a-9b3a-03c44fdfe2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-49b03ded-0849-4a3c-b610-7a805cee8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-1294e1f0-be23-41bc-9dc3-0121b91eebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-9a793537-54f7-47df-a77b-017ec2a9bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-9d52007d-ad79-4a5f-93ad-67c8a239b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-7dfdf411-6760-48be-8c4d-e895737c6d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-c4bb835b-2179-496c-aaf7-77f4e999f519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081682793-172.17.0.21-1595481237831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34924,DS-225a373b-4972-4e9d-bf45-5c3948232877,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-1983325b-8f3c-4dd4-a826-93bcbc897160,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-e5226286-58f0-43d7-b084-70700c355482,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-d1ba3bac-3d7f-4032-a634-125f3a380932,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-f33c600e-52c3-47ef-a6e3-c33311916c36,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-a15da83f-5fde-4654-aee8-60b539a05921,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-dd0c6bee-e834-4462-9d1f-7b6543954258,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-5ef2fc4d-ba88-4bf6-923d-c478dd0b7d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081682793-172.17.0.21-1595481237831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34924,DS-225a373b-4972-4e9d-bf45-5c3948232877,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-1983325b-8f3c-4dd4-a826-93bcbc897160,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-e5226286-58f0-43d7-b084-70700c355482,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-d1ba3bac-3d7f-4032-a634-125f3a380932,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-f33c600e-52c3-47ef-a6e3-c33311916c36,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-a15da83f-5fde-4654-aee8-60b539a05921,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-dd0c6bee-e834-4462-9d1f-7b6543954258,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-5ef2fc4d-ba88-4bf6-923d-c478dd0b7d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199965842-172.17.0.21-1595481280468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33938,DS-8456c0de-1889-4016-b44b-38b4c81ce03c,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-545ce6b9-8ed4-4689-a6cd-61709fcb86d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-5120a19f-c601-46ac-b8b5-7a2525c398e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-5182f0fb-9b6d-400e-9958-0ab89737c363,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-26ed496e-4381-4f03-a927-c550626fd445,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-342a7616-d921-4c3d-a3b1-1475972bb048,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-acc10ebe-26e8-4b9e-8276-d2cd948e8461,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-5da76b27-0f55-47ab-a444-6f84731a1ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199965842-172.17.0.21-1595481280468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33938,DS-8456c0de-1889-4016-b44b-38b4c81ce03c,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-545ce6b9-8ed4-4689-a6cd-61709fcb86d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-5120a19f-c601-46ac-b8b5-7a2525c398e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-5182f0fb-9b6d-400e-9958-0ab89737c363,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-26ed496e-4381-4f03-a927-c550626fd445,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-342a7616-d921-4c3d-a3b1-1475972bb048,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-acc10ebe-26e8-4b9e-8276-d2cd948e8461,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-5da76b27-0f55-47ab-a444-6f84731a1ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967801453-172.17.0.21-1595482037914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46327,DS-6bf6572f-435e-4871-873a-fbbc7eaf2cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-7cfe9a30-8809-4be5-8696-24f8741f85d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-c6f1cca3-bb76-4fa8-aa61-c74edb5b4655,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-4a1683d7-c14c-49e7-9312-47d8e0fea7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-d246298f-1075-4189-8db2-aa2071891a88,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-41e891df-a291-447a-b91d-7ecc682d6711,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-5a6c0dee-5b45-4853-b8db-f19a99a964e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-5c822133-2cf6-4cf4-a92f-e0f6823e8ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1967801453-172.17.0.21-1595482037914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46327,DS-6bf6572f-435e-4871-873a-fbbc7eaf2cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-7cfe9a30-8809-4be5-8696-24f8741f85d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-c6f1cca3-bb76-4fa8-aa61-c74edb5b4655,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-4a1683d7-c14c-49e7-9312-47d8e0fea7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-d246298f-1075-4189-8db2-aa2071891a88,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-41e891df-a291-447a-b91d-7ecc682d6711,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-5a6c0dee-5b45-4853-b8db-f19a99a964e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-5c822133-2cf6-4cf4-a92f-e0f6823e8ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577742521-172.17.0.21-1595482266309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42592,DS-f9846a04-c81b-41ca-90ac-ef0b9481bb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-d0c3a537-dce6-44b2-b227-a9622d66215c,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-59c7ed78-4711-4774-813d-53e79f5a383f,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-c371a47d-586c-4a87-a6a2-605e5635eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-2bb2206e-0c34-45ad-b945-22a55911ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-ff1ed3d3-7909-4d11-93aa-0ca06df08204,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-3cf16cb4-62d8-479f-a046-fec2281200b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-5f8337d0-1051-411a-82c2-6e6aba456412,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577742521-172.17.0.21-1595482266309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42592,DS-f9846a04-c81b-41ca-90ac-ef0b9481bb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-d0c3a537-dce6-44b2-b227-a9622d66215c,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-59c7ed78-4711-4774-813d-53e79f5a383f,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-c371a47d-586c-4a87-a6a2-605e5635eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-2bb2206e-0c34-45ad-b945-22a55911ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-ff1ed3d3-7909-4d11-93aa-0ca06df08204,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-3cf16cb4-62d8-479f-a046-fec2281200b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-5f8337d0-1051-411a-82c2-6e6aba456412,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596861597-172.17.0.21-1595482692207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-e7d08ef9-6a5f-4b78-9a32-35fc3e04ba3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-468a33e4-38ee-4462-9923-1c4581faa904,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-bbfa728f-cba6-4f94-9657-542f6362f483,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-cc766773-9c0d-454a-9202-2fef50d85b31,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-964cb2dd-8ff9-4147-a80e-8bbd409e95a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-ae3fce0d-a82d-41a0-9073-3d6851095795,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-9cd22eef-fa88-483c-8bf7-5bedcafc67c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-acc1fe48-6627-4185-ac91-44105c9cf607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596861597-172.17.0.21-1595482692207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-e7d08ef9-6a5f-4b78-9a32-35fc3e04ba3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-468a33e4-38ee-4462-9923-1c4581faa904,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-bbfa728f-cba6-4f94-9657-542f6362f483,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-cc766773-9c0d-454a-9202-2fef50d85b31,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-964cb2dd-8ff9-4147-a80e-8bbd409e95a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-ae3fce0d-a82d-41a0-9073-3d6851095795,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-9cd22eef-fa88-483c-8bf7-5bedcafc67c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-acc1fe48-6627-4185-ac91-44105c9cf607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112291503-172.17.0.21-1595482907189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-fa35a167-b71e-4463-9587-8f5bd650dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-f96cb1e4-6098-463a-b863-9fe72d3f4b56,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-c361894e-0a41-4839-916a-6fce640e5e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-4af1d147-5192-4c86-8986-fee7d3cef1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-cec1bbd3-0d09-4a19-a11f-a322992f073c,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-2a5be395-ef8c-446f-9b0c-88fbc2e3ae19,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-eeb7ebde-21c6-4efd-b35f-7f3aecfb88f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-55a68651-7521-4843-bede-390a97aa4eea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112291503-172.17.0.21-1595482907189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-fa35a167-b71e-4463-9587-8f5bd650dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-f96cb1e4-6098-463a-b863-9fe72d3f4b56,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-c361894e-0a41-4839-916a-6fce640e5e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-4af1d147-5192-4c86-8986-fee7d3cef1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-cec1bbd3-0d09-4a19-a11f-a322992f073c,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-2a5be395-ef8c-446f-9b0c-88fbc2e3ae19,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-eeb7ebde-21c6-4efd-b35f-7f3aecfb88f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-55a68651-7521-4843-bede-390a97aa4eea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053061670-172.17.0.21-1595482999665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-86f540eb-23c3-4755-8539-7a7ba40f4c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-177ffa76-17a5-42a1-bd8a-2ec1e1f994c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-6db3ff6c-863a-45b3-9b83-11baff37f297,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-e6f4c377-41fa-4f7f-b060-2028813590b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-ff923bba-dffb-4359-9c20-28a8a25ed053,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-f4bf0f6c-a0c7-4749-a298-773defc65005,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-810de0f0-f4b7-47d9-b4b1-38fe23515028,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-f9ce09b4-7943-4644-a807-ed0a0f76b39c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053061670-172.17.0.21-1595482999665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-86f540eb-23c3-4755-8539-7a7ba40f4c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-177ffa76-17a5-42a1-bd8a-2ec1e1f994c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-6db3ff6c-863a-45b3-9b83-11baff37f297,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-e6f4c377-41fa-4f7f-b060-2028813590b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-ff923bba-dffb-4359-9c20-28a8a25ed053,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-f4bf0f6c-a0c7-4749-a298-773defc65005,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-810de0f0-f4b7-47d9-b4b1-38fe23515028,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-f9ce09b4-7943-4644-a807-ed0a0f76b39c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144343786-172.17.0.21-1595483036295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34190,DS-3a81a1ed-2477-4e39-8fc1-997a36c0c562,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-e43bc3b9-c520-40b4-9257-da58a9a379a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-1b086ae6-d573-494c-80c6-efb77be6795f,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-2e08fc52-191e-47e8-9f8b-dcf95934fb72,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-b4da67ed-9785-4955-b9b9-09081974109b,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-2e32126c-0071-4c4f-81bb-d055ec05b923,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-a082a848-6b36-47ce-ba64-0358338094a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-663d60a6-148f-46b5-9f03-10d650b1519c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144343786-172.17.0.21-1595483036295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34190,DS-3a81a1ed-2477-4e39-8fc1-997a36c0c562,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-e43bc3b9-c520-40b4-9257-da58a9a379a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-1b086ae6-d573-494c-80c6-efb77be6795f,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-2e08fc52-191e-47e8-9f8b-dcf95934fb72,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-b4da67ed-9785-4955-b9b9-09081974109b,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-2e32126c-0071-4c4f-81bb-d055ec05b923,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-a082a848-6b36-47ce-ba64-0358338094a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-663d60a6-148f-46b5-9f03-10d650b1519c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194590975-172.17.0.21-1595483156990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-642a1efa-3339-40a4-8010-3b47c856f7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-c5b1c5ac-307c-4f74-b40a-773aa32987ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-844405f6-d8d7-46c8-b263-08a71cd11fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-a71542dd-eba6-47b4-87f3-6cc764972a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-bb365f07-14a0-4003-8a99-fbc9237c283d,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-882f2917-5e5a-43e5-81c8-94df685f7ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-86079f42-7d95-487f-9c8b-821696f1f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-d996aa9a-f357-4bc9-a206-737a6451caf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194590975-172.17.0.21-1595483156990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-642a1efa-3339-40a4-8010-3b47c856f7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-c5b1c5ac-307c-4f74-b40a-773aa32987ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-844405f6-d8d7-46c8-b263-08a71cd11fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-a71542dd-eba6-47b4-87f3-6cc764972a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-bb365f07-14a0-4003-8a99-fbc9237c283d,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-882f2917-5e5a-43e5-81c8-94df685f7ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-86079f42-7d95-487f-9c8b-821696f1f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-d996aa9a-f357-4bc9-a206-737a6451caf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525279283-172.17.0.21-1595483928758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35304,DS-f6656039-6883-4e42-8f5e-ad79bf9aa742,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-ddddbc94-7f2b-4740-ab0f-f5b9cc858453,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-9bad1615-627f-4840-84b9-373d7ddddc50,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-d36d3b0a-ae4c-451b-9ec0-6919c5902be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-aa1a9736-a426-44a5-a23b-71a9af386ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-467588d9-49e1-4725-8112-82e998d4f5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-03a14cc8-62f2-419d-8861-a517318d0efa,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-3449efbd-bd74-49a8-883a-003aa2d19493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525279283-172.17.0.21-1595483928758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35304,DS-f6656039-6883-4e42-8f5e-ad79bf9aa742,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-ddddbc94-7f2b-4740-ab0f-f5b9cc858453,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-9bad1615-627f-4840-84b9-373d7ddddc50,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-d36d3b0a-ae4c-451b-9ec0-6919c5902be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-aa1a9736-a426-44a5-a23b-71a9af386ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-467588d9-49e1-4725-8112-82e998d4f5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-03a14cc8-62f2-419d-8861-a517318d0efa,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-3449efbd-bd74-49a8-883a-003aa2d19493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559877937-172.17.0.21-1595484013684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43036,DS-d4210658-c8c9-455f-9cb8-a3626b25af3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-63a5f382-1642-42a8-879b-a1f223496af7,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-3931e62f-1aa8-426a-8934-0823d4756095,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-43652b10-bfe4-4bf9-a04a-7f54e8b470be,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-87d88d1e-5220-472f-8eac-230509034958,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-5d8fe973-ef19-4f39-889c-a6c7f304fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-3a701190-15cd-44d1-9f9f-a41d6263be1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-044a244c-1b3a-4ad4-b6cf-720d108930f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559877937-172.17.0.21-1595484013684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43036,DS-d4210658-c8c9-455f-9cb8-a3626b25af3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-63a5f382-1642-42a8-879b-a1f223496af7,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-3931e62f-1aa8-426a-8934-0823d4756095,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-43652b10-bfe4-4bf9-a04a-7f54e8b470be,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-87d88d1e-5220-472f-8eac-230509034958,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-5d8fe973-ef19-4f39-889c-a6c7f304fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-3a701190-15cd-44d1-9f9f-a41d6263be1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-044a244c-1b3a-4ad4-b6cf-720d108930f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654707808-172.17.0.21-1595484311700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-1ee65eb9-4239-4d42-bc03-bbd99340fc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-782436e1-38c1-4b39-a1e7-7d52e61f48c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-e3314018-7ef5-4dec-a9a6-44becbd9e994,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-c62f89b9-d71a-4a5a-ad42-8befc8d11b12,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-2db9fc92-b0c0-4e3a-888b-d56b8159240b,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-6b47f659-426f-427e-ab44-927d671f225d,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-e1ec7ef1-a1e4-4dd3-9af6-820dba28d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-d958f9ad-ee11-4238-a67a-c15f2768fa91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654707808-172.17.0.21-1595484311700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-1ee65eb9-4239-4d42-bc03-bbd99340fc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-782436e1-38c1-4b39-a1e7-7d52e61f48c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-e3314018-7ef5-4dec-a9a6-44becbd9e994,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-c62f89b9-d71a-4a5a-ad42-8befc8d11b12,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-2db9fc92-b0c0-4e3a-888b-d56b8159240b,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-6b47f659-426f-427e-ab44-927d671f225d,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-e1ec7ef1-a1e4-4dd3-9af6-820dba28d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-d958f9ad-ee11-4238-a67a-c15f2768fa91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2097151
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079989036-172.17.0.21-1595484388201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46745,DS-73da2ab4-87da-4e92-8d51-8911a0454d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-e32f6e2d-26b1-40a3-88fd-e9174138c340,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-a2e690a1-10d3-40f9-a958-f0fcd322d15c,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-2832d12e-8efa-44da-b518-6250deaaf05f,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-9df3b8e8-f3f3-48dc-b479-71a663f8ca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-423c0e80-72c9-4ec5-98e4-21073c48604e,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-0792240f-d671-4d84-9be1-c07f92997e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-d4ba5f5b-c66b-4314-95aa-dca837df7b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079989036-172.17.0.21-1595484388201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46745,DS-73da2ab4-87da-4e92-8d51-8911a0454d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-e32f6e2d-26b1-40a3-88fd-e9174138c340,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-a2e690a1-10d3-40f9-a958-f0fcd322d15c,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-2832d12e-8efa-44da-b518-6250deaaf05f,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-9df3b8e8-f3f3-48dc-b479-71a663f8ca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-423c0e80-72c9-4ec5-98e4-21073c48604e,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-0792240f-d671-4d84-9be1-c07f92997e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-d4ba5f5b-c66b-4314-95aa-dca837df7b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6716
