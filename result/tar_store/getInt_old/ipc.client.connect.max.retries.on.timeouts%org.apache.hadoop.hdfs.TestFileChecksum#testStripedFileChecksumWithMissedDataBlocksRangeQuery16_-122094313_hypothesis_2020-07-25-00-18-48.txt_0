reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416667862-172.17.0.20-1595637329123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43727,DS-c3d1596a-20d4-43f3-a15d-f3634c219658,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-c14087b8-644a-4e60-865b-0f7bb88c1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-9d423f81-c833-4ca2-b46c-0a7a3ac6cf40,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-20b9a2a9-44df-4d7f-97bb-d22b41588bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-6ace4e27-360f-4e86-b365-f407adb003b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-4d29ae27-0935-4b89-9a07-9efc5b60d1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-0dc499cc-62d6-436f-aa27-486300f322bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-ecd4cb81-69c2-4415-a096-a0b527b3fa56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416667862-172.17.0.20-1595637329123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43727,DS-c3d1596a-20d4-43f3-a15d-f3634c219658,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-c14087b8-644a-4e60-865b-0f7bb88c1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-9d423f81-c833-4ca2-b46c-0a7a3ac6cf40,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-20b9a2a9-44df-4d7f-97bb-d22b41588bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-6ace4e27-360f-4e86-b365-f407adb003b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-4d29ae27-0935-4b89-9a07-9efc5b60d1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-0dc499cc-62d6-436f-aa27-486300f322bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-ecd4cb81-69c2-4415-a096-a0b527b3fa56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788774913-172.17.0.20-1595637429264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41371,DS-0f3a3fd8-4df7-49a1-8b63-34daacddc75a,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-ae4185a7-7c3c-472d-b6ae-3579b578590d,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-72aef277-1c4d-4c79-b68d-e42aca934316,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-262caf42-41f2-439d-9d88-551e7c18b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-9ea4a421-4f0a-4101-a281-76072ef0d087,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-cf30f789-54a9-420c-90b4-e7c672df08e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-806dc089-09ed-4471-8e5e-97e7bac84a76,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-8fbe9105-b81b-4b5d-9327-e5b4a85a8c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788774913-172.17.0.20-1595637429264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41371,DS-0f3a3fd8-4df7-49a1-8b63-34daacddc75a,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-ae4185a7-7c3c-472d-b6ae-3579b578590d,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-72aef277-1c4d-4c79-b68d-e42aca934316,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-262caf42-41f2-439d-9d88-551e7c18b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-9ea4a421-4f0a-4101-a281-76072ef0d087,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-cf30f789-54a9-420c-90b4-e7c672df08e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-806dc089-09ed-4471-8e5e-97e7bac84a76,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-8fbe9105-b81b-4b5d-9327-e5b4a85a8c01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399521603-172.17.0.20-1595637526426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-82c735bf-ed22-4961-961d-08e19a885dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-1329dec6-0ac8-49b0-84c7-b11c175778be,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-a262ac91-1b2d-4cd4-aa56-0190155b0cce,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-89a76414-1142-4ca0-a390-7690d17fda04,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-f21bde2e-d7c2-4dbe-b020-7def74160fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-56a25369-526f-4e9a-9217-cc4aaf17524b,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-988b64f8-4d06-40d0-8da9-54e11d9c2019,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-cf598826-fb57-421f-b993-0df6763cc225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399521603-172.17.0.20-1595637526426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-82c735bf-ed22-4961-961d-08e19a885dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-1329dec6-0ac8-49b0-84c7-b11c175778be,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-a262ac91-1b2d-4cd4-aa56-0190155b0cce,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-89a76414-1142-4ca0-a390-7690d17fda04,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-f21bde2e-d7c2-4dbe-b020-7def74160fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-56a25369-526f-4e9a-9217-cc4aaf17524b,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-988b64f8-4d06-40d0-8da9-54e11d9c2019,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-cf598826-fb57-421f-b993-0df6763cc225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368451425-172.17.0.20-1595637657589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-b90c4a98-72fd-4a8b-9072-98c55e0c7c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-afb2c597-d15f-4bb6-89b4-1e66bede3567,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-ce08cd0d-6e1a-451b-800f-c4cc1a78a8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-546e23be-542b-4778-8a93-c5ea9f8ff875,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-a962a5a4-4c06-415b-b78c-4daf33fb2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-64a83491-ebea-4446-b94e-a3b850913c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-1ca9541a-e009-4b53-ad73-8cd5dd50b700,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-c1c90d42-b31d-4770-ac44-fe83ab1d3e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368451425-172.17.0.20-1595637657589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-b90c4a98-72fd-4a8b-9072-98c55e0c7c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-afb2c597-d15f-4bb6-89b4-1e66bede3567,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-ce08cd0d-6e1a-451b-800f-c4cc1a78a8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-546e23be-542b-4778-8a93-c5ea9f8ff875,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-a962a5a4-4c06-415b-b78c-4daf33fb2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-64a83491-ebea-4446-b94e-a3b850913c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-1ca9541a-e009-4b53-ad73-8cd5dd50b700,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-c1c90d42-b31d-4770-ac44-fe83ab1d3e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977676477-172.17.0.20-1595637729069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-8aefb296-dd33-4ff6-bb8d-a0202e159f46,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-d3cfdb3e-7a13-4096-9f11-ea370ecdd90a,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-609cf112-6341-41f0-b9fd-547838fdc0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-7f6f755a-960c-4248-968b-b21880755ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-a3772118-a6c1-4353-b647-4b8c875bfe02,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-a9b47edc-d527-482b-bd53-490bec56a0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-d638fc3d-e7bc-4ae7-a928-6cf9eb2164ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-d796f8f0-45a4-433b-bc19-50cf16d77c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977676477-172.17.0.20-1595637729069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-8aefb296-dd33-4ff6-bb8d-a0202e159f46,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-d3cfdb3e-7a13-4096-9f11-ea370ecdd90a,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-609cf112-6341-41f0-b9fd-547838fdc0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-7f6f755a-960c-4248-968b-b21880755ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-a3772118-a6c1-4353-b647-4b8c875bfe02,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-a9b47edc-d527-482b-bd53-490bec56a0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-d638fc3d-e7bc-4ae7-a928-6cf9eb2164ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-d796f8f0-45a4-433b-bc19-50cf16d77c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656017670-172.17.0.20-1595637912311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-8af41051-680e-494e-a662-75233ada2f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-16193941-3b0c-4893-89b3-d25592f80f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-a97fcdb4-1d86-4c82-b212-dffd7f60bb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-180ce86d-c5fe-480f-ba9d-1ddb68dfbb41,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-03f6d3a5-ec3e-445a-931b-aca2fffbd722,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-deaa13f1-2ea8-4936-ba23-73d52e1434b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-5649d4a4-209b-478d-bc7e-52e976543302,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-b5343d94-c975-4a40-ad6a-0afa8b230d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656017670-172.17.0.20-1595637912311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-8af41051-680e-494e-a662-75233ada2f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-16193941-3b0c-4893-89b3-d25592f80f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-a97fcdb4-1d86-4c82-b212-dffd7f60bb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-180ce86d-c5fe-480f-ba9d-1ddb68dfbb41,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-03f6d3a5-ec3e-445a-931b-aca2fffbd722,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-deaa13f1-2ea8-4936-ba23-73d52e1434b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-5649d4a4-209b-478d-bc7e-52e976543302,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-b5343d94-c975-4a40-ad6a-0afa8b230d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102314820-172.17.0.20-1595638029513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46028,DS-d523749e-95bf-4b8e-9d25-bf5f6d53c373,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-8c1590ab-0c67-4c84-8296-f4236312a98a,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-ce531408-bb4d-4212-bd75-02bb8664ec1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-7e186a39-f9b6-4b20-87c4-29877a14ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-ec2ef9d1-0ce1-4530-a0f2-4e6f5990b5af,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-e31922e4-03e5-4d88-ac49-10882d50048e,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-503ac7de-e534-437d-80dd-defa26e0a375,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-64fa1d99-faee-4fe1-a3e6-fad90838e7b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102314820-172.17.0.20-1595638029513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46028,DS-d523749e-95bf-4b8e-9d25-bf5f6d53c373,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-8c1590ab-0c67-4c84-8296-f4236312a98a,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-ce531408-bb4d-4212-bd75-02bb8664ec1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-7e186a39-f9b6-4b20-87c4-29877a14ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-ec2ef9d1-0ce1-4530-a0f2-4e6f5990b5af,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-e31922e4-03e5-4d88-ac49-10882d50048e,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-503ac7de-e534-437d-80dd-defa26e0a375,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-64fa1d99-faee-4fe1-a3e6-fad90838e7b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31221359-172.17.0.20-1595638234293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37927,DS-be75ff83-b738-4f55-b723-fdbe389e8eec,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-52c4f6ee-96c7-4a52-83d4-4aa8f879d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-e987d56c-402b-4d20-85f3-521d7e36b7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b980e491-db37-4c6d-8d4f-22a9307dc89a,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-6719eacb-f982-4f5c-8b40-baa4b1129653,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-ce5fe3c4-a7de-4f70-bcb9-6409bfd56d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-36ded631-153b-476e-a1a8-04ab36630f46,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-db61c2d2-32f6-4d05-a921-5ded23ad32d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31221359-172.17.0.20-1595638234293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37927,DS-be75ff83-b738-4f55-b723-fdbe389e8eec,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-52c4f6ee-96c7-4a52-83d4-4aa8f879d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-e987d56c-402b-4d20-85f3-521d7e36b7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b980e491-db37-4c6d-8d4f-22a9307dc89a,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-6719eacb-f982-4f5c-8b40-baa4b1129653,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-ce5fe3c4-a7de-4f70-bcb9-6409bfd56d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-36ded631-153b-476e-a1a8-04ab36630f46,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-db61c2d2-32f6-4d05-a921-5ded23ad32d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320602662-172.17.0.20-1595638837091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45015,DS-839bf6ec-b9e6-4440-b5d5-87db6c745432,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-f36348fc-eda7-4bae-a4c9-ea0b730fc43a,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-e9fa4ce2-0c73-4663-ae28-ccf4b43ee731,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-bd602009-0e1d-429d-8f2a-be7d5bd369b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-da55b37a-7547-4b97-beff-730c72851050,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-2668da49-6ba1-43ff-b744-8104fbaac878,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-ea3b407f-2a2e-4b58-9150-04d32bf59706,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-77222bbd-b5cd-4c68-bc13-e09b8efda64f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320602662-172.17.0.20-1595638837091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45015,DS-839bf6ec-b9e6-4440-b5d5-87db6c745432,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-f36348fc-eda7-4bae-a4c9-ea0b730fc43a,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-e9fa4ce2-0c73-4663-ae28-ccf4b43ee731,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-bd602009-0e1d-429d-8f2a-be7d5bd369b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-da55b37a-7547-4b97-beff-730c72851050,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-2668da49-6ba1-43ff-b744-8104fbaac878,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-ea3b407f-2a2e-4b58-9150-04d32bf59706,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-77222bbd-b5cd-4c68-bc13-e09b8efda64f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641626548-172.17.0.20-1595639026894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42382,DS-9fd302f1-213d-4f6b-9b8e-0b9589f896bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-081cac1c-ab8d-46ca-acfb-89261c1717d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-441fd582-ee48-4058-af7c-e973f08f278c,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-9536fcb5-1a48-4e4c-86a6-a7d727bf60ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-e22dc4ac-2595-4140-95eb-8b7c064b4d06,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-46344635-1ec9-4235-8206-d96748b70486,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-0c0ecce4-5c0b-4ac6-9efa-998e42a8c5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-8845978d-8322-4960-9d96-3ae871476504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641626548-172.17.0.20-1595639026894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42382,DS-9fd302f1-213d-4f6b-9b8e-0b9589f896bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-081cac1c-ab8d-46ca-acfb-89261c1717d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-441fd582-ee48-4058-af7c-e973f08f278c,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-9536fcb5-1a48-4e4c-86a6-a7d727bf60ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-e22dc4ac-2595-4140-95eb-8b7c064b4d06,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-46344635-1ec9-4235-8206-d96748b70486,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-0c0ecce4-5c0b-4ac6-9efa-998e42a8c5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-8845978d-8322-4960-9d96-3ae871476504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961701629-172.17.0.20-1595639168789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33717,DS-60e973b4-bbb1-4707-8c9f-a337aba613c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-74fd85bf-5513-45b5-8d7c-2084aed9de36,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-e9646929-f84e-4645-a4c2-6602dbe9973d,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-24464ed1-ae9e-4b8c-9469-4a79d1cfe17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-a4b7c679-b856-4093-8ffa-6fc7f1a9db04,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-c20bbd52-7973-417b-914c-d9f556fc71c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-3dbafa05-eac4-4290-92fd-3b022d180984,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-af879335-94d9-4358-b416-b5c9c335ddad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961701629-172.17.0.20-1595639168789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33717,DS-60e973b4-bbb1-4707-8c9f-a337aba613c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-74fd85bf-5513-45b5-8d7c-2084aed9de36,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-e9646929-f84e-4645-a4c2-6602dbe9973d,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-24464ed1-ae9e-4b8c-9469-4a79d1cfe17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-a4b7c679-b856-4093-8ffa-6fc7f1a9db04,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-c20bbd52-7973-417b-914c-d9f556fc71c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-3dbafa05-eac4-4290-92fd-3b022d180984,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-af879335-94d9-4358-b416-b5c9c335ddad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480390797-172.17.0.20-1595639633000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41586,DS-8c85b26d-5f67-4d48-8dc8-ef9d2d19d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-13d5574b-8942-4d72-9043-f2edbccfff89,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-ea819d7b-0699-486b-870c-cb9ad360e47c,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-c071cbda-535e-4d66-aecb-d73906c480a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-8f58c3de-2783-4024-9f6a-fdf6c83cf452,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-94dc75b8-a587-4ebc-b2f6-d722ec3a3df8,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-5328bd41-c99f-4866-83e1-f779dec15342,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-9a1050c7-059c-48ee-85bf-377b0226a1ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480390797-172.17.0.20-1595639633000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41586,DS-8c85b26d-5f67-4d48-8dc8-ef9d2d19d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-13d5574b-8942-4d72-9043-f2edbccfff89,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-ea819d7b-0699-486b-870c-cb9ad360e47c,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-c071cbda-535e-4d66-aecb-d73906c480a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-8f58c3de-2783-4024-9f6a-fdf6c83cf452,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-94dc75b8-a587-4ebc-b2f6-d722ec3a3df8,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-5328bd41-c99f-4866-83e1-f779dec15342,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-9a1050c7-059c-48ee-85bf-377b0226a1ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787587494-172.17.0.20-1595640580888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33016,DS-dd55718d-ce07-4deb-a588-6f25ba5d022d,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-6af58366-523e-42fe-bf76-c3ede2eb1633,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-bde7c0d9-85da-491c-b70f-4b723fb8dff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-dd6266d4-52c6-4d37-b02c-33c7f33e2bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-5e863aee-73ef-4f03-b2da-cc6d68d0c0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-2e007b51-8f07-417b-860d-90fd40d9bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-6eaa0aca-d800-41d0-a20e-cd5ae12cde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-ead308c2-5f59-495c-98f8-ea11afd0bdec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787587494-172.17.0.20-1595640580888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33016,DS-dd55718d-ce07-4deb-a588-6f25ba5d022d,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-6af58366-523e-42fe-bf76-c3ede2eb1633,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-bde7c0d9-85da-491c-b70f-4b723fb8dff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-dd6266d4-52c6-4d37-b02c-33c7f33e2bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-5e863aee-73ef-4f03-b2da-cc6d68d0c0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-2e007b51-8f07-417b-860d-90fd40d9bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-6eaa0aca-d800-41d0-a20e-cd5ae12cde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-ead308c2-5f59-495c-98f8-ea11afd0bdec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397665089-172.17.0.20-1595640816023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35403,DS-9cee3de0-239e-47d1-ab6c-40c2521459a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-5c76fe3d-5d4e-4c6e-a5d8-b456c9dca661,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-f0ce644e-ddf8-42b1-94a3-34978a335883,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-d8af2e52-dc7d-4768-8ce2-45f47cee0ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-edfd7048-01d0-492f-9912-5104c199a3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-12ac078e-c6cd-48a3-b89b-e53d243d8832,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-db013d4a-5e8a-4b20-ac9b-7dc2fe578eba,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-00618670-47cc-43b6-971c-8991b9647ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397665089-172.17.0.20-1595640816023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35403,DS-9cee3de0-239e-47d1-ab6c-40c2521459a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-5c76fe3d-5d4e-4c6e-a5d8-b456c9dca661,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-f0ce644e-ddf8-42b1-94a3-34978a335883,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-d8af2e52-dc7d-4768-8ce2-45f47cee0ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-edfd7048-01d0-492f-9912-5104c199a3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-12ac078e-c6cd-48a3-b89b-e53d243d8832,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-db013d4a-5e8a-4b20-ac9b-7dc2fe578eba,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-00618670-47cc-43b6-971c-8991b9647ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478232649-172.17.0.20-1595640913027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34670,DS-7f33f174-98c0-46f1-a9e1-fd6014b5e373,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-a744e05e-3b56-4cf5-9b43-35b491f4cc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-b4278937-361d-4a6e-a878-cc0cbddcf5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-eabb4473-c49e-4bee-9aee-cb816388470b,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-31eae7af-80ad-459a-b14b-5437c612cbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-ecbbb6a5-014b-43a7-9777-9dc7233c8122,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-c42828be-dd7f-4dbc-ad5d-fa8db3e955bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-df197c6f-d0e2-4e06-9e5b-433bd85bc848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478232649-172.17.0.20-1595640913027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34670,DS-7f33f174-98c0-46f1-a9e1-fd6014b5e373,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-a744e05e-3b56-4cf5-9b43-35b491f4cc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-b4278937-361d-4a6e-a878-cc0cbddcf5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-eabb4473-c49e-4bee-9aee-cb816388470b,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-31eae7af-80ad-459a-b14b-5437c612cbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-ecbbb6a5-014b-43a7-9777-9dc7233c8122,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-c42828be-dd7f-4dbc-ad5d-fa8db3e955bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-df197c6f-d0e2-4e06-9e5b-433bd85bc848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125231206-172.17.0.20-1595641236392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-39dee9c7-706e-4093-830e-00b0a2c3e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-eea18108-6b3c-47a8-8e82-849cc34d767c,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-2efd9991-6e68-4293-8a9f-cedb5ccb60f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-191be8a6-2988-4539-b383-c3968e7234de,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-fc4639d0-23e7-4591-afe1-f484cf69c9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-b07109c3-3f59-4b30-bc9b-7197838d0ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-4a859bbe-344e-4155-9c26-663967465506,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-7567985e-d1f9-48f1-abe4-7dafc141f3c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125231206-172.17.0.20-1595641236392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-39dee9c7-706e-4093-830e-00b0a2c3e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-eea18108-6b3c-47a8-8e82-849cc34d767c,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-2efd9991-6e68-4293-8a9f-cedb5ccb60f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-191be8a6-2988-4539-b383-c3968e7234de,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-fc4639d0-23e7-4591-afe1-f484cf69c9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-b07109c3-3f59-4b30-bc9b-7197838d0ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-4a859bbe-344e-4155-9c26-663967465506,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-7567985e-d1f9-48f1-abe4-7dafc141f3c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5187
