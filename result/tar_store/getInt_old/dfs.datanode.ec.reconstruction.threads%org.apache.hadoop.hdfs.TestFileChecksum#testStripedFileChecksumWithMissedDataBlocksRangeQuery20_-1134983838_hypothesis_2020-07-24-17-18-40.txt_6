reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550448381-172.17.0.13-1595611201451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-6e947235-2b5f-4427-9884-c8ad3eeacbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-0599447e-3435-4074-b8f5-8ea1d7147f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-8e2770af-b255-4ce5-a7cb-a2604d48e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-3a95376d-0f41-4bda-a9ae-a01a9d2cdadf,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-3a8ba4c6-84a9-4d7c-a37f-8f6d5c8761d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-7efbf25e-c61c-437d-a979-7806dfed804c,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-7701990b-5547-40d4-b658-d143da5e2edb,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-f957cdcf-d32a-4fc1-9675-7ca845e1aa24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550448381-172.17.0.13-1595611201451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-6e947235-2b5f-4427-9884-c8ad3eeacbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-0599447e-3435-4074-b8f5-8ea1d7147f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-8e2770af-b255-4ce5-a7cb-a2604d48e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-3a95376d-0f41-4bda-a9ae-a01a9d2cdadf,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-3a8ba4c6-84a9-4d7c-a37f-8f6d5c8761d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-7efbf25e-c61c-437d-a979-7806dfed804c,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-7701990b-5547-40d4-b658-d143da5e2edb,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-f957cdcf-d32a-4fc1-9675-7ca845e1aa24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005909377-172.17.0.13-1595611270885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-351edfa0-ce5e-406b-8b1c-b42ff83cdc71,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-8a430a7e-ac43-4035-abe6-4173d9b3c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-e21321f3-ed0e-4699-b673-fb3043843e98,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-589dfb92-482d-4758-805e-e29c4c057b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-e5b4698f-6480-4870-982c-ba642983525b,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-ffccbc68-207d-4c93-b5e0-a3d6d9d5e26b,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-db5613c2-5f30-4257-bdbc-2ce7d893ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-0ff319da-fa22-4ec2-ad9b-575069b8a2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005909377-172.17.0.13-1595611270885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-351edfa0-ce5e-406b-8b1c-b42ff83cdc71,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-8a430a7e-ac43-4035-abe6-4173d9b3c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-e21321f3-ed0e-4699-b673-fb3043843e98,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-589dfb92-482d-4758-805e-e29c4c057b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-e5b4698f-6480-4870-982c-ba642983525b,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-ffccbc68-207d-4c93-b5e0-a3d6d9d5e26b,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-db5613c2-5f30-4257-bdbc-2ce7d893ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-0ff319da-fa22-4ec2-ad9b-575069b8a2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933748279-172.17.0.13-1595611844442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-a0ad2ad3-e4e3-4220-8c9f-dbde31268658,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-316a481a-2a3e-481a-8c0d-6831289fdb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-7f5a6e1f-d59e-4820-aa0c-b4d7b0a28c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-b287f73b-2835-4422-8be7-85ce44fac28c,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-27681654-7221-4a2b-89f9-5d072c48cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-2b8791c7-5c99-47a8-9b5a-0be1b7324ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-15502e79-7175-40ca-90d7-7d9790be8f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-81e582a0-413a-4815-a2cb-9b9a598722d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933748279-172.17.0.13-1595611844442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-a0ad2ad3-e4e3-4220-8c9f-dbde31268658,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-316a481a-2a3e-481a-8c0d-6831289fdb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-7f5a6e1f-d59e-4820-aa0c-b4d7b0a28c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-b287f73b-2835-4422-8be7-85ce44fac28c,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-27681654-7221-4a2b-89f9-5d072c48cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-2b8791c7-5c99-47a8-9b5a-0be1b7324ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-15502e79-7175-40ca-90d7-7d9790be8f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-81e582a0-413a-4815-a2cb-9b9a598722d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675297154-172.17.0.13-1595611912805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-de5833ba-e0fb-4095-a066-969e374b3ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-56261563-054b-4e9f-b97d-a6790e4db6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-8c774520-44bc-4d44-bd6e-e83e23ae2a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-ae031c3a-6436-4281-b7c0-ba3376c6a553,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-d842cdb6-62ee-48b0-a77c-8b20c18194c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-5d7b284c-ddf2-468a-a292-dcfda632c0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-9179382a-571d-4804-8b33-76049db9a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-dee85756-a188-4d39-8240-4cfec9f60042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675297154-172.17.0.13-1595611912805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-de5833ba-e0fb-4095-a066-969e374b3ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-56261563-054b-4e9f-b97d-a6790e4db6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-8c774520-44bc-4d44-bd6e-e83e23ae2a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-ae031c3a-6436-4281-b7c0-ba3376c6a553,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-d842cdb6-62ee-48b0-a77c-8b20c18194c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-5d7b284c-ddf2-468a-a292-dcfda632c0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-9179382a-571d-4804-8b33-76049db9a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-dee85756-a188-4d39-8240-4cfec9f60042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323372612-172.17.0.13-1595612024309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34379,DS-c9ccd09b-e4c6-4759-8f9e-e2c3b3ca5208,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-60aa129d-0fb7-4df5-a2f6-ceb0d66bc277,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-e8025cb4-d17b-42c3-8ee1-710b539d3740,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-6d2df5b9-95b9-465f-8d6c-345094613db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-129ba4de-4dcf-4c4c-b191-c4134804e317,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-1ec05a2e-2607-49a5-8c05-415450e2809e,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-701d2d35-7e8d-4dff-87b0-f89dddff1984,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-fbbd42c2-1839-4fcb-9adc-f918cab6efc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323372612-172.17.0.13-1595612024309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34379,DS-c9ccd09b-e4c6-4759-8f9e-e2c3b3ca5208,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-60aa129d-0fb7-4df5-a2f6-ceb0d66bc277,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-e8025cb4-d17b-42c3-8ee1-710b539d3740,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-6d2df5b9-95b9-465f-8d6c-345094613db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-129ba4de-4dcf-4c4c-b191-c4134804e317,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-1ec05a2e-2607-49a5-8c05-415450e2809e,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-701d2d35-7e8d-4dff-87b0-f89dddff1984,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-fbbd42c2-1839-4fcb-9adc-f918cab6efc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803943987-172.17.0.13-1595612133839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-185dcde7-a4c7-4988-99f3-12e140900e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-3d39b2aa-96de-4edd-932f-020bc527f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-98bf40a9-2538-4cd0-a03e-8fe8ffcd2df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-5b670e41-97a8-454d-b3ea-45355118b7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-71b932a4-6959-4603-8314-00748844e930,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-c569e322-5001-4895-9b74-a91f1f9d8584,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-c9bb6b44-0f84-48f5-aae0-21003c3313cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-a7706d37-07fd-4dee-9b29-9c526c57a01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803943987-172.17.0.13-1595612133839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-185dcde7-a4c7-4988-99f3-12e140900e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-3d39b2aa-96de-4edd-932f-020bc527f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-98bf40a9-2538-4cd0-a03e-8fe8ffcd2df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-5b670e41-97a8-454d-b3ea-45355118b7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-71b932a4-6959-4603-8314-00748844e930,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-c569e322-5001-4895-9b74-a91f1f9d8584,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-c9bb6b44-0f84-48f5-aae0-21003c3313cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-a7706d37-07fd-4dee-9b29-9c526c57a01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952091308-172.17.0.13-1595612242145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33605,DS-cc74260e-786b-4528-acf7-8e4c090292b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-05b84eb0-1da9-45a6-a1d2-2905da4d52cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-2efab5f7-0e74-45a7-bfa6-a27f3029279a,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-47137d02-4a85-450f-80bb-b2d26de271bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-0e38b416-0b06-43ee-b610-6775850df844,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-1a3ffc62-e0bc-4a8d-8411-bcf78802000c,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-70969e6e-f867-40c8-aa20-307a9940138b,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-60d19c99-718f-4728-a865-4c83c0baf606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952091308-172.17.0.13-1595612242145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33605,DS-cc74260e-786b-4528-acf7-8e4c090292b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-05b84eb0-1da9-45a6-a1d2-2905da4d52cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-2efab5f7-0e74-45a7-bfa6-a27f3029279a,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-47137d02-4a85-450f-80bb-b2d26de271bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-0e38b416-0b06-43ee-b610-6775850df844,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-1a3ffc62-e0bc-4a8d-8411-bcf78802000c,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-70969e6e-f867-40c8-aa20-307a9940138b,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-60d19c99-718f-4728-a865-4c83c0baf606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113800408-172.17.0.13-1595612350495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-3c43ce65-46ab-44ee-ae33-15117daaee78,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-f15296d8-4466-43b0-8cd5-81f52d0b80ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-d49b0002-7b57-480b-b394-6fa17110d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-fc7c4199-2d7e-4519-ba57-e82b10390fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-749ceda8-cdaa-4bb1-985f-2d661801e6af,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-bf76de65-e77b-4aa2-a8a9-b3359ebe44c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-67931dd3-3936-4478-997a-6c849203435b,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-72894553-430c-4e15-b3ef-aa39eab37d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113800408-172.17.0.13-1595612350495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-3c43ce65-46ab-44ee-ae33-15117daaee78,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-f15296d8-4466-43b0-8cd5-81f52d0b80ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-d49b0002-7b57-480b-b394-6fa17110d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-fc7c4199-2d7e-4519-ba57-e82b10390fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-749ceda8-cdaa-4bb1-985f-2d661801e6af,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-bf76de65-e77b-4aa2-a8a9-b3359ebe44c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-67931dd3-3936-4478-997a-6c849203435b,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-72894553-430c-4e15-b3ef-aa39eab37d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258504453-172.17.0.13-1595612684061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40459,DS-b8b2a6cd-bef2-4128-a2d8-4706e8156541,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-cabec78e-7a39-4626-8c8f-3080568b81d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-5a2ff9b4-ee0e-406d-87bf-573d5263662b,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-639591a9-334f-4377-847d-4e00a79dba98,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-df3fb38a-ec30-4048-b3cb-dba85346d671,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-1b2d2f33-1bcb-43e9-b121-dc1c49292d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-5a1c2c83-41b1-4202-b4e3-ed01add63c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-204dde6b-6e2d-4bcf-a70a-859c8b0afca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258504453-172.17.0.13-1595612684061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40459,DS-b8b2a6cd-bef2-4128-a2d8-4706e8156541,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-cabec78e-7a39-4626-8c8f-3080568b81d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-5a2ff9b4-ee0e-406d-87bf-573d5263662b,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-639591a9-334f-4377-847d-4e00a79dba98,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-df3fb38a-ec30-4048-b3cb-dba85346d671,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-1b2d2f33-1bcb-43e9-b121-dc1c49292d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-5a1c2c83-41b1-4202-b4e3-ed01add63c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-204dde6b-6e2d-4bcf-a70a-859c8b0afca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336993254-172.17.0.13-1595613199485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41118,DS-551f3021-179d-43a0-9f7e-e569d464b397,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-48f2ed97-64e1-4d09-8885-69a379b126a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-2bc0156e-41bd-4850-a49a-5130c8210a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-0061016f-4369-489c-97c9-41060b1a4128,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-e10d775b-01ac-44e5-bbf4-9b8680de52b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-93795f97-1440-421c-980f-da91e84443cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-184c9a15-cc82-49be-baeb-31c494a41c48,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-8f2b6627-a9a2-49a9-b546-68c0f8dc92cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336993254-172.17.0.13-1595613199485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41118,DS-551f3021-179d-43a0-9f7e-e569d464b397,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-48f2ed97-64e1-4d09-8885-69a379b126a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-2bc0156e-41bd-4850-a49a-5130c8210a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-0061016f-4369-489c-97c9-41060b1a4128,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-e10d775b-01ac-44e5-bbf4-9b8680de52b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-93795f97-1440-421c-980f-da91e84443cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-184c9a15-cc82-49be-baeb-31c494a41c48,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-8f2b6627-a9a2-49a9-b546-68c0f8dc92cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361827543-172.17.0.13-1595613421454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37934,DS-e8d6134e-502a-4f03-87fb-0dd2955cc6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-fbf25ee3-1b96-4d46-8083-e808f4b24c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-1136d50f-0760-4db8-a752-6b891067e645,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-e30e661b-575f-4ddc-9bea-9a467831e356,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-4d991c04-2e34-437c-bed5-d938215f684f,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-0ca14ba0-91db-48ce-aba7-a7ca8a6e0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-a0d368f2-9eed-402f-8fa1-8f5dc42b167b,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-8688e085-05cb-4e1d-bacd-a808f899d17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361827543-172.17.0.13-1595613421454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37934,DS-e8d6134e-502a-4f03-87fb-0dd2955cc6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-fbf25ee3-1b96-4d46-8083-e808f4b24c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-1136d50f-0760-4db8-a752-6b891067e645,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-e30e661b-575f-4ddc-9bea-9a467831e356,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-4d991c04-2e34-437c-bed5-d938215f684f,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-0ca14ba0-91db-48ce-aba7-a7ca8a6e0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-a0d368f2-9eed-402f-8fa1-8f5dc42b167b,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-8688e085-05cb-4e1d-bacd-a808f899d17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921357849-172.17.0.13-1595614066743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34574,DS-b6759434-15cc-441b-b446-3865694c0566,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-c146f10b-7d35-42da-b6bb-a1a26bb5e54b,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-bf2dc096-704b-4913-8440-2fe305cfcb36,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-c54da9de-975a-44e1-be9b-57a034ff1c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-2c8aea0a-c7cf-4f3c-880a-da1c190d5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-c84f3989-2ea7-4ba0-9f01-ae61ee6b5eee,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-d0c68ed1-d209-4665-af9b-92cdf280e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-d6800316-90ac-4129-8794-b0701cc14ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921357849-172.17.0.13-1595614066743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34574,DS-b6759434-15cc-441b-b446-3865694c0566,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-c146f10b-7d35-42da-b6bb-a1a26bb5e54b,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-bf2dc096-704b-4913-8440-2fe305cfcb36,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-c54da9de-975a-44e1-be9b-57a034ff1c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-2c8aea0a-c7cf-4f3c-880a-da1c190d5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-c84f3989-2ea7-4ba0-9f01-ae61ee6b5eee,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-d0c68ed1-d209-4665-af9b-92cdf280e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-d6800316-90ac-4129-8794-b0701cc14ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762202783-172.17.0.13-1595614221814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33308,DS-95ae7af8-239d-4ede-96ba-3d888b982585,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-12312e87-eac2-4d27-bd38-611bfcb2f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-0de87a7e-aa7d-4e59-bd84-5066942d50c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-675ceae0-47e8-4331-a5e5-bf928c071865,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-f9a447e4-e386-4402-b8d5-c86161ea7d63,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-20d58411-c213-43a6-a0a4-85923a0fbbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-fa30b3b1-45ff-4a0b-819c-26575100f977,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-0e512f71-ed13-49dd-915c-d11ee020db5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762202783-172.17.0.13-1595614221814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33308,DS-95ae7af8-239d-4ede-96ba-3d888b982585,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-12312e87-eac2-4d27-bd38-611bfcb2f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-0de87a7e-aa7d-4e59-bd84-5066942d50c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-675ceae0-47e8-4331-a5e5-bf928c071865,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-f9a447e4-e386-4402-b8d5-c86161ea7d63,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-20d58411-c213-43a6-a0a4-85923a0fbbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-fa30b3b1-45ff-4a0b-819c-26575100f977,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-0e512f71-ed13-49dd-915c-d11ee020db5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687598360-172.17.0.13-1595614582318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-e9f823c7-8b59-4893-9b49-c45a512c7e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-bcc28989-6245-4919-b2d0-a0488f37f10a,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-39121832-b3bd-45e1-a5a9-bb2dee3156f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-8c1ad038-c260-4b0d-869d-7a050f360494,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-4bf088d1-7d3b-45d0-b731-a9f91d3db092,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-3c49da37-fc69-4a38-9edf-7fe63c96f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-04ca0825-a2a9-4f3c-bc92-86c2e12c2253,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-eae8a638-f4b0-45a6-ae81-5c2e19064240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687598360-172.17.0.13-1595614582318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-e9f823c7-8b59-4893-9b49-c45a512c7e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-bcc28989-6245-4919-b2d0-a0488f37f10a,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-39121832-b3bd-45e1-a5a9-bb2dee3156f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-8c1ad038-c260-4b0d-869d-7a050f360494,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-4bf088d1-7d3b-45d0-b731-a9f91d3db092,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-3c49da37-fc69-4a38-9edf-7fe63c96f94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-04ca0825-a2a9-4f3c-bc92-86c2e12c2253,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-eae8a638-f4b0-45a6-ae81-5c2e19064240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692993124-172.17.0.13-1595614746432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33342,DS-4e9f3859-e3f0-4166-8afa-c168d390ebcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-fef3cc83-964d-4daa-862d-1aff4c3d25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-fbcce75b-7d23-44c0-a230-a6e768f0f7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-58666ae0-a2a1-4ec0-848a-9076ab666e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-bc4504d2-45cd-470b-bd3c-3e9fd699944d,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-7d081ffe-a00e-4d7d-8d5c-6fb99213234e,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-8c124ea6-b4b1-4245-9bed-5e50e8514015,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-9bca62c6-26f4-4d4b-b108-11e358426550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692993124-172.17.0.13-1595614746432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33342,DS-4e9f3859-e3f0-4166-8afa-c168d390ebcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-fef3cc83-964d-4daa-862d-1aff4c3d25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-fbcce75b-7d23-44c0-a230-a6e768f0f7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-58666ae0-a2a1-4ec0-848a-9076ab666e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-bc4504d2-45cd-470b-bd3c-3e9fd699944d,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-7d081ffe-a00e-4d7d-8d5c-6fb99213234e,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-8c124ea6-b4b1-4245-9bed-5e50e8514015,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-9bca62c6-26f4-4d4b-b108-11e358426550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720457370-172.17.0.13-1595615059438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45904,DS-75ac7819-05d2-4263-93c5-26c466ad2be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-6e1f76f7-4173-485b-a979-0d6b3af6206a,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-5a53adfd-372c-47f6-9a86-a9c021f7a126,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-f28728bb-974d-4b84-9617-6fb89e0ec8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-d61db42d-d7f7-4607-8bde-0a45af207a41,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-cfcdb7c1-79b4-40e8-862a-53f38bbee794,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-55f20685-f880-4aed-b3cf-1d5615c44f37,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-f821dc5d-0193-430a-a584-ecec93d22b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720457370-172.17.0.13-1595615059438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45904,DS-75ac7819-05d2-4263-93c5-26c466ad2be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-6e1f76f7-4173-485b-a979-0d6b3af6206a,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-5a53adfd-372c-47f6-9a86-a9c021f7a126,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-f28728bb-974d-4b84-9617-6fb89e0ec8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-d61db42d-d7f7-4607-8bde-0a45af207a41,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-cfcdb7c1-79b4-40e8-862a-53f38bbee794,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-55f20685-f880-4aed-b3cf-1d5615c44f37,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-f821dc5d-0193-430a-a584-ecec93d22b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059000597-172.17.0.13-1595615587794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38842,DS-44c20f0c-c600-4582-9bb6-324fd94895fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-4aa86483-d818-44a8-bae2-2ae536443887,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-c273227f-802e-42ec-8b11-4bbe3ce28203,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-55e850aa-e60e-421e-af8a-e89aa34f6304,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-808cc0d2-7ad3-4b8b-a25c-354830408754,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-626ca1a2-2b2c-4a06-bea0-51e296b26c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-a25acba8-9501-4da2-8429-4dfa1dab5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-28f79354-f71d-4186-8485-a8ed874b1b9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059000597-172.17.0.13-1595615587794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38842,DS-44c20f0c-c600-4582-9bb6-324fd94895fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-4aa86483-d818-44a8-bae2-2ae536443887,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-c273227f-802e-42ec-8b11-4bbe3ce28203,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-55e850aa-e60e-421e-af8a-e89aa34f6304,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-808cc0d2-7ad3-4b8b-a25c-354830408754,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-626ca1a2-2b2c-4a06-bea0-51e296b26c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-a25acba8-9501-4da2-8429-4dfa1dab5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-28f79354-f71d-4186-8485-a8ed874b1b9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134343881-172.17.0.13-1595615615494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44764,DS-c524818b-7126-43eb-8192-84a9f89c9086,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-7fba00f4-3eac-4d08-bea7-2fbc5f3b64ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-f3c6ac30-8162-470c-93b2-1617f79093db,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-c333d0aa-632a-49ca-b1b5-dba09f44eae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-860f8c77-85b4-413a-943b-b9485e7c50ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-6cdba2ad-5570-472b-9059-10faea38c664,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-ad1e181d-527c-453f-9855-47710b49347d,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-7859e21f-0119-47b0-a7f6-99e0fd0acd47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134343881-172.17.0.13-1595615615494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44764,DS-c524818b-7126-43eb-8192-84a9f89c9086,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-7fba00f4-3eac-4d08-bea7-2fbc5f3b64ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-f3c6ac30-8162-470c-93b2-1617f79093db,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-c333d0aa-632a-49ca-b1b5-dba09f44eae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-860f8c77-85b4-413a-943b-b9485e7c50ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-6cdba2ad-5570-472b-9059-10faea38c664,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-ad1e181d-527c-453f-9855-47710b49347d,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-7859e21f-0119-47b0-a7f6-99e0fd0acd47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5308
