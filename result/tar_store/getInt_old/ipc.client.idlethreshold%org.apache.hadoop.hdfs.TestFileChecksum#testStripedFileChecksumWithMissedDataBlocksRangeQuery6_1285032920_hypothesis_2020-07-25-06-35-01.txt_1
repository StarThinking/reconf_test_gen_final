reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126630617-172.17.0.4-1595659153794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-827328d2-7bff-42df-b5e0-3dd93991b811,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-4c4fc5f4-061a-442f-b3cb-65460451945f,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-0e7eb4e0-d418-4860-aa9f-c84ac8feeba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-f4d159a7-aba6-4111-9923-f8d4ffb0f07b,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-ec2cf7c2-8ded-4390-8764-2c3ecfa954b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-0d4bccec-ef8a-4047-9bca-68adaa216198,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-3d2bcc1f-92c2-4ccb-90d6-36017461741b,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-8b6a56f8-d434-4a18-bfd7-c1a57a2a1f9a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126630617-172.17.0.4-1595659153794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-827328d2-7bff-42df-b5e0-3dd93991b811,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-4c4fc5f4-061a-442f-b3cb-65460451945f,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-0e7eb4e0-d418-4860-aa9f-c84ac8feeba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-f4d159a7-aba6-4111-9923-f8d4ffb0f07b,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-ec2cf7c2-8ded-4390-8764-2c3ecfa954b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-0d4bccec-ef8a-4047-9bca-68adaa216198,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-3d2bcc1f-92c2-4ccb-90d6-36017461741b,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-8b6a56f8-d434-4a18-bfd7-c1a57a2a1f9a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975355339-172.17.0.4-1595659519476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34278,DS-1f3dd3bd-484a-4d24-90c9-c36281dca817,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-1c18c8cf-84c3-4332-8ed3-97bc90756419,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-7bd7686c-b6a3-4110-8f0c-40843a21b004,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-427b81fc-ac30-44a4-91a0-a8e554157472,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-15cdac4a-8028-42b6-9f4e-2c49f0237e05,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-d4ae674a-b75c-4ed6-876a-263194ab23e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-1df522c2-1e52-4a98-8543-981e5bdfd57f,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-afc21dd0-9d37-4dd2-b191-03875a604d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975355339-172.17.0.4-1595659519476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34278,DS-1f3dd3bd-484a-4d24-90c9-c36281dca817,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-1c18c8cf-84c3-4332-8ed3-97bc90756419,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-7bd7686c-b6a3-4110-8f0c-40843a21b004,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-427b81fc-ac30-44a4-91a0-a8e554157472,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-15cdac4a-8028-42b6-9f4e-2c49f0237e05,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-d4ae674a-b75c-4ed6-876a-263194ab23e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-1df522c2-1e52-4a98-8543-981e5bdfd57f,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-afc21dd0-9d37-4dd2-b191-03875a604d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278043996-172.17.0.4-1595659929616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-45a79e6d-479a-4720-a82c-ab72f6440160,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-f3173f09-238a-4118-8276-ce0d921bdeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-971d2377-2447-41c3-91ff-0aac4a97a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-5565a9da-0582-496d-99cc-c32ae7262868,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-427f2122-1c1b-4592-b491-845f13235071,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-45bd2564-eeac-48f3-9d14-1c659d194657,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-5c772fba-ed95-42c4-83ad-bff65c2f3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-4b9c7db8-916b-4974-b21c-80fe2946fe36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278043996-172.17.0.4-1595659929616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-45a79e6d-479a-4720-a82c-ab72f6440160,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-f3173f09-238a-4118-8276-ce0d921bdeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-971d2377-2447-41c3-91ff-0aac4a97a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-5565a9da-0582-496d-99cc-c32ae7262868,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-427f2122-1c1b-4592-b491-845f13235071,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-45bd2564-eeac-48f3-9d14-1c659d194657,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-5c772fba-ed95-42c4-83ad-bff65c2f3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-4b9c7db8-916b-4974-b21c-80fe2946fe36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571749047-172.17.0.4-1595660297728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37329,DS-736809f6-bfcc-4dda-9a47-de2cc9162005,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-13d0eb43-78e5-4786-8b7a-3efa5da6d8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-71b2e085-b2e8-4bcb-9c9f-cf3223444dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-04726a77-19d2-4948-a480-ff1cd2fbfa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-8bb6d4b8-f8c3-4b12-ad98-7c6e301eb5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-ef795840-d953-4026-8700-649e9602cf25,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-9ae0c5d3-2913-497f-a002-c732cf2f2c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-0abc4432-7314-48e6-9d7f-b1b2e1a1dcee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571749047-172.17.0.4-1595660297728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37329,DS-736809f6-bfcc-4dda-9a47-de2cc9162005,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-13d0eb43-78e5-4786-8b7a-3efa5da6d8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-71b2e085-b2e8-4bcb-9c9f-cf3223444dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-04726a77-19d2-4948-a480-ff1cd2fbfa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-8bb6d4b8-f8c3-4b12-ad98-7c6e301eb5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-ef795840-d953-4026-8700-649e9602cf25,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-9ae0c5d3-2913-497f-a002-c732cf2f2c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-0abc4432-7314-48e6-9d7f-b1b2e1a1dcee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34278088-172.17.0.4-1595660514784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44288,DS-5fe26363-74d5-48e2-820f-0fe321e63093,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-6c897188-8939-407a-900d-b33a41d0343f,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-4741faa4-21a4-42ef-bbce-188ed55571d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-eaad1d38-9be2-4e7f-8f9d-654079475a00,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-35e39889-2f59-424f-9984-6897a7d773fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-e02bc727-a883-41aa-85b2-07e22e61d0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-c39f9fa7-91c9-4eea-b5f2-72841a56e03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-9da96fed-7465-4820-8253-ec5b278804be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34278088-172.17.0.4-1595660514784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44288,DS-5fe26363-74d5-48e2-820f-0fe321e63093,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-6c897188-8939-407a-900d-b33a41d0343f,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-4741faa4-21a4-42ef-bbce-188ed55571d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-eaad1d38-9be2-4e7f-8f9d-654079475a00,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-35e39889-2f59-424f-9984-6897a7d773fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-e02bc727-a883-41aa-85b2-07e22e61d0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-c39f9fa7-91c9-4eea-b5f2-72841a56e03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-9da96fed-7465-4820-8253-ec5b278804be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27830146-172.17.0.4-1595660615261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-dbd36235-ea40-4202-a2b8-b96269a7455f,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-3e32ffac-f451-4a63-9954-248ef29b2c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-8be0e7ed-3ca2-455b-9144-b70992426687,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-efdd9ffb-ff46-4150-9c70-0efe7ef02cae,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-343678f2-857a-4126-b6c7-96e06bac9745,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-d65a84d8-b9e5-4a80-8c17-9105b62c9bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-1fbfe941-2a64-4ab7-96d5-c028f3a71841,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-5ee0c3d0-1069-49a8-83b3-37e06f193be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27830146-172.17.0.4-1595660615261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-dbd36235-ea40-4202-a2b8-b96269a7455f,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-3e32ffac-f451-4a63-9954-248ef29b2c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-8be0e7ed-3ca2-455b-9144-b70992426687,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-efdd9ffb-ff46-4150-9c70-0efe7ef02cae,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-343678f2-857a-4126-b6c7-96e06bac9745,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-d65a84d8-b9e5-4a80-8c17-9105b62c9bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-1fbfe941-2a64-4ab7-96d5-c028f3a71841,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-5ee0c3d0-1069-49a8-83b3-37e06f193be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320961281-172.17.0.4-1595660797209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40540,DS-54b5ad89-e6b4-4f99-adaf-1ced10a64a49,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-a9d186a9-6a0e-4efd-b2be-f9eb832df4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-c026a47b-fd92-436d-af54-9afb67681690,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-ab0b1c15-2edc-4d21-b1f2-35f5336de878,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-fc02fd83-43bc-4a32-8fdb-6b1a8cba416d,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-362c0e81-b2cb-4051-a3f2-d365fc71bef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-62fe7fe5-f078-4757-8c8f-4022986276be,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-974de0f0-d535-461b-9e32-4626a13def72,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320961281-172.17.0.4-1595660797209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40540,DS-54b5ad89-e6b4-4f99-adaf-1ced10a64a49,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-a9d186a9-6a0e-4efd-b2be-f9eb832df4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-c026a47b-fd92-436d-af54-9afb67681690,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-ab0b1c15-2edc-4d21-b1f2-35f5336de878,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-fc02fd83-43bc-4a32-8fdb-6b1a8cba416d,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-362c0e81-b2cb-4051-a3f2-d365fc71bef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-62fe7fe5-f078-4757-8c8f-4022986276be,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-974de0f0-d535-461b-9e32-4626a13def72,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836026656-172.17.0.4-1595660834765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-d41f98ea-bdd5-41c6-ac0a-fd95279409f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-bbb85a53-1051-4c96-85ad-caad7f249373,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-b0df1e78-fdbc-4493-8cd7-11ab3f2d5a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-216d515d-2e17-4ada-8004-f51218ec1350,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-a9a9ca53-4694-41bd-9dd8-4958765de488,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-d7bcd286-7ddf-4552-8386-8276b46e6dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-082f6226-6ded-4ac2-98e2-1ef3e519f01d,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-3a27202e-2247-4b22-a799-9d1311424e0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836026656-172.17.0.4-1595660834765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-d41f98ea-bdd5-41c6-ac0a-fd95279409f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-bbb85a53-1051-4c96-85ad-caad7f249373,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-b0df1e78-fdbc-4493-8cd7-11ab3f2d5a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-216d515d-2e17-4ada-8004-f51218ec1350,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-a9a9ca53-4694-41bd-9dd8-4958765de488,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-d7bcd286-7ddf-4552-8386-8276b46e6dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-082f6226-6ded-4ac2-98e2-1ef3e519f01d,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-3a27202e-2247-4b22-a799-9d1311424e0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227035728-172.17.0.4-1595661094064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45695,DS-bdc27efe-4ea3-4f73-8d95-0334aa69a445,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-46b0ac59-9b33-4ed5-8e9f-555e8117c921,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-17e87cec-ffc9-40d3-bd5c-fa76daf11420,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-fdf385ae-ce7f-4c20-af90-76f21fbc5723,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-346d9f61-49a6-45dd-9531-892d4831ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-08e5c447-9dd2-40d5-acd0-7613524ffd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-34d6f7c3-40f9-4073-b001-8262d4c7371d,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-638fe9e5-f259-4495-9687-eae95e7679d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227035728-172.17.0.4-1595661094064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45695,DS-bdc27efe-4ea3-4f73-8d95-0334aa69a445,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-46b0ac59-9b33-4ed5-8e9f-555e8117c921,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-17e87cec-ffc9-40d3-bd5c-fa76daf11420,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-fdf385ae-ce7f-4c20-af90-76f21fbc5723,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-346d9f61-49a6-45dd-9531-892d4831ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-08e5c447-9dd2-40d5-acd0-7613524ffd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-34d6f7c3-40f9-4073-b001-8262d4c7371d,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-638fe9e5-f259-4495-9687-eae95e7679d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130523345-172.17.0.4-1595661162334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-e107dd5e-a96a-4b07-bf05-8c6b7e8e7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-ffa014f3-fa57-4215-b112-d5968ffe0a78,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-c9570f31-2653-4f9f-acce-30ea8768f2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-26a34fc0-b441-4e18-a1be-92cefb6c75ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-b1ad16e3-96d7-4171-b33f-b4d49252d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-425c1b56-e489-4951-a73d-79b00f07f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-7914f135-e17a-4342-b054-73240460af25,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-1a92baa7-1859-455a-8b14-4e1497d0d0ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130523345-172.17.0.4-1595661162334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-e107dd5e-a96a-4b07-bf05-8c6b7e8e7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-ffa014f3-fa57-4215-b112-d5968ffe0a78,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-c9570f31-2653-4f9f-acce-30ea8768f2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-26a34fc0-b441-4e18-a1be-92cefb6c75ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-b1ad16e3-96d7-4171-b33f-b4d49252d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-425c1b56-e489-4951-a73d-79b00f07f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-7914f135-e17a-4342-b054-73240460af25,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-1a92baa7-1859-455a-8b14-4e1497d0d0ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107638341-172.17.0.4-1595661199224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-24771f9a-bd10-41c7-8a53-56be0281e00e,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-df991bbe-93f8-4b25-a641-e75431347262,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-cddceca8-ee91-4dfc-8a3b-392ba5b51100,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-36a8e115-ae5d-4b1a-86a3-033a5fb27831,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-b35ae546-2927-44f5-8139-c8f3df99a5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-70a7e69f-4de6-4fb5-a8d0-091978ea3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-375fa4bd-7c5c-4c29-a8f2-4e9b62a4c630,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-f59065be-dc13-4650-9cde-d9e40c8fea68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107638341-172.17.0.4-1595661199224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-24771f9a-bd10-41c7-8a53-56be0281e00e,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-df991bbe-93f8-4b25-a641-e75431347262,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-cddceca8-ee91-4dfc-8a3b-392ba5b51100,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-36a8e115-ae5d-4b1a-86a3-033a5fb27831,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-b35ae546-2927-44f5-8139-c8f3df99a5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-70a7e69f-4de6-4fb5-a8d0-091978ea3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-375fa4bd-7c5c-4c29-a8f2-4e9b62a4c630,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-f59065be-dc13-4650-9cde-d9e40c8fea68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922595317-172.17.0.4-1595661359174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42664,DS-80a8aeaf-88ac-4deb-b219-3f493dff9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-89f790de-d5d3-4bc5-9231-6d7854413b60,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-8a3f8f7e-420e-4ab7-adb1-2c23d506b983,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-1d2db943-7bc9-4437-a031-fe9337150451,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-859972b5-f82c-4091-b067-2f10aff9a818,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-be0d3df9-39ff-44f0-8622-006262add8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-5ad8f382-3bd5-4c52-8f27-a94c625be343,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-1e57def5-c38c-4b66-b39a-004d27a269ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922595317-172.17.0.4-1595661359174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42664,DS-80a8aeaf-88ac-4deb-b219-3f493dff9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-89f790de-d5d3-4bc5-9231-6d7854413b60,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-8a3f8f7e-420e-4ab7-adb1-2c23d506b983,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-1d2db943-7bc9-4437-a031-fe9337150451,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-859972b5-f82c-4091-b067-2f10aff9a818,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-be0d3df9-39ff-44f0-8622-006262add8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-5ad8f382-3bd5-4c52-8f27-a94c625be343,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-1e57def5-c38c-4b66-b39a-004d27a269ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138754721-172.17.0.4-1595661425705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45950,DS-f56a959b-5e9d-49d8-8c4b-c098ccefcd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-1d54c392-d67e-479a-81d0-a45957a097e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-c7d22b80-7f7b-49cb-b542-f00fc923d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-43403529-d2c6-4676-bee9-c3664f533b88,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-74a1c207-5f49-40a4-b0b0-108adc333ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-6ba72701-d497-4b9e-bb00-f5ed5656606a,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-a13e96ad-42d6-4288-aee7-d3be955b64df,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-d6e43747-8b89-4a79-9497-5d660b0ab5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138754721-172.17.0.4-1595661425705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45950,DS-f56a959b-5e9d-49d8-8c4b-c098ccefcd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-1d54c392-d67e-479a-81d0-a45957a097e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-c7d22b80-7f7b-49cb-b542-f00fc923d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-43403529-d2c6-4676-bee9-c3664f533b88,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-74a1c207-5f49-40a4-b0b0-108adc333ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-6ba72701-d497-4b9e-bb00-f5ed5656606a,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-a13e96ad-42d6-4288-aee7-d3be955b64df,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-d6e43747-8b89-4a79-9497-5d660b0ab5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809438364-172.17.0.4-1595661538180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-98675eb6-9641-42cb-ad6b-b253d9da0f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-889ace74-4d62-4dff-a97a-08f798c0918d,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-72e6b357-72dc-4c6a-9aa4-7e04d76c7e87,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-511bc72b-ccc0-4634-91a2-b73ea827f708,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-eee0776f-84ce-4389-958f-8b6cdf32d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-8984ba2c-4b04-475a-b50e-ea035e4fd4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-66bf129e-5f55-4c9f-bbc2-90e470346817,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-12ee0e17-90eb-410d-8d7e-747b45bc8069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809438364-172.17.0.4-1595661538180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-98675eb6-9641-42cb-ad6b-b253d9da0f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-889ace74-4d62-4dff-a97a-08f798c0918d,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-72e6b357-72dc-4c6a-9aa4-7e04d76c7e87,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-511bc72b-ccc0-4634-91a2-b73ea827f708,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-eee0776f-84ce-4389-958f-8b6cdf32d6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-8984ba2c-4b04-475a-b50e-ea035e4fd4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-66bf129e-5f55-4c9f-bbc2-90e470346817,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-12ee0e17-90eb-410d-8d7e-747b45bc8069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819705036-172.17.0.4-1595661609539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35331,DS-9752591c-97a5-443d-89f4-be9113791b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-7580334e-5e21-41d3-a822-c8551bffec8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-7d4ff931-78b6-4e40-9684-c00dc17f58d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-df1682db-c135-4683-9123-458fb21c0d55,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-e92aff3f-8d20-4f94-9665-187a9cf7e600,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-1ff1770f-f43f-4345-b896-4ade7d2273ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-312e77fc-c47e-43d0-9e53-aad8a650785d,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-58adbc95-ba22-4f66-a1f0-c380b1bf30db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819705036-172.17.0.4-1595661609539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35331,DS-9752591c-97a5-443d-89f4-be9113791b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-7580334e-5e21-41d3-a822-c8551bffec8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-7d4ff931-78b6-4e40-9684-c00dc17f58d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-df1682db-c135-4683-9123-458fb21c0d55,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-e92aff3f-8d20-4f94-9665-187a9cf7e600,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-1ff1770f-f43f-4345-b896-4ade7d2273ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-312e77fc-c47e-43d0-9e53-aad8a650785d,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-58adbc95-ba22-4f66-a1f0-c380b1bf30db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559369203-172.17.0.4-1595662058238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-402cdba6-1287-48c4-a2ac-a2bed56a0093,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-9bba69f4-83a0-4415-bbf2-93927001df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-b46c6115-9ff6-4b72-8b52-5e3804de7705,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-b7bccdb1-1640-417c-8c42-0e502a9cacb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-6348bc8e-90d8-4874-88cd-ed2013aafab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-a1a7788e-1a22-48a5-b650-d175784ffede,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-4727e406-309d-4287-b410-bf38e4497f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-828d4c98-62bf-4543-b760-eb46347b4437,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559369203-172.17.0.4-1595662058238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-402cdba6-1287-48c4-a2ac-a2bed56a0093,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-9bba69f4-83a0-4415-bbf2-93927001df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-b46c6115-9ff6-4b72-8b52-5e3804de7705,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-b7bccdb1-1640-417c-8c42-0e502a9cacb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-6348bc8e-90d8-4874-88cd-ed2013aafab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-a1a7788e-1a22-48a5-b650-d175784ffede,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-4727e406-309d-4287-b410-bf38e4497f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-828d4c98-62bf-4543-b760-eb46347b4437,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414341620-172.17.0.4-1595662229737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-6617b847-20ec-4bef-965a-70c5ae856dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-d3e4a937-115c-4692-864b-c6fc3b8ae397,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-e2b00c69-6554-4f3c-b01a-a0b431a167cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-c51a23cb-459d-4e69-a8bf-c7ecb88235fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-89c90b99-2ab4-4cf9-a33f-0997614c14b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-ebf47b60-81f5-42b6-ad23-1a8d2066c3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-235c2cf2-35a5-46c7-b67f-11e36e6c667a,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-5e7ea695-0268-437f-b2aa-82edbe211bee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414341620-172.17.0.4-1595662229737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-6617b847-20ec-4bef-965a-70c5ae856dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-d3e4a937-115c-4692-864b-c6fc3b8ae397,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-e2b00c69-6554-4f3c-b01a-a0b431a167cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-c51a23cb-459d-4e69-a8bf-c7ecb88235fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-89c90b99-2ab4-4cf9-a33f-0997614c14b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-ebf47b60-81f5-42b6-ad23-1a8d2066c3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-235c2cf2-35a5-46c7-b67f-11e36e6c667a,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-5e7ea695-0268-437f-b2aa-82edbe211bee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704693399-172.17.0.4-1595662497553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36069,DS-5b5220c8-87d3-4d9a-a121-136bee15534c,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-caa09cf8-e264-484f-86d1-ebe19f8563d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-530b89e3-3271-4186-9d12-2058508b6af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-96498f51-0523-40f1-b523-c5b5dc23d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-a647d566-a275-4ec6-a3bf-879c4df86d17,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-8a9334ed-30ec-46d2-9516-7c4e9185834e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-583a7342-073a-452e-84da-33fef986ffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-3c4e96cd-cb6c-481d-a449-e6fc61954e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704693399-172.17.0.4-1595662497553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36069,DS-5b5220c8-87d3-4d9a-a121-136bee15534c,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-caa09cf8-e264-484f-86d1-ebe19f8563d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-530b89e3-3271-4186-9d12-2058508b6af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-96498f51-0523-40f1-b523-c5b5dc23d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-a647d566-a275-4ec6-a3bf-879c4df86d17,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-8a9334ed-30ec-46d2-9516-7c4e9185834e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-583a7342-073a-452e-84da-33fef986ffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-3c4e96cd-cb6c-481d-a449-e6fc61954e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160720310-172.17.0.4-1595662600854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-1f2a4083-7fd1-455e-97ef-d771c99af7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-bcd2deb8-9a4a-467c-a31f-5a0f6a223d03,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-34f64750-152a-4a82-97ea-08c0f9e49906,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-8010e38c-3e79-44f3-930a-be39cc079c43,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-9c955ea1-3ccf-4ca2-8884-657d546323c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-08e32a07-bba0-45cd-a9e7-a6790f138a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-326688f4-07ba-40d1-ac58-f4e7eac0578d,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-f472792f-0403-40a5-b7bc-778586f316df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160720310-172.17.0.4-1595662600854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-1f2a4083-7fd1-455e-97ef-d771c99af7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-bcd2deb8-9a4a-467c-a31f-5a0f6a223d03,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-34f64750-152a-4a82-97ea-08c0f9e49906,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-8010e38c-3e79-44f3-930a-be39cc079c43,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-9c955ea1-3ccf-4ca2-8884-657d546323c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-08e32a07-bba0-45cd-a9e7-a6790f138a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-326688f4-07ba-40d1-ac58-f4e7eac0578d,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-f472792f-0403-40a5-b7bc-778586f316df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057865504-172.17.0.4-1595662636251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-bcaa1cc9-4736-412f-ac49-07aa41bf3439,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-9837aaca-1845-46ef-9c3f-cb9bf09b3919,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-7656a9b3-cbe2-4c06-b37a-3c7f2241b9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-3233480e-442a-4af0-871c-5257533262a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-1ab1febc-1723-4100-85b5-4ba72dc7a2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-8f58a345-8689-4824-ac1a-5e2eae95e660,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-2c9b05ca-1184-4a56-9d55-06e8bfa988ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-d77b2ad5-70f9-4625-824c-ce7a30c6a745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057865504-172.17.0.4-1595662636251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-bcaa1cc9-4736-412f-ac49-07aa41bf3439,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-9837aaca-1845-46ef-9c3f-cb9bf09b3919,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-7656a9b3-cbe2-4c06-b37a-3c7f2241b9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-3233480e-442a-4af0-871c-5257533262a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-1ab1febc-1723-4100-85b5-4ba72dc7a2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-8f58a345-8689-4824-ac1a-5e2eae95e660,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-2c9b05ca-1184-4a56-9d55-06e8bfa988ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-d77b2ad5-70f9-4625-824c-ce7a30c6a745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108325267-172.17.0.4-1595662807780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33338,DS-21c5a117-b0d3-492b-a9b2-c87f27873837,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-da646150-bc16-4067-b1cc-eee34ace2120,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-3ab14df1-9646-4dca-904d-5814b3fa874d,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-b7f18dd7-cec5-4500-9c83-4b6e2d80f0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-559be411-b4c3-4144-a2ec-41aaf2f1bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-51293745-1bb5-4844-8618-e019dee67b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-4ceacded-9da4-4829-bb69-5e7f5731c242,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-6606ecb1-848d-426d-bc8c-be42b1fe5ca3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108325267-172.17.0.4-1595662807780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33338,DS-21c5a117-b0d3-492b-a9b2-c87f27873837,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-da646150-bc16-4067-b1cc-eee34ace2120,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-3ab14df1-9646-4dca-904d-5814b3fa874d,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-b7f18dd7-cec5-4500-9c83-4b6e2d80f0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-559be411-b4c3-4144-a2ec-41aaf2f1bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-51293745-1bb5-4844-8618-e019dee67b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-4ceacded-9da4-4829-bb69-5e7f5731c242,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-6606ecb1-848d-426d-bc8c-be42b1fe5ca3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225375450-172.17.0.4-1595662838495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45997,DS-c22c88ac-0266-48c7-8089-76765431543b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-7fa4e355-6597-4b10-a20d-e0c070811e64,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-263d5aba-3bdd-4b56-a93a-ca4984f0efc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-26f56122-4664-455d-8de3-eae77423b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-a73e13bc-0177-4d22-a144-0c36f00c9190,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-169a9169-6d5d-4b18-a718-5f849d9416cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-7dd8f959-0b2e-4991-af16-1dd87c7a3500,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-b61b8f6f-5095-49a5-ad2d-02732c661577,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225375450-172.17.0.4-1595662838495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45997,DS-c22c88ac-0266-48c7-8089-76765431543b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-7fa4e355-6597-4b10-a20d-e0c070811e64,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-263d5aba-3bdd-4b56-a93a-ca4984f0efc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-26f56122-4664-455d-8de3-eae77423b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-a73e13bc-0177-4d22-a144-0c36f00c9190,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-169a9169-6d5d-4b18-a718-5f849d9416cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-7dd8f959-0b2e-4991-af16-1dd87c7a3500,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-b61b8f6f-5095-49a5-ad2d-02732c661577,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078329708-172.17.0.4-1595663001760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-3dc97640-1cd2-4c90-85ed-d01c52f01afe,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-ba4be33a-ecd0-4035-8245-50a30dfc4669,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-c212d0a2-5439-4eda-bec9-c6a151e19357,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-f5ef45ef-39e6-4663-b55a-25abc3b4c334,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-8adb911f-1a5c-437a-92ad-732f41b5541b,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-9572a0e9-0f95-4f82-b190-1223ad7b5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-d749cb47-abca-44b1-a4e9-e314042abd96,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-d12bae56-72c1-4322-9f22-2d142ebc7637,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078329708-172.17.0.4-1595663001760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-3dc97640-1cd2-4c90-85ed-d01c52f01afe,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-ba4be33a-ecd0-4035-8245-50a30dfc4669,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-c212d0a2-5439-4eda-bec9-c6a151e19357,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-f5ef45ef-39e6-4663-b55a-25abc3b4c334,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-8adb911f-1a5c-437a-92ad-732f41b5541b,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-9572a0e9-0f95-4f82-b190-1223ad7b5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-d749cb47-abca-44b1-a4e9-e314042abd96,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-d12bae56-72c1-4322-9f22-2d142ebc7637,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960293333-172.17.0.4-1595663245564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43385,DS-22a66155-a850-4d22-863e-1971d815268c,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-c76577ae-e0b0-4557-854b-6e5d8e717904,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-9bf436e6-d5fa-4429-9dcd-55a926bcfa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-b2fa87ff-e54a-4a97-be9e-a67abb5fed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-76a32877-bcd8-4762-b965-022a2adc1a11,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-5f9294d7-ec85-4bc9-ac95-8174eb6a4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-9765e9c6-fc99-4697-8ac3-44bd2288272d,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-e7f943d0-eea9-41cc-b297-329e82438301,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960293333-172.17.0.4-1595663245564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43385,DS-22a66155-a850-4d22-863e-1971d815268c,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-c76577ae-e0b0-4557-854b-6e5d8e717904,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-9bf436e6-d5fa-4429-9dcd-55a926bcfa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-b2fa87ff-e54a-4a97-be9e-a67abb5fed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-76a32877-bcd8-4762-b965-022a2adc1a11,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-5f9294d7-ec85-4bc9-ac95-8174eb6a4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-9765e9c6-fc99-4697-8ac3-44bd2288272d,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-e7f943d0-eea9-41cc-b297-329e82438301,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568348458-172.17.0.4-1595663317188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-701dd98c-db87-43b3-abdb-3ddb5ec28341,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-6cde607a-b8df-4a47-b6e7-8d14db0c22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-513e99f0-56e0-4f5d-b338-ce15301f7459,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-eacc20f6-3c5a-4ca3-8dc0-7c71f40a65dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-d8b28a84-798e-4bbd-a775-ce24c5b0e685,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-559eb7fd-c90d-455c-a62e-dfa7cd04dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-ae07fdbf-84a4-4666-b4ab-88c0ebf22d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-6ee76a94-92cc-4c01-973e-29bcf1a65164,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568348458-172.17.0.4-1595663317188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-701dd98c-db87-43b3-abdb-3ddb5ec28341,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-6cde607a-b8df-4a47-b6e7-8d14db0c22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-513e99f0-56e0-4f5d-b338-ce15301f7459,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-eacc20f6-3c5a-4ca3-8dc0-7c71f40a65dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-d8b28a84-798e-4bbd-a775-ce24c5b0e685,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-559eb7fd-c90d-455c-a62e-dfa7cd04dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-ae07fdbf-84a4-4666-b4ab-88c0ebf22d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-6ee76a94-92cc-4c01-973e-29bcf1a65164,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895502968-172.17.0.4-1595663461425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33255,DS-d865d6aa-2354-44e5-9131-7b0f541a0cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-1c20003c-c382-4323-a638-1bad23e80ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-0eb51aba-7bd0-4e1c-b78f-5a67da9d692f,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-db24ef57-6404-4e0f-ac4b-f75f9eed76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-b172b9e5-7474-44fb-aa94-b70aa8e306e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-17732a3c-6357-4b4f-8a99-f8222e6d713f,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-be4ec5b7-8694-4746-b717-4eabe8108ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-1f7095f9-e7b9-480b-8c45-353b7af48406,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895502968-172.17.0.4-1595663461425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33255,DS-d865d6aa-2354-44e5-9131-7b0f541a0cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-1c20003c-c382-4323-a638-1bad23e80ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-0eb51aba-7bd0-4e1c-b78f-5a67da9d692f,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-db24ef57-6404-4e0f-ac4b-f75f9eed76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-b172b9e5-7474-44fb-aa94-b70aa8e306e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-17732a3c-6357-4b4f-8a99-f8222e6d713f,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-be4ec5b7-8694-4746-b717-4eabe8108ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-1f7095f9-e7b9-480b-8c45-353b7af48406,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101278202-172.17.0.4-1595663680835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-327afaea-75cd-4189-96b2-0f8091303f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-373bfb68-19b4-4056-a274-55f06ba5e64c,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-d4b86482-cf27-4827-b87e-7d778ba7da96,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-0d56795b-7a05-4a54-81e5-76611a4fb8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-708cb694-a924-41aa-b01c-857db9b9a737,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-036776be-da03-4336-a129-8b7651639aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-ca4f98c8-f5c1-4bce-8039-b1412d614e32,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-7a9550ec-8116-48dd-8e0d-d087fda85009,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101278202-172.17.0.4-1595663680835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-327afaea-75cd-4189-96b2-0f8091303f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-373bfb68-19b4-4056-a274-55f06ba5e64c,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-d4b86482-cf27-4827-b87e-7d778ba7da96,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-0d56795b-7a05-4a54-81e5-76611a4fb8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-708cb694-a924-41aa-b01c-857db9b9a737,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-036776be-da03-4336-a129-8b7651639aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-ca4f98c8-f5c1-4bce-8039-b1412d614e32,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-7a9550ec-8116-48dd-8e0d-d087fda85009,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915250499-172.17.0.4-1595663748130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33602,DS-e7afcecf-ef05-40f7-bb3d-f4173731f285,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-8f675eec-d71e-4a2e-b847-636d3110cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-76f1e4ca-45fe-4aaf-848b-c5bffff89862,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-93198d6d-a9e4-473a-a5a1-83df19484cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-acffd24b-7368-4e79-83c5-40eff971ea70,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-d7ac15e4-3e2d-45b0-8894-42f572ab04fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-434b404b-7bdc-4b5a-a542-b53a094c5ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-05a2fb68-9cf4-48f3-94ff-6342022b7427,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915250499-172.17.0.4-1595663748130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33602,DS-e7afcecf-ef05-40f7-bb3d-f4173731f285,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-8f675eec-d71e-4a2e-b847-636d3110cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-76f1e4ca-45fe-4aaf-848b-c5bffff89862,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-93198d6d-a9e4-473a-a5a1-83df19484cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-acffd24b-7368-4e79-83c5-40eff971ea70,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-d7ac15e4-3e2d-45b0-8894-42f572ab04fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-434b404b-7bdc-4b5a-a542-b53a094c5ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-05a2fb68-9cf4-48f3-94ff-6342022b7427,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833279523-172.17.0.4-1595663819877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39682,DS-013a18e7-cae2-4777-8692-63a7464ee68b,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-4c5c349a-4a79-492b-a38a-ccdb3dcc5b92,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-00f5b3dc-38bf-4129-bcd2-dc3a068a0561,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-27e63051-6ea4-47c8-81ad-8f6682c9d922,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-aa144f67-e25d-42f1-a267-9f812c10976b,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-b925f7d6-1ebf-4448-94c9-08581320bdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-ee11e128-c045-4919-8113-1b763476753e,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-11b0c30e-61e5-4250-b8f4-666f1aeb181c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833279523-172.17.0.4-1595663819877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39682,DS-013a18e7-cae2-4777-8692-63a7464ee68b,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-4c5c349a-4a79-492b-a38a-ccdb3dcc5b92,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-00f5b3dc-38bf-4129-bcd2-dc3a068a0561,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-27e63051-6ea4-47c8-81ad-8f6682c9d922,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-aa144f67-e25d-42f1-a267-9f812c10976b,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-b925f7d6-1ebf-4448-94c9-08581320bdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-ee11e128-c045-4919-8113-1b763476753e,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-11b0c30e-61e5-4250-b8f4-666f1aeb181c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 400
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889290967-172.17.0.4-1595663885192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36052,DS-65e24798-a49d-467f-8846-c437bb7832ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-858f3453-68b9-42a7-bc15-f744eb932734,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-6aae9187-2843-4920-aec8-a2420f2a1e53,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-ad96f0fd-1e2e-45f1-a691-de1878b54f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-271a6c46-ba48-48dd-8752-76b7add815c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-a988a488-99f9-42fd-bd3d-fe0f7ebe069b,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-cf1ebc06-1501-4a28-b9e1-bc48a2ad5470,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-be1b68b7-325e-4c83-a984-4b6eae921d7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889290967-172.17.0.4-1595663885192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36052,DS-65e24798-a49d-467f-8846-c437bb7832ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-858f3453-68b9-42a7-bc15-f744eb932734,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-6aae9187-2843-4920-aec8-a2420f2a1e53,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-ad96f0fd-1e2e-45f1-a691-de1878b54f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-271a6c46-ba48-48dd-8752-76b7add815c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-a988a488-99f9-42fd-bd3d-fe0f7ebe069b,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-cf1ebc06-1501-4a28-b9e1-bc48a2ad5470,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-be1b68b7-325e-4c83-a984-4b6eae921d7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5368
