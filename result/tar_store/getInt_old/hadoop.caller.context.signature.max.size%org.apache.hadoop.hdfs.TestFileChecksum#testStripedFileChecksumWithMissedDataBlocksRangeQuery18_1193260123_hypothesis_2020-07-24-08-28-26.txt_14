reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004509350-172.17.0.12-1595579369955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-497b0747-0c20-4503-889b-ee9f1879e914,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-44f4e33e-9248-4f67-9899-af6bd024cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-7d983700-a063-4723-824a-87768c07cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-1007b0b0-81ae-4bcc-bb55-71aa2f145320,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-e2577a15-b7f7-4ae3-a93a-85b98f3ba462,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-cb6ce4df-b3e6-4cb0-bad4-d46c830b6bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-c247ac9e-4cea-4049-8050-b3a528450b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-d7b444e1-1381-4ec7-949d-587c68effdfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004509350-172.17.0.12-1595579369955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-497b0747-0c20-4503-889b-ee9f1879e914,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-44f4e33e-9248-4f67-9899-af6bd024cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-7d983700-a063-4723-824a-87768c07cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-1007b0b0-81ae-4bcc-bb55-71aa2f145320,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-e2577a15-b7f7-4ae3-a93a-85b98f3ba462,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-cb6ce4df-b3e6-4cb0-bad4-d46c830b6bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-c247ac9e-4cea-4049-8050-b3a528450b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-d7b444e1-1381-4ec7-949d-587c68effdfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881243449-172.17.0.12-1595579832850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-89e8af51-c5c0-4807-bed0-de46cfcd146a,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-9e4cdf6a-48f0-41db-90cc-4f04070c6599,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-6bac677a-71f7-4531-ab91-7538ed5dba68,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-12d01e1d-c6cd-4098-b3e1-de1c8c257a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-5ba1136c-9f8e-422e-801f-fad759b346df,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-5f972f6f-5548-4229-b433-5770a9110c96,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-af6ee15a-36fb-41ad-93ab-6ed60aacfd53,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-4e9d9b5b-a0d8-4fa2-8f42-bf3a9b4c1b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881243449-172.17.0.12-1595579832850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-89e8af51-c5c0-4807-bed0-de46cfcd146a,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-9e4cdf6a-48f0-41db-90cc-4f04070c6599,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-6bac677a-71f7-4531-ab91-7538ed5dba68,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-12d01e1d-c6cd-4098-b3e1-de1c8c257a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-5ba1136c-9f8e-422e-801f-fad759b346df,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-5f972f6f-5548-4229-b433-5770a9110c96,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-af6ee15a-36fb-41ad-93ab-6ed60aacfd53,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-4e9d9b5b-a0d8-4fa2-8f42-bf3a9b4c1b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260771808-172.17.0.12-1595579867942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42102,DS-55380b7a-d5da-4265-9abd-e7369c383c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-30130b49-01dd-4801-9738-37c9f29b31ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-b1692dac-0a85-4b8d-9c31-0162b190c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-64645a4f-4cbe-403d-a888-00529b63d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-26ace713-a824-4360-b4bb-ae6970bbfbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-f41eac8a-316f-494a-8cd3-8f856ebaffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-28c30055-d081-447a-987b-1bf24adef610,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-56ddc667-6369-4ddf-8e1b-4d0e096bd6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260771808-172.17.0.12-1595579867942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42102,DS-55380b7a-d5da-4265-9abd-e7369c383c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-30130b49-01dd-4801-9738-37c9f29b31ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-b1692dac-0a85-4b8d-9c31-0162b190c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-64645a4f-4cbe-403d-a888-00529b63d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-26ace713-a824-4360-b4bb-ae6970bbfbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-f41eac8a-316f-494a-8cd3-8f856ebaffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-28c30055-d081-447a-987b-1bf24adef610,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-56ddc667-6369-4ddf-8e1b-4d0e096bd6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495900529-172.17.0.12-1595580379952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-8ec0dd11-9cf5-4a24-8934-6331a4f168ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-7826c784-163b-42aa-a016-5ea0d54f418b,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-47371981-b82e-452d-b297-6901a351911e,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-167d8d49-e29d-4b5f-b6fb-4f5d3c2218f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-337814d4-7783-4e8a-ae10-f9aff1d82f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-2aab58d6-3b2a-407a-ad13-bbfbc22a0e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-2ccf3571-adfd-444c-a46b-8795d3172d53,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-187811be-2175-490f-8e7a-8c15ddacc8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495900529-172.17.0.12-1595580379952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-8ec0dd11-9cf5-4a24-8934-6331a4f168ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-7826c784-163b-42aa-a016-5ea0d54f418b,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-47371981-b82e-452d-b297-6901a351911e,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-167d8d49-e29d-4b5f-b6fb-4f5d3c2218f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-337814d4-7783-4e8a-ae10-f9aff1d82f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-2aab58d6-3b2a-407a-ad13-bbfbc22a0e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-2ccf3571-adfd-444c-a46b-8795d3172d53,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-187811be-2175-490f-8e7a-8c15ddacc8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189735340-172.17.0.12-1595580556650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-38b18d14-bfc6-4ce7-be3b-b97ac310137b,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-98641cdb-46f4-48b4-a790-2607bf139527,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-702ac87c-a762-4be9-87b0-0c568e85995e,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-1eb503b4-955e-4fdc-984d-bb494e5e8202,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-0225eed5-cbf7-4efc-883e-c7c576dfed02,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-9518578e-2d05-4336-8404-dff816fde94a,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-9d3bdf24-bef4-4493-bd89-03ff70f9b0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-880e900e-fbfd-4814-be8d-eb5f28ab0a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189735340-172.17.0.12-1595580556650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-38b18d14-bfc6-4ce7-be3b-b97ac310137b,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-98641cdb-46f4-48b4-a790-2607bf139527,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-702ac87c-a762-4be9-87b0-0c568e85995e,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-1eb503b4-955e-4fdc-984d-bb494e5e8202,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-0225eed5-cbf7-4efc-883e-c7c576dfed02,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-9518578e-2d05-4336-8404-dff816fde94a,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-9d3bdf24-bef4-4493-bd89-03ff70f9b0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-880e900e-fbfd-4814-be8d-eb5f28ab0a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018158013-172.17.0.12-1595580593353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-d19bc191-e5a1-45af-8be4-0d4b7b80be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-2a69542a-f264-402e-9de8-12aa6ca1e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-900177ff-8bf5-4946-b673-988404127832,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-8ba500bc-c926-4fc2-ba7f-349d699b97c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-60de3a37-027e-4c44-a701-271e255e1391,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-b34671e0-3390-48d6-b86c-a694897ede1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-e128fb10-d09c-44ca-aa0f-5789b9c05f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-98604f0b-6851-42ef-b816-c92f30713863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018158013-172.17.0.12-1595580593353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-d19bc191-e5a1-45af-8be4-0d4b7b80be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-2a69542a-f264-402e-9de8-12aa6ca1e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-900177ff-8bf5-4946-b673-988404127832,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-8ba500bc-c926-4fc2-ba7f-349d699b97c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-60de3a37-027e-4c44-a701-271e255e1391,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-b34671e0-3390-48d6-b86c-a694897ede1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-e128fb10-d09c-44ca-aa0f-5789b9c05f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-98604f0b-6851-42ef-b816-c92f30713863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229184694-172.17.0.12-1595580818263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-6acbdad8-ac64-4148-b98c-d197e0470915,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-3c0a3460-1034-4572-b034-a9528bbb4e71,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-553e21de-1b45-4018-bb62-9d55b2816ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-74b21b85-b588-49c6-aa98-a8a7e057caae,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-dbd48580-5661-43eb-a360-9e3dd1488e69,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-ce25c87d-5bb6-4213-9104-882f6e00c778,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-1b10ffc3-b3d8-45eb-93c5-ddb55c83e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-5b46c823-ce8c-4a44-af5c-d07c31387583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1229184694-172.17.0.12-1595580818263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-6acbdad8-ac64-4148-b98c-d197e0470915,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-3c0a3460-1034-4572-b034-a9528bbb4e71,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-553e21de-1b45-4018-bb62-9d55b2816ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-74b21b85-b588-49c6-aa98-a8a7e057caae,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-dbd48580-5661-43eb-a360-9e3dd1488e69,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-ce25c87d-5bb6-4213-9104-882f6e00c778,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-1b10ffc3-b3d8-45eb-93c5-ddb55c83e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-5b46c823-ce8c-4a44-af5c-d07c31387583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700553448-172.17.0.12-1595581075698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45026,DS-52b8813c-f80f-4b89-87dc-ddd0c168396a,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-1d3513c0-7cba-48eb-90e0-8a44535759d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-2340f4fe-6ad1-4d0f-9e8a-6901a517bd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-ff824cc9-02ef-4f51-84b3-a134c948df00,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-1d7b15a6-1464-4ee3-9083-261dc0c3b8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-0294876b-290d-4ea6-9f87-fc7dfdd474f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-e107a6df-c7eb-4606-a491-0a4183a4393b,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-cce3a64a-17ac-490b-995c-da3870570271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700553448-172.17.0.12-1595581075698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45026,DS-52b8813c-f80f-4b89-87dc-ddd0c168396a,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-1d3513c0-7cba-48eb-90e0-8a44535759d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-2340f4fe-6ad1-4d0f-9e8a-6901a517bd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-ff824cc9-02ef-4f51-84b3-a134c948df00,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-1d7b15a6-1464-4ee3-9083-261dc0c3b8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-0294876b-290d-4ea6-9f87-fc7dfdd474f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-e107a6df-c7eb-4606-a491-0a4183a4393b,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-cce3a64a-17ac-490b-995c-da3870570271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449254797-172.17.0.12-1595581577929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35373,DS-41186f69-f921-42cf-9d35-168be9cfc335,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-b043c28b-b9bd-486b-a69a-80fbdea1349b,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-1d085aa9-ffee-4407-a6fa-d989d14999fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-50d5860b-08d2-4d8a-9213-bf170b057efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-2b311190-d1ae-428a-9d35-07993a65d02e,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-92931d61-bcfd-4458-90ae-38ab11a309ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-96398ac8-8f27-466e-90b8-49b11ee40dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-b2b1294c-d79a-40b5-8c52-30e91fc6d8ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449254797-172.17.0.12-1595581577929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35373,DS-41186f69-f921-42cf-9d35-168be9cfc335,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-b043c28b-b9bd-486b-a69a-80fbdea1349b,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-1d085aa9-ffee-4407-a6fa-d989d14999fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-50d5860b-08d2-4d8a-9213-bf170b057efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-2b311190-d1ae-428a-9d35-07993a65d02e,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-92931d61-bcfd-4458-90ae-38ab11a309ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-96398ac8-8f27-466e-90b8-49b11ee40dad,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-b2b1294c-d79a-40b5-8c52-30e91fc6d8ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535723095-172.17.0.12-1595581970901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35866,DS-3969c5ef-7f37-4e11-99a1-50dbfe40f837,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-b3233b24-7e85-4fb3-85d5-a65ffc20cd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-988d6872-3c10-44a9-95d6-082a7394cd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-dfe6bbe5-29e9-4fee-b2ac-a9126d63d330,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-09fe73bf-1755-4ade-80d6-a9959d797db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-7c715405-b3c2-4390-b394-7f181737bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-03832a9f-3b82-40ab-8831-59c97fe44693,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-7f4a38c6-1dec-4c3d-b46a-4fae26a05a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535723095-172.17.0.12-1595581970901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35866,DS-3969c5ef-7f37-4e11-99a1-50dbfe40f837,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-b3233b24-7e85-4fb3-85d5-a65ffc20cd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-988d6872-3c10-44a9-95d6-082a7394cd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-dfe6bbe5-29e9-4fee-b2ac-a9126d63d330,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-09fe73bf-1755-4ade-80d6-a9959d797db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-7c715405-b3c2-4390-b394-7f181737bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-03832a9f-3b82-40ab-8831-59c97fe44693,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-7f4a38c6-1dec-4c3d-b46a-4fae26a05a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1062478882-172.17.0.12-1595582012795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39849,DS-2e289d91-c7b0-4f02-9c9e-ec659fa95aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-174ae8c3-33ff-4625-aab5-89c077cd7381,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-0145605a-24c4-4f1d-8316-7c5b5e08ce26,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-a27a65ab-94f6-46ef-9df6-6605f9ffde3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-fdf5ee1f-8523-4a2e-8840-2e7a4214156d,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-3aadff36-ba16-4feb-b4cf-6cdd408b1110,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-39380b99-82e2-4cd6-a707-d56e229eb4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-59327939-0b02-4a80-b737-6371ac53f23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1062478882-172.17.0.12-1595582012795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39849,DS-2e289d91-c7b0-4f02-9c9e-ec659fa95aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-174ae8c3-33ff-4625-aab5-89c077cd7381,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-0145605a-24c4-4f1d-8316-7c5b5e08ce26,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-a27a65ab-94f6-46ef-9df6-6605f9ffde3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-fdf5ee1f-8523-4a2e-8840-2e7a4214156d,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-3aadff36-ba16-4feb-b4cf-6cdd408b1110,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-39380b99-82e2-4cd6-a707-d56e229eb4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-59327939-0b02-4a80-b737-6371ac53f23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603048059-172.17.0.12-1595582277141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-da2c170e-de4d-4218-9219-668789abfe37,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-02d87633-4d48-4038-8059-9e315b29d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-d59fc9c4-1094-4b79-ab72-db0918056d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-ccf9a64d-0411-41ce-a878-1b8f4a4aefc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-ebb3ec2d-35f9-4056-852d-027b04eca47d,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-765a4916-9bce-450f-a751-1212e2bb7fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-8791e808-6891-4cc3-8d8c-2170f38ace6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-f3c67643-8a58-4001-9670-df1970e54253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603048059-172.17.0.12-1595582277141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-da2c170e-de4d-4218-9219-668789abfe37,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-02d87633-4d48-4038-8059-9e315b29d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-d59fc9c4-1094-4b79-ab72-db0918056d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-ccf9a64d-0411-41ce-a878-1b8f4a4aefc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-ebb3ec2d-35f9-4056-852d-027b04eca47d,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-765a4916-9bce-450f-a751-1212e2bb7fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-8791e808-6891-4cc3-8d8c-2170f38ace6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-f3c67643-8a58-4001-9670-df1970e54253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241085053-172.17.0.12-1595582455594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-4541910b-c708-4d67-b066-b46557f6742e,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-dcc5156c-1acd-4d1a-9e4d-4f5025ce19d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-a731ef8a-3c5d-40fd-98f7-46ef6eb41c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-de943e31-5bb8-4541-b0b4-20b33cdf03e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-ae0516e6-50f0-4a7c-afbc-2a44d9b01166,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-d3a576b5-2479-4b14-a3f1-aba5874358f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-d32b5819-db4e-449c-b12d-306cb4f091cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-1ef20acb-434a-418f-b7e6-ca2c58062e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241085053-172.17.0.12-1595582455594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-4541910b-c708-4d67-b066-b46557f6742e,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-dcc5156c-1acd-4d1a-9e4d-4f5025ce19d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-a731ef8a-3c5d-40fd-98f7-46ef6eb41c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-de943e31-5bb8-4541-b0b4-20b33cdf03e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-ae0516e6-50f0-4a7c-afbc-2a44d9b01166,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-d3a576b5-2479-4b14-a3f1-aba5874358f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-d32b5819-db4e-449c-b12d-306cb4f091cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-1ef20acb-434a-418f-b7e6-ca2c58062e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307338006-172.17.0.12-1595582584145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45984,DS-fcae03fd-988d-420f-a068-ad8c23c8a908,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-31a593f5-063d-4545-a418-e4765b9b05a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-34e64362-465d-4ec4-9f12-2dcdbe466b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-d2cb428e-7619-480f-aa54-aa68721ec165,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-925c0021-c23d-4a85-986f-77eb00887e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-38ba9818-640e-41a8-825f-8d8fe9e624cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-9ee44188-a4c2-45b5-ac45-68da79dd815c,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-fabeeac5-92da-4eb6-9bea-631643712bd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307338006-172.17.0.12-1595582584145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45984,DS-fcae03fd-988d-420f-a068-ad8c23c8a908,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-31a593f5-063d-4545-a418-e4765b9b05a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-34e64362-465d-4ec4-9f12-2dcdbe466b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-d2cb428e-7619-480f-aa54-aa68721ec165,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-925c0021-c23d-4a85-986f-77eb00887e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-38ba9818-640e-41a8-825f-8d8fe9e624cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-9ee44188-a4c2-45b5-ac45-68da79dd815c,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-fabeeac5-92da-4eb6-9bea-631643712bd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871133023-172.17.0.12-1595582893073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45146,DS-b43a4de3-ea62-467e-871d-32f4b36cca84,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-fc86f694-3565-479d-8a63-e971753348bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-acf796ba-1a3d-4f5a-9fce-cdb9738666e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-862fa774-c17e-4870-a6bf-9978e483b06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-ad3dbaa8-ff92-42f1-ac08-3950c4d2bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-5c9e4af2-6975-46d2-a256-38b4e6c257fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-237fb416-af7d-4860-b979-72e8a0745cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-5200bfba-84ec-4130-9260-7fba4fc774ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871133023-172.17.0.12-1595582893073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45146,DS-b43a4de3-ea62-467e-871d-32f4b36cca84,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-fc86f694-3565-479d-8a63-e971753348bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-acf796ba-1a3d-4f5a-9fce-cdb9738666e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-862fa774-c17e-4870-a6bf-9978e483b06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-ad3dbaa8-ff92-42f1-ac08-3950c4d2bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-5c9e4af2-6975-46d2-a256-38b4e6c257fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-237fb416-af7d-4860-b979-72e8a0745cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-5200bfba-84ec-4130-9260-7fba4fc774ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327836285-172.17.0.12-1595583365457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-2a0942b0-2b56-4ca8-9637-1352a74d49aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-97e37296-786a-47a6-9768-c42eba2f3c49,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-e69f1f05-cda9-4aa5-8a99-e9e51b649e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-72aea7e3-ce0c-40ce-94e6-c06eaf2f62af,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-18a3cdc9-b6f0-4476-8c9c-2f020895cd89,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-45c4dee7-5691-4d08-817b-0944d77a2906,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-4c14ad10-dc99-4111-a70c-95eef8b3350f,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-7c658069-b2d2-42c8-b559-bfd686fc2e91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327836285-172.17.0.12-1595583365457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-2a0942b0-2b56-4ca8-9637-1352a74d49aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-97e37296-786a-47a6-9768-c42eba2f3c49,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-e69f1f05-cda9-4aa5-8a99-e9e51b649e90,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-72aea7e3-ce0c-40ce-94e6-c06eaf2f62af,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-18a3cdc9-b6f0-4476-8c9c-2f020895cd89,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-45c4dee7-5691-4d08-817b-0944d77a2906,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-4c14ad10-dc99-4111-a70c-95eef8b3350f,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-7c658069-b2d2-42c8-b559-bfd686fc2e91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585579955-172.17.0.12-1595583574064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-6700878c-0aa6-4994-b3cc-f81a7b4de6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-e838a533-4c80-4b2c-ae6c-54204f32bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-34e52cba-d383-47d7-bb78-b328c00d2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-be46f895-fc1e-42af-b109-198423e486dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-d0cfd8f5-f4da-4533-b8f5-734231f71812,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-47c3ac11-8409-4f67-8980-b2effaeea519,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-099dd722-657e-4f8a-b525-cd893a0463bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-26ac8169-bcb6-49cf-bf0f-f0405fdf48dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585579955-172.17.0.12-1595583574064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-6700878c-0aa6-4994-b3cc-f81a7b4de6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-e838a533-4c80-4b2c-ae6c-54204f32bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-34e52cba-d383-47d7-bb78-b328c00d2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-be46f895-fc1e-42af-b109-198423e486dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-d0cfd8f5-f4da-4533-b8f5-734231f71812,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-47c3ac11-8409-4f67-8980-b2effaeea519,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-099dd722-657e-4f8a-b525-cd893a0463bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-26ac8169-bcb6-49cf-bf0f-f0405fdf48dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518874070-172.17.0.12-1595584124100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34394,DS-c3878f2b-decd-4fdb-9807-294eeb2273ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-8158fc2e-690f-464f-8daf-9b41952c046e,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-0a5a196a-6926-428c-973b-441c30646508,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-42413b21-41b1-4cf5-b969-8a352a3a01e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-5528b090-6456-457e-b0e1-324f049f0454,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-0699002e-7404-442f-9932-855bff88dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-c119dab4-26aa-4dea-962d-8737fec88be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-80c413c3-4d17-4655-9a18-ee7e5f1025c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518874070-172.17.0.12-1595584124100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34394,DS-c3878f2b-decd-4fdb-9807-294eeb2273ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-8158fc2e-690f-464f-8daf-9b41952c046e,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-0a5a196a-6926-428c-973b-441c30646508,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-42413b21-41b1-4cf5-b969-8a352a3a01e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-5528b090-6456-457e-b0e1-324f049f0454,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-0699002e-7404-442f-9932-855bff88dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-c119dab4-26aa-4dea-962d-8737fec88be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-80c413c3-4d17-4655-9a18-ee7e5f1025c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797485633-172.17.0.12-1595584534953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33803,DS-09477aa1-a818-4672-bc59-f8888d4383cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-68cfc5ad-9f95-4112-a8a9-3340c3571abc,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-73c84c9d-3b97-40f4-8bf8-9e804817ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-6b534790-54c7-4afb-a231-b2e468394770,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-711f99b1-4685-4e83-8d80-c0b350f5ff61,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-0035dafe-4d16-4ce3-8d14-2183fc55a5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-de9a5af7-4b8e-4bd6-9263-7915f28bc197,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-5165de31-24b3-4298-8528-f42f122cb637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797485633-172.17.0.12-1595584534953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33803,DS-09477aa1-a818-4672-bc59-f8888d4383cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-68cfc5ad-9f95-4112-a8a9-3340c3571abc,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-73c84c9d-3b97-40f4-8bf8-9e804817ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-6b534790-54c7-4afb-a231-b2e468394770,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-711f99b1-4685-4e83-8d80-c0b350f5ff61,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-0035dafe-4d16-4ce3-8d14-2183fc55a5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-de9a5af7-4b8e-4bd6-9263-7915f28bc197,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-5165de31-24b3-4298-8528-f42f122cb637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812227432-172.17.0.12-1595584711517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45658,DS-cfbc4a53-3d19-4b82-9a40-6bcb190000ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-4ae282ae-f902-4cf6-830d-6f6b44c3c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-ad60a168-c07c-4bfb-b8dc-a54ba2e220d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-b706f131-20e7-46cb-be2f-4f386d38d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-36417504-583b-4099-ba89-2d53acbf9ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-34b87686-40c7-4d71-8415-04e845026f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-750c0de9-d4d1-4e9e-a434-1184d975f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-daf35919-2029-458a-9174-20120bd615ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812227432-172.17.0.12-1595584711517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45658,DS-cfbc4a53-3d19-4b82-9a40-6bcb190000ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-4ae282ae-f902-4cf6-830d-6f6b44c3c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-ad60a168-c07c-4bfb-b8dc-a54ba2e220d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-b706f131-20e7-46cb-be2f-4f386d38d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-36417504-583b-4099-ba89-2d53acbf9ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-34b87686-40c7-4d71-8415-04e845026f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-750c0de9-d4d1-4e9e-a434-1184d975f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-daf35919-2029-458a-9174-20120bd615ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096876221-172.17.0.12-1595584753421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-6139e1fd-cc50-47f4-8365-9a3e6b564591,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-d085a449-9a94-44c7-95b4-52bd7fb14510,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-e6f94cc8-1bd3-4718-a374-641c8654bccf,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-40f830c3-2e46-4465-8859-3a71da4e1450,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-b5a06b0c-4a72-4e07-bdc6-1619ad0cfad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-24fd96b4-43f3-472b-8d1d-c55f752d69cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-345312cf-d97e-48ab-9247-1d79844c2289,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-ea016b13-a0cc-4463-9e73-5cf21251a048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096876221-172.17.0.12-1595584753421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-6139e1fd-cc50-47f4-8365-9a3e6b564591,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-d085a449-9a94-44c7-95b4-52bd7fb14510,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-e6f94cc8-1bd3-4718-a374-641c8654bccf,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-40f830c3-2e46-4465-8859-3a71da4e1450,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-b5a06b0c-4a72-4e07-bdc6-1619ad0cfad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-24fd96b4-43f3-472b-8d1d-c55f752d69cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-345312cf-d97e-48ab-9247-1d79844c2289,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-ea016b13-a0cc-4463-9e73-5cf21251a048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-228581152-172.17.0.12-1595584883571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-60e078b6-57af-4fce-bd3d-b6f4a0402c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-b1378ecf-93aa-4f13-a460-320578bd7c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-6ba14b99-07b5-4e2a-98ff-00f00b6ff50d,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-82dd3533-c268-4bf3-89c0-85db8de4d1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-e2d67367-b633-4721-a68c-0eaf49c88a57,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-8aa0e23e-d9f7-47b3-9613-d0edf89340b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-0b098ac6-5b13-41e2-899e-6b82b2fcae01,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-a8dde1c7-8d2e-4eb1-8dca-bb01ef57c8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-228581152-172.17.0.12-1595584883571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-60e078b6-57af-4fce-bd3d-b6f4a0402c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-b1378ecf-93aa-4f13-a460-320578bd7c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-6ba14b99-07b5-4e2a-98ff-00f00b6ff50d,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-82dd3533-c268-4bf3-89c0-85db8de4d1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-e2d67367-b633-4721-a68c-0eaf49c88a57,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-8aa0e23e-d9f7-47b3-9613-d0edf89340b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-0b098ac6-5b13-41e2-899e-6b82b2fcae01,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-a8dde1c7-8d2e-4eb1-8dca-bb01ef57c8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858352854-172.17.0.12-1595585508687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-b51a66fa-7078-4d0b-8ac9-8a8c8283a0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-43d76f19-4176-4d15-a61f-435c64e82a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-40eb2368-3976-45d2-a4e9-40d16a48411a,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-7c02f1c2-1d04-4122-a78e-c3ca74d3620c,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-84434f67-4602-4cb4-b527-c83d12f95f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-d4dcae51-bf9f-404c-9536-6a5228c2a12d,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-17c15bd0-edce-4ac6-a902-545318150e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-be457267-6be5-4108-8e10-62f6844dd07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858352854-172.17.0.12-1595585508687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-b51a66fa-7078-4d0b-8ac9-8a8c8283a0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-43d76f19-4176-4d15-a61f-435c64e82a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-40eb2368-3976-45d2-a4e9-40d16a48411a,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-7c02f1c2-1d04-4122-a78e-c3ca74d3620c,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-84434f67-4602-4cb4-b527-c83d12f95f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-d4dcae51-bf9f-404c-9536-6a5228c2a12d,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-17c15bd0-edce-4ac6-a902-545318150e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-be457267-6be5-4108-8e10-62f6844dd07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178911587-172.17.0.12-1595585673353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-a94c1a8e-5eb2-4cd2-b918-2381f0c95160,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-312020fe-a26c-4046-8a96-045b7d464099,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-82db5f15-fb08-4ed8-b7f1-9549a98dd496,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-301a541d-5f7b-4e30-8571-dec490d390ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-43eaa273-4a71-4a2a-8aea-037841c59d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-4340fc72-b2cd-432d-a7b0-d78785dae10b,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-6ad6c043-c7a3-400e-a4b5-b572e0038082,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-89e953e3-a238-4fe5-8a24-3df2be8f1763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178911587-172.17.0.12-1595585673353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-a94c1a8e-5eb2-4cd2-b918-2381f0c95160,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-312020fe-a26c-4046-8a96-045b7d464099,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-82db5f15-fb08-4ed8-b7f1-9549a98dd496,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-301a541d-5f7b-4e30-8571-dec490d390ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-43eaa273-4a71-4a2a-8aea-037841c59d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-4340fc72-b2cd-432d-a7b0-d78785dae10b,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-6ad6c043-c7a3-400e-a4b5-b572e0038082,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-89e953e3-a238-4fe5-8a24-3df2be8f1763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 6508
