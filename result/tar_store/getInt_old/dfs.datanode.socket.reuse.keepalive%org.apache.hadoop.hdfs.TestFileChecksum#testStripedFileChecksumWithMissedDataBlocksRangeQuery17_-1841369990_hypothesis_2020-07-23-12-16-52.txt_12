reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817185957-172.17.0.21-1595506992341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35903,DS-6bda6d72-fcc5-4511-ad50-25ad7472b69d,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-993994fe-8dc6-4cdd-8840-18be9af21a18,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-82de53d4-c41a-41d0-9728-95ca014a41f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-4c7e31b7-6aa4-4404-bdd8-52ac4bd36c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-9dfea493-3742-4a69-b1dd-cc8e6c76c057,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-5413cc01-9b56-4e81-9138-566818bc1d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-3e0bf15e-a546-4408-a9ae-15ca584565e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-1f0d9999-63ba-4a08-8a10-804217bfd166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817185957-172.17.0.21-1595506992341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35903,DS-6bda6d72-fcc5-4511-ad50-25ad7472b69d,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-993994fe-8dc6-4cdd-8840-18be9af21a18,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-82de53d4-c41a-41d0-9728-95ca014a41f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-4c7e31b7-6aa4-4404-bdd8-52ac4bd36c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-9dfea493-3742-4a69-b1dd-cc8e6c76c057,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-5413cc01-9b56-4e81-9138-566818bc1d80,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-3e0bf15e-a546-4408-a9ae-15ca584565e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-1f0d9999-63ba-4a08-8a10-804217bfd166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004035714-172.17.0.21-1595507257916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40479,DS-deed9ded-b114-4cc8-a75b-af9f93bc2a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-0f11a653-b7a7-45c0-85be-782ab1d6d656,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-9d545530-c11c-4402-9f60-e2b06afabce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-ad593409-8f54-4ff8-86e3-d6e6ac551a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-3b04cc6b-3f3f-4145-b483-b5eade73dd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-ac01fe6b-ccb4-41cd-9cd2-4fb81704c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-2f1524cb-ce9a-47e9-9e54-490dee30a446,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-e52ba85c-925a-4e37-917e-2a5b730d10d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004035714-172.17.0.21-1595507257916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40479,DS-deed9ded-b114-4cc8-a75b-af9f93bc2a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-0f11a653-b7a7-45c0-85be-782ab1d6d656,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-9d545530-c11c-4402-9f60-e2b06afabce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-ad593409-8f54-4ff8-86e3-d6e6ac551a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-3b04cc6b-3f3f-4145-b483-b5eade73dd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-ac01fe6b-ccb4-41cd-9cd2-4fb81704c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-2f1524cb-ce9a-47e9-9e54-490dee30a446,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-e52ba85c-925a-4e37-917e-2a5b730d10d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166871562-172.17.0.21-1595507647723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-3fab672d-afb0-4fc6-928c-ea9219e54573,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-90eed88d-8af5-4206-b57d-17164a021d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-5a182a01-9069-4a9f-8782-7031128a09e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-7ecbe24e-e606-4acc-bdef-644fd04ba11b,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-15e37c5e-8cd3-4aab-825f-a6c935902322,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-42df55e6-de62-47e4-a83b-b91446754ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-379ac4ac-2ad0-4dee-849c-178aabaee887,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-7da9285e-5a6d-4c8f-8a68-ee997a5487de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166871562-172.17.0.21-1595507647723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-3fab672d-afb0-4fc6-928c-ea9219e54573,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-90eed88d-8af5-4206-b57d-17164a021d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-5a182a01-9069-4a9f-8782-7031128a09e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-7ecbe24e-e606-4acc-bdef-644fd04ba11b,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-15e37c5e-8cd3-4aab-825f-a6c935902322,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-42df55e6-de62-47e4-a83b-b91446754ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-379ac4ac-2ad0-4dee-849c-178aabaee887,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-7da9285e-5a6d-4c8f-8a68-ee997a5487de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546444615-172.17.0.21-1595507852500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32813,DS-981b5cbe-68eb-4221-b6dd-560c22ddf5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-014df8af-abff-4be0-9313-42e7bddde4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-439f587c-14db-4022-bd66-aa543ceec3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-511ac574-817a-444b-82ea-67ddb48169f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-7d5ded43-f3ae-4bdb-95f5-99995ce4ca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-b616d887-114d-4665-b49f-b35419abbe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-5f7da7f4-62d2-42d9-adcb-8d4bbe975079,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-e2e7049e-3bc2-477f-b482-bc0c662152c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546444615-172.17.0.21-1595507852500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32813,DS-981b5cbe-68eb-4221-b6dd-560c22ddf5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-014df8af-abff-4be0-9313-42e7bddde4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-439f587c-14db-4022-bd66-aa543ceec3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-511ac574-817a-444b-82ea-67ddb48169f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-7d5ded43-f3ae-4bdb-95f5-99995ce4ca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-b616d887-114d-4665-b49f-b35419abbe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-5f7da7f4-62d2-42d9-adcb-8d4bbe975079,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-e2e7049e-3bc2-477f-b482-bc0c662152c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624430311-172.17.0.21-1595507888145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44322,DS-11ca556d-b17d-44f8-8ef5-a659cf3011bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-8f1cd259-bbc8-4f33-9fe7-3a122eead1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-55752906-e588-4ae0-9fb6-d411d9bbd9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-2f59ada4-a4aa-4b4f-aeb6-01ee28f463ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-9579a724-dc44-49a8-9d0a-802de0ba915f,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-23289cd1-22e8-45bf-979b-f80850146256,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-0bf3a2d2-02b8-4380-9b25-421242f4878e,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-3322b377-c5aa-4131-b53f-cb74524f8d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624430311-172.17.0.21-1595507888145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44322,DS-11ca556d-b17d-44f8-8ef5-a659cf3011bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-8f1cd259-bbc8-4f33-9fe7-3a122eead1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-55752906-e588-4ae0-9fb6-d411d9bbd9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-2f59ada4-a4aa-4b4f-aeb6-01ee28f463ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-9579a724-dc44-49a8-9d0a-802de0ba915f,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-23289cd1-22e8-45bf-979b-f80850146256,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-0bf3a2d2-02b8-4380-9b25-421242f4878e,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-3322b377-c5aa-4131-b53f-cb74524f8d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742153475-172.17.0.21-1595508191323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43644,DS-7920325e-f659-4f87-9e5f-7482c0217a23,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-3cab9d19-9af0-4932-a39a-cc22deb9b8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-548abd67-9003-4d65-8236-5e18a0d7af78,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-d0501768-944e-4b11-b2e9-f8473ab8a9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-8038927c-d7b8-4c2a-be54-abedb2b1885e,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-2a902652-39e1-466e-8735-50f3fb42e447,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-d859e1bb-7a6a-4a15-b567-2947d914c920,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-298343c0-77c0-49c3-886e-4c791caf296f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742153475-172.17.0.21-1595508191323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43644,DS-7920325e-f659-4f87-9e5f-7482c0217a23,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-3cab9d19-9af0-4932-a39a-cc22deb9b8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-548abd67-9003-4d65-8236-5e18a0d7af78,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-d0501768-944e-4b11-b2e9-f8473ab8a9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-8038927c-d7b8-4c2a-be54-abedb2b1885e,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-2a902652-39e1-466e-8735-50f3fb42e447,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-d859e1bb-7a6a-4a15-b567-2947d914c920,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-298343c0-77c0-49c3-886e-4c791caf296f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507512296-172.17.0.21-1595509695960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39080,DS-adbfe1c5-e90c-4012-957f-89c39483c93a,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-49d222c6-e7e1-4a6e-8551-80849e9e2bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-0f95571b-ad07-4611-8a47-ae8b1450213e,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-3b5811d1-f477-4a04-b665-0ab8a057e211,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-cba5e50f-3c12-4534-bf9f-e59b047d1edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-ada274ae-edd5-46fd-aa70-88a52de1557e,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-9ef0df11-db80-4260-899c-85b2c26bf08b,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-3d34fdef-e44e-451b-b0b6-f84ab474bf97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507512296-172.17.0.21-1595509695960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39080,DS-adbfe1c5-e90c-4012-957f-89c39483c93a,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-49d222c6-e7e1-4a6e-8551-80849e9e2bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-0f95571b-ad07-4611-8a47-ae8b1450213e,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-3b5811d1-f477-4a04-b665-0ab8a057e211,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-cba5e50f-3c12-4534-bf9f-e59b047d1edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-ada274ae-edd5-46fd-aa70-88a52de1557e,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-9ef0df11-db80-4260-899c-85b2c26bf08b,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-3d34fdef-e44e-451b-b0b6-f84ab474bf97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253548665-172.17.0.21-1595509723779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33162,DS-0a72c0e0-1604-4919-a219-d6782aaae356,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-e9007955-89cb-4769-aaf0-e9af8da04140,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-99305ccf-e3a7-402c-86be-cb9772d156e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-3301c14f-c3c7-4a98-b071-469098bf0eff,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-084e0740-bdd9-493e-81c2-6c9d6ad9f127,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-18af28dc-671a-4d43-8398-09c788e88a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-e93f0dae-8685-4dd4-9d90-af6cceb1b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-3d03fed7-0202-4dd0-bf5b-a6e49ca233cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253548665-172.17.0.21-1595509723779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33162,DS-0a72c0e0-1604-4919-a219-d6782aaae356,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-e9007955-89cb-4769-aaf0-e9af8da04140,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-99305ccf-e3a7-402c-86be-cb9772d156e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-3301c14f-c3c7-4a98-b071-469098bf0eff,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-084e0740-bdd9-493e-81c2-6c9d6ad9f127,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-18af28dc-671a-4d43-8398-09c788e88a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-e93f0dae-8685-4dd4-9d90-af6cceb1b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-3d03fed7-0202-4dd0-bf5b-a6e49ca233cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831691462-172.17.0.21-1595509878657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-5402f859-8ac0-490c-aa89-ab57b243e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-6b5a48dd-ca7a-4108-b6c8-e64c029c1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-a5bf18d2-7bbf-4b4e-af26-099ca95f6a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-358c60d5-8ec8-4d70-bdaf-0d799d44fb84,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-3daa548e-0c3e-45d6-a77d-603c482089a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-f746c8c3-684a-451f-9987-68cd7abe3ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-27443a5c-4582-411e-9b5f-7a61124972a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-635a6daf-4310-4e48-b6ab-a326bca63350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831691462-172.17.0.21-1595509878657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-5402f859-8ac0-490c-aa89-ab57b243e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-6b5a48dd-ca7a-4108-b6c8-e64c029c1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-a5bf18d2-7bbf-4b4e-af26-099ca95f6a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-358c60d5-8ec8-4d70-bdaf-0d799d44fb84,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-3daa548e-0c3e-45d6-a77d-603c482089a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-f746c8c3-684a-451f-9987-68cd7abe3ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-27443a5c-4582-411e-9b5f-7a61124972a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-635a6daf-4310-4e48-b6ab-a326bca63350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725221626-172.17.0.21-1595510078437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41503,DS-23ac6547-6ec2-4b33-b113-ab0b07eab904,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-627c7290-38bc-4110-be0c-1f79b0668559,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-e2e60168-83b6-4500-bc06-d1deba17f48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-121169dd-3330-4e65-ad89-a6d10e35b8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-d662fc9c-264f-4be5-b58c-eced59f3720d,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-cf46d7fd-4b7e-413e-aa66-007ccda64307,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-5a043f38-ba73-482b-92f6-168b4d7fc954,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-948c330c-a5e8-49ff-8441-53c4df7d938d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725221626-172.17.0.21-1595510078437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41503,DS-23ac6547-6ec2-4b33-b113-ab0b07eab904,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-627c7290-38bc-4110-be0c-1f79b0668559,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-e2e60168-83b6-4500-bc06-d1deba17f48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-121169dd-3330-4e65-ad89-a6d10e35b8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-d662fc9c-264f-4be5-b58c-eced59f3720d,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-cf46d7fd-4b7e-413e-aa66-007ccda64307,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-5a043f38-ba73-482b-92f6-168b4d7fc954,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-948c330c-a5e8-49ff-8441-53c4df7d938d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597473738-172.17.0.21-1595510141233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-513f4a9f-71b1-4924-bcaa-1bf912f62c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-68da6202-b55c-4902-aff1-8725189bb8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-203d5032-d4c8-43ca-ac3a-941bc8a69d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-dec749ee-795b-41f1-96fd-2f30b9b2ebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-644e4133-3c91-4018-8c23-36b0cc0efe00,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-66d203fe-e809-46ca-bb16-9f190a368aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-2112ea25-df26-4d1b-95e4-31f2f5a77ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-d6573ecd-0899-4c60-b747-5f1fd1319a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597473738-172.17.0.21-1595510141233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-513f4a9f-71b1-4924-bcaa-1bf912f62c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-68da6202-b55c-4902-aff1-8725189bb8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-203d5032-d4c8-43ca-ac3a-941bc8a69d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-dec749ee-795b-41f1-96fd-2f30b9b2ebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-644e4133-3c91-4018-8c23-36b0cc0efe00,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-66d203fe-e809-46ca-bb16-9f190a368aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-2112ea25-df26-4d1b-95e4-31f2f5a77ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-d6573ecd-0899-4c60-b747-5f1fd1319a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329037970-172.17.0.21-1595510531706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38139,DS-8a8f6ae2-6e00-4091-a730-a0fcb0c5767d,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-043b72ff-52ff-495a-8dec-af1580b2170d,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f8ed2c3a-39d5-4f00-a349-721abfeee081,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-fc627eb7-72e5-4646-93da-66396c57c893,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-dc2d58a6-3b8b-4ccc-9773-1bbfc57b439a,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-29a3404b-45d4-428f-9164-5f46ec57bdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-fc02f19f-f15a-4676-b15c-e82fc8df1064,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-4998a8d3-e7f2-4bdc-91e8-d3c67b7f93c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329037970-172.17.0.21-1595510531706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38139,DS-8a8f6ae2-6e00-4091-a730-a0fcb0c5767d,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-043b72ff-52ff-495a-8dec-af1580b2170d,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f8ed2c3a-39d5-4f00-a349-721abfeee081,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-fc627eb7-72e5-4646-93da-66396c57c893,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-dc2d58a6-3b8b-4ccc-9773-1bbfc57b439a,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-29a3404b-45d4-428f-9164-5f46ec57bdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-fc02f19f-f15a-4676-b15c-e82fc8df1064,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-4998a8d3-e7f2-4bdc-91e8-d3c67b7f93c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042955134-172.17.0.21-1595510570300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-bed1ac89-fb16-4b03-b8f3-5164c6324233,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-7f9a26a5-c6df-4ee7-b633-30a390a2818a,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-43985440-be89-4ccc-85d6-3cde89cb1a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-fe8c04a2-3dfd-493a-a824-421086a1f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-362bd761-3514-4cb9-9ee9-5ef3ef1dfbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-110fba56-8fdd-456b-a06e-c4a66060d415,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-4db5ec67-f176-4829-834a-ea5959e3d96e,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-ddef063b-2540-41ed-9a9f-5f7b1a09ce79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042955134-172.17.0.21-1595510570300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-bed1ac89-fb16-4b03-b8f3-5164c6324233,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-7f9a26a5-c6df-4ee7-b633-30a390a2818a,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-43985440-be89-4ccc-85d6-3cde89cb1a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-fe8c04a2-3dfd-493a-a824-421086a1f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-362bd761-3514-4cb9-9ee9-5ef3ef1dfbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-110fba56-8fdd-456b-a06e-c4a66060d415,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-4db5ec67-f176-4829-834a-ea5959e3d96e,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-ddef063b-2540-41ed-9a9f-5f7b1a09ce79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701504894-172.17.0.21-1595510960098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-3e4c31f2-88f3-4595-b7b7-abfab3d754bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-180b9478-bb39-4c26-92ba-8727ecacd109,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-5d0e32ed-94cc-4f0b-a9cd-80a4a48c4eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-7aa310c8-7f89-4251-b095-d79a42825819,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-fea35b28-4a25-4a61-8bdb-cd9fe3f75d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-3a3295a2-c252-4e6f-b20b-e5da35eefb16,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-a8c1cb6e-343e-4efc-8441-d6ae1cfda831,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-2d02639c-de7f-40e1-bbd5-883365e85584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701504894-172.17.0.21-1595510960098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-3e4c31f2-88f3-4595-b7b7-abfab3d754bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-180b9478-bb39-4c26-92ba-8727ecacd109,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-5d0e32ed-94cc-4f0b-a9cd-80a4a48c4eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-7aa310c8-7f89-4251-b095-d79a42825819,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-fea35b28-4a25-4a61-8bdb-cd9fe3f75d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-3a3295a2-c252-4e6f-b20b-e5da35eefb16,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-a8c1cb6e-343e-4efc-8441-d6ae1cfda831,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-2d02639c-de7f-40e1-bbd5-883365e85584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521568279-172.17.0.21-1595511331476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36145,DS-0db95a73-e8e6-4369-8361-c9062ee733f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-bb81f246-9449-402b-9736-d65eab39da09,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-35d29ab3-e41e-4756-b42e-2379b2568dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-8393bac5-9f4a-4ad0-a69a-2e3458de6d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-a0a676ff-67af-4c5e-8ae8-9913aff70205,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-5d8dcfad-091b-4b77-8b03-2a823bd660f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-a4eaa8b8-900f-4cc3-a164-56cb2d3da997,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-482e95a8-6fe4-47e1-9eaf-052ba0df75c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521568279-172.17.0.21-1595511331476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36145,DS-0db95a73-e8e6-4369-8361-c9062ee733f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-bb81f246-9449-402b-9736-d65eab39da09,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-35d29ab3-e41e-4756-b42e-2379b2568dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-8393bac5-9f4a-4ad0-a69a-2e3458de6d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-a0a676ff-67af-4c5e-8ae8-9913aff70205,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-5d8dcfad-091b-4b77-8b03-2a823bd660f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-a4eaa8b8-900f-4cc3-a164-56cb2d3da997,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-482e95a8-6fe4-47e1-9eaf-052ba0df75c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292293097-172.17.0.21-1595511372188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46102,DS-cb55dd3c-d5cb-4f6b-b9e4-8a197bd98ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-15d71ed8-7212-4af2-a121-2b73c46a0089,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-606ef850-5d76-4923-8927-70b00fba5166,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-9984fa1a-1e16-44c9-ad78-2565c05322cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-0f739ae3-710a-4b69-8d95-d7c3c1583014,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-81f6b02e-59ae-43c9-ac8d-5952430e2233,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-c8fcd78c-0102-4136-9831-f449e99137f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-902c116e-5409-4cc6-9121-6cbe18cfe6f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292293097-172.17.0.21-1595511372188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46102,DS-cb55dd3c-d5cb-4f6b-b9e4-8a197bd98ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-15d71ed8-7212-4af2-a121-2b73c46a0089,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-606ef850-5d76-4923-8927-70b00fba5166,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-9984fa1a-1e16-44c9-ad78-2565c05322cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-0f739ae3-710a-4b69-8d95-d7c3c1583014,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-81f6b02e-59ae-43c9-ac8d-5952430e2233,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-c8fcd78c-0102-4136-9831-f449e99137f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-902c116e-5409-4cc6-9121-6cbe18cfe6f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4946
