reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302550099-172.17.0.11-1595626995871:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-66767b9c-4161-4714-acf2-5baea282fce6,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-51bb1b0e-93da-4635-a643-3023615ac502,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-66f83e3d-8882-44b1-a025-4d05eb57d783,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-1c1f9476-8987-4760-b86c-5547625da7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-74d33eea-52d0-43a6-b41c-dbaf5f1103e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-054c43e3-73fe-43cb-a390-418bcceae71b,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-d2c3ef40-c927-4039-b5ef-44292201784a,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-b2e0d863-40ac-4776-985a-87c584fdabc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302550099-172.17.0.11-1595626995871:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-66767b9c-4161-4714-acf2-5baea282fce6,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-51bb1b0e-93da-4635-a643-3023615ac502,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-66f83e3d-8882-44b1-a025-4d05eb57d783,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-1c1f9476-8987-4760-b86c-5547625da7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-74d33eea-52d0-43a6-b41c-dbaf5f1103e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-054c43e3-73fe-43cb-a390-418bcceae71b,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-d2c3ef40-c927-4039-b5ef-44292201784a,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-b2e0d863-40ac-4776-985a-87c584fdabc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453860915-172.17.0.11-1595627336089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33806,DS-21615701-abff-442c-8f1e-1bd259ae2abd,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-de8b1c35-4ad7-4239-abd5-73ff71db46ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-fb910d4b-bacf-4f2c-8223-51c1df33acc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-ebf8363f-ed5a-4e64-9867-c58d4a15eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-5bf74ae0-781e-4c6b-a5ba-9c5bbd12b2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-6ce2b335-9d78-4a61-bd43-0a598edd3e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-64300bc5-5398-44e8-a613-e78341ed0a69,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-2b741fd7-4161-4f4a-8a2a-89b2f8ec6356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453860915-172.17.0.11-1595627336089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33806,DS-21615701-abff-442c-8f1e-1bd259ae2abd,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-de8b1c35-4ad7-4239-abd5-73ff71db46ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-fb910d4b-bacf-4f2c-8223-51c1df33acc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-ebf8363f-ed5a-4e64-9867-c58d4a15eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-5bf74ae0-781e-4c6b-a5ba-9c5bbd12b2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-6ce2b335-9d78-4a61-bd43-0a598edd3e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-64300bc5-5398-44e8-a613-e78341ed0a69,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-2b741fd7-4161-4f4a-8a2a-89b2f8ec6356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936399503-172.17.0.11-1595627381726:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39335,DS-efabb805-ebb4-4eb0-afad-d797f3ed3c08,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-16b7b151-7c3d-4a0d-9085-dccefc400927,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-ff7e4953-9871-49b9-b81c-704838402f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-650bc796-27df-4f06-a3b7-d1e49909c3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-88fef549-35d5-4e39-af72-598ded97024a,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-9a6b016b-e80c-48a4-bb26-cd7a63ae8323,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-3185518a-f3d2-456e-88d1-5cd68d97c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-7b54c288-66a2-4bce-8edc-54bfe407c14e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936399503-172.17.0.11-1595627381726:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39335,DS-efabb805-ebb4-4eb0-afad-d797f3ed3c08,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-16b7b151-7c3d-4a0d-9085-dccefc400927,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-ff7e4953-9871-49b9-b81c-704838402f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-650bc796-27df-4f06-a3b7-d1e49909c3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-88fef549-35d5-4e39-af72-598ded97024a,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-9a6b016b-e80c-48a4-bb26-cd7a63ae8323,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-3185518a-f3d2-456e-88d1-5cd68d97c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-7b54c288-66a2-4bce-8edc-54bfe407c14e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806397067-172.17.0.11-1595628318400:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-7048b8cb-08b9-49ca-8641-9b6a1620e0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-026ce79f-96d1-44cb-944f-c16608eb96fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-d4de8d35-f5ca-4dea-928b-8fe231d3f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-5b9f81f6-42a5-4cc3-83c1-559f8c8b6548,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-f06b5202-d970-4d35-a29a-616502e3369f,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-45e58047-1620-40f0-9390-127b68c5845b,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-db04d7a9-e942-4787-b25e-ef6125f4784d,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-f2f4fe83-baee-4ea3-8745-e1eb433c8dd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806397067-172.17.0.11-1595628318400:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-7048b8cb-08b9-49ca-8641-9b6a1620e0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-026ce79f-96d1-44cb-944f-c16608eb96fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-d4de8d35-f5ca-4dea-928b-8fe231d3f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-5b9f81f6-42a5-4cc3-83c1-559f8c8b6548,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-f06b5202-d970-4d35-a29a-616502e3369f,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-45e58047-1620-40f0-9390-127b68c5845b,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-db04d7a9-e942-4787-b25e-ef6125f4784d,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-f2f4fe83-baee-4ea3-8745-e1eb433c8dd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830245638-172.17.0.11-1595629884937:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33289,DS-529bd790-d050-46e6-8b6d-d3b8406b0cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-9b1cceb8-e075-43f1-9c75-48b74a6d6ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-99d54c59-f45a-480e-a669-ccacefd4deb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-7fdacf78-9e65-41bd-82f8-f6a67ba1d267,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-de311800-df35-4e4f-ac84-624a52d772fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-0d12b961-a871-4fe6-9ad5-3fab03beb446,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-f286bbb9-e9a4-42fb-819c-8eba605c27e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-d96d2b49-c9cd-4860-a185-20241661cef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830245638-172.17.0.11-1595629884937:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33289,DS-529bd790-d050-46e6-8b6d-d3b8406b0cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-9b1cceb8-e075-43f1-9c75-48b74a6d6ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-99d54c59-f45a-480e-a669-ccacefd4deb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-7fdacf78-9e65-41bd-82f8-f6a67ba1d267,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-de311800-df35-4e4f-ac84-624a52d772fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-0d12b961-a871-4fe6-9ad5-3fab03beb446,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-f286bbb9-e9a4-42fb-819c-8eba605c27e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-d96d2b49-c9cd-4860-a185-20241661cef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560777352-172.17.0.11-1595630168949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-f3dfb517-b1ba-4f59-ad27-a4799ab894f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-3a52090f-e233-419d-90db-e8dd6a097c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-1b4c91c0-2f2d-432d-80e6-08d30a9f03e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-74619528-4ed4-433f-b3b7-51a1b18448aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-a9465495-14f2-4ccd-8bdd-9064a0193a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-fd908575-cf6d-46b3-88ed-11e9ce4a0345,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-af3793fd-2e65-4b9a-a42d-a57807adcfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-59ba2232-3b91-4733-9b80-74f53a7f254a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560777352-172.17.0.11-1595630168949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-f3dfb517-b1ba-4f59-ad27-a4799ab894f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-3a52090f-e233-419d-90db-e8dd6a097c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-1b4c91c0-2f2d-432d-80e6-08d30a9f03e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-74619528-4ed4-433f-b3b7-51a1b18448aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-a9465495-14f2-4ccd-8bdd-9064a0193a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-fd908575-cf6d-46b3-88ed-11e9ce4a0345,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-af3793fd-2e65-4b9a-a42d-a57807adcfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-59ba2232-3b91-4733-9b80-74f53a7f254a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101841683-172.17.0.11-1595630299811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-bfd58374-b119-4ecd-8acb-6a85508ede45,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-1b0d2754-d905-4284-85c8-e834109392fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-104ad0eb-5cb5-4961-a33f-552ed39ecfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-e196e1b4-d13b-43af-a5c2-7d695c4fdb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-0453e68f-011d-46c3-b1d6-7123e79a0bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-c0d177eb-2fff-4734-a00b-6bc94ed5eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-1e0752a8-ce10-4391-b203-9dc43b131ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-e7984729-7efe-42ff-b4c8-cd71b9785069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101841683-172.17.0.11-1595630299811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-bfd58374-b119-4ecd-8acb-6a85508ede45,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-1b0d2754-d905-4284-85c8-e834109392fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-104ad0eb-5cb5-4961-a33f-552ed39ecfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-e196e1b4-d13b-43af-a5c2-7d695c4fdb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-0453e68f-011d-46c3-b1d6-7123e79a0bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-c0d177eb-2fff-4734-a00b-6bc94ed5eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-1e0752a8-ce10-4391-b203-9dc43b131ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-e7984729-7efe-42ff-b4c8-cd71b9785069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255977896-172.17.0.11-1595631065128:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-ec7d0f0e-b93b-467b-98bd-969e2d35b565,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-167e1576-e2f3-4977-9f36-c454c138a784,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-fb2e7ecc-4632-43cc-966c-81aefc4e7601,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-6eba6b94-cac6-4454-9682-f5efb728ee20,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-a47e03e0-2476-477f-b947-855fe9dd52ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-737de674-c120-4111-b023-1d8660800870,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-1afbd6d1-564c-4cb0-bcbe-b536284b5fba,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-36fdd4aa-fe60-4a7c-b0a4-0f18a81b12e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255977896-172.17.0.11-1595631065128:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-ec7d0f0e-b93b-467b-98bd-969e2d35b565,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-167e1576-e2f3-4977-9f36-c454c138a784,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-fb2e7ecc-4632-43cc-966c-81aefc4e7601,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-6eba6b94-cac6-4454-9682-f5efb728ee20,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-a47e03e0-2476-477f-b947-855fe9dd52ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-737de674-c120-4111-b023-1d8660800870,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-1afbd6d1-564c-4cb0-bcbe-b536284b5fba,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-36fdd4aa-fe60-4a7c-b0a4-0f18a81b12e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200282242-172.17.0.11-1595631099881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-184bccd2-ccdf-4779-bf92-429f8c39592a,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-91a4d6b2-6636-4be3-99ff-12d366078ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-b4c26ff3-868d-4628-9a15-61f7104b1e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-612126be-1803-4e86-a3e3-773ac63e275e,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-59674f4d-9f5a-4a1c-9146-68ba9e5962b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-36bf88e9-6eef-4dce-a862-4c55fc4922cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-c0d3c632-bc55-4106-ab3e-7fc5511e70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-51f3aff5-18f9-42b4-b667-133ecda2121f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200282242-172.17.0.11-1595631099881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-184bccd2-ccdf-4779-bf92-429f8c39592a,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-91a4d6b2-6636-4be3-99ff-12d366078ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-b4c26ff3-868d-4628-9a15-61f7104b1e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-612126be-1803-4e86-a3e3-773ac63e275e,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-59674f4d-9f5a-4a1c-9146-68ba9e5962b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-36bf88e9-6eef-4dce-a862-4c55fc4922cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-c0d3c632-bc55-4106-ab3e-7fc5511e70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-51f3aff5-18f9-42b4-b667-133ecda2121f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628270427-172.17.0.11-1595631132061:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38232,DS-01d874b7-8df1-483e-99da-99c6ab37a1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-aaeb167e-8424-437d-abe4-c01c5ac40309,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-e3e84df9-746d-4881-8917-ec2dab455ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-cfd32a5c-2e27-40ca-8590-34f0e3ce2bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-d43307cd-c301-420b-a815-74853a831910,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-7ae3f341-4476-494a-a055-f61ec18c9572,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-2296dd78-39cb-4d24-aac4-a445d278031b,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7576f48f-6efe-4aca-8ff9-93f4673e17d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628270427-172.17.0.11-1595631132061:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38232,DS-01d874b7-8df1-483e-99da-99c6ab37a1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-aaeb167e-8424-437d-abe4-c01c5ac40309,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-e3e84df9-746d-4881-8917-ec2dab455ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-cfd32a5c-2e27-40ca-8590-34f0e3ce2bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-d43307cd-c301-420b-a815-74853a831910,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-7ae3f341-4476-494a-a055-f61ec18c9572,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-2296dd78-39cb-4d24-aac4-a445d278031b,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7576f48f-6efe-4aca-8ff9-93f4673e17d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824475351-172.17.0.11-1595631900622:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40915,DS-f05d2bff-7ecb-423b-bcf4-f6c21f8bf0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-86fc85cc-d58b-46e4-a4a4-81a22143e083,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-cc879d18-9e14-475a-83e4-06a3c50a7d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-00058594-356a-4179-bb66-49ae6a257774,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-73d496d0-9868-4ad7-938b-4ef6459599f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-6700b48f-1f52-4311-bee6-7c04379ccbec,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-04230da3-1f4b-4f69-9680-62b77acc16d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-9f61f4be-c6c6-4092-b0f1-428b35956668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824475351-172.17.0.11-1595631900622:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40915,DS-f05d2bff-7ecb-423b-bcf4-f6c21f8bf0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-86fc85cc-d58b-46e4-a4a4-81a22143e083,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-cc879d18-9e14-475a-83e4-06a3c50a7d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-00058594-356a-4179-bb66-49ae6a257774,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-73d496d0-9868-4ad7-938b-4ef6459599f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-6700b48f-1f52-4311-bee6-7c04379ccbec,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-04230da3-1f4b-4f69-9680-62b77acc16d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-9f61f4be-c6c6-4092-b0f1-428b35956668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 1048576
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134066352-172.17.0.11-1595632409327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-db84d9d7-4baa-46cb-b79c-c46693cfeb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-cc736f12-aefd-4d6a-b31a-a103904b9a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-e6a9a200-bff5-40fc-baa5-d1c28ebbc0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-1bcda1ab-18e2-4bb6-bb8a-1907e4fb3c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-c8fc477c-0cd2-4194-a32b-1c18928490d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-a19d510a-43d0-40a4-8ed6-25a69e968c75,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-c681ac5a-f819-4de1-9e44-4f06adfb761a,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-26d84cef-50cf-4e98-a982-54df4af355ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134066352-172.17.0.11-1595632409327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-db84d9d7-4baa-46cb-b79c-c46693cfeb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-cc736f12-aefd-4d6a-b31a-a103904b9a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-e6a9a200-bff5-40fc-baa5-d1c28ebbc0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-1bcda1ab-18e2-4bb6-bb8a-1907e4fb3c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-c8fc477c-0cd2-4194-a32b-1c18928490d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-a19d510a-43d0-40a4-8ed6-25a69e968c75,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-c681ac5a-f819-4de1-9e44-4f06adfb761a,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-26d84cef-50cf-4e98-a982-54df4af355ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6180
