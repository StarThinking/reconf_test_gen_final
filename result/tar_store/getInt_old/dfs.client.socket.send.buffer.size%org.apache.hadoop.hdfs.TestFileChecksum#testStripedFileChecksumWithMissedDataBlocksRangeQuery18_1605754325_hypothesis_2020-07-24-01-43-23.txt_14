reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647924184-172.17.0.11-1595555083514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-08b1591b-90f2-4f08-ba5b-997c8c568005,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-f986fa00-3411-49ef-b4b6-9277285510e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-7877d6ba-2b16-418e-a251-c9464e5bc3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-52f0d1d2-1786-44b7-a989-539c10e117c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-cb8e2591-b601-4302-b0d2-8defc85fcdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-7ae2734c-7cc4-4326-9a22-a4f9fbd692c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-88497e5e-d781-4650-adf8-bcc0554a9eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-39a906b2-5677-4763-a661-a4fc201e01cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647924184-172.17.0.11-1595555083514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-08b1591b-90f2-4f08-ba5b-997c8c568005,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-f986fa00-3411-49ef-b4b6-9277285510e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-7877d6ba-2b16-418e-a251-c9464e5bc3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-52f0d1d2-1786-44b7-a989-539c10e117c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-cb8e2591-b601-4302-b0d2-8defc85fcdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-7ae2734c-7cc4-4326-9a22-a4f9fbd692c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-88497e5e-d781-4650-adf8-bcc0554a9eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-39a906b2-5677-4763-a661-a4fc201e01cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604752994-172.17.0.11-1595555418617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-bcb68503-c085-4a7d-92cb-65c7f4e802bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-85a6c1a7-5f56-48bd-8074-52715b8ffda8,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-96fbe35a-a0b9-4dc2-b731-7500f849faa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-b6d0b6a8-c09b-4c2b-a05f-ca88dab81962,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-c578b9c3-93a0-4aa2-ab52-689b755a8ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-de233745-0a79-4195-9bf6-18f25ed9db1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-3db15cad-028e-42a3-85b1-a9c0f887d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-0b845005-af08-4483-96a8-188166a6ca3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604752994-172.17.0.11-1595555418617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-bcb68503-c085-4a7d-92cb-65c7f4e802bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-85a6c1a7-5f56-48bd-8074-52715b8ffda8,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-96fbe35a-a0b9-4dc2-b731-7500f849faa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-b6d0b6a8-c09b-4c2b-a05f-ca88dab81962,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-c578b9c3-93a0-4aa2-ab52-689b755a8ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-de233745-0a79-4195-9bf6-18f25ed9db1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-3db15cad-028e-42a3-85b1-a9c0f887d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-0b845005-af08-4483-96a8-188166a6ca3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693523663-172.17.0.11-1595556571707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-10ee873d-3357-400c-ad26-0f183123573c,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-955d5adf-c962-4b2f-9628-a5c69ff480b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-10f90df6-c2bd-4f48-a37b-06d278affb55,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-476e6ebc-f55e-41f1-bd40-eb9d5c8f5819,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-d228a297-de3b-4557-9287-a3f3871330cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-ff4d7217-b459-4dc5-b518-cb36299eeff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-8a69dda5-69cd-4722-a7c8-845cef5790dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-a39e38d3-5e4f-49d3-a96e-90d14f47edcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693523663-172.17.0.11-1595556571707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-10ee873d-3357-400c-ad26-0f183123573c,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-955d5adf-c962-4b2f-9628-a5c69ff480b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-10f90df6-c2bd-4f48-a37b-06d278affb55,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-476e6ebc-f55e-41f1-bd40-eb9d5c8f5819,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-d228a297-de3b-4557-9287-a3f3871330cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-ff4d7217-b459-4dc5-b518-cb36299eeff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-8a69dda5-69cd-4722-a7c8-845cef5790dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-a39e38d3-5e4f-49d3-a96e-90d14f47edcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804857785-172.17.0.11-1595556779283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33269,DS-c5df9ee4-4334-4d53-b21b-1b4daee388eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-b351d35f-664d-4ce8-a5f0-29b75a4c9f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-9237dd15-bc99-41c2-bc47-eec9f9575975,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-85823e16-33c7-4829-9f34-ad6bf682ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-f8afde2a-ecd5-40e9-9faf-cba6ad4d5e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-114d526b-cf2d-4b8f-b8c8-eed5562ab764,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-debffc28-29eb-48f3-8087-2bd85ede5f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-76dfa074-f4d9-4268-93ea-d77b305603ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804857785-172.17.0.11-1595556779283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33269,DS-c5df9ee4-4334-4d53-b21b-1b4daee388eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-b351d35f-664d-4ce8-a5f0-29b75a4c9f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-9237dd15-bc99-41c2-bc47-eec9f9575975,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-85823e16-33c7-4829-9f34-ad6bf682ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-f8afde2a-ecd5-40e9-9faf-cba6ad4d5e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-114d526b-cf2d-4b8f-b8c8-eed5562ab764,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-debffc28-29eb-48f3-8087-2bd85ede5f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-76dfa074-f4d9-4268-93ea-d77b305603ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676637980-172.17.0.11-1595556958992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36590,DS-b7cc06d3-3f60-4e83-9f9c-f97b780e4771,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-99d4bfc7-4907-4e0d-83f0-58cec80bbbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-c40dbf7c-2721-4770-a987-cc8e827276ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-9b7f6fca-f88d-460f-b6c4-d249e4747c76,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-8eb2b170-0c65-4d5f-af17-c7557543bff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-75d94a69-d5e0-475e-a4a2-a283c9f7d816,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-58d21f8a-a813-4708-a01a-2cba3168e9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-f9493ed5-63f5-4ca4-b79b-244fac2ecc7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676637980-172.17.0.11-1595556958992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36590,DS-b7cc06d3-3f60-4e83-9f9c-f97b780e4771,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-99d4bfc7-4907-4e0d-83f0-58cec80bbbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-c40dbf7c-2721-4770-a987-cc8e827276ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-9b7f6fca-f88d-460f-b6c4-d249e4747c76,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-8eb2b170-0c65-4d5f-af17-c7557543bff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-75d94a69-d5e0-475e-a4a2-a283c9f7d816,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-58d21f8a-a813-4708-a01a-2cba3168e9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-f9493ed5-63f5-4ca4-b79b-244fac2ecc7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593896495-172.17.0.11-1595556993332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39844,DS-ee896ae9-a9b1-4e10-8803-6c5db65c86db,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-2e6ecbfa-ca1a-4015-9426-0b88677186db,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-5f1fb3ee-703c-433c-af02-4137a710764a,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-8c22206b-5b64-434d-8c09-182c851e4978,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-0aea2c29-0f19-48ef-946a-d7e337c677e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-9363f880-174a-43c5-abd5-a180252a1066,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-98ebeab0-2427-4f2d-b08e-95710143ebc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-60b84912-6ffe-432b-be6f-33efa4de6505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593896495-172.17.0.11-1595556993332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39844,DS-ee896ae9-a9b1-4e10-8803-6c5db65c86db,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-2e6ecbfa-ca1a-4015-9426-0b88677186db,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-5f1fb3ee-703c-433c-af02-4137a710764a,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-8c22206b-5b64-434d-8c09-182c851e4978,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-0aea2c29-0f19-48ef-946a-d7e337c677e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-9363f880-174a-43c5-abd5-a180252a1066,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-98ebeab0-2427-4f2d-b08e-95710143ebc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-60b84912-6ffe-432b-be6f-33efa4de6505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238588809-172.17.0.11-1595557088280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46388,DS-8268bcfa-cee7-41e2-b999-3dc08638c35d,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-85bdb7de-b362-4404-beb8-549898b5369a,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-943d43ee-1033-4785-bad5-923ae3f36a87,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-79898f8c-a539-4013-9497-3e5fab73485e,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-f4fa9e69-adde-4eb0-a945-f2c7cf375c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-59f8e1aa-6728-4e89-8712-26ff61831aed,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-2380a161-748e-4513-ab10-079678cf3f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-e1f28b16-3c0f-4e29-96a8-38757d414fb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238588809-172.17.0.11-1595557088280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46388,DS-8268bcfa-cee7-41e2-b999-3dc08638c35d,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-85bdb7de-b362-4404-beb8-549898b5369a,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-943d43ee-1033-4785-bad5-923ae3f36a87,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-79898f8c-a539-4013-9497-3e5fab73485e,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-f4fa9e69-adde-4eb0-a945-f2c7cf375c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-59f8e1aa-6728-4e89-8712-26ff61831aed,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-2380a161-748e-4513-ab10-079678cf3f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-e1f28b16-3c0f-4e29-96a8-38757d414fb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627429475-172.17.0.11-1595557545105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-1025e1af-50e5-4cbe-9390-f88369e24103,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-4e724add-1e00-4f04-882e-c55776eda2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-d0d98932-b5e8-477e-9d33-3fc0cbb4577f,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-d5f7bc67-916b-4ea4-a29f-f98eccc4ac72,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-f189c8d7-a6e4-448b-8d7c-34229572cbea,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-79ab9fce-f883-4a19-afd4-8ab38a816803,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-b988bd68-a031-4f59-8369-44b36f9062d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-4a393cb5-5552-424c-8de4-bba13dee51d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627429475-172.17.0.11-1595557545105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-1025e1af-50e5-4cbe-9390-f88369e24103,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-4e724add-1e00-4f04-882e-c55776eda2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-d0d98932-b5e8-477e-9d33-3fc0cbb4577f,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-d5f7bc67-916b-4ea4-a29f-f98eccc4ac72,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-f189c8d7-a6e4-448b-8d7c-34229572cbea,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-79ab9fce-f883-4a19-afd4-8ab38a816803,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-b988bd68-a031-4f59-8369-44b36f9062d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-4a393cb5-5552-424c-8de4-bba13dee51d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599249297-172.17.0.11-1595557577302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38007,DS-a84189d2-5e6b-4611-b71e-320465a1a173,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-2aa2ba05-fe65-4ab7-ad59-63fb591c8a88,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-9e360d5a-5ee6-437d-9ead-f6d834c4e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-b929d8b0-22a3-4c6b-ab76-5e3a9da0752e,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e3bd4250-1f96-4787-8b7b-9e720b5287e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-33bba546-aa7c-4a71-842f-125361920ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-94e4a519-d1df-4d59-8bd7-d29b81e6fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-4f0b61da-2837-4be6-8f2f-fb107e71718c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599249297-172.17.0.11-1595557577302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38007,DS-a84189d2-5e6b-4611-b71e-320465a1a173,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-2aa2ba05-fe65-4ab7-ad59-63fb591c8a88,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-9e360d5a-5ee6-437d-9ead-f6d834c4e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-b929d8b0-22a3-4c6b-ab76-5e3a9da0752e,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-e3bd4250-1f96-4787-8b7b-9e720b5287e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-33bba546-aa7c-4a71-842f-125361920ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-94e4a519-d1df-4d59-8bd7-d29b81e6fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-4f0b61da-2837-4be6-8f2f-fb107e71718c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684684112-172.17.0.11-1595557679830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36810,DS-3dcac5c5-85d2-4fe0-9bab-ee17a1937764,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-e28965d4-339e-42cf-a7ba-f0f8d68f703f,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-789bff15-3e9d-4999-804c-7d01b561527c,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-e73b1b04-ae71-4dfb-8047-454cd5798b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-677b7e00-4f2d-4105-8474-d6deab4dcb85,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-c5dc1d56-ba93-4c07-965c-7222037b71ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-2163a5cd-0932-4b62-a642-957974f99f15,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-aad90d91-5331-46f1-88a9-757cc7000db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684684112-172.17.0.11-1595557679830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36810,DS-3dcac5c5-85d2-4fe0-9bab-ee17a1937764,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-e28965d4-339e-42cf-a7ba-f0f8d68f703f,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-789bff15-3e9d-4999-804c-7d01b561527c,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-e73b1b04-ae71-4dfb-8047-454cd5798b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-677b7e00-4f2d-4105-8474-d6deab4dcb85,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-c5dc1d56-ba93-4c07-965c-7222037b71ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-2163a5cd-0932-4b62-a642-957974f99f15,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-aad90d91-5331-46f1-88a9-757cc7000db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058796703-172.17.0.11-1595557909388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34630,DS-34af02bf-7be0-4578-b311-6fee88249de7,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-e804f3a1-123b-4e18-bebb-5c230a58eb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-ec1f26fc-a8d9-46aa-bf83-e7dd886e132e,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-65ff38c2-1faf-45a8-ae69-91e047902a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-9ed663c4-f58f-4139-9f5f-0df2a4297f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-46155cb1-500e-4b5c-9af5-c07ca5b52f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-68663802-4573-4fa8-99e4-928ce583dde1,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-441336b9-9035-483e-b58a-3ea7233bf0e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058796703-172.17.0.11-1595557909388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34630,DS-34af02bf-7be0-4578-b311-6fee88249de7,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-e804f3a1-123b-4e18-bebb-5c230a58eb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-ec1f26fc-a8d9-46aa-bf83-e7dd886e132e,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-65ff38c2-1faf-45a8-ae69-91e047902a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-9ed663c4-f58f-4139-9f5f-0df2a4297f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-46155cb1-500e-4b5c-9af5-c07ca5b52f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-68663802-4573-4fa8-99e4-928ce583dde1,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-441336b9-9035-483e-b58a-3ea7233bf0e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582616635-172.17.0.11-1595558188438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35073,DS-bb65322d-1887-4d47-9b94-1f7e5b3aeb49,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-bc301fb4-788f-470c-b09d-42a9e5365a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-f2ab81dd-9609-4661-a3ed-ea45bed82da6,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-7f984c83-8331-44d4-8e44-2f4d2c180235,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-324440c6-7819-4812-b4db-330118cad805,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-39256e1a-5534-4f49-a0cd-899b03fdb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-cbe1801f-3e96-4e2c-ad3b-d0e91b74ba78,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-10fb78be-6782-4b36-8f4c-b95cef1f4041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582616635-172.17.0.11-1595558188438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35073,DS-bb65322d-1887-4d47-9b94-1f7e5b3aeb49,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-bc301fb4-788f-470c-b09d-42a9e5365a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-f2ab81dd-9609-4661-a3ed-ea45bed82da6,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-7f984c83-8331-44d4-8e44-2f4d2c180235,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-324440c6-7819-4812-b4db-330118cad805,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-39256e1a-5534-4f49-a0cd-899b03fdb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-cbe1801f-3e96-4e2c-ad3b-d0e91b74ba78,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-10fb78be-6782-4b36-8f4c-b95cef1f4041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127840730-172.17.0.11-1595558225444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33343,DS-f9cc33c0-55df-4376-839b-d9d345e8deae,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-4d0374ae-c0c0-410f-b880-2635d4f8fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-b1104840-c56e-47e5-945b-7dd73e7b2811,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-ad23bb99-b324-4718-a047-6e8f365555dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-9e69c049-3c4d-4320-86c7-76757503d6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-fcec0b01-5c91-4ea0-ab11-1f1e70db95bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-93e3314b-8acf-48f7-a930-ebfb5f5c51f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-73587d93-bb2a-438d-817a-9d363419668a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127840730-172.17.0.11-1595558225444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33343,DS-f9cc33c0-55df-4376-839b-d9d345e8deae,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-4d0374ae-c0c0-410f-b880-2635d4f8fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-b1104840-c56e-47e5-945b-7dd73e7b2811,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-ad23bb99-b324-4718-a047-6e8f365555dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-9e69c049-3c4d-4320-86c7-76757503d6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-fcec0b01-5c91-4ea0-ab11-1f1e70db95bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-93e3314b-8acf-48f7-a930-ebfb5f5c51f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-73587d93-bb2a-438d-817a-9d363419668a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987239533-172.17.0.11-1595558439652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-910b0f55-e560-4801-ace1-e1b23d61a8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-b43987f7-48b9-4199-918e-d804b3541da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-c5bd23fd-2733-43d2-b95d-a66f129b5310,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-9836a381-29b6-44ee-bc82-e67f3ed4649a,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-cb5c7239-71fe-4ba0-a9b3-160f24a84cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-9052cefa-efc6-44e6-913d-4820fd41006b,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-ab6827f4-2169-4b99-bc6d-c6948edab9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-80c72774-8b73-438c-8f98-3d79fa39d44c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987239533-172.17.0.11-1595558439652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-910b0f55-e560-4801-ace1-e1b23d61a8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-b43987f7-48b9-4199-918e-d804b3541da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-c5bd23fd-2733-43d2-b95d-a66f129b5310,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-9836a381-29b6-44ee-bc82-e67f3ed4649a,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-cb5c7239-71fe-4ba0-a9b3-160f24a84cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-9052cefa-efc6-44e6-913d-4820fd41006b,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-ab6827f4-2169-4b99-bc6d-c6948edab9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-80c72774-8b73-438c-8f98-3d79fa39d44c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622027635-172.17.0.11-1595558468811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-2cb42892-4405-4a27-baeb-fd3777a72317,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-231343c8-7ce3-4290-aff7-d32fde46a333,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-e1ad0324-0bbd-4eae-8f31-c0277cb79bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-f73c5508-684b-48a1-8e18-5724f839807c,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-1b78165f-2183-4190-b7b9-53733d2969b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-12fc3067-ff5e-4389-a5fb-4fc3a8acddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-07bcb63d-095b-43cf-84ac-0f3739b8e74e,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-471b46f3-0585-470c-81c0-d8caab5a55b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622027635-172.17.0.11-1595558468811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-2cb42892-4405-4a27-baeb-fd3777a72317,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-231343c8-7ce3-4290-aff7-d32fde46a333,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-e1ad0324-0bbd-4eae-8f31-c0277cb79bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-f73c5508-684b-48a1-8e18-5724f839807c,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-1b78165f-2183-4190-b7b9-53733d2969b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-12fc3067-ff5e-4389-a5fb-4fc3a8acddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-07bcb63d-095b-43cf-84ac-0f3739b8e74e,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-471b46f3-0585-470c-81c0-d8caab5a55b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797715567-172.17.0.11-1595559489747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36693,DS-4408eaf1-e93e-464d-bb80-caa53d7bb398,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-2aac14d3-3b04-462c-8af7-faba3f737e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-efccb7d6-33da-4f96-a464-ce95909989b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-82fb24a2-7e8d-462f-8fb0-815c343ccd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-bb6bfca4-cdf1-432b-9ee1-5f9ab5b73f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-20f9fd12-a120-4b73-bd9c-8bfd0db20b94,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-721a5e6b-b457-44c5-b5f2-5cdaa113c872,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-5af4fa6b-1425-4e19-a6b5-c9ddd43a6084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797715567-172.17.0.11-1595559489747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36693,DS-4408eaf1-e93e-464d-bb80-caa53d7bb398,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-2aac14d3-3b04-462c-8af7-faba3f737e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-efccb7d6-33da-4f96-a464-ce95909989b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-82fb24a2-7e8d-462f-8fb0-815c343ccd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-bb6bfca4-cdf1-432b-9ee1-5f9ab5b73f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-20f9fd12-a120-4b73-bd9c-8bfd0db20b94,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-721a5e6b-b457-44c5-b5f2-5cdaa113c872,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-5af4fa6b-1425-4e19-a6b5-c9ddd43a6084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047728478-172.17.0.11-1595559639355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44989,DS-2027674f-0f84-40bd-8e4e-4e5c5d460d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-74842a24-9f49-45a2-b56d-e65817d5667a,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-a3e887eb-44e8-4e59-8ff4-a899e38dce25,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-3ed88a2c-770c-4603-a698-f98a581bc0df,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-0f109141-9401-4702-9dea-4889d935ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-a282e86e-24fe-48ad-985e-1cff15e48b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-d0ac53a0-50b3-4ad2-ad1f-1aeee4f99d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-44dc5498-a7c4-4695-be31-b99a6742e6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047728478-172.17.0.11-1595559639355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44989,DS-2027674f-0f84-40bd-8e4e-4e5c5d460d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-74842a24-9f49-45a2-b56d-e65817d5667a,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-a3e887eb-44e8-4e59-8ff4-a899e38dce25,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-3ed88a2c-770c-4603-a698-f98a581bc0df,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-0f109141-9401-4702-9dea-4889d935ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-a282e86e-24fe-48ad-985e-1cff15e48b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-d0ac53a0-50b3-4ad2-ad1f-1aeee4f99d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-44dc5498-a7c4-4695-be31-b99a6742e6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5354
