reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536722431-172.17.0.13-1595492863474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33981,DS-a51008b3-ce17-498d-8b1e-4e295f448669,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-3ba6cf36-c856-4feb-af83-39af72fd3ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-f0ab32d1-e2fb-4133-8aea-8479507cd87a,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-8c99d66b-2b98-4f11-8b57-1958db2c736b,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-5f6f4d48-a2a3-4ac1-a0e4-15d342ae9f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-ed3ab0e8-b488-4109-acb1-ae97d2034544,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-5662d909-3ada-4aee-92ad-ddb296e9960c,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-b921f9d3-09c7-41e3-a7e8-8227715ff1bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536722431-172.17.0.13-1595492863474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33981,DS-a51008b3-ce17-498d-8b1e-4e295f448669,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-3ba6cf36-c856-4feb-af83-39af72fd3ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-f0ab32d1-e2fb-4133-8aea-8479507cd87a,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-8c99d66b-2b98-4f11-8b57-1958db2c736b,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-5f6f4d48-a2a3-4ac1-a0e4-15d342ae9f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-ed3ab0e8-b488-4109-acb1-ae97d2034544,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-5662d909-3ada-4aee-92ad-ddb296e9960c,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-b921f9d3-09c7-41e3-a7e8-8227715ff1bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946319828-172.17.0.13-1595493283313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34726,DS-6ae5a6a5-23c1-4cc1-a97c-d65f14da913f,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-229dad4a-8f87-46d7-ba9f-8a4757a223e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-eaa613b4-89a6-4c1b-ba4d-78282872b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-9215f315-c395-44fa-a180-206af9b6d3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-db393888-fc06-4aa7-90cd-bc013bccbc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-cb6863d5-90ba-4f7d-b1b5-f19aeeb0c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-e6697590-8f1e-43ec-992d-a856f49dd81e,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-c649dda4-35ad-442f-b6e5-14f7acb185ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946319828-172.17.0.13-1595493283313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34726,DS-6ae5a6a5-23c1-4cc1-a97c-d65f14da913f,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-229dad4a-8f87-46d7-ba9f-8a4757a223e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-eaa613b4-89a6-4c1b-ba4d-78282872b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-9215f315-c395-44fa-a180-206af9b6d3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-db393888-fc06-4aa7-90cd-bc013bccbc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-cb6863d5-90ba-4f7d-b1b5-f19aeeb0c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-e6697590-8f1e-43ec-992d-a856f49dd81e,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-c649dda4-35ad-442f-b6e5-14f7acb185ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803191520-172.17.0.13-1595493544572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-8da4a823-5441-4c17-b2ee-69defa278343,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-5beb633a-ea2b-4531-a7fc-5a35427370a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-5ddcb9d6-7fdc-40b7-be7b-b3950dced682,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-dc191b88-336f-4158-b247-04e1f59c8c22,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-a70dcf61-91dd-4f2e-8b63-3887b60b3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-be102f5b-2a9a-4ccf-b239-5eb5351ddc47,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-bab4635d-84f6-4ac0-98d3-bc676e97a61d,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-03c32b83-fe81-45f2-91d5-ce6cc6b95663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803191520-172.17.0.13-1595493544572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-8da4a823-5441-4c17-b2ee-69defa278343,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-5beb633a-ea2b-4531-a7fc-5a35427370a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-5ddcb9d6-7fdc-40b7-be7b-b3950dced682,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-dc191b88-336f-4158-b247-04e1f59c8c22,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-a70dcf61-91dd-4f2e-8b63-3887b60b3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-be102f5b-2a9a-4ccf-b239-5eb5351ddc47,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-bab4635d-84f6-4ac0-98d3-bc676e97a61d,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-03c32b83-fe81-45f2-91d5-ce6cc6b95663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521089261-172.17.0.13-1595493575393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-fffc18b8-fdcc-46a5-8680-31dd933354df,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-557ae842-aacf-4fad-a09b-753ecff0d23e,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-2aea002b-8f24-4d4d-b201-160063a51241,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-c9dea918-56f6-4fed-ae3d-b4d11a32040b,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-dfda90db-60de-4a7b-8812-08b26b5e3b52,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-a8e814d8-26ec-49c1-a397-4bf0b48f0f55,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-7ede6d81-2d2d-4ef1-908d-b8be9046da99,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-38af95dd-fadd-4d50-865b-c983f435d0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521089261-172.17.0.13-1595493575393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-fffc18b8-fdcc-46a5-8680-31dd933354df,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-557ae842-aacf-4fad-a09b-753ecff0d23e,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-2aea002b-8f24-4d4d-b201-160063a51241,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-c9dea918-56f6-4fed-ae3d-b4d11a32040b,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-dfda90db-60de-4a7b-8812-08b26b5e3b52,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-a8e814d8-26ec-49c1-a397-4bf0b48f0f55,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-7ede6d81-2d2d-4ef1-908d-b8be9046da99,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-38af95dd-fadd-4d50-865b-c983f435d0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288105003-172.17.0.13-1595493645778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42705,DS-fea1ea5a-19ef-4375-8950-5400db5eb1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-71980e7a-7ef9-420f-b007-a88fb09f44e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-2d88e3b1-81d3-4018-99a3-99f619c50e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-c8e0facd-a9bc-4bcb-9f66-5458406f3848,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-fbe200c5-486e-4bda-b409-3da5240acb03,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-7e758801-db3d-4556-9740-03160253c802,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-586770c7-7b4c-4009-9cba-462d6855306c,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-aeef0951-36b7-403a-9fd6-565994e5a5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288105003-172.17.0.13-1595493645778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42705,DS-fea1ea5a-19ef-4375-8950-5400db5eb1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-71980e7a-7ef9-420f-b007-a88fb09f44e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-2d88e3b1-81d3-4018-99a3-99f619c50e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-c8e0facd-a9bc-4bcb-9f66-5458406f3848,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-fbe200c5-486e-4bda-b409-3da5240acb03,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-7e758801-db3d-4556-9740-03160253c802,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-586770c7-7b4c-4009-9cba-462d6855306c,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-aeef0951-36b7-403a-9fd6-565994e5a5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568993676-172.17.0.13-1595493896076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34134,DS-58ad0494-c592-4daf-a40d-234306d786e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-1814f114-a1ae-4f03-b708-b52c53778f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-745030b4-a93e-4b23-81de-f641f34768f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-6f081457-1035-475e-8436-b15cb5744d63,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-a9824c92-a281-41ea-8ac1-fde792e7fa42,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-f10698a4-d1b9-4ed3-9326-ddfff59fe728,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-eb7e4ce4-3fec-4daf-aabb-7f2a36dad15d,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-c91cea64-efe3-4d63-af29-8a18f73b91d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568993676-172.17.0.13-1595493896076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34134,DS-58ad0494-c592-4daf-a40d-234306d786e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-1814f114-a1ae-4f03-b708-b52c53778f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-745030b4-a93e-4b23-81de-f641f34768f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-6f081457-1035-475e-8436-b15cb5744d63,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-a9824c92-a281-41ea-8ac1-fde792e7fa42,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-f10698a4-d1b9-4ed3-9326-ddfff59fe728,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-eb7e4ce4-3fec-4daf-aabb-7f2a36dad15d,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-c91cea64-efe3-4d63-af29-8a18f73b91d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375114563-172.17.0.13-1595494142743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-a8f6b5b8-fd41-47e5-a989-2a7fd8754e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-b70f92f7-8d45-4c10-8e03-fdd530433cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-b9ff0d9e-3302-4292-b114-892a2132329b,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-2fce380e-24ad-4369-aa38-d1bb765f81cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-cc7151c8-6b4c-4919-addf-96c14b9f448d,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-4491948e-0e61-4451-b70b-4fc644c03f88,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-15267ddf-7e25-490f-a34a-2d2417fcef27,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-40ee4acf-bc6b-431c-bd3c-47d5e1b2549a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375114563-172.17.0.13-1595494142743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-a8f6b5b8-fd41-47e5-a989-2a7fd8754e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-b70f92f7-8d45-4c10-8e03-fdd530433cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-b9ff0d9e-3302-4292-b114-892a2132329b,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-2fce380e-24ad-4369-aa38-d1bb765f81cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-cc7151c8-6b4c-4919-addf-96c14b9f448d,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-4491948e-0e61-4451-b70b-4fc644c03f88,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-15267ddf-7e25-490f-a34a-2d2417fcef27,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-40ee4acf-bc6b-431c-bd3c-47d5e1b2549a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380691512-172.17.0.13-1595494555490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-07ab173a-fe13-4d88-8c98-f22b95dae56b,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-83019b50-4295-45a7-947e-86d256372c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-577a3208-edf4-4fce-b970-e6d29b447da4,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-d6eca506-f068-4d9a-9a3f-ec0203d5f4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-619e13d3-32ee-4ef5-be9d-459b20af3a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-d965efb6-6a2d-4d5e-90cc-c1649351b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-ab4ee864-d00d-4d0d-bba2-752d5ce83bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-48a5efa7-9295-4002-99d9-ff50a49fcd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380691512-172.17.0.13-1595494555490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-07ab173a-fe13-4d88-8c98-f22b95dae56b,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-83019b50-4295-45a7-947e-86d256372c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-577a3208-edf4-4fce-b970-e6d29b447da4,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-d6eca506-f068-4d9a-9a3f-ec0203d5f4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-619e13d3-32ee-4ef5-be9d-459b20af3a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-d965efb6-6a2d-4d5e-90cc-c1649351b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-ab4ee864-d00d-4d0d-bba2-752d5ce83bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-48a5efa7-9295-4002-99d9-ff50a49fcd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989115921-172.17.0.13-1595495652438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-45ebf675-ca01-469e-a843-b14b10c91ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-14d360cd-1837-4c10-ace3-7833a9a154c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-cd02f752-418b-4d97-919e-555876678f21,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-de301848-d3c3-4dc5-89f9-41f96a640413,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-50b72161-0308-4af4-9105-fda60beb4b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-a83272a5-90a2-4f55-8877-a79db9485513,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-62b4949b-6ab4-4657-80c1-7d99c354947d,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-2d920098-dd86-4515-a55d-398c111871d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989115921-172.17.0.13-1595495652438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-45ebf675-ca01-469e-a843-b14b10c91ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-14d360cd-1837-4c10-ace3-7833a9a154c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-cd02f752-418b-4d97-919e-555876678f21,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-de301848-d3c3-4dc5-89f9-41f96a640413,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-50b72161-0308-4af4-9105-fda60beb4b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-a83272a5-90a2-4f55-8877-a79db9485513,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-62b4949b-6ab4-4657-80c1-7d99c354947d,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-2d920098-dd86-4515-a55d-398c111871d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779244622-172.17.0.13-1595495834099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-4db6f5bb-8abd-456d-9592-2b88607a53fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-b12bcb76-6ead-4603-a9b9-f0b966d0bfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-838cf5c5-a3e7-4f59-bd30-c2a0bc03ad58,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-040ef60c-8f31-4466-bec1-435d1eeb3cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-256666d8-2af2-4ff5-bccc-4fe3bc07f543,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-6dfad9bf-476c-43bc-9ab9-e486510cb822,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-b06236c5-41e7-440e-816f-33943d7ec52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-16f50a6c-4df8-4bf6-a277-0ffad38226f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779244622-172.17.0.13-1595495834099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-4db6f5bb-8abd-456d-9592-2b88607a53fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-b12bcb76-6ead-4603-a9b9-f0b966d0bfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-838cf5c5-a3e7-4f59-bd30-c2a0bc03ad58,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-040ef60c-8f31-4466-bec1-435d1eeb3cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-256666d8-2af2-4ff5-bccc-4fe3bc07f543,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-6dfad9bf-476c-43bc-9ab9-e486510cb822,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-b06236c5-41e7-440e-816f-33943d7ec52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-16f50a6c-4df8-4bf6-a277-0ffad38226f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626167170-172.17.0.13-1595496140873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40868,DS-4908588d-3949-4464-ae76-95980642797c,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-62a7a9ab-0443-4182-a625-e02f73224f90,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-3e26a18a-cd44-4027-aa48-ec409420b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-536a6951-7774-48b2-8f12-c3b9aeeb8d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-6bc7028f-6fae-4d43-b3f4-35942af6c93e,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-beffa698-3889-4f8a-bdd5-d69f96832ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-b78ca557-a75b-4160-ad29-3f7f05516475,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-c804bfac-ff80-46da-97a9-6eff4b9693c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626167170-172.17.0.13-1595496140873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40868,DS-4908588d-3949-4464-ae76-95980642797c,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-62a7a9ab-0443-4182-a625-e02f73224f90,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-3e26a18a-cd44-4027-aa48-ec409420b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-536a6951-7774-48b2-8f12-c3b9aeeb8d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-6bc7028f-6fae-4d43-b3f4-35942af6c93e,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-beffa698-3889-4f8a-bdd5-d69f96832ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-b78ca557-a75b-4160-ad29-3f7f05516475,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-c804bfac-ff80-46da-97a9-6eff4b9693c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482025080-172.17.0.13-1595496286074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-1a1fb932-a4ec-4851-9faf-21591cb7e036,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-27ed9e50-4a9f-4db8-b1b4-9ca6fb87432f,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-e522014f-b81f-4e93-bde0-4e76f0782383,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-bfa44ee3-8c05-4c2d-9d7f-a6795982fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-1fa42d00-b546-4ba5-9f33-6f92f4c3654e,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-1b39d002-5796-4bb1-9014-cdc44776210b,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-661a2ad4-2f70-440c-9b1f-316739096d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-4583a3cc-ac78-4957-9349-aa05ecc8e455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482025080-172.17.0.13-1595496286074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-1a1fb932-a4ec-4851-9faf-21591cb7e036,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-27ed9e50-4a9f-4db8-b1b4-9ca6fb87432f,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-e522014f-b81f-4e93-bde0-4e76f0782383,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-bfa44ee3-8c05-4c2d-9d7f-a6795982fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-1fa42d00-b546-4ba5-9f33-6f92f4c3654e,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-1b39d002-5796-4bb1-9014-cdc44776210b,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-661a2ad4-2f70-440c-9b1f-316739096d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-4583a3cc-ac78-4957-9349-aa05ecc8e455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250107077-172.17.0.13-1595496319279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-202acf48-199b-4ac9-bf85-c4c062218d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-f3b8e4a1-3740-416c-8732-cea1a00532c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-32d5f7a6-e3e1-4c4f-a61f-7a72db08090b,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-8c76634b-1bc4-45f6-a7fc-57d041ab683b,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-9cf33c05-ddac-4404-9319-88c7a978c098,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-de4f18f8-c19d-4b2a-9454-78f31cb92276,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-db9af6ac-72f2-4168-89b9-cb43d19aaa84,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-c67d1a1c-0ffa-4d81-ae7c-21383bf5ff68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250107077-172.17.0.13-1595496319279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-202acf48-199b-4ac9-bf85-c4c062218d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-f3b8e4a1-3740-416c-8732-cea1a00532c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-32d5f7a6-e3e1-4c4f-a61f-7a72db08090b,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-8c76634b-1bc4-45f6-a7fc-57d041ab683b,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-9cf33c05-ddac-4404-9319-88c7a978c098,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-de4f18f8-c19d-4b2a-9454-78f31cb92276,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-db9af6ac-72f2-4168-89b9-cb43d19aaa84,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-c67d1a1c-0ffa-4d81-ae7c-21383bf5ff68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757099558-172.17.0.13-1595496360418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-d0a9d483-cfab-4871-8823-fa691dc50a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-dee42736-c0e1-43c2-8ab4-fc21453cc543,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-4cb5ba41-e307-4ff7-a633-518b6b3fa9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-0f44d48f-6d73-4012-ae06-243cb05cfafb,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-04ae5425-e225-435a-847a-df0f2787f895,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-c04135d0-c33b-4a5b-b525-873cf2df2298,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-da0aea21-6d50-4d0c-9471-671823b12e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-b09193b3-85a7-4eb8-80a8-ffbd214af704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757099558-172.17.0.13-1595496360418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-d0a9d483-cfab-4871-8823-fa691dc50a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-dee42736-c0e1-43c2-8ab4-fc21453cc543,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-4cb5ba41-e307-4ff7-a633-518b6b3fa9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-0f44d48f-6d73-4012-ae06-243cb05cfafb,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-04ae5425-e225-435a-847a-df0f2787f895,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-c04135d0-c33b-4a5b-b525-873cf2df2298,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-da0aea21-6d50-4d0c-9471-671823b12e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-b09193b3-85a7-4eb8-80a8-ffbd214af704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37506611-172.17.0.13-1595496429606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-3fa5b8bf-0550-4eb9-8715-20ed6ff9d97b,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-1000d381-6a33-4efc-a791-0fa76b9efa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-6d7fe099-d713-4751-b18b-2ec60075f3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-3ebe3a7a-5102-40e7-a40a-94f08bf2bcce,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-c26471c2-10c7-4837-9b1f-3b232f3509bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-0f6fd984-37d8-476d-9f8e-4e44b65c50b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-289166ae-94e3-478a-9d23-b14480310d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-0366c37d-1377-47e4-bc3e-a81df92fc7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37506611-172.17.0.13-1595496429606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-3fa5b8bf-0550-4eb9-8715-20ed6ff9d97b,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-1000d381-6a33-4efc-a791-0fa76b9efa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-6d7fe099-d713-4751-b18b-2ec60075f3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-3ebe3a7a-5102-40e7-a40a-94f08bf2bcce,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-c26471c2-10c7-4837-9b1f-3b232f3509bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-0f6fd984-37d8-476d-9f8e-4e44b65c50b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-289166ae-94e3-478a-9d23-b14480310d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-0366c37d-1377-47e4-bc3e-a81df92fc7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238734548-172.17.0.13-1595497595777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-966bfd36-aa27-4550-885a-e6cc5997e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-17cf5134-335a-4d1b-99d8-f68af10fb707,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-ced8ed0a-1f12-4c8d-bcc0-c29e47703e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-0c715618-52d1-4539-9b64-87e13da163e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-47e5c6bc-e767-42c0-9aa3-b6b75f07d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-2a4ed587-3f93-40fd-b78a-f05b68f40b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-2fe7b9b7-5021-46c2-8556-c679a3ee7fea,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-c6d5ad0c-7ff8-45f6-9e2a-916cc69f8489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238734548-172.17.0.13-1595497595777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-966bfd36-aa27-4550-885a-e6cc5997e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-17cf5134-335a-4d1b-99d8-f68af10fb707,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-ced8ed0a-1f12-4c8d-bcc0-c29e47703e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-0c715618-52d1-4539-9b64-87e13da163e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-47e5c6bc-e767-42c0-9aa3-b6b75f07d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-2a4ed587-3f93-40fd-b78a-f05b68f40b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-2fe7b9b7-5021-46c2-8556-c679a3ee7fea,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-c6d5ad0c-7ff8-45f6-9e2a-916cc69f8489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5336
