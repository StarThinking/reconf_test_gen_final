reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669292618-172.17.0.21-1595699407538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-048fca5d-ef77-4946-8b1b-a6178fe7c062,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-eeff1ef3-2200-4b14-afe1-a59a52c0f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-6188e85a-fd0d-4397-9298-4debe18f6468,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-0f679102-1669-40bc-a77c-9f9f40d40d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-9630700f-309a-4738-9542-6d87ac5faa55,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-4ca6406e-d46b-48b9-84d0-4f9953693b86,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-b3871f4e-b996-40b5-b7dc-7d73a7c5ff54,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-dcb14d12-079b-47f1-8bba-fb88218804f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669292618-172.17.0.21-1595699407538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-048fca5d-ef77-4946-8b1b-a6178fe7c062,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-eeff1ef3-2200-4b14-afe1-a59a52c0f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-6188e85a-fd0d-4397-9298-4debe18f6468,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-0f679102-1669-40bc-a77c-9f9f40d40d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-9630700f-309a-4738-9542-6d87ac5faa55,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-4ca6406e-d46b-48b9-84d0-4f9953693b86,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-b3871f4e-b996-40b5-b7dc-7d73a7c5ff54,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-dcb14d12-079b-47f1-8bba-fb88218804f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284069154-172.17.0.21-1595699671856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44264,DS-6508e809-7bf4-4b63-a01b-4c00a72daec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-5854c06e-a4b5-4227-b3e8-9ea20c8a61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-db6186c9-65e6-487e-8cb8-9e543d8d9712,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-4a752ab2-d3b3-49ee-bef4-0b9f8b9976d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-ba18a07c-f74b-4e75-b9b3-8fcda64a8dec,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-d6524cf8-d2c4-4c05-a04c-31df5819b589,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-813d5712-984d-4cfa-b3ac-fb95bc127eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-ba5e4f25-b7ed-4589-a1c9-9fe259b9e9e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284069154-172.17.0.21-1595699671856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44264,DS-6508e809-7bf4-4b63-a01b-4c00a72daec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-5854c06e-a4b5-4227-b3e8-9ea20c8a61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-db6186c9-65e6-487e-8cb8-9e543d8d9712,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-4a752ab2-d3b3-49ee-bef4-0b9f8b9976d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-ba18a07c-f74b-4e75-b9b3-8fcda64a8dec,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-d6524cf8-d2c4-4c05-a04c-31df5819b589,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-813d5712-984d-4cfa-b3ac-fb95bc127eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-ba5e4f25-b7ed-4589-a1c9-9fe259b9e9e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464707024-172.17.0.21-1595699772168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-4db76dc6-9f0c-48dc-9c2d-32463c9140c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-9980cfd9-a22c-427a-add0-721fd1083e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-8ef02d7a-6850-4531-ae79-414c3a7e0b41,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-af3ad9b4-3c1b-4657-a61f-8ae4439976c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-98b61219-a087-4134-8ad7-bab24d7332aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-bdd28df9-9807-49c8-8e49-4e6fa07b710c,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-cbdc5f4c-671d-41e1-aa42-759c1fb92381,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-d39af625-df15-423e-bdc2-422e645f8160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464707024-172.17.0.21-1595699772168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-4db76dc6-9f0c-48dc-9c2d-32463c9140c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-9980cfd9-a22c-427a-add0-721fd1083e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-8ef02d7a-6850-4531-ae79-414c3a7e0b41,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-af3ad9b4-3c1b-4657-a61f-8ae4439976c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-98b61219-a087-4134-8ad7-bab24d7332aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-bdd28df9-9807-49c8-8e49-4e6fa07b710c,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-cbdc5f4c-671d-41e1-aa42-759c1fb92381,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-d39af625-df15-423e-bdc2-422e645f8160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700195097-172.17.0.21-1595699871520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-8e210f4b-1572-4559-aee1-7cbdf7864453,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-3c46ab83-0a1f-496f-a42d-212e03669a37,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-d0dc2e09-a3cf-44bf-9a54-be6cb80e815f,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-f514a1a8-0a82-4441-83be-d5c041d5bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-3fd01218-62cc-40a7-a56d-e7eff2453e79,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-62922d8e-f76d-4d28-bc60-897f130bd964,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-60813a1e-6bcd-4035-b81c-1876287afa65,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-ed85d581-0840-4e90-b8d4-3a81e38163fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700195097-172.17.0.21-1595699871520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-8e210f4b-1572-4559-aee1-7cbdf7864453,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-3c46ab83-0a1f-496f-a42d-212e03669a37,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-d0dc2e09-a3cf-44bf-9a54-be6cb80e815f,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-f514a1a8-0a82-4441-83be-d5c041d5bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-3fd01218-62cc-40a7-a56d-e7eff2453e79,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-62922d8e-f76d-4d28-bc60-897f130bd964,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-60813a1e-6bcd-4035-b81c-1876287afa65,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-ed85d581-0840-4e90-b8d4-3a81e38163fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571131729-172.17.0.21-1595699995797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-de73cedf-aced-4f85-86d5-069afc7ec53f,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-069d81f1-00cb-48e0-bde2-e2c9355c2a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-531c7df4-f97c-4c15-8d80-187b08f966d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-1a9c9637-2221-40be-a22b-887ef92a9ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-2d20aa39-b3d5-452c-bc36-cbaa41a9e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-1e050101-569c-4fa0-80dc-347f104faf54,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-88f4bca2-e1b4-4fe2-9172-642a9f875c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-f3c6e37c-fd1d-4840-b78e-5e2ca48f9c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571131729-172.17.0.21-1595699995797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-de73cedf-aced-4f85-86d5-069afc7ec53f,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-069d81f1-00cb-48e0-bde2-e2c9355c2a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-531c7df4-f97c-4c15-8d80-187b08f966d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-1a9c9637-2221-40be-a22b-887ef92a9ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-2d20aa39-b3d5-452c-bc36-cbaa41a9e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-1e050101-569c-4fa0-80dc-347f104faf54,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-88f4bca2-e1b4-4fe2-9172-642a9f875c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-f3c6e37c-fd1d-4840-b78e-5e2ca48f9c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332974977-172.17.0.21-1595700372258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39872,DS-72567aed-6ff2-483d-9a7b-8ca6a52df74f,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-33081c25-9f0e-48d6-97c1-5df4b21ea01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-adae6eeb-83a3-4f35-bc46-262c727f8656,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-8f22d8a5-93f2-4e53-af53-6e1ffc02886a,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-f1016c71-e46b-4140-a171-d43c44afb9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-fb9959dd-1f53-4381-ad53-1798dbe9b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-10c81b74-04ea-45f1-9e2e-db5c67fff8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-cf61ae62-7504-42ad-9c28-5fd267f97c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332974977-172.17.0.21-1595700372258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39872,DS-72567aed-6ff2-483d-9a7b-8ca6a52df74f,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-33081c25-9f0e-48d6-97c1-5df4b21ea01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-adae6eeb-83a3-4f35-bc46-262c727f8656,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-8f22d8a5-93f2-4e53-af53-6e1ffc02886a,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-f1016c71-e46b-4140-a171-d43c44afb9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-fb9959dd-1f53-4381-ad53-1798dbe9b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-10c81b74-04ea-45f1-9e2e-db5c67fff8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-cf61ae62-7504-42ad-9c28-5fd267f97c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41175409-172.17.0.21-1595700477975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33980,DS-24bfac6e-199b-4454-9608-70326d309e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-215df0b8-8ecd-4f92-b9f6-b9d5d577bd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-2a684851-83e6-4d77-b800-c4dcf8ed53cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-eb8282c3-3df2-4e77-ad9e-891b3c08018b,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-7b41a2ef-1337-47ba-8ed1-7527271468a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-15871e6c-33c5-44c3-9be5-a859d927583c,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-79c04ea6-3042-4236-ac6e-8096f4cfe4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-167534ea-01e0-413e-9bb6-2b767790d8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41175409-172.17.0.21-1595700477975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33980,DS-24bfac6e-199b-4454-9608-70326d309e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-215df0b8-8ecd-4f92-b9f6-b9d5d577bd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-2a684851-83e6-4d77-b800-c4dcf8ed53cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-eb8282c3-3df2-4e77-ad9e-891b3c08018b,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-7b41a2ef-1337-47ba-8ed1-7527271468a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-15871e6c-33c5-44c3-9be5-a859d927583c,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-79c04ea6-3042-4236-ac6e-8096f4cfe4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-167534ea-01e0-413e-9bb6-2b767790d8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946606186-172.17.0.21-1595700611492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39339,DS-af9df79e-fefb-49fd-ac65-88946b791604,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-8068cf72-aead-458e-83ec-7b65c47d3449,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-933c4f25-c83d-4b48-b490-aa49315aaf36,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-2e85c57f-be65-496e-98eb-345671433055,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-d6e17e8e-52b0-45fc-80c5-624ff0adc66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-0d05cc1a-abe2-44d8-b3c4-3794c6123b07,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-86cba8b6-0f81-4735-801e-8709c315fd78,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-f0626060-5ea0-4726-a03b-e10601bb00d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946606186-172.17.0.21-1595700611492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39339,DS-af9df79e-fefb-49fd-ac65-88946b791604,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-8068cf72-aead-458e-83ec-7b65c47d3449,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-933c4f25-c83d-4b48-b490-aa49315aaf36,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-2e85c57f-be65-496e-98eb-345671433055,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-d6e17e8e-52b0-45fc-80c5-624ff0adc66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-0d05cc1a-abe2-44d8-b3c4-3794c6123b07,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-86cba8b6-0f81-4735-801e-8709c315fd78,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-f0626060-5ea0-4726-a03b-e10601bb00d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303671070-172.17.0.21-1595700707174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-2b42568a-bc9f-409e-82ba-3399d16f69d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-36e107b5-44b1-44cc-92a5-9b1d06f2d8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-369960b8-cb80-4d7c-af5f-2465d56dc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-9340d384-ba62-4c02-91b4-5627812bac0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-1e3f151f-cca0-421f-9cd0-37ac34eeccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-caa53932-3a5f-47b6-a175-330ccf89abbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-2855d375-9702-4f89-88e0-5ecf7208de10,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-1ed46fbc-32eb-4c7a-b459-6982b41b0c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303671070-172.17.0.21-1595700707174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-2b42568a-bc9f-409e-82ba-3399d16f69d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-36e107b5-44b1-44cc-92a5-9b1d06f2d8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-369960b8-cb80-4d7c-af5f-2465d56dc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-9340d384-ba62-4c02-91b4-5627812bac0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-1e3f151f-cca0-421f-9cd0-37ac34eeccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-caa53932-3a5f-47b6-a175-330ccf89abbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-2855d375-9702-4f89-88e0-5ecf7208de10,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-1ed46fbc-32eb-4c7a-b459-6982b41b0c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842699079-172.17.0.21-1595701085588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-0bbd1929-2370-4c77-9b5f-f7c5592f5642,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-752657b6-6998-42e0-990e-b1f226f6b081,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-1e3a83a7-b9d6-4c30-9ff9-7313821b930f,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-a2ee38c9-f0c1-40c4-9309-f066ff9e03eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-a359709b-00f6-4d9c-930a-ded2fa80c7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-d243c52f-9a25-4b2c-ac33-2b836ad2f8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-f895e67f-8a83-474e-9562-d2fb16132473,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-2915bf50-ec4e-43d8-a4e6-17dd3f0af4ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842699079-172.17.0.21-1595701085588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-0bbd1929-2370-4c77-9b5f-f7c5592f5642,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-752657b6-6998-42e0-990e-b1f226f6b081,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-1e3a83a7-b9d6-4c30-9ff9-7313821b930f,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-a2ee38c9-f0c1-40c4-9309-f066ff9e03eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-a359709b-00f6-4d9c-930a-ded2fa80c7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-d243c52f-9a25-4b2c-ac33-2b836ad2f8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-f895e67f-8a83-474e-9562-d2fb16132473,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-2915bf50-ec4e-43d8-a4e6-17dd3f0af4ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145489381-172.17.0.21-1595701118847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-b1f5d411-5c99-47bd-8add-fc891a21f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-72dee79d-558c-4160-a734-1bc173825646,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-f6eb9501-0199-4032-af73-7b553760a4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-1de96335-cb2d-4eb7-8a95-45237b10a456,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-82f0f6f1-be09-44e2-b549-4ea6b2541ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-f9989d59-3ff7-4963-8c66-d8f4f3c02fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-1af13831-9a10-4bf1-9def-d05d5a6113ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-ce0724d9-d860-4268-82b7-c8d8395adee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145489381-172.17.0.21-1595701118847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-b1f5d411-5c99-47bd-8add-fc891a21f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-72dee79d-558c-4160-a734-1bc173825646,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-f6eb9501-0199-4032-af73-7b553760a4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-1de96335-cb2d-4eb7-8a95-45237b10a456,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-82f0f6f1-be09-44e2-b549-4ea6b2541ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-f9989d59-3ff7-4963-8c66-d8f4f3c02fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-1af13831-9a10-4bf1-9def-d05d5a6113ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-ce0724d9-d860-4268-82b7-c8d8395adee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61324879-172.17.0.21-1595703070584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39025,DS-0835a8fe-d80d-417a-b693-73811172c27c,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-aced8dea-f618-4e14-94c2-35a93e78142e,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-206909f5-9b21-478e-8d9e-ea87b7184699,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-83084dee-1a20-466d-87e9-6f6d0c2e9360,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-74b33c7b-a1b1-4e79-a9d8-3991bd558bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-22deea78-5d3c-44bb-9caf-3a0665ac003d,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-e58358d8-c986-4e34-a512-6a9a763cd515,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-34aff062-66f4-4349-88cf-24d396b5a79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61324879-172.17.0.21-1595703070584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39025,DS-0835a8fe-d80d-417a-b693-73811172c27c,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-aced8dea-f618-4e14-94c2-35a93e78142e,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-206909f5-9b21-478e-8d9e-ea87b7184699,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-83084dee-1a20-466d-87e9-6f6d0c2e9360,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-74b33c7b-a1b1-4e79-a9d8-3991bd558bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-22deea78-5d3c-44bb-9caf-3a0665ac003d,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-e58358d8-c986-4e34-a512-6a9a763cd515,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-34aff062-66f4-4349-88cf-24d396b5a79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155871374-172.17.0.21-1595703344365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-f2234f7f-82fd-4753-9526-871d347793f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-013e9c0e-9722-4262-86ff-e8a5596f5e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-7ae18216-1cdf-4b71-9ac8-533637c9e112,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-3ded17e8-fee0-4553-9aa0-e5f1c85858ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-521db02f-b0ca-4cf2-86f6-ab9f876c9207,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-50e91cf4-5689-415b-bc83-f0cc2f4621b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-260a42ed-b5bd-49d3-b523-c8c512a9b943,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-1868a68a-8a43-4b9f-acfd-da483834b903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155871374-172.17.0.21-1595703344365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-f2234f7f-82fd-4753-9526-871d347793f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-013e9c0e-9722-4262-86ff-e8a5596f5e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-7ae18216-1cdf-4b71-9ac8-533637c9e112,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-3ded17e8-fee0-4553-9aa0-e5f1c85858ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-521db02f-b0ca-4cf2-86f6-ab9f876c9207,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-50e91cf4-5689-415b-bc83-f0cc2f4621b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-260a42ed-b5bd-49d3-b523-c8c512a9b943,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-1868a68a-8a43-4b9f-acfd-da483834b903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340263547-172.17.0.21-1595703449776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-07b0fab1-597d-4b6b-a6c7-228b6647e82b,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-76e2ec11-9906-4837-a33d-fbb3f7ca125d,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-a29aefc7-498f-425d-80e7-b7cecc5a69b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-b3f08b25-2724-4c57-877a-1394ac5a0864,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-30bad709-2f67-4e7c-ba2d-32fd1336d20d,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-d39c4dce-5402-41f7-a591-855c26ef1f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-c248040d-0a4a-42b8-8a4b-2209472509d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-441ed25c-d68f-4c41-a2a3-20df7167712c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340263547-172.17.0.21-1595703449776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-07b0fab1-597d-4b6b-a6c7-228b6647e82b,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-76e2ec11-9906-4837-a33d-fbb3f7ca125d,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-a29aefc7-498f-425d-80e7-b7cecc5a69b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-b3f08b25-2724-4c57-877a-1394ac5a0864,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-30bad709-2f67-4e7c-ba2d-32fd1336d20d,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-d39c4dce-5402-41f7-a591-855c26ef1f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-c248040d-0a4a-42b8-8a4b-2209472509d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-441ed25c-d68f-4c41-a2a3-20df7167712c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294724152-172.17.0.21-1595704213007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43582,DS-b710c9ca-45ee-472f-802e-651862ab49e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-f760862c-d0ff-4ff8-a7ab-338a5a313f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-68bfcd30-7c61-4071-929a-1e7c5de83efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-deca513b-dd94-426f-b853-9772985b6d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-0b9aafa9-9761-46f2-a08f-cd02db656da2,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-3761c911-7497-4efb-9db8-dd0952322329,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-73aa9e3d-b877-490a-b2a8-6e3a4c2c6749,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-f88878bd-402d-4608-b69c-d463f6779131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294724152-172.17.0.21-1595704213007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43582,DS-b710c9ca-45ee-472f-802e-651862ab49e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-f760862c-d0ff-4ff8-a7ab-338a5a313f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-68bfcd30-7c61-4071-929a-1e7c5de83efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-deca513b-dd94-426f-b853-9772985b6d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-0b9aafa9-9761-46f2-a08f-cd02db656da2,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-3761c911-7497-4efb-9db8-dd0952322329,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-73aa9e3d-b877-490a-b2a8-6e3a4c2c6749,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-f88878bd-402d-4608-b69c-d463f6779131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5230
