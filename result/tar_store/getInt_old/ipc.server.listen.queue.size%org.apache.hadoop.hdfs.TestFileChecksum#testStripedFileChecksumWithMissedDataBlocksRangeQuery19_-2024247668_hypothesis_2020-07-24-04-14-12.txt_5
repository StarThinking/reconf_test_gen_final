reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538782540-172.17.0.8-1595564164351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-8aefe039-9a22-4f30-9db1-ff8dc6248763,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-109ddeea-320d-4dc6-8ea2-3d12d6d78828,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-785e496c-85ff-45de-b9af-d55c06fb129a,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-07d3cb9e-5499-4046-a8d2-f2b3a023198a,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-64e0077b-6847-40d0-9a38-f0cc4cdc201f,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-00b6ca90-1ddc-4404-9d72-cdf39c4f678d,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-331a05c1-34f1-4536-a6ac-a1c58f31ca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-b04a19c9-a03d-4b87-98fc-f0e83b96aa2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538782540-172.17.0.8-1595564164351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-8aefe039-9a22-4f30-9db1-ff8dc6248763,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-109ddeea-320d-4dc6-8ea2-3d12d6d78828,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-785e496c-85ff-45de-b9af-d55c06fb129a,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-07d3cb9e-5499-4046-a8d2-f2b3a023198a,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-64e0077b-6847-40d0-9a38-f0cc4cdc201f,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-00b6ca90-1ddc-4404-9d72-cdf39c4f678d,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-331a05c1-34f1-4536-a6ac-a1c58f31ca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-b04a19c9-a03d-4b87-98fc-f0e83b96aa2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577757921-172.17.0.8-1595564893316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-a2e20d26-cb01-4c7a-9d61-a0f23e07c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-1fc6912f-a298-4b80-9fea-acf99acab0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ba3f9ffd-0f52-4096-8fe9-c7d810b5bfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-5d63638b-3c8b-4b48-b27f-37ce1f2b4ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-b558e3dc-3095-43e9-bbf5-3a7dbb8bd8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-1b6ecd69-f525-4331-b460-aa4c2368e4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-26a6a92d-4153-4457-be5b-f8e84d04accf,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-36c3225c-f81f-4674-ad4a-48daead44ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577757921-172.17.0.8-1595564893316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-a2e20d26-cb01-4c7a-9d61-a0f23e07c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-1fc6912f-a298-4b80-9fea-acf99acab0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ba3f9ffd-0f52-4096-8fe9-c7d810b5bfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-5d63638b-3c8b-4b48-b27f-37ce1f2b4ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-b558e3dc-3095-43e9-bbf5-3a7dbb8bd8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-1b6ecd69-f525-4331-b460-aa4c2368e4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-26a6a92d-4153-4457-be5b-f8e84d04accf,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-36c3225c-f81f-4674-ad4a-48daead44ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103165522-172.17.0.8-1595565080301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-e427c0b9-d484-4622-8888-d076f67764fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a186d6e2-d373-4c3c-9506-714af1f25a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-4c8822b9-abf2-41cd-b7d6-f1f84b819e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-bad145cf-625a-4cdc-91eb-226e79fde594,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-463e9362-c469-4897-9629-eb81eeb3c39e,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-821971e1-3843-488f-a9dc-6c6af604ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-bbb5de93-da3c-48d5-aaf2-a9000ab814fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-4f7e82e5-d212-4c87-9b61-efea77024208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103165522-172.17.0.8-1595565080301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-e427c0b9-d484-4622-8888-d076f67764fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a186d6e2-d373-4c3c-9506-714af1f25a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-4c8822b9-abf2-41cd-b7d6-f1f84b819e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-bad145cf-625a-4cdc-91eb-226e79fde594,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-463e9362-c469-4897-9629-eb81eeb3c39e,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-821971e1-3843-488f-a9dc-6c6af604ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-bbb5de93-da3c-48d5-aaf2-a9000ab814fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-4f7e82e5-d212-4c87-9b61-efea77024208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602708609-172.17.0.8-1595565376279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42613,DS-c1c261a0-12b1-4e19-9598-d859aaed2fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-31ad8e19-1217-4453-889f-58bf838018fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-492c3c4c-b338-49c1-ab59-c5f678c175ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-283acf49-617f-4b41-abd9-bfeddfb24f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-9368043c-2ede-4bd9-9a91-03167e655482,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-a37e073b-2a75-4e07-80bf-ef87d6ffa2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-eb60300b-ada9-4f1f-bc93-5a845cd6b321,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-c8e3e111-a8d3-4a67-9f9f-aad365cdb844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602708609-172.17.0.8-1595565376279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42613,DS-c1c261a0-12b1-4e19-9598-d859aaed2fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-31ad8e19-1217-4453-889f-58bf838018fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-492c3c4c-b338-49c1-ab59-c5f678c175ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-283acf49-617f-4b41-abd9-bfeddfb24f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-9368043c-2ede-4bd9-9a91-03167e655482,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-a37e073b-2a75-4e07-80bf-ef87d6ffa2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-eb60300b-ada9-4f1f-bc93-5a845cd6b321,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-c8e3e111-a8d3-4a67-9f9f-aad365cdb844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969662757-172.17.0.8-1595566172177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36033,DS-d02e9080-b36f-4f7f-a45b-1b3fb9ba19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-17e38fd4-28f4-46c5-80aa-28826e44336a,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-f1e8c188-4a2f-4a52-88eb-f3ec30611bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-476067b6-9c75-4b23-b734-aba2d3f97fde,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-7bce1d4e-c90c-42d1-be31-318046fbe7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-5dca8be1-1256-40f8-80fa-9592989b15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-4f48baf6-7268-4f52-9c0f-aef41b9918a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7035def8-b365-4c1f-b5ee-20c2d6edff79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969662757-172.17.0.8-1595566172177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36033,DS-d02e9080-b36f-4f7f-a45b-1b3fb9ba19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-17e38fd4-28f4-46c5-80aa-28826e44336a,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-f1e8c188-4a2f-4a52-88eb-f3ec30611bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-476067b6-9c75-4b23-b734-aba2d3f97fde,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-7bce1d4e-c90c-42d1-be31-318046fbe7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-5dca8be1-1256-40f8-80fa-9592989b15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-4f48baf6-7268-4f52-9c0f-aef41b9918a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-7035def8-b365-4c1f-b5ee-20c2d6edff79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184139656-172.17.0.8-1595566268420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-bcaea999-9b0e-418d-91e3-a62b8015b1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-2d28a77b-cef6-45ff-877f-0d851c04faca,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-491abbb9-fb4e-49f3-ada4-32c278878afa,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-693216c6-bd14-489b-b52b-d5d28f27f775,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-0bccc722-389a-409f-b76b-58f7ca19067e,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-2de16666-fc3c-4a2d-a8c2-b39231d9bb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-bcbce6dd-4117-4e15-871a-8042277bae02,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-db010390-3191-43ce-a11c-de0878d43009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184139656-172.17.0.8-1595566268420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-bcaea999-9b0e-418d-91e3-a62b8015b1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-2d28a77b-cef6-45ff-877f-0d851c04faca,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-491abbb9-fb4e-49f3-ada4-32c278878afa,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-693216c6-bd14-489b-b52b-d5d28f27f775,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-0bccc722-389a-409f-b76b-58f7ca19067e,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-2de16666-fc3c-4a2d-a8c2-b39231d9bb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-bcbce6dd-4117-4e15-871a-8042277bae02,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-db010390-3191-43ce-a11c-de0878d43009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076825070-172.17.0.8-1595566438211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40197,DS-2595b306-d114-4cdd-84f8-d839621c0653,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-970ad68d-01bd-400d-9e9c-1e7e0999d531,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-c20e4363-eba7-448a-b34c-37b8969ef39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-e46a5785-ccd6-40b2-867c-bc1f1591fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-06f3523a-e971-49c6-8500-78aa9e3e1ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-851936cc-9ad0-4334-bd4d-f6a7af01ef56,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-1ee5497d-2d6b-4b89-abd6-6f3b26833053,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-a011167c-d611-4dee-b642-1e0c53668500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076825070-172.17.0.8-1595566438211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40197,DS-2595b306-d114-4cdd-84f8-d839621c0653,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-970ad68d-01bd-400d-9e9c-1e7e0999d531,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-c20e4363-eba7-448a-b34c-37b8969ef39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-e46a5785-ccd6-40b2-867c-bc1f1591fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-06f3523a-e971-49c6-8500-78aa9e3e1ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-851936cc-9ad0-4334-bd4d-f6a7af01ef56,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-1ee5497d-2d6b-4b89-abd6-6f3b26833053,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-a011167c-d611-4dee-b642-1e0c53668500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279329993-172.17.0.8-1595566719661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38979,DS-255944a8-b57d-4803-9398-6425d5246368,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-81043d9f-d09a-4826-9fcf-c4a9927c4200,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-0c62e592-44f9-450e-8037-c9b5a4ceeff4,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-96a0a29b-1401-459e-9fbd-d0462d09fe69,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-72465399-3d0d-4453-8ea8-1f1815222a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-c6e55472-c747-4fac-beaf-64886d05ee43,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-a1b3600d-3445-4971-a50a-b13f7e33e455,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-77b52638-7c3e-4c8c-87c1-1d8554b79ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279329993-172.17.0.8-1595566719661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38979,DS-255944a8-b57d-4803-9398-6425d5246368,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-81043d9f-d09a-4826-9fcf-c4a9927c4200,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-0c62e592-44f9-450e-8037-c9b5a4ceeff4,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-96a0a29b-1401-459e-9fbd-d0462d09fe69,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-72465399-3d0d-4453-8ea8-1f1815222a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-c6e55472-c747-4fac-beaf-64886d05ee43,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-a1b3600d-3445-4971-a50a-b13f7e33e455,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-77b52638-7c3e-4c8c-87c1-1d8554b79ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062350342-172.17.0.8-1595566829632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-83e315d9-1df5-45d5-816d-d3b2da4349db,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-28916373-807a-497b-b84a-e4ce6d2eaa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-a9509172-7915-4fb9-aeea-f070b3723ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-d48d2e46-594b-46d1-8497-976df42a4673,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-3cd0e130-0c4e-457e-b9c7-476d0a57ec87,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-224c8e4f-40c2-4a9c-a181-2ee951499727,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-74ebc743-53dc-4c06-ae3c-79ceab70a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-a903b2ce-9257-4018-83de-21e56d44cab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062350342-172.17.0.8-1595566829632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-83e315d9-1df5-45d5-816d-d3b2da4349db,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-28916373-807a-497b-b84a-e4ce6d2eaa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-a9509172-7915-4fb9-aeea-f070b3723ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-d48d2e46-594b-46d1-8497-976df42a4673,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-3cd0e130-0c4e-457e-b9c7-476d0a57ec87,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-224c8e4f-40c2-4a9c-a181-2ee951499727,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-74ebc743-53dc-4c06-ae3c-79ceab70a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-a903b2ce-9257-4018-83de-21e56d44cab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667303396-172.17.0.8-1595566987557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33598,DS-8fe0e885-160e-4f12-a050-d614120c941c,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-d1117996-3182-449f-9888-edb745238c52,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-4d3febef-0e35-422a-96b9-1fe8c09b905f,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-fcb184cf-ee33-43c6-858b-c815f7c7911f,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-fc0dd3be-1a77-4fc8-bbeb-ac383309cc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-4340f947-9f5d-4408-af4b-b472bd760265,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-41226367-52dc-44cc-9478-e2d697f7fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-9695a2e4-bcca-47ac-8323-32b1c6cb3c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667303396-172.17.0.8-1595566987557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33598,DS-8fe0e885-160e-4f12-a050-d614120c941c,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-d1117996-3182-449f-9888-edb745238c52,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-4d3febef-0e35-422a-96b9-1fe8c09b905f,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-fcb184cf-ee33-43c6-858b-c815f7c7911f,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-fc0dd3be-1a77-4fc8-bbeb-ac383309cc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-4340f947-9f5d-4408-af4b-b472bd760265,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-41226367-52dc-44cc-9478-e2d697f7fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-9695a2e4-bcca-47ac-8323-32b1c6cb3c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515373937-172.17.0.8-1595567866759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39567,DS-dd60ccc4-105c-4822-887e-b1d729259056,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-be17312a-9dff-4643-b3d6-ff173f4c8b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-848f4309-39df-4f1f-a9a8-5779ba93b935,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-182d5bc7-83e3-4b90-a34b-6bc9412b1563,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-a995257a-2317-442e-b779-bd82a9b1b9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-a5d88bc0-bafc-4e5c-ba07-31a8f59eb808,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-3ebd4f83-73a5-4892-b783-77854ffcad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-e35449ea-a516-43b2-a319-75badac2a883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515373937-172.17.0.8-1595567866759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39567,DS-dd60ccc4-105c-4822-887e-b1d729259056,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-be17312a-9dff-4643-b3d6-ff173f4c8b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-848f4309-39df-4f1f-a9a8-5779ba93b935,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-182d5bc7-83e3-4b90-a34b-6bc9412b1563,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-a995257a-2317-442e-b779-bd82a9b1b9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-a5d88bc0-bafc-4e5c-ba07-31a8f59eb808,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-3ebd4f83-73a5-4892-b783-77854ffcad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-e35449ea-a516-43b2-a319-75badac2a883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088623591-172.17.0.8-1595567936155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45457,DS-14a3272f-63d0-4403-ad9a-3c31c0373ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-e0082005-c0ef-444a-9d2b-c1dbb50f5750,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-b31d494e-946c-4b8b-bc88-db72a8677bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-40b06cb8-be7b-415d-b7a0-bc3145ea4f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-21526178-ad61-40b8-8885-5470c3e71a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-3fe3e04b-d91b-45a3-9ebc-26daaaca51bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-f0ae3c89-2dab-42f6-8b11-7f4e20ae02ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-95fdeda1-d3ea-421f-8b57-0ea386bf7121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088623591-172.17.0.8-1595567936155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45457,DS-14a3272f-63d0-4403-ad9a-3c31c0373ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-e0082005-c0ef-444a-9d2b-c1dbb50f5750,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-b31d494e-946c-4b8b-bc88-db72a8677bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-40b06cb8-be7b-415d-b7a0-bc3145ea4f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-21526178-ad61-40b8-8885-5470c3e71a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-3fe3e04b-d91b-45a3-9ebc-26daaaca51bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-f0ae3c89-2dab-42f6-8b11-7f4e20ae02ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-95fdeda1-d3ea-421f-8b57-0ea386bf7121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354626620-172.17.0.8-1595568091460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-fea6f927-2b88-4b1c-bd62-f9c0a5d47c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-c0e76bc6-6b85-4403-bd9f-07d7ed54b149,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-86cfb3d6-4d9f-4085-998b-ca6c50b6f202,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-47750c61-4629-432f-b20d-7c2a9ace10be,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-ed470008-471b-431d-991f-6365e3a9f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-a84af9af-ebc2-441d-9451-c01f5967115a,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-332be4d7-c366-47bd-8a9e-55ebd4d72c23,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-d9ec18e1-be2b-400e-a266-92ac5f2f4bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354626620-172.17.0.8-1595568091460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-fea6f927-2b88-4b1c-bd62-f9c0a5d47c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-c0e76bc6-6b85-4403-bd9f-07d7ed54b149,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-86cfb3d6-4d9f-4085-998b-ca6c50b6f202,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-47750c61-4629-432f-b20d-7c2a9ace10be,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-ed470008-471b-431d-991f-6365e3a9f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-a84af9af-ebc2-441d-9451-c01f5967115a,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-332be4d7-c366-47bd-8a9e-55ebd4d72c23,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-d9ec18e1-be2b-400e-a266-92ac5f2f4bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439028956-172.17.0.8-1595569032507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40962,DS-8e86dfb1-db17-4a11-a5d9-333d2edf147f,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-80ebb208-433a-46c2-9823-927f5cc4f1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-459277dc-3374-454a-98d8-f3fbc1ff82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-bc3d4272-bab5-4d7e-b484-69c911aea277,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-7ba1c1c4-cbc2-4998-bbd2-dbeb603240c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-0460820f-7d8d-4aea-aa42-6d9d84b56360,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-e8fec883-64ec-46e4-8187-38b9b07d5d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-a0438f3e-7d46-47ae-b0c7-d89a55b5ce54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439028956-172.17.0.8-1595569032507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40962,DS-8e86dfb1-db17-4a11-a5d9-333d2edf147f,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-80ebb208-433a-46c2-9823-927f5cc4f1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-459277dc-3374-454a-98d8-f3fbc1ff82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-bc3d4272-bab5-4d7e-b484-69c911aea277,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-7ba1c1c4-cbc2-4998-bbd2-dbeb603240c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-0460820f-7d8d-4aea-aa42-6d9d84b56360,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-e8fec883-64ec-46e4-8187-38b9b07d5d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-a0438f3e-7d46-47ae-b0c7-d89a55b5ce54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5146
