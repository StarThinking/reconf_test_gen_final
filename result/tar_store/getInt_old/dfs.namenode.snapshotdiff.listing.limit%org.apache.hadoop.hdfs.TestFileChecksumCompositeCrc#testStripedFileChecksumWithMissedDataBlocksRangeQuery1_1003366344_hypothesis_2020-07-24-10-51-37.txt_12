reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298514298-172.17.0.12-1595588061239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36676,DS-34fde895-625a-4a76-b04c-fae9a1410c35,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-3e12014b-2311-4b4d-bccd-ba113aa9ccf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-e6aa9050-43a1-4ed7-ac1c-1a8a193c4689,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-8e4bbbae-072e-4d90-8f81-27ebd1ec0ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-38a7eff4-ab5e-4d44-8556-713f68e44931,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-a971ce61-58be-497a-bd57-41d9ee54ae85,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-4677ef3d-2ef9-4f13-83f0-b21f18c53c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-216b66fe-9c84-4b85-aac0-147ded03ed93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298514298-172.17.0.12-1595588061239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36676,DS-34fde895-625a-4a76-b04c-fae9a1410c35,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-3e12014b-2311-4b4d-bccd-ba113aa9ccf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-e6aa9050-43a1-4ed7-ac1c-1a8a193c4689,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-8e4bbbae-072e-4d90-8f81-27ebd1ec0ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-38a7eff4-ab5e-4d44-8556-713f68e44931,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-a971ce61-58be-497a-bd57-41d9ee54ae85,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-4677ef3d-2ef9-4f13-83f0-b21f18c53c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-216b66fe-9c84-4b85-aac0-147ded03ed93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059125519-172.17.0.12-1595588362872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42622,DS-52ed9b5c-6c38-4805-86de-fd9872eae3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-93ee6488-8ca6-4686-9e17-24ace59f9063,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-a8af9c34-3499-4eef-8001-6f21dd800fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-316ab823-9ca2-403e-90e2-e117844736a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-6e423b4a-8dd5-43f6-8cee-849f8c5d8dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-e51467c8-81bd-4cc4-9351-40a15e1be40d,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-1de49e0e-ae0d-4733-850f-94fcc3763429,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-4b3630e6-049c-480e-a705-3073a7c59188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059125519-172.17.0.12-1595588362872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42622,DS-52ed9b5c-6c38-4805-86de-fd9872eae3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-93ee6488-8ca6-4686-9e17-24ace59f9063,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-a8af9c34-3499-4eef-8001-6f21dd800fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-316ab823-9ca2-403e-90e2-e117844736a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-6e423b4a-8dd5-43f6-8cee-849f8c5d8dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-e51467c8-81bd-4cc4-9351-40a15e1be40d,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-1de49e0e-ae0d-4733-850f-94fcc3763429,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-4b3630e6-049c-480e-a705-3073a7c59188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471064707-172.17.0.12-1595588547922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-78b56194-8e4b-480b-bdbf-b28732a194b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-9a1e0aaf-a514-4b9a-9651-97c75e3e787e,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-4fa90ca7-db13-4987-a980-f87bfb9b0a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-e77fea2c-c30b-4ffa-8d67-607dadc7db49,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-5e884140-9ee4-4957-a14e-a7394fa62458,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-8c8be68c-6e22-41e2-94e2-3853971d6d25,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-c54f5c66-d794-4864-bca1-140103d943e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-794ce520-2cd6-48d2-adb9-df73ffb5f6ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471064707-172.17.0.12-1595588547922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-78b56194-8e4b-480b-bdbf-b28732a194b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-9a1e0aaf-a514-4b9a-9651-97c75e3e787e,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-4fa90ca7-db13-4987-a980-f87bfb9b0a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-e77fea2c-c30b-4ffa-8d67-607dadc7db49,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-5e884140-9ee4-4957-a14e-a7394fa62458,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-8c8be68c-6e22-41e2-94e2-3853971d6d25,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-c54f5c66-d794-4864-bca1-140103d943e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-794ce520-2cd6-48d2-adb9-df73ffb5f6ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371048769-172.17.0.12-1595589514816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-d5b36c38-0817-41c9-a096-f66acf32cfda,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-e6da3c91-030f-400d-8d15-e56c445da5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-f88c7522-8ed1-4623-ad62-9ce768f2dca4,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-ae95249a-ddde-4bdb-8efc-271af628d652,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-a1b49211-4d16-4313-8ae9-3cd370ef6f72,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-5e7e6739-39c9-49cf-aaad-7f796b2990c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1059ec22-bb2c-4fe8-81ac-879093b58156,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-3f864d3f-c3f4-4f61-b0c6-7605f3d77066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371048769-172.17.0.12-1595589514816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-d5b36c38-0817-41c9-a096-f66acf32cfda,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-e6da3c91-030f-400d-8d15-e56c445da5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-f88c7522-8ed1-4623-ad62-9ce768f2dca4,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-ae95249a-ddde-4bdb-8efc-271af628d652,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-a1b49211-4d16-4313-8ae9-3cd370ef6f72,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-5e7e6739-39c9-49cf-aaad-7f796b2990c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1059ec22-bb2c-4fe8-81ac-879093b58156,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-3f864d3f-c3f4-4f61-b0c6-7605f3d77066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745579546-172.17.0.12-1595589596861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40895,DS-059438cc-c393-4c58-b3e2-2ef27e0ce65a,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-9c09c3a1-0a34-4e02-b7ac-34134bc26d69,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-ea17da4a-5b5e-42cb-9cac-8fae472dbc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-8a13f168-08be-49bd-9f7a-d368afd6b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-c6fdc348-8b49-4882-a611-c287ca6e0c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-2057d76d-5ee1-483a-9bb9-f6f6b4acc781,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-5576833b-5839-4fbd-aa7b-e87101fbe08f,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-8105a179-042f-4773-b639-d40a4d3dbcd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745579546-172.17.0.12-1595589596861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40895,DS-059438cc-c393-4c58-b3e2-2ef27e0ce65a,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-9c09c3a1-0a34-4e02-b7ac-34134bc26d69,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-ea17da4a-5b5e-42cb-9cac-8fae472dbc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-8a13f168-08be-49bd-9f7a-d368afd6b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-c6fdc348-8b49-4882-a611-c287ca6e0c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-2057d76d-5ee1-483a-9bb9-f6f6b4acc781,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-5576833b-5839-4fbd-aa7b-e87101fbe08f,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-8105a179-042f-4773-b639-d40a4d3dbcd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707757949-172.17.0.12-1595589741957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-1a13f426-7c17-47a9-8197-6ac77c8afed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-406d8786-46b0-403e-869b-77bbdbded581,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-fa78c179-a429-40b0-ae13-4c63b1082277,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-76cd1f88-2eab-465d-9d22-8708343079fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-8a637b44-822f-47a4-815f-7a2775053d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-9e4c7a8a-edbe-44b0-a6bd-8c85f4b0682c,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-4bf1d2c7-5054-477c-b221-cbade811ad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-fd76163d-7b75-47ad-8921-6ccd8fa48ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707757949-172.17.0.12-1595589741957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-1a13f426-7c17-47a9-8197-6ac77c8afed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-406d8786-46b0-403e-869b-77bbdbded581,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-fa78c179-a429-40b0-ae13-4c63b1082277,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-76cd1f88-2eab-465d-9d22-8708343079fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-8a637b44-822f-47a4-815f-7a2775053d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-9e4c7a8a-edbe-44b0-a6bd-8c85f4b0682c,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-4bf1d2c7-5054-477c-b221-cbade811ad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-fd76163d-7b75-47ad-8921-6ccd8fa48ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133104457-172.17.0.12-1595589780773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45207,DS-e55249f4-bee0-45b1-8fc3-07b41f37f6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-a6f47b32-d547-4f08-854e-8aeaa28676a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-46128362-11be-44ae-995d-6917c754f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-700c780d-d591-42a0-bc39-fd08b0ffbc35,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-f9a07666-14d7-42d1-801b-a097e49157e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-61fa58df-45d3-4e99-a6ca-51ca8aeb9b42,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-77baf8a8-9dd6-4170-9b67-d6f842fb8ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-124d8413-3ec2-4821-a9ff-68556793c99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133104457-172.17.0.12-1595589780773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45207,DS-e55249f4-bee0-45b1-8fc3-07b41f37f6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-a6f47b32-d547-4f08-854e-8aeaa28676a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-46128362-11be-44ae-995d-6917c754f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-700c780d-d591-42a0-bc39-fd08b0ffbc35,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-f9a07666-14d7-42d1-801b-a097e49157e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-61fa58df-45d3-4e99-a6ca-51ca8aeb9b42,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-77baf8a8-9dd6-4170-9b67-d6f842fb8ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-124d8413-3ec2-4821-a9ff-68556793c99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715947436-172.17.0.12-1595589896306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-7ed5ea7c-5251-4bb2-bc17-7ec671ded51e,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-aaa25b81-f7fd-4f93-bec1-9e1f3587d960,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-84942d9d-143a-4970-9aae-baf9a7566694,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-3867ad7e-0060-4a7e-a63b-8e5c3de92c13,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-ce172dc1-02d2-4064-8c44-9f3270edbb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-81b1c527-2739-4d57-9f71-69b0677049f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-224199ea-d122-4c34-824d-99148e11f01e,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-0aaf2f8d-a0ed-427f-b558-3b26e54e7f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715947436-172.17.0.12-1595589896306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-7ed5ea7c-5251-4bb2-bc17-7ec671ded51e,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-aaa25b81-f7fd-4f93-bec1-9e1f3587d960,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-84942d9d-143a-4970-9aae-baf9a7566694,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-3867ad7e-0060-4a7e-a63b-8e5c3de92c13,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-ce172dc1-02d2-4064-8c44-9f3270edbb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-81b1c527-2739-4d57-9f71-69b0677049f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-224199ea-d122-4c34-824d-99148e11f01e,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-0aaf2f8d-a0ed-427f-b558-3b26e54e7f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831474586-172.17.0.12-1595590000098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36084,DS-d021968d-7a9a-4a72-bab1-8d036aacd0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-b2eeea4f-6cd9-45f5-81e4-9959a2d9ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-efffe14d-ddc5-40fc-b233-81a69d88eaec,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-ecde0c44-2456-4994-82a2-d8f1fecbede1,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-827afa47-da6b-42ea-ae46-8fb5532ee8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-a834b164-7a56-40c0-b594-a651680b9500,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-b8ae9eeb-49a4-432f-a517-448b33578b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-0a0fdd64-f75c-478e-957a-3fc69d54733a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831474586-172.17.0.12-1595590000098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36084,DS-d021968d-7a9a-4a72-bab1-8d036aacd0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-b2eeea4f-6cd9-45f5-81e4-9959a2d9ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-efffe14d-ddc5-40fc-b233-81a69d88eaec,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-ecde0c44-2456-4994-82a2-d8f1fecbede1,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-827afa47-da6b-42ea-ae46-8fb5532ee8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-a834b164-7a56-40c0-b594-a651680b9500,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-b8ae9eeb-49a4-432f-a517-448b33578b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-0a0fdd64-f75c-478e-957a-3fc69d54733a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059933779-172.17.0.12-1595590169025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38016,DS-e269853a-45e9-4e0f-bcaa-4d21dd646a11,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-dde4ab62-9290-4a6b-b664-732ebec32492,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-f3c32649-2f2d-4aa0-8986-f2e115b4bb24,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-18a01edb-bb0e-4605-8cc9-b5459f27f271,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-e2e12741-bc56-427c-bffd-91e062990ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-3772ada5-e8d9-47f6-aff1-47a952a449fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-447cf7ca-0fbc-4cf6-9a44-8ad841112244,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-90dba5a1-ca57-4a81-ac44-312507441f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059933779-172.17.0.12-1595590169025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38016,DS-e269853a-45e9-4e0f-bcaa-4d21dd646a11,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-dde4ab62-9290-4a6b-b664-732ebec32492,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-f3c32649-2f2d-4aa0-8986-f2e115b4bb24,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-18a01edb-bb0e-4605-8cc9-b5459f27f271,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-e2e12741-bc56-427c-bffd-91e062990ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-3772ada5-e8d9-47f6-aff1-47a952a449fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-447cf7ca-0fbc-4cf6-9a44-8ad841112244,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-90dba5a1-ca57-4a81-ac44-312507441f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95045824-172.17.0.12-1595590744376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-70a155b7-c2e5-4586-9f0f-68edd3c2f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-0d32e948-c556-4416-8b32-9651626ae532,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-78293733-ea3b-4753-8403-512170c28ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-a421619a-b5d7-49e5-8c29-ba515bdb4f09,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-96e916d0-1eb9-4708-b803-2ae049fbb515,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-c059324c-5fb4-4938-975a-010d9255a5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-753b7e3e-d0be-4286-9bc2-45b312fdfbee,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-6651b45d-a748-4673-b475-4981bd3ea5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95045824-172.17.0.12-1595590744376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42476,DS-70a155b7-c2e5-4586-9f0f-68edd3c2f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-0d32e948-c556-4416-8b32-9651626ae532,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-78293733-ea3b-4753-8403-512170c28ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-a421619a-b5d7-49e5-8c29-ba515bdb4f09,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-96e916d0-1eb9-4708-b803-2ae049fbb515,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-c059324c-5fb4-4938-975a-010d9255a5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-753b7e3e-d0be-4286-9bc2-45b312fdfbee,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-6651b45d-a748-4673-b475-4981bd3ea5c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599802061-172.17.0.12-1595591322004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38131,DS-fce54e3f-dedd-4d16-a076-1c61de0c73a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-5531ce0c-bed6-43dc-887b-0b89e5d6068e,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-1c93fe35-bd59-4951-9b1c-cc8e64627b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-02bd0bd8-0178-4e6f-a351-32f8832787f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-c21b453b-7ef7-4577-b393-02deb8f9fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-8beed142-cca1-479d-a119-cca975217db9,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-48b8bd6a-1908-4f6c-94a2-5fda847dbe24,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-b3ebe548-d82c-41f5-be5a-5944cb0fd95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599802061-172.17.0.12-1595591322004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38131,DS-fce54e3f-dedd-4d16-a076-1c61de0c73a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-5531ce0c-bed6-43dc-887b-0b89e5d6068e,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-1c93fe35-bd59-4951-9b1c-cc8e64627b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-02bd0bd8-0178-4e6f-a351-32f8832787f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-c21b453b-7ef7-4577-b393-02deb8f9fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-8beed142-cca1-479d-a119-cca975217db9,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-48b8bd6a-1908-4f6c-94a2-5fda847dbe24,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-b3ebe548-d82c-41f5-be5a-5944cb0fd95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525798117-172.17.0.12-1595591895807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-689cf3cd-bfaa-49db-8e81-f3f1b8f217de,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-a6c84784-02ac-458e-b6fa-494315f2ceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-67c9e0b6-f9ac-406c-a724-4ca56251ddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-2f454e5b-fd93-4710-b18d-9f37fa96cfde,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-0b5e40b4-5558-4796-a12e-20fcf11dedf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-442571dc-443f-40b6-b7ad-8bc0a2b94e58,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-60107fd2-9790-44af-803d-2d5a7f24a4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-71b3e53d-0126-4b48-a368-c128634f6af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525798117-172.17.0.12-1595591895807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-689cf3cd-bfaa-49db-8e81-f3f1b8f217de,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-a6c84784-02ac-458e-b6fa-494315f2ceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-67c9e0b6-f9ac-406c-a724-4ca56251ddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-2f454e5b-fd93-4710-b18d-9f37fa96cfde,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-0b5e40b4-5558-4796-a12e-20fcf11dedf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-442571dc-443f-40b6-b7ad-8bc0a2b94e58,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-60107fd2-9790-44af-803d-2d5a7f24a4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-71b3e53d-0126-4b48-a368-c128634f6af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175486943-172.17.0.12-1595592923937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-22be8d4e-6efc-4b8a-b9b9-bcb9300013c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-45428507-7e6c-46d1-8cc7-c71682eb9dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-53e2cb98-21cb-48d0-9563-ffcebe39f994,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-cb93dc2f-995a-42e2-ad5f-f23bc5d4c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-ae525e51-1917-46aa-817d-143034bc4d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-2cdf235f-eeba-4756-af66-3e4d2c7ec811,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-c814a260-073f-4b07-8917-1e2d87a38c32,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-9a3e958e-1e9b-4659-a37d-89ee017eda40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175486943-172.17.0.12-1595592923937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-22be8d4e-6efc-4b8a-b9b9-bcb9300013c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-45428507-7e6c-46d1-8cc7-c71682eb9dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-53e2cb98-21cb-48d0-9563-ffcebe39f994,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-cb93dc2f-995a-42e2-ad5f-f23bc5d4c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-ae525e51-1917-46aa-817d-143034bc4d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-2cdf235f-eeba-4756-af66-3e4d2c7ec811,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-c814a260-073f-4b07-8917-1e2d87a38c32,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-9a3e958e-1e9b-4659-a37d-89ee017eda40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438586962-172.17.0.12-1595592957235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-6f3949dd-7e4e-4243-978b-658bca11d8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-99f6948f-192f-4ab3-acf7-4ae28343ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-5d146652-a1dc-4650-a7d7-61a8a16b44d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-625b96b4-6915-4b08-b0d7-d1fa36cb6e85,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-c19e9776-0d3f-4358-b36a-42ae8fc3c7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-35c97337-094b-4bd7-b816-b39981ea8e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-77ddb85a-424a-4319-be3b-9befddeb0479,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-51efdd46-9d66-4b68-946b-1de595489893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438586962-172.17.0.12-1595592957235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-6f3949dd-7e4e-4243-978b-658bca11d8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-99f6948f-192f-4ab3-acf7-4ae28343ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-5d146652-a1dc-4650-a7d7-61a8a16b44d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-625b96b4-6915-4b08-b0d7-d1fa36cb6e85,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-c19e9776-0d3f-4358-b36a-42ae8fc3c7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-35c97337-094b-4bd7-b816-b39981ea8e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-77ddb85a-424a-4319-be3b-9befddeb0479,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-51efdd46-9d66-4b68-946b-1de595489893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5566
