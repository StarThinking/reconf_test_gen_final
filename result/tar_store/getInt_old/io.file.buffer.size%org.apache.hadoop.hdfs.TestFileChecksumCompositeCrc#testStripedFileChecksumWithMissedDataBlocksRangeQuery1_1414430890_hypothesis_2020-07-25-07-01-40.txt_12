reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974818355-172.17.0.12-1595660629376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-4e1cac87-7460-4e10-8a46-8554a0d36c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-9cb79a19-2339-479e-9627-de830f353d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-18605060-1e03-4329-954e-9d73b534574c,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-ef8cef1b-574b-4cef-9595-7dae8cb66a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-24854134-06a5-4a2d-8f46-013750a53f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-c9dd8fdc-da3e-407e-a9a5-f0ec48700578,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-57c207dc-a054-4fc5-8fae-9829f0e32502,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-203dfa62-a374-418d-944b-00960f43e047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974818355-172.17.0.12-1595660629376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-4e1cac87-7460-4e10-8a46-8554a0d36c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-9cb79a19-2339-479e-9627-de830f353d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-18605060-1e03-4329-954e-9d73b534574c,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-ef8cef1b-574b-4cef-9595-7dae8cb66a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-24854134-06a5-4a2d-8f46-013750a53f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-c9dd8fdc-da3e-407e-a9a5-f0ec48700578,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-57c207dc-a054-4fc5-8fae-9829f0e32502,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-203dfa62-a374-418d-944b-00960f43e047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150777887-172.17.0.12-1595660739226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-382251b6-e8fa-4bc2-965f-aaae058e0828,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-97909f89-abe2-4988-a646-c071e331f665,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-a4f7377b-ccfe-43a7-995f-79ef88a5f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-11b257b8-18b6-4ec1-9352-445c722d2db8,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-fad6e133-2304-43c1-9777-a50d664f5782,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-149b1c9b-7669-4d96-b025-2449c23a6253,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-0b6b9607-6750-4763-8b88-bbeb3f7b87ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-a4ed92a0-40e1-4df0-9404-ce8b8709b4cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150777887-172.17.0.12-1595660739226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-382251b6-e8fa-4bc2-965f-aaae058e0828,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-97909f89-abe2-4988-a646-c071e331f665,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-a4f7377b-ccfe-43a7-995f-79ef88a5f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-11b257b8-18b6-4ec1-9352-445c722d2db8,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-fad6e133-2304-43c1-9777-a50d664f5782,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-149b1c9b-7669-4d96-b025-2449c23a6253,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-0b6b9607-6750-4763-8b88-bbeb3f7b87ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-a4ed92a0-40e1-4df0-9404-ce8b8709b4cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216145055-172.17.0.12-1595661340615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46795,DS-b35997b1-7d2c-4542-bcfa-6d2f7619f831,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-a14a5d04-151e-4b64-9fa8-cdc6f1477c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-d9c2c07b-c980-4d89-979b-e222c7e5d1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-100ea712-96bc-481c-a8be-01e48d7e772d,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-4fb8ea64-ef85-4840-bbda-20181ce124a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-f65b5586-de88-4961-a130-c00446305dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-5cb89574-23dc-4a0e-a02e-8064a24663fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-33f30e5f-3919-47a7-863a-65786d427595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216145055-172.17.0.12-1595661340615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46795,DS-b35997b1-7d2c-4542-bcfa-6d2f7619f831,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-a14a5d04-151e-4b64-9fa8-cdc6f1477c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-d9c2c07b-c980-4d89-979b-e222c7e5d1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-100ea712-96bc-481c-a8be-01e48d7e772d,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-4fb8ea64-ef85-4840-bbda-20181ce124a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-f65b5586-de88-4961-a130-c00446305dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-5cb89574-23dc-4a0e-a02e-8064a24663fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-33f30e5f-3919-47a7-863a-65786d427595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139894765-172.17.0.12-1595661414664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34978,DS-2bd3b327-6b3c-411d-b79a-36e5f2ba1791,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-10c2a3d5-19b5-4f2c-bda3-68812d20b48e,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-347f5d7f-5dfb-4e92-9107-8b1bc121216f,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-8846c7e2-98fc-4531-a089-37c26313b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-dc1a0cca-a960-4bdd-a5ab-c7482949c369,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-7f02d52b-69a2-4b8d-ad74-d4814639a2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-cd76b00f-732f-4de9-b647-812a9b6501b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-c6f80338-594a-4ab9-9e39-57251b5d4bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139894765-172.17.0.12-1595661414664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34978,DS-2bd3b327-6b3c-411d-b79a-36e5f2ba1791,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-10c2a3d5-19b5-4f2c-bda3-68812d20b48e,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-347f5d7f-5dfb-4e92-9107-8b1bc121216f,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-8846c7e2-98fc-4531-a089-37c26313b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-dc1a0cca-a960-4bdd-a5ab-c7482949c369,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-7f02d52b-69a2-4b8d-ad74-d4814639a2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-cd76b00f-732f-4de9-b647-812a9b6501b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-c6f80338-594a-4ab9-9e39-57251b5d4bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892193003-172.17.0.12-1595662341927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-f181c873-97e5-44a2-8c1d-4d123701018c,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-7f32f534-0663-4a87-8126-1d0cf7c23bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-abce3bdb-2115-4004-9e0c-95c8c1e09873,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-407873ee-c7d4-4209-afd7-3bbda71f28db,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-80c8e0ea-6407-4e45-a343-a20f27d7e4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-2cc80a92-fca9-47e2-b3a8-feac1cb6b085,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-35acd2d6-0406-4ea8-92eb-ec3fa9b09e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-c7aebde7-6e1c-465d-b12c-db72e1db33f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892193003-172.17.0.12-1595662341927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-f181c873-97e5-44a2-8c1d-4d123701018c,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-7f32f534-0663-4a87-8126-1d0cf7c23bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-abce3bdb-2115-4004-9e0c-95c8c1e09873,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-407873ee-c7d4-4209-afd7-3bbda71f28db,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-80c8e0ea-6407-4e45-a343-a20f27d7e4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-2cc80a92-fca9-47e2-b3a8-feac1cb6b085,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-35acd2d6-0406-4ea8-92eb-ec3fa9b09e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-c7aebde7-6e1c-465d-b12c-db72e1db33f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124649078-172.17.0.12-1595662421372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34542,DS-2f0aedb1-0739-4fb8-9b64-f88a02588700,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-8ee165da-267d-4ea9-a62c-ab15c77a14b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-f32d97e7-2fc8-4b33-bb2e-4bf17f90faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-97e8ab9c-1356-43c1-a7fa-b48a8dccf558,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-f48b6525-09d2-4e7d-a9bb-9d0592b3ca36,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-f2b8a2f5-a20d-4e08-9cb7-863308294823,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-5eb50d4b-5a1e-43c5-8ace-e8752745128e,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-bfc4f6a7-fb30-41e7-8a86-5456eaa12c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124649078-172.17.0.12-1595662421372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34542,DS-2f0aedb1-0739-4fb8-9b64-f88a02588700,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-8ee165da-267d-4ea9-a62c-ab15c77a14b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-f32d97e7-2fc8-4b33-bb2e-4bf17f90faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-97e8ab9c-1356-43c1-a7fa-b48a8dccf558,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-f48b6525-09d2-4e7d-a9bb-9d0592b3ca36,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-f2b8a2f5-a20d-4e08-9cb7-863308294823,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-5eb50d4b-5a1e-43c5-8ace-e8752745128e,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-bfc4f6a7-fb30-41e7-8a86-5456eaa12c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976120986-172.17.0.12-1595662497197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39402,DS-49fc9011-fcd6-4d77-b6db-326522727bda,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-566c1421-8273-49ff-9511-8c4008d8dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-dd001989-cbd9-4111-bb64-1628462b2af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-0388869b-b178-42eb-b3ba-a56ef96b7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-2e40c089-c72e-484b-b950-e6fd0a4791ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-44179618-1c26-4ecc-b7f2-aeaa2af35802,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-d846f5f1-477d-4565-8330-837594d30afb,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-110661bd-087f-4cd5-ab6c-ecdd8f18bd27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976120986-172.17.0.12-1595662497197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39402,DS-49fc9011-fcd6-4d77-b6db-326522727bda,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-566c1421-8273-49ff-9511-8c4008d8dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-dd001989-cbd9-4111-bb64-1628462b2af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-0388869b-b178-42eb-b3ba-a56ef96b7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-2e40c089-c72e-484b-b950-e6fd0a4791ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-44179618-1c26-4ecc-b7f2-aeaa2af35802,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-d846f5f1-477d-4565-8330-837594d30afb,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-110661bd-087f-4cd5-ab6c-ecdd8f18bd27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987146044-172.17.0.12-1595662618310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-b13e7095-8d49-4ae1-890e-6868589bc939,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-8a358077-8417-4f1a-aabb-cf1911b40ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-7dc4d62d-eccc-4699-a6fa-a183ca7f2d86,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-a430c684-f50d-4c45-a0a2-c89306524341,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-f4ae24df-055d-4914-894c-57bf1b5cb11f,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-f8f01195-7e74-46ad-a5d1-795ecd0ef153,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-fe503cbf-1bd6-4ef6-a80c-624eb4029b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-8b6724bd-32ba-40fa-998f-eeb5dab61267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987146044-172.17.0.12-1595662618310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-b13e7095-8d49-4ae1-890e-6868589bc939,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-8a358077-8417-4f1a-aabb-cf1911b40ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-7dc4d62d-eccc-4699-a6fa-a183ca7f2d86,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-a430c684-f50d-4c45-a0a2-c89306524341,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-f4ae24df-055d-4914-894c-57bf1b5cb11f,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-f8f01195-7e74-46ad-a5d1-795ecd0ef153,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-fe503cbf-1bd6-4ef6-a80c-624eb4029b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-8b6724bd-32ba-40fa-998f-eeb5dab61267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860037840-172.17.0.12-1595662956617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-95f2700a-4ccb-4333-97fa-79aa665f25b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-d17144a0-6ddb-4b5a-8389-0511d07e3503,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-c8f1ea16-f362-4797-9cb3-5ce473e54dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-97feb98f-527f-4e16-9cf2-a0a9fcc3ca53,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-0e16bd0f-eb17-40c9-b64d-8894d6875baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-cba03341-b60f-4075-bb5c-6c6a6c9dd535,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-b40814c0-f26a-43b3-97fd-d8ea45b290c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-8ae3a019-60fb-47e7-8eaf-ab5773fd8cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860037840-172.17.0.12-1595662956617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-95f2700a-4ccb-4333-97fa-79aa665f25b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-d17144a0-6ddb-4b5a-8389-0511d07e3503,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-c8f1ea16-f362-4797-9cb3-5ce473e54dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-97feb98f-527f-4e16-9cf2-a0a9fcc3ca53,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-0e16bd0f-eb17-40c9-b64d-8894d6875baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-cba03341-b60f-4075-bb5c-6c6a6c9dd535,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-b40814c0-f26a-43b3-97fd-d8ea45b290c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-8ae3a019-60fb-47e7-8eaf-ab5773fd8cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512166190-172.17.0.12-1595663104235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39012,DS-42a68dd7-d694-4be1-b9ed-a900c85a9fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-aa0d3ba1-c7e2-4a36-8786-cd6671c21a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-f86b937e-5887-486d-8c0e-e29292f5e693,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-2edf849d-5454-4ef4-894c-bb07fe7f046c,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-bf4a3263-4c47-44be-a872-32009b20b809,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-caf7df84-66d8-48a0-b5e4-0ce5a2c00b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-b0e6f4c7-1802-4ab7-87eb-b3d3beedb78d,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-efa54c91-d131-40df-a5af-16953ddd5e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512166190-172.17.0.12-1595663104235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39012,DS-42a68dd7-d694-4be1-b9ed-a900c85a9fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-aa0d3ba1-c7e2-4a36-8786-cd6671c21a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-f86b937e-5887-486d-8c0e-e29292f5e693,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-2edf849d-5454-4ef4-894c-bb07fe7f046c,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-bf4a3263-4c47-44be-a872-32009b20b809,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-caf7df84-66d8-48a0-b5e4-0ce5a2c00b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-b0e6f4c7-1802-4ab7-87eb-b3d3beedb78d,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-efa54c91-d131-40df-a5af-16953ddd5e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616017068-172.17.0.12-1595664205762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41515,DS-736bbf76-9703-4fab-abfd-0c1486892bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-3d6ff854-d8d5-414c-9d09-14b60a73d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-a3f5bf9a-1325-4190-8f4b-9ae207762886,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-d7fcf96d-1970-415b-95f9-8575b445bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-2927432b-56c7-4808-a9cf-f5fe31a58710,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-8a1deff7-3cce-4ad4-8b53-03178f53cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-0f768719-aaff-4705-adee-a2e0ab500888,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-3b4a1926-7216-4668-9834-8ba41951972d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616017068-172.17.0.12-1595664205762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41515,DS-736bbf76-9703-4fab-abfd-0c1486892bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-3d6ff854-d8d5-414c-9d09-14b60a73d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-a3f5bf9a-1325-4190-8f4b-9ae207762886,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-d7fcf96d-1970-415b-95f9-8575b445bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-2927432b-56c7-4808-a9cf-f5fe31a58710,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-8a1deff7-3cce-4ad4-8b53-03178f53cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-0f768719-aaff-4705-adee-a2e0ab500888,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-3b4a1926-7216-4668-9834-8ba41951972d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398787001-172.17.0.12-1595664477495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-5359fe0d-df79-4fde-b172-31832c2b9836,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-0fc84d95-91e2-42c0-805b-d6169adb1f14,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-8e9fd555-092e-454e-977c-e5126f049503,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-a256bbe2-c613-481b-b606-74304c72b223,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-8a40811f-711f-44ff-96d6-dd73508d6b99,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-af8b33eb-b9d2-42c0-8ea1-8fde069249ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-cc8ffc2b-42ec-4ea6-b767-f79eb2d506f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-503427b6-4a52-48a2-81fc-3aa916a4fed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398787001-172.17.0.12-1595664477495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-5359fe0d-df79-4fde-b172-31832c2b9836,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-0fc84d95-91e2-42c0-805b-d6169adb1f14,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-8e9fd555-092e-454e-977c-e5126f049503,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-a256bbe2-c613-481b-b606-74304c72b223,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-8a40811f-711f-44ff-96d6-dd73508d6b99,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-af8b33eb-b9d2-42c0-8ea1-8fde069249ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-cc8ffc2b-42ec-4ea6-b767-f79eb2d506f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-503427b6-4a52-48a2-81fc-3aa916a4fed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809916666-172.17.0.12-1595665120785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45299,DS-3d61e36c-3993-45eb-9041-af73ef2fbc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-1066c664-bdf4-43e9-83c0-f2f03e67a6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-8fb640ba-a641-473d-80ce-e8de8c3dfd92,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-f2b80c94-ecdf-4cdd-86d0-49fb9a1506e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-658db72e-557d-4de2-b317-de5e9acd6276,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-93619626-8487-456d-83d3-a9de6e1591f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-1f6abe58-d922-46c3-b604-0914a1df1f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-f7e17ffb-57bc-47db-9840-c680579e0089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809916666-172.17.0.12-1595665120785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45299,DS-3d61e36c-3993-45eb-9041-af73ef2fbc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-1066c664-bdf4-43e9-83c0-f2f03e67a6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-8fb640ba-a641-473d-80ce-e8de8c3dfd92,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-f2b80c94-ecdf-4cdd-86d0-49fb9a1506e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-658db72e-557d-4de2-b317-de5e9acd6276,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-93619626-8487-456d-83d3-a9de6e1591f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-1f6abe58-d922-46c3-b604-0914a1df1f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-f7e17ffb-57bc-47db-9840-c680579e0089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168018823-172.17.0.12-1595665713262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36997,DS-e90f566f-38e5-48ac-a775-de1c4407174f,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-9b20cfb3-55ad-4682-82ad-56ac72b2cb79,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-87764c12-de47-4a9f-9437-bddda6b09d18,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-14cecf02-b901-4bb9-bd67-114a7cf4f80e,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-93e2966d-a02e-46f0-8029-61838990aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-fb10f6e7-db6e-48c4-9d75-9d5dce613801,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-0681b199-3a53-4ab1-9cd9-52e5e99a034f,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-4544100a-036a-4d15-a425-380293713a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168018823-172.17.0.12-1595665713262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36997,DS-e90f566f-38e5-48ac-a775-de1c4407174f,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-9b20cfb3-55ad-4682-82ad-56ac72b2cb79,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-87764c12-de47-4a9f-9437-bddda6b09d18,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-14cecf02-b901-4bb9-bd67-114a7cf4f80e,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-93e2966d-a02e-46f0-8029-61838990aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-fb10f6e7-db6e-48c4-9d75-9d5dce613801,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-0681b199-3a53-4ab1-9cd9-52e5e99a034f,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-4544100a-036a-4d15-a425-380293713a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 2048
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843543079-172.17.0.12-1595665753147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-6af29fa4-e528-40dc-ba76-86aa44b1e616,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-5d9cc2fe-490a-43b6-8617-6e70ee757a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-2d72d699-d1af-4bbb-b5c4-1ce7724d566b,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-f8650bd5-f273-4704-88a9-77666d5b31ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-46bc3de6-911f-4593-b577-8c15cde5ae5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-1403a54c-ef37-4472-9432-f27b0c899080,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-61d94872-34c2-4b22-8afc-f0ae1fcb38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-9bfb6ae8-24ef-4b8c-b9f7-3c0b522c560a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843543079-172.17.0.12-1595665753147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-6af29fa4-e528-40dc-ba76-86aa44b1e616,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-5d9cc2fe-490a-43b6-8617-6e70ee757a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-2d72d699-d1af-4bbb-b5c4-1ce7724d566b,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-f8650bd5-f273-4704-88a9-77666d5b31ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-46bc3de6-911f-4593-b577-8c15cde5ae5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-1403a54c-ef37-4472-9432-f27b0c899080,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-61d94872-34c2-4b22-8afc-f0ae1fcb38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-9bfb6ae8-24ef-4b8c-b9f7-3c0b522c560a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5427
