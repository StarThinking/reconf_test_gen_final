reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289014656-172.17.0.18-1595521870845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-28bc29e4-49fe-4a90-af15-2759612662b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-55bc5fe8-24ae-4d17-9d46-fb48a5b4dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-ddc5cc1c-be17-4c5b-b198-a7dd03064fac,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-b2678305-b0a5-4fe0-845c-64a5b3bee5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-ae5f234d-f8d7-4773-888e-b805cc93a826,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-df24368a-ee52-47cd-8b73-3850b90b0800,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-48088313-9727-4d01-8172-881e33c22a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-207088b2-705f-4d48-9039-2ec31919948f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289014656-172.17.0.18-1595521870845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-28bc29e4-49fe-4a90-af15-2759612662b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-55bc5fe8-24ae-4d17-9d46-fb48a5b4dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-ddc5cc1c-be17-4c5b-b198-a7dd03064fac,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-b2678305-b0a5-4fe0-845c-64a5b3bee5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-ae5f234d-f8d7-4773-888e-b805cc93a826,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-df24368a-ee52-47cd-8b73-3850b90b0800,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-48088313-9727-4d01-8172-881e33c22a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-207088b2-705f-4d48-9039-2ec31919948f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927574853-172.17.0.18-1595522011940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-99ea15c6-8073-406d-bee0-7a3b9352ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-828addcb-8670-42c4-9eeb-af93cde95554,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-69796b25-d9a0-4c51-b006-ec71be9c832a,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-dd3ce90d-ea07-44f7-99d9-e13bb491a000,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-2483b54f-2ec6-415a-a3e4-bf753b9710a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-30964a82-fbd5-4842-967f-d4320886507c,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-e88b041b-d775-41bc-bfaa-e3aed2e5ac14,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-3187ba4e-1521-4507-a4cf-ba704792dd3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927574853-172.17.0.18-1595522011940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-99ea15c6-8073-406d-bee0-7a3b9352ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-828addcb-8670-42c4-9eeb-af93cde95554,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-69796b25-d9a0-4c51-b006-ec71be9c832a,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-dd3ce90d-ea07-44f7-99d9-e13bb491a000,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-2483b54f-2ec6-415a-a3e4-bf753b9710a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-30964a82-fbd5-4842-967f-d4320886507c,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-e88b041b-d775-41bc-bfaa-e3aed2e5ac14,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-3187ba4e-1521-4507-a4cf-ba704792dd3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080185942-172.17.0.18-1595522114337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-e708d5c9-10f8-4789-9034-e1ca5a4e3dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-503c57d2-52b6-4b43-ba7c-1580cf88311a,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-ddd04b57-b540-4878-b16e-8f432bd89c55,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-33ed6840-fca8-4547-9b60-66eccd3fe2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-2f3b85e1-5ca8-49ed-86ef-1a7885ad3532,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-eb514991-8617-4e5a-bb7e-2848d0536005,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-9a95338f-ac78-4af5-9d0b-9c81f50dd099,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-1290901d-c0f2-4899-af41-93d820117ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080185942-172.17.0.18-1595522114337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-e708d5c9-10f8-4789-9034-e1ca5a4e3dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-503c57d2-52b6-4b43-ba7c-1580cf88311a,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-ddd04b57-b540-4878-b16e-8f432bd89c55,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-33ed6840-fca8-4547-9b60-66eccd3fe2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-2f3b85e1-5ca8-49ed-86ef-1a7885ad3532,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-eb514991-8617-4e5a-bb7e-2848d0536005,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-9a95338f-ac78-4af5-9d0b-9c81f50dd099,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-1290901d-c0f2-4899-af41-93d820117ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656960639-172.17.0.18-1595522149224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-6d677d20-c82a-467b-8af1-7bc1934fbe29,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-ab738740-b9c8-465d-b1ea-ab7bcf651501,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-39393be6-4fe0-4f13-8fe8-84157e22807e,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-b8b0e9b3-a048-49d1-8d3f-9bb42623c450,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-25c3c816-ee68-47f5-bc5c-5fac8e32100e,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-1d2e5115-8b10-49aa-8835-51d66cec71c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-ffe71227-3f2f-4c81-8a9e-ca03602573d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-69f08362-24d3-4dec-82da-648fc956e5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656960639-172.17.0.18-1595522149224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-6d677d20-c82a-467b-8af1-7bc1934fbe29,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-ab738740-b9c8-465d-b1ea-ab7bcf651501,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-39393be6-4fe0-4f13-8fe8-84157e22807e,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-b8b0e9b3-a048-49d1-8d3f-9bb42623c450,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-25c3c816-ee68-47f5-bc5c-5fac8e32100e,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-1d2e5115-8b10-49aa-8835-51d66cec71c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-ffe71227-3f2f-4c81-8a9e-ca03602573d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-69f08362-24d3-4dec-82da-648fc956e5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893920947-172.17.0.18-1595522238679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35608,DS-68676fc6-15c8-4bd7-9dd8-0a9ca1ed1350,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-12015150-70c2-4692-ab80-53d4c4a515b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-e4d663ee-129c-4144-a052-9daa29126db6,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-fb33ca2f-9ede-4e1b-89cf-fff3537e3c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-855293fd-0744-448a-b9f7-8afec2cb4a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-753125e7-1c03-4a76-88fe-538fe3b73959,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-23ea915c-bd94-4d0f-9f0e-5a70e7d1f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-efc95521-9929-4060-81e8-c08a4723c2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893920947-172.17.0.18-1595522238679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35608,DS-68676fc6-15c8-4bd7-9dd8-0a9ca1ed1350,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-12015150-70c2-4692-ab80-53d4c4a515b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-e4d663ee-129c-4144-a052-9daa29126db6,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-fb33ca2f-9ede-4e1b-89cf-fff3537e3c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-855293fd-0744-448a-b9f7-8afec2cb4a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-753125e7-1c03-4a76-88fe-538fe3b73959,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-23ea915c-bd94-4d0f-9f0e-5a70e7d1f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-efc95521-9929-4060-81e8-c08a4723c2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553669648-172.17.0.18-1595522283429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36177,DS-40142560-884c-4514-89c0-1a20f4ca4d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-99923fcf-9da5-4c69-ad3a-b06738eaf273,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-311053a0-2c5c-41f3-a79a-f0a0a77827da,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-f061e6ec-762b-4e6a-8f25-ee6966bb20c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-cb8b610d-ba45-4ba5-b951-a37fde01bcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-f132c26b-14b3-499c-913e-5aafb93f1f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-d32d4800-21c5-4916-b356-0e532c040040,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-a3905bbf-c36b-434c-9b48-992b3b238775,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553669648-172.17.0.18-1595522283429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36177,DS-40142560-884c-4514-89c0-1a20f4ca4d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-99923fcf-9da5-4c69-ad3a-b06738eaf273,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-311053a0-2c5c-41f3-a79a-f0a0a77827da,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-f061e6ec-762b-4e6a-8f25-ee6966bb20c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-cb8b610d-ba45-4ba5-b951-a37fde01bcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-f132c26b-14b3-499c-913e-5aafb93f1f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-d32d4800-21c5-4916-b356-0e532c040040,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-a3905bbf-c36b-434c-9b48-992b3b238775,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099652005-172.17.0.18-1595522378356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42037,DS-bd02134b-af3e-41e6-ac61-cc95eb8af52b,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-8f2ada4d-9aba-4e8e-808c-bdf3ff410925,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-ed8e0b66-885a-4204-8d93-80194b602058,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-9d380877-129a-4636-a733-4e8dbe5eec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-f6a751ed-dfc1-4dc2-b16a-2c78f5359998,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-f9438c8c-f02d-4062-a836-a66244ae2e68,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-60e28f8d-d7f6-464a-b44b-4de3b4509b62,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-467910f9-dabc-4732-997f-bb19b78ac543,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099652005-172.17.0.18-1595522378356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42037,DS-bd02134b-af3e-41e6-ac61-cc95eb8af52b,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-8f2ada4d-9aba-4e8e-808c-bdf3ff410925,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-ed8e0b66-885a-4204-8d93-80194b602058,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-9d380877-129a-4636-a733-4e8dbe5eec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-f6a751ed-dfc1-4dc2-b16a-2c78f5359998,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-f9438c8c-f02d-4062-a836-a66244ae2e68,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-60e28f8d-d7f6-464a-b44b-4de3b4509b62,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-467910f9-dabc-4732-997f-bb19b78ac543,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490328069-172.17.0.18-1595522586043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38234,DS-617e6f95-54aa-4a20-8763-87a31b214e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-ae04cb41-7e14-470b-91c4-2d9c0ed23e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-6737fd55-78d5-44d0-988f-1525fd148b05,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-0097e5b1-b77a-4d41-8f78-4c395dea1c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-5e492e14-c1c8-4524-b86e-1630487d4850,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-092f37fa-bb66-4fc0-bcce-5d3882f04015,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-2bf5b2eb-93d7-49ac-919d-11400bf2f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-daf014f9-5f2f-4fec-8498-e591e7098159,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490328069-172.17.0.18-1595522586043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38234,DS-617e6f95-54aa-4a20-8763-87a31b214e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-ae04cb41-7e14-470b-91c4-2d9c0ed23e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-6737fd55-78d5-44d0-988f-1525fd148b05,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-0097e5b1-b77a-4d41-8f78-4c395dea1c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-5e492e14-c1c8-4524-b86e-1630487d4850,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-092f37fa-bb66-4fc0-bcce-5d3882f04015,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-2bf5b2eb-93d7-49ac-919d-11400bf2f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-daf014f9-5f2f-4fec-8498-e591e7098159,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725291100-172.17.0.18-1595522783703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41207,DS-1c6acb33-d602-4ef9-9751-0e013b05e0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-3b894619-3c99-4e77-8515-e1ddaf73e964,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-adde5813-8e14-4523-ab69-cedbe81c9556,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-ca82d866-6665-470b-aff0-c846aab49a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-e815e5c0-1213-4fb3-baa4-9c3018173fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-3245bfbb-c6de-4e3f-b790-4445830182c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-0a34c066-eece-4e00-9a57-4d01ff6d8c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-861bcee5-1af5-43d7-bf75-0b9b162f1724,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725291100-172.17.0.18-1595522783703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41207,DS-1c6acb33-d602-4ef9-9751-0e013b05e0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-3b894619-3c99-4e77-8515-e1ddaf73e964,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-adde5813-8e14-4523-ab69-cedbe81c9556,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-ca82d866-6665-470b-aff0-c846aab49a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-e815e5c0-1213-4fb3-baa4-9c3018173fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-3245bfbb-c6de-4e3f-b790-4445830182c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-0a34c066-eece-4e00-9a57-4d01ff6d8c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-861bcee5-1af5-43d7-bf75-0b9b162f1724,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025995151-172.17.0.18-1595522870221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36239,DS-49ce55ff-4a79-475f-b528-f54fd94c17d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-e6f34223-4004-4929-82d9-25c172cfd5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-585d7731-817a-4ee8-a79f-92d02439f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-cab3b804-2f21-4c77-96ac-77630a0bf64d,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-6fbee39e-94c5-4723-a693-8ce055d59a44,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-9418102f-8169-4344-a8c1-c1045fb655c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-090ccc9c-652f-4231-abdc-5f763c5d1035,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-ef420b58-b182-4eb7-80b5-c7e0d35e12dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025995151-172.17.0.18-1595522870221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36239,DS-49ce55ff-4a79-475f-b528-f54fd94c17d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-e6f34223-4004-4929-82d9-25c172cfd5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-585d7731-817a-4ee8-a79f-92d02439f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-cab3b804-2f21-4c77-96ac-77630a0bf64d,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-6fbee39e-94c5-4723-a693-8ce055d59a44,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-9418102f-8169-4344-a8c1-c1045fb655c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-090ccc9c-652f-4231-abdc-5f763c5d1035,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-ef420b58-b182-4eb7-80b5-c7e0d35e12dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692456194-172.17.0.18-1595522989443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41210,DS-afef08ae-b2fb-4517-a5a4-df8a3eaed0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-8ce261ce-37d6-4ec4-a25e-3f75b8103ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-d63c0253-6429-4aa2-9bbc-d67fe5012bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-d54b9e28-1cc1-4c31-8d58-4dca180b5ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-4eaf55d4-8ffc-4e26-950b-7f2ca25fda8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-0402ddfd-c90c-4faa-bcac-fc19045ec465,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-ff67193a-06fc-4821-a13b-bed2c68e685a,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-47bf9de8-a041-4134-9be3-ea876b08c5a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692456194-172.17.0.18-1595522989443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41210,DS-afef08ae-b2fb-4517-a5a4-df8a3eaed0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-8ce261ce-37d6-4ec4-a25e-3f75b8103ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-d63c0253-6429-4aa2-9bbc-d67fe5012bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-d54b9e28-1cc1-4c31-8d58-4dca180b5ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-4eaf55d4-8ffc-4e26-950b-7f2ca25fda8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-0402ddfd-c90c-4faa-bcac-fc19045ec465,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-ff67193a-06fc-4821-a13b-bed2c68e685a,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-47bf9de8-a041-4134-9be3-ea876b08c5a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169810595-172.17.0.18-1595523306757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-48ce502b-20c3-47a5-ab6e-192fbc22c711,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-a38b8ef8-14ae-4630-9cdd-a720f6f31bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-7ee48f78-be52-4b92-8f65-eb1f87488f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-0413afeb-0bef-426c-9368-4af521c1dfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-ecd87a9e-5542-4425-8c0f-8f35331fe4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-c498d03c-6915-4a71-9a63-f59721176c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-7777ed77-1c8c-49ff-94ee-15001dc7df77,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-ad8c4e14-2d3a-4cd1-a46a-776d62dd40e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169810595-172.17.0.18-1595523306757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-48ce502b-20c3-47a5-ab6e-192fbc22c711,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-a38b8ef8-14ae-4630-9cdd-a720f6f31bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-7ee48f78-be52-4b92-8f65-eb1f87488f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-0413afeb-0bef-426c-9368-4af521c1dfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-ecd87a9e-5542-4425-8c0f-8f35331fe4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-c498d03c-6915-4a71-9a63-f59721176c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-7777ed77-1c8c-49ff-94ee-15001dc7df77,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-ad8c4e14-2d3a-4cd1-a46a-776d62dd40e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295780286-172.17.0.18-1595523614988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44510,DS-b0f26bf4-7500-4b72-9530-4c0f4469d16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-8ded5c14-1c68-4431-9cc5-9035d7a3f464,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-401f0559-eb4b-48ec-bf9b-056e18ab6549,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-0b169e62-3688-4218-b60c-40f40a241206,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-87490b65-80a2-4943-88b1-038bd47c014d,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-7dd3d858-fee6-4abf-a68b-eb4057d123ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-c506ca11-a87a-4f47-9bbd-64774f3854d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-45c95671-0a00-4b73-910c-425abf73abaf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295780286-172.17.0.18-1595523614988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44510,DS-b0f26bf4-7500-4b72-9530-4c0f4469d16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-8ded5c14-1c68-4431-9cc5-9035d7a3f464,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-401f0559-eb4b-48ec-bf9b-056e18ab6549,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-0b169e62-3688-4218-b60c-40f40a241206,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-87490b65-80a2-4943-88b1-038bd47c014d,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-7dd3d858-fee6-4abf-a68b-eb4057d123ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-c506ca11-a87a-4f47-9bbd-64774f3854d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-45c95671-0a00-4b73-910c-425abf73abaf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846417832-172.17.0.18-1595523755921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-8b5bebd7-ae2f-4a75-a01b-ef41a513153a,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-b1f14d38-d7c9-4c41-b9cc-88725b3a1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-a99c444c-67de-49b2-b47d-3c1deb16fd01,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-54473241-c5f1-484d-ba36-928a125dfef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-c1a6360d-1584-41be-9878-07b7180fb089,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-b0b6cb21-0751-4224-868e-436604b7ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-d3adfcb4-68b9-434c-b62d-54a7bfad2c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-3c7e2b3c-9641-4fec-9576-9155bf3b93c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846417832-172.17.0.18-1595523755921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-8b5bebd7-ae2f-4a75-a01b-ef41a513153a,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-b1f14d38-d7c9-4c41-b9cc-88725b3a1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-a99c444c-67de-49b2-b47d-3c1deb16fd01,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-54473241-c5f1-484d-ba36-928a125dfef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-c1a6360d-1584-41be-9878-07b7180fb089,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-b0b6cb21-0751-4224-868e-436604b7ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-d3adfcb4-68b9-434c-b62d-54a7bfad2c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-3c7e2b3c-9641-4fec-9576-9155bf3b93c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807541399-172.17.0.18-1595523843386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-a64aa9db-698e-4872-802f-fa6ce5d6f3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-5f7bc40e-3f4a-41f7-969c-67895cbc86fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-8389991e-8195-43dc-9f66-cd3e1c0c1ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-3ded6671-76fb-42ea-b7a2-a6e4a6591895,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-abd4d4e5-a1b4-4ea9-9e68-21e058e47cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-65131d3f-7b1b-438c-b94a-0ce8c2874275,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-5e4b4cd6-a84c-49ee-ab70-4c7962246b98,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-7bef409b-9dde-49be-b19c-05c6b74312c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807541399-172.17.0.18-1595523843386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-a64aa9db-698e-4872-802f-fa6ce5d6f3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-5f7bc40e-3f4a-41f7-969c-67895cbc86fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-8389991e-8195-43dc-9f66-cd3e1c0c1ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-3ded6671-76fb-42ea-b7a2-a6e4a6591895,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-abd4d4e5-a1b4-4ea9-9e68-21e058e47cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-65131d3f-7b1b-438c-b94a-0ce8c2874275,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-5e4b4cd6-a84c-49ee-ab70-4c7962246b98,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-7bef409b-9dde-49be-b19c-05c6b74312c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482280942-172.17.0.18-1595524116453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-700119cd-f431-4f24-b70c-39888f0f831c,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-02556359-ee23-4bf4-b469-cb574a71437c,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-8ec8ccda-c0aa-49bc-b0ce-0c6f402512f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-95712a4c-c537-4b59-89f1-9fbc0da57437,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-eb46ac31-8b13-4d5e-9984-e343622e85da,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-96583ae0-0cbc-40c4-b0f5-845bd88f933f,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-5cf9a1c4-d621-4b79-9403-8a7f330d1046,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-63c12db3-4662-4362-ae7a-611c4e629987,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482280942-172.17.0.18-1595524116453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-700119cd-f431-4f24-b70c-39888f0f831c,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-02556359-ee23-4bf4-b469-cb574a71437c,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-8ec8ccda-c0aa-49bc-b0ce-0c6f402512f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-95712a4c-c537-4b59-89f1-9fbc0da57437,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-eb46ac31-8b13-4d5e-9984-e343622e85da,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-96583ae0-0cbc-40c4-b0f5-845bd88f933f,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-5cf9a1c4-d621-4b79-9403-8a7f330d1046,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-63c12db3-4662-4362-ae7a-611c4e629987,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888634446-172.17.0.18-1595524245048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-94193d07-7389-4401-9eaa-e44f3fc40700,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-e146afb2-4819-47ab-b4e6-24ff7c95bcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-4e8112a4-6a69-4b32-b9b4-bcf75acd4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-c883781f-c33a-4392-9226-bc3fa1ba336d,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-9f6a9cf6-89c5-4751-8eab-0ef2235777ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-7b037fb7-49ff-43f3-af8d-26a1fccb65c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-f9c441a9-990c-4775-87fa-ef8612aaaf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-e56a476d-bf3b-4c36-b50a-16da2a2ab4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888634446-172.17.0.18-1595524245048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-94193d07-7389-4401-9eaa-e44f3fc40700,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-e146afb2-4819-47ab-b4e6-24ff7c95bcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-4e8112a4-6a69-4b32-b9b4-bcf75acd4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-c883781f-c33a-4392-9226-bc3fa1ba336d,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-9f6a9cf6-89c5-4751-8eab-0ef2235777ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-7b037fb7-49ff-43f3-af8d-26a1fccb65c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-f9c441a9-990c-4775-87fa-ef8612aaaf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-e56a476d-bf3b-4c36-b50a-16da2a2ab4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538366068-172.17.0.18-1595524460310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-6a7c5c56-78b2-4765-885c-a7669bcf065a,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-3082011b-1402-428b-a873-3b3e01b69a02,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-d2080ff8-25c6-447c-b748-b36f3320fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-f1cf40a8-cdce-44cd-bc4d-a819ac0489c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-9f724b78-8619-400f-8387-74700ab160f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-ccc4f509-9908-44f6-a273-a1d2e8667d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-d080ffb3-19a3-46ca-93ba-c51b37e6980c,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-d0aa09ad-7aa7-415f-8221-a6321943097f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538366068-172.17.0.18-1595524460310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45830,DS-6a7c5c56-78b2-4765-885c-a7669bcf065a,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-3082011b-1402-428b-a873-3b3e01b69a02,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-d2080ff8-25c6-447c-b748-b36f3320fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-f1cf40a8-cdce-44cd-bc4d-a819ac0489c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-9f724b78-8619-400f-8387-74700ab160f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-ccc4f509-9908-44f6-a273-a1d2e8667d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-d080ffb3-19a3-46ca-93ba-c51b37e6980c,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-d0aa09ad-7aa7-415f-8221-a6321943097f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2829692-172.17.0.18-1595524504075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44502,DS-f32dc36b-7db0-4db6-8a66-35466007563e,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-9a4cfa5e-c863-4afe-8854-2a07d97f011c,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-23bdde7f-3a38-4c4d-b44f-81f0ce883d37,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-37d88c63-048f-4255-9edc-360e8ef92ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-732034c8-0157-45a7-b5f7-65df1610c322,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-4617fc3f-960d-4f71-8504-510636b26583,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-4787b3bc-e051-4bb3-933b-c5faf3c8a506,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-3e9e76ea-11e1-44b6-8fed-40d62fc03ba4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2829692-172.17.0.18-1595524504075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44502,DS-f32dc36b-7db0-4db6-8a66-35466007563e,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-9a4cfa5e-c863-4afe-8854-2a07d97f011c,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-23bdde7f-3a38-4c4d-b44f-81f0ce883d37,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-37d88c63-048f-4255-9edc-360e8ef92ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-732034c8-0157-45a7-b5f7-65df1610c322,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-4617fc3f-960d-4f71-8504-510636b26583,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-4787b3bc-e051-4bb3-933b-c5faf3c8a506,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-3e9e76ea-11e1-44b6-8fed-40d62fc03ba4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934869468-172.17.0.18-1595524590490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-92e05121-9cc7-47f1-aa13-249b2f8b5dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-e2f00513-99a6-4f2a-b8d2-cb26fe9f616f,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-2c659a5f-af82-4ea6-9722-6be8db1409a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-1a6422b8-76d0-4220-ba17-d49628d12f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-2fc4a043-63dd-4c73-b344-35de9f5e22ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-75245eaa-7107-4e54-b104-2d3689de56e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-2cee3ccc-f57f-4bf0-8c21-dfb64a9ab2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-542b2a0c-e0a8-4eb5-b08f-9cb3d85f0388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934869468-172.17.0.18-1595524590490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-92e05121-9cc7-47f1-aa13-249b2f8b5dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-e2f00513-99a6-4f2a-b8d2-cb26fe9f616f,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-2c659a5f-af82-4ea6-9722-6be8db1409a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-1a6422b8-76d0-4220-ba17-d49628d12f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-2fc4a043-63dd-4c73-b344-35de9f5e22ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-75245eaa-7107-4e54-b104-2d3689de56e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-2cee3ccc-f57f-4bf0-8c21-dfb64a9ab2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-542b2a0c-e0a8-4eb5-b08f-9cb3d85f0388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236580322-172.17.0.18-1595525003721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41038,DS-3b3ca403-5b3e-456e-8612-587e8b997608,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-1853e195-d706-47f4-8a76-1f90ba57fbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-05cfc21f-ead9-4fc6-8d56-d5d1b18577e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-68b66d0e-0b06-439f-98a7-716e2e0eb697,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-59dfff4b-4085-43d0-8582-e0e113bf6efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-0d54aeeb-e518-4525-8b99-21948b0140ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-ffa94706-a6bf-4148-8fa3-0503a1495bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-f0c3e01d-b90d-459c-aba4-fadc413ae46c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236580322-172.17.0.18-1595525003721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41038,DS-3b3ca403-5b3e-456e-8612-587e8b997608,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-1853e195-d706-47f4-8a76-1f90ba57fbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-05cfc21f-ead9-4fc6-8d56-d5d1b18577e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-68b66d0e-0b06-439f-98a7-716e2e0eb697,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-59dfff4b-4085-43d0-8582-e0e113bf6efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-0d54aeeb-e518-4525-8b99-21948b0140ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-ffa94706-a6bf-4148-8fa3-0503a1495bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-f0c3e01d-b90d-459c-aba4-fadc413ae46c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565445119-172.17.0.18-1595525139832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44999,DS-0d475dec-3c42-4428-bb14-1aace3ee4164,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-3bb64b7f-3454-4217-9d49-1119deef2646,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-ae5d85e5-c80e-4b3f-b3b4-c38ee478435a,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-f34da1db-14f2-4d5a-b50d-58ebdae5b17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-6ef64f01-50dd-446e-aba0-ce6dd36ae1de,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-312d113e-4567-4ac2-a4d2-2aec863ca725,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-dd31c039-1644-4e90-8bf4-b886dd4f9463,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-33216b41-a38e-4364-8afe-8f5e822483a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565445119-172.17.0.18-1595525139832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44999,DS-0d475dec-3c42-4428-bb14-1aace3ee4164,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-3bb64b7f-3454-4217-9d49-1119deef2646,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-ae5d85e5-c80e-4b3f-b3b4-c38ee478435a,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-f34da1db-14f2-4d5a-b50d-58ebdae5b17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-6ef64f01-50dd-446e-aba0-ce6dd36ae1de,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-312d113e-4567-4ac2-a4d2-2aec863ca725,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-dd31c039-1644-4e90-8bf4-b886dd4f9463,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-33216b41-a38e-4364-8afe-8f5e822483a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22127136-172.17.0.18-1595525587267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39312,DS-1ce9e325-0e0a-4c41-9395-a30ac7f456ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-dbc6d1c6-f327-4966-833a-e850051ba39e,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-70ecd8e0-0920-49d8-86ce-2e8fa14be166,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-8e0c47dd-30d2-44d1-a2df-3117250da3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-e3efa2f0-1a02-4bc7-82a1-0e564f2c52d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-57203f5a-782c-4a42-ba58-fa250d68d545,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-faf99b06-974c-4726-9f07-890214b044ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-4f85daf4-5e99-4fa6-a182-04674a447076,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22127136-172.17.0.18-1595525587267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39312,DS-1ce9e325-0e0a-4c41-9395-a30ac7f456ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-dbc6d1c6-f327-4966-833a-e850051ba39e,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-70ecd8e0-0920-49d8-86ce-2e8fa14be166,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-8e0c47dd-30d2-44d1-a2df-3117250da3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-e3efa2f0-1a02-4bc7-82a1-0e564f2c52d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-57203f5a-782c-4a42-ba58-fa250d68d545,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-faf99b06-974c-4726-9f07-890214b044ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-4f85daf4-5e99-4fa6-a182-04674a447076,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014912626-172.17.0.18-1595525638990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38594,DS-b2cdea48-3dce-44f8-857d-cdc08f270519,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-19708fc4-5662-4774-a25a-40889ac77d13,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-c682edda-2233-4906-8d97-f0e2d5818abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-d70504df-5484-46d1-8c33-07cdb47468b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-9f77178f-a9ab-4463-905f-f081607e5468,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-fba03508-674b-4a0f-86aa-bd410a6dae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-93396a29-0622-48ee-8728-b4c7086ae9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-ee7146d3-92a6-49b2-8d49-cea5a2594836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014912626-172.17.0.18-1595525638990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38594,DS-b2cdea48-3dce-44f8-857d-cdc08f270519,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-19708fc4-5662-4774-a25a-40889ac77d13,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-c682edda-2233-4906-8d97-f0e2d5818abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-d70504df-5484-46d1-8c33-07cdb47468b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-9f77178f-a9ab-4463-905f-f081607e5468,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-fba03508-674b-4a0f-86aa-bd410a6dae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-93396a29-0622-48ee-8728-b4c7086ae9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-ee7146d3-92a6-49b2-8d49-cea5a2594836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591105834-172.17.0.18-1595525824231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42784,DS-b73d6004-934f-4689-af1f-0bbb454ef0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-664fc70b-f161-484f-8930-cd37a3af35ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-8ebfa233-8c4e-42a6-b73d-bf4fdd382212,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-a5898eaf-447c-4381-b4f0-e6162b17bc80,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-7a880859-2ffc-40b2-9546-ffe62b8cb90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-bc9860be-fd6b-4473-97e7-3134f2dbcb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-c4b6a02d-d81a-4ca4-a1d5-ffd915f96afb,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-c476bd1d-ca85-4c16-90cb-e89c2d2ab345,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591105834-172.17.0.18-1595525824231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42784,DS-b73d6004-934f-4689-af1f-0bbb454ef0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-664fc70b-f161-484f-8930-cd37a3af35ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-8ebfa233-8c4e-42a6-b73d-bf4fdd382212,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-a5898eaf-447c-4381-b4f0-e6162b17bc80,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-7a880859-2ffc-40b2-9546-ffe62b8cb90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-bc9860be-fd6b-4473-97e7-3134f2dbcb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-c4b6a02d-d81a-4ca4-a1d5-ffd915f96afb,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-c476bd1d-ca85-4c16-90cb-e89c2d2ab345,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094318139-172.17.0.18-1595525949232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-a216b9a3-ec03-4bfa-a1c7-a5dc2ac41b17,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-c7892475-a3c9-474a-a6c8-944755c5d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-c54a7245-ac80-44d7-a2ee-c2bd6584ea56,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-a410a2ff-d0e7-494f-97ba-49b2fd77304b,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-6e74c1b8-1732-4f27-832f-1b1fdc9125ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-4ebee7d9-b94d-49ab-b7bd-65fa482d4018,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-4feba3d2-bf38-46fd-9451-9769115157c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-332f1eab-9e95-4113-87c1-e32270b27811,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094318139-172.17.0.18-1595525949232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-a216b9a3-ec03-4bfa-a1c7-a5dc2ac41b17,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-c7892475-a3c9-474a-a6c8-944755c5d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-c54a7245-ac80-44d7-a2ee-c2bd6584ea56,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-a410a2ff-d0e7-494f-97ba-49b2fd77304b,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-6e74c1b8-1732-4f27-832f-1b1fdc9125ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-4ebee7d9-b94d-49ab-b7bd-65fa482d4018,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-4feba3d2-bf38-46fd-9451-9769115157c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-332f1eab-9e95-4113-87c1-e32270b27811,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330498791-172.17.0.18-1595526119539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36763,DS-65561b12-c47d-4eb4-bc0b-0124fd8bc138,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-f4b17084-3f0a-4813-8dea-8592ab7350dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-6bd15cf9-3a74-49f6-b6d2-2b53ee90134b,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-3b71eff2-37ff-4ed9-bfac-3291e33ef7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-338b9136-d256-4760-ac4f-300fe996c174,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-32972fd1-64b4-480a-84db-e06469c2aa27,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-4efb6d81-532a-49cc-a6f2-11bd60e1b26a,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-7c8e2efc-f12c-4b93-ba3b-4b6069c85550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330498791-172.17.0.18-1595526119539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36763,DS-65561b12-c47d-4eb4-bc0b-0124fd8bc138,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-f4b17084-3f0a-4813-8dea-8592ab7350dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-6bd15cf9-3a74-49f6-b6d2-2b53ee90134b,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-3b71eff2-37ff-4ed9-bfac-3291e33ef7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-338b9136-d256-4760-ac4f-300fe996c174,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-32972fd1-64b4-480a-84db-e06469c2aa27,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-4efb6d81-532a-49cc-a6f2-11bd60e1b26a,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-7c8e2efc-f12c-4b93-ba3b-4b6069c85550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522677756-172.17.0.18-1595526162227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40358,DS-df18a9bd-0f4d-4172-b076-8da2d262fc97,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-0752fc0b-57d0-4ce2-b1c4-0cee727a65aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-1d82c6e0-1823-41ea-96f3-4359a28d7793,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-30bb5cde-ef6f-47f4-91b0-a1f28eaced3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-c506f646-75f4-41ab-b9a2-f3bf8342b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-28f42703-d127-42c0-a6ac-15273bb2d625,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-8aa88abb-5df7-4b57-9950-7da1c34f2625,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-af7522ed-149d-42b3-afd0-9879095ae71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522677756-172.17.0.18-1595526162227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40358,DS-df18a9bd-0f4d-4172-b076-8da2d262fc97,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-0752fc0b-57d0-4ce2-b1c4-0cee727a65aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-1d82c6e0-1823-41ea-96f3-4359a28d7793,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-30bb5cde-ef6f-47f4-91b0-a1f28eaced3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-c506f646-75f4-41ab-b9a2-f3bf8342b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-28f42703-d127-42c0-a6ac-15273bb2d625,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-8aa88abb-5df7-4b57-9950-7da1c34f2625,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-af7522ed-149d-42b3-afd0-9879095ae71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102068748-172.17.0.18-1595526324990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43457,DS-4869ae8b-c6d4-45ef-943b-377a6505853f,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-46c2d8d6-a15f-4303-9760-c886dbf916b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-373709a4-50de-469c-8694-aace1d3326b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-17fc02f3-b089-443f-830b-2f07177e02e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-5ae9f10b-b1f0-4e63-adfb-95c5c2a8996b,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-bc75746e-88a5-48c3-81c1-6a81b24bc838,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-c8d53587-2f56-46e0-8244-9539747dcc38,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-56333608-5ffa-47ac-9f72-56f850011ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102068748-172.17.0.18-1595526324990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43457,DS-4869ae8b-c6d4-45ef-943b-377a6505853f,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-46c2d8d6-a15f-4303-9760-c886dbf916b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-373709a4-50de-469c-8694-aace1d3326b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-17fc02f3-b089-443f-830b-2f07177e02e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-5ae9f10b-b1f0-4e63-adfb-95c5c2a8996b,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-bc75746e-88a5-48c3-81c1-6a81b24bc838,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-c8d53587-2f56-46e0-8244-9539747dcc38,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-56333608-5ffa-47ac-9f72-56f850011ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202296912-172.17.0.18-1595526451121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-552ca545-9579-4e70-ac5f-657f0ed1f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-76c46852-e8e3-4357-a603-2667ad92f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-bc885b20-4224-423a-a71b-ef4d8fc2a516,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-3f5ea916-767e-4739-94ca-dadd06c713d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-8f02fe8f-03b3-497a-8b74-17e4ff295d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-75a38c9a-becc-48f7-a765-e47ca0e13e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-503b3471-a23e-4736-8658-9726e406fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-30483504-2f96-4f5a-b13a-29ad2c65def0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202296912-172.17.0.18-1595526451121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-552ca545-9579-4e70-ac5f-657f0ed1f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-76c46852-e8e3-4357-a603-2667ad92f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-bc885b20-4224-423a-a71b-ef4d8fc2a516,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-3f5ea916-767e-4739-94ca-dadd06c713d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-8f02fe8f-03b3-497a-8b74-17e4ff295d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-75a38c9a-becc-48f7-a765-e47ca0e13e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-503b3471-a23e-4736-8658-9726e406fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-30483504-2f96-4f5a-b13a-29ad2c65def0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103521953-172.17.0.18-1595526614654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45510,DS-3532ffcd-5012-4591-b96a-7d5b15f1090d,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-2af3c842-ddcb-4b5a-8770-9b2d4e1e28cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-d5cdb6c6-2ffc-4a80-8a5e-64493334577e,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-0767a7da-c46f-4dea-966e-1f3756b7051c,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-910c1247-7e55-492f-8c68-bbd14b5ab149,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-258ec38b-f8bf-4f17-9b54-dff65b8d611e,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-8abc6998-445e-4025-9efe-da1da5339f70,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-f75cd16a-0ece-4267-9d1a-3faa29698689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103521953-172.17.0.18-1595526614654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45510,DS-3532ffcd-5012-4591-b96a-7d5b15f1090d,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-2af3c842-ddcb-4b5a-8770-9b2d4e1e28cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-d5cdb6c6-2ffc-4a80-8a5e-64493334577e,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-0767a7da-c46f-4dea-966e-1f3756b7051c,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-910c1247-7e55-492f-8c68-bbd14b5ab149,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-258ec38b-f8bf-4f17-9b54-dff65b8d611e,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-8abc6998-445e-4025-9efe-da1da5339f70,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-f75cd16a-0ece-4267-9d1a-3faa29698689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805059975-172.17.0.18-1595527113743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-75588516-18fd-434b-969b-2e6fb5fbdfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-97b2736f-54fc-4bca-a155-29f410cc1728,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-8d463672-43b8-4b2b-a229-a977eaac7db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-9a7d1234-2938-4400-b2d3-cd478236ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-394af326-c6a7-414a-909f-93d0035f990f,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-f330e777-860a-4a22-ac05-6ec53c589422,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-0136712b-beb5-4fb6-ac5a-4f89ef28ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-c5c6059c-8f32-4522-8782-59ab3df05e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805059975-172.17.0.18-1595527113743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-75588516-18fd-434b-969b-2e6fb5fbdfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-97b2736f-54fc-4bca-a155-29f410cc1728,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-8d463672-43b8-4b2b-a229-a977eaac7db6,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-9a7d1234-2938-4400-b2d3-cd478236ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-394af326-c6a7-414a-909f-93d0035f990f,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-f330e777-860a-4a22-ac05-6ec53c589422,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-0136712b-beb5-4fb6-ac5a-4f89ef28ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-c5c6059c-8f32-4522-8782-59ab3df05e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263422129-172.17.0.18-1595527241900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-fbd89880-6c8f-41ad-b8f1-bdf77c249d04,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-1d3a5ca7-4432-4d10-a1f2-0645bc6dd9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-a8ccf7dd-abd7-425e-9806-59ec596bc817,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-70070281-5821-4e9d-af31-c7d50e63d47f,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-9d294b78-7176-4814-bb3d-112305502b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-a018fb1c-2d2e-4488-87db-a14f3e30c8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-430c66ee-b797-44f6-93df-9b08a4ff5039,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-38552a18-488d-4b46-9cfc-a8302554fc04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263422129-172.17.0.18-1595527241900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-fbd89880-6c8f-41ad-b8f1-bdf77c249d04,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-1d3a5ca7-4432-4d10-a1f2-0645bc6dd9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-a8ccf7dd-abd7-425e-9806-59ec596bc817,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-70070281-5821-4e9d-af31-c7d50e63d47f,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-9d294b78-7176-4814-bb3d-112305502b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-a018fb1c-2d2e-4488-87db-a14f3e30c8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-430c66ee-b797-44f6-93df-9b08a4ff5039,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-38552a18-488d-4b46-9cfc-a8302554fc04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710232189-172.17.0.18-1595527285894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-9033a749-e8c4-440b-a3d9-9ebafbd04781,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-aaf4baf0-8583-4fe3-81e5-0443e377c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-e1881d9d-2425-46ff-ae2e-048c247270c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-70a5bde5-7f8a-4fb0-a6ed-a650c65e09c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-acd7dac3-ae49-44b6-8bea-ba7eb82dfe44,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-506a5622-fde6-4f3f-878e-f3862e32eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-7d0b4d9f-9640-4a70-b731-f9d0064e5eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-e39edfc6-ee51-4537-83e9-63d952d3cb74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710232189-172.17.0.18-1595527285894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-9033a749-e8c4-440b-a3d9-9ebafbd04781,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-aaf4baf0-8583-4fe3-81e5-0443e377c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-e1881d9d-2425-46ff-ae2e-048c247270c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-70a5bde5-7f8a-4fb0-a6ed-a650c65e09c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-acd7dac3-ae49-44b6-8bea-ba7eb82dfe44,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-506a5622-fde6-4f3f-878e-f3862e32eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-7d0b4d9f-9640-4a70-b731-f9d0064e5eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-e39edfc6-ee51-4537-83e9-63d952d3cb74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280445943-172.17.0.18-1595527774505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40085,DS-007b24dc-1e87-44bf-8f82-284eae4c3997,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-b92253fc-18a3-4303-b827-6d8a8a00fcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-5889d651-a879-4a1f-a0bd-3bc8ad42c585,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-9dc72f78-0ebb-49f6-a64f-38bdd12597ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-b8ca41ec-65a5-4e8a-ad3e-92f865fa8119,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-f637e2e6-4fb2-417a-81ca-3f6d888b44f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-19804f21-f6fb-40ab-af5c-388af9fca916,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-5415cb61-3d9d-47f4-8e45-e34cd94cba5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280445943-172.17.0.18-1595527774505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40085,DS-007b24dc-1e87-44bf-8f82-284eae4c3997,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-b92253fc-18a3-4303-b827-6d8a8a00fcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-5889d651-a879-4a1f-a0bd-3bc8ad42c585,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-9dc72f78-0ebb-49f6-a64f-38bdd12597ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-b8ca41ec-65a5-4e8a-ad3e-92f865fa8119,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-f637e2e6-4fb2-417a-81ca-3f6d888b44f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-19804f21-f6fb-40ab-af5c-388af9fca916,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-5415cb61-3d9d-47f4-8e45-e34cd94cba5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750129341-172.17.0.18-1595527905164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42386,DS-9788cab8-8dad-4413-86b2-4d0389c87dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-69235ff4-50b2-4a89-95bd-5d3243189db8,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-57f9c9e2-c823-4149-a649-41eaa19221c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-074e6000-3b3c-4b3f-8432-250137df0a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-b62825d8-79e6-495d-9f6d-4d451b1550a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-dd944972-1d0c-4140-ac17-241fa28d41fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-d5607fb5-07c9-4490-af3b-392fcc1c9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-313d7a25-10a7-4d52-8b38-ce4bba8ec830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750129341-172.17.0.18-1595527905164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42386,DS-9788cab8-8dad-4413-86b2-4d0389c87dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-69235ff4-50b2-4a89-95bd-5d3243189db8,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-57f9c9e2-c823-4149-a649-41eaa19221c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-074e6000-3b3c-4b3f-8432-250137df0a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-b62825d8-79e6-495d-9f6d-4d451b1550a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-dd944972-1d0c-4140-ac17-241fa28d41fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-d5607fb5-07c9-4490-af3b-392fcc1c9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-313d7a25-10a7-4d52-8b38-ce4bba8ec830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497361549-172.17.0.18-1595528160637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33087,DS-adcf54d9-41df-43a7-a0aa-b0c9d71846ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-53d6c9c5-829c-47ae-af01-bbd84619c3be,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-14e3d453-9489-4bbc-a50f-9ccbdc3e6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-6cb597ae-caed-4188-a195-4f8a68befcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-65b99149-4213-4b71-9757-82049eac5251,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-133bbcbd-a89c-4c91-bc45-16eeb840114e,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-cbb8820e-6d03-4eb7-b04e-e470daf7274e,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-9c19b127-83b8-4d8e-a185-c7c419df413b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497361549-172.17.0.18-1595528160637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33087,DS-adcf54d9-41df-43a7-a0aa-b0c9d71846ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-53d6c9c5-829c-47ae-af01-bbd84619c3be,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-14e3d453-9489-4bbc-a50f-9ccbdc3e6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-6cb597ae-caed-4188-a195-4f8a68befcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-65b99149-4213-4b71-9757-82049eac5251,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-133bbcbd-a89c-4c91-bc45-16eeb840114e,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-cbb8820e-6d03-4eb7-b04e-e470daf7274e,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-9c19b127-83b8-4d8e-a185-c7c419df413b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035988834-172.17.0.18-1595528298356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-f21be187-04fc-4f45-a300-0085744c9459,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-f64ca1aa-5566-429b-a454-23d55ed14204,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-cf783280-d80b-4a84-83c7-de41e72c84a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-810a4dcd-4d4c-42f0-b8c0-8cfbe31a5935,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-e0be62de-12cc-4b73-aed5-5b2b29799a16,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-874e40ef-1dbf-481e-a62a-6bea59f9b2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-e3484638-4679-4b37-bd6c-a7499a93cdad,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-93595524-16b9-462c-9b57-6fbd2d7849cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035988834-172.17.0.18-1595528298356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-f21be187-04fc-4f45-a300-0085744c9459,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-f64ca1aa-5566-429b-a454-23d55ed14204,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-cf783280-d80b-4a84-83c7-de41e72c84a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-810a4dcd-4d4c-42f0-b8c0-8cfbe31a5935,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-e0be62de-12cc-4b73-aed5-5b2b29799a16,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-874e40ef-1dbf-481e-a62a-6bea59f9b2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-e3484638-4679-4b37-bd6c-a7499a93cdad,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-93595524-16b9-462c-9b57-6fbd2d7849cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 6614
