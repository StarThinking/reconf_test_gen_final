reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622601373-172.17.0.20-1595643152316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33915,DS-a0f0abd2-b91d-40bb-9182-f138c22fb3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-76e4b7b7-e010-430b-b2ef-58032fb9cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-10092e46-9470-43e7-9228-275c5e35a09c,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-5ea7708b-9594-4836-9720-f87a2352d358,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-65ef4f22-6aa6-47d7-8189-27001df6985d,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-04b6997d-d98a-4d97-a769-c41a312a8aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-2618e0b8-d0ef-4323-9285-348ac11f7896,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-4f596817-a90c-43b5-86cc-81beb20b955b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622601373-172.17.0.20-1595643152316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33915,DS-a0f0abd2-b91d-40bb-9182-f138c22fb3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-76e4b7b7-e010-430b-b2ef-58032fb9cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-10092e46-9470-43e7-9228-275c5e35a09c,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-5ea7708b-9594-4836-9720-f87a2352d358,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-65ef4f22-6aa6-47d7-8189-27001df6985d,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-04b6997d-d98a-4d97-a769-c41a312a8aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-2618e0b8-d0ef-4323-9285-348ac11f7896,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-4f596817-a90c-43b5-86cc-81beb20b955b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952526147-172.17.0.20-1595643222217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34059,DS-f4bbd331-c5b7-4496-ae73-da876a047167,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-a3565be3-2c8b-4dde-b998-76bcfc68ad78,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-0a47aa31-9dc6-4475-af70-9e609fc32f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-9e51dd15-4d07-45c1-9b14-8d4ce638591d,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-9ac70feb-975e-4392-bdbd-c3097a861078,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-bdde5118-b28a-4c28-97a2-31d42b753b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-54e7064e-73f1-456e-98d2-8c5dac345e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-b7f483f3-ea03-48be-a3db-ccb118d8f3fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952526147-172.17.0.20-1595643222217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34059,DS-f4bbd331-c5b7-4496-ae73-da876a047167,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-a3565be3-2c8b-4dde-b998-76bcfc68ad78,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-0a47aa31-9dc6-4475-af70-9e609fc32f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-9e51dd15-4d07-45c1-9b14-8d4ce638591d,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-9ac70feb-975e-4392-bdbd-c3097a861078,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-bdde5118-b28a-4c28-97a2-31d42b753b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-54e7064e-73f1-456e-98d2-8c5dac345e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-b7f483f3-ea03-48be-a3db-ccb118d8f3fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511677400-172.17.0.20-1595643899976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39856,DS-73498634-d4dd-468e-a98c-318ba05cd144,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-cf415e1a-1885-4b85-8ae9-63d47619eb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-a5f604ae-0273-45c6-8638-6d41fdca9f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-891757de-7bc9-4a0d-b689-1deea6700ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-8b26ff24-9cc3-46f2-ad77-4c959d4cd88c,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-dcdce9c3-1614-4e28-88db-c921572658c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-d96c83cf-d444-48e8-b00e-f7441d807584,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-52ba408f-c6a9-492e-8ef3-884b0be382fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511677400-172.17.0.20-1595643899976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39856,DS-73498634-d4dd-468e-a98c-318ba05cd144,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-cf415e1a-1885-4b85-8ae9-63d47619eb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-a5f604ae-0273-45c6-8638-6d41fdca9f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-891757de-7bc9-4a0d-b689-1deea6700ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-8b26ff24-9cc3-46f2-ad77-4c959d4cd88c,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-dcdce9c3-1614-4e28-88db-c921572658c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-d96c83cf-d444-48e8-b00e-f7441d807584,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-52ba408f-c6a9-492e-8ef3-884b0be382fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853818365-172.17.0.20-1595643942808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33891,DS-32ead641-65d7-42e9-bd9c-48c2cfdd4f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-5c16c07d-5835-4e20-8a55-d01170ac4c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-50724bad-da37-4952-bd6b-0ebd3644dd27,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-f53f325a-4aac-4a33-bdbb-52427f22bc97,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-aa1005c8-fa26-48f3-969d-1d241e5b8bea,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-bbc423e7-979f-4550-a130-7134066b4d29,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-dd745a85-44aa-4372-8c1d-9e10559b9a37,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-e34ebd41-ba4c-444b-8f79-3d9808cd4401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853818365-172.17.0.20-1595643942808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33891,DS-32ead641-65d7-42e9-bd9c-48c2cfdd4f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-5c16c07d-5835-4e20-8a55-d01170ac4c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-50724bad-da37-4952-bd6b-0ebd3644dd27,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-f53f325a-4aac-4a33-bdbb-52427f22bc97,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-aa1005c8-fa26-48f3-969d-1d241e5b8bea,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-bbc423e7-979f-4550-a130-7134066b4d29,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-dd745a85-44aa-4372-8c1d-9e10559b9a37,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-e34ebd41-ba4c-444b-8f79-3d9808cd4401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841237570-172.17.0.20-1595644257422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-79d1559f-0cc7-415f-9ba9-11d1cc216e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-10601d91-d72a-46c5-a521-c0c1a7217464,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-5aa6251d-236e-4821-a534-8b3fc8e8df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-dd375f75-588a-4454-bab0-5ff8fc61ee7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-cec6c16a-27ce-41a9-91d5-cbe5ba6b485d,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-a5497ae9-9f0d-4ca6-8fa2-35c2f561a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-799d44ed-5d54-4ccf-978d-8ad4533d4850,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-d3a17b8b-4fde-45e8-b483-6e454a072a26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841237570-172.17.0.20-1595644257422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-79d1559f-0cc7-415f-9ba9-11d1cc216e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-10601d91-d72a-46c5-a521-c0c1a7217464,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-5aa6251d-236e-4821-a534-8b3fc8e8df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-dd375f75-588a-4454-bab0-5ff8fc61ee7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-cec6c16a-27ce-41a9-91d5-cbe5ba6b485d,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-a5497ae9-9f0d-4ca6-8fa2-35c2f561a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-799d44ed-5d54-4ccf-978d-8ad4533d4850,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-d3a17b8b-4fde-45e8-b483-6e454a072a26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693925082-172.17.0.20-1595644334483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42070,DS-9b980382-6417-4f29-9fa8-d88197483209,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-07062a35-7bdf-477f-beeb-882e70879eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-86896f33-d6f8-483f-a1b9-910941795d45,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-e92a1805-f7a0-45cc-9f81-11efb6a4373f,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-68325fa2-c242-450e-a1b6-f052504002d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-16c2b9cd-152e-4938-8608-9e890bbd7367,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-cf694664-d739-431a-963c-6d20ddd87d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-a0892984-0411-49ca-9913-010718bb054e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693925082-172.17.0.20-1595644334483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42070,DS-9b980382-6417-4f29-9fa8-d88197483209,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-07062a35-7bdf-477f-beeb-882e70879eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-86896f33-d6f8-483f-a1b9-910941795d45,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-e92a1805-f7a0-45cc-9f81-11efb6a4373f,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-68325fa2-c242-450e-a1b6-f052504002d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-16c2b9cd-152e-4938-8608-9e890bbd7367,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-cf694664-d739-431a-963c-6d20ddd87d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-a0892984-0411-49ca-9913-010718bb054e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047995329-172.17.0.20-1595644405050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-90d1f84f-055b-46f2-bd4f-3180ff19ddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-1559a5c2-5e62-4467-a309-8c40b4acd29d,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-8042cb11-20dc-4700-930b-d08476f856d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-8fdad88f-0ea9-4425-a199-d1a00423f24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-817ce1f1-97cf-4132-870b-32ff13113601,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-511384dd-8567-4c09-820b-bdbf489544fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-85f21ac5-5ea9-4b71-b50d-b45a60dc5197,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-fac549b2-48cb-4682-9abb-6cf99100e4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047995329-172.17.0.20-1595644405050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-90d1f84f-055b-46f2-bd4f-3180ff19ddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-1559a5c2-5e62-4467-a309-8c40b4acd29d,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-8042cb11-20dc-4700-930b-d08476f856d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-8fdad88f-0ea9-4425-a199-d1a00423f24e,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-817ce1f1-97cf-4132-870b-32ff13113601,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-511384dd-8567-4c09-820b-bdbf489544fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-85f21ac5-5ea9-4b71-b50d-b45a60dc5197,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-fac549b2-48cb-4682-9abb-6cf99100e4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983966892-172.17.0.20-1595645677653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-80d13ea3-650d-4c1a-b967-45b414cac618,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-774e5fe9-44ab-405e-9815-992469ea6c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-b6369f61-9199-4f5a-b49f-9f5290420b52,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-f9af1a2f-c670-4760-89ba-b3b862ffc14c,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-38f6b9ce-63aa-43f0-b344-29dd3d52474a,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-ebe6c744-077d-4e4f-b039-54c612686875,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-b91c9819-dbdf-4de1-be9e-05c09c93a745,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-16ea1709-099b-4396-8fb6-adf3c1280d1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983966892-172.17.0.20-1595645677653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-80d13ea3-650d-4c1a-b967-45b414cac618,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-774e5fe9-44ab-405e-9815-992469ea6c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-b6369f61-9199-4f5a-b49f-9f5290420b52,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-f9af1a2f-c670-4760-89ba-b3b862ffc14c,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-38f6b9ce-63aa-43f0-b344-29dd3d52474a,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-ebe6c744-077d-4e4f-b039-54c612686875,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-b91c9819-dbdf-4de1-be9e-05c09c93a745,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-16ea1709-099b-4396-8fb6-adf3c1280d1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205666394-172.17.0.20-1595645949864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-702f8a5c-8d4e-4ec4-94a1-6b22a0d7df02,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-ae2650c1-39e2-4d43-83b0-f7f1847e7fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-9428d42e-6121-4e99-9fc3-4ef462d13ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-de5a6dc6-6586-4dfe-91ce-a8c8eaf91835,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-36a9385d-207d-4895-b02f-8e418b0d4067,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-72316d9c-1048-4e53-aeb7-e90867e3b902,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-f89bbef2-f35e-4b7c-a4d8-aed96a2e84f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-1d59405b-9223-46ea-9bca-59720391dcd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205666394-172.17.0.20-1595645949864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-702f8a5c-8d4e-4ec4-94a1-6b22a0d7df02,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-ae2650c1-39e2-4d43-83b0-f7f1847e7fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-9428d42e-6121-4e99-9fc3-4ef462d13ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-de5a6dc6-6586-4dfe-91ce-a8c8eaf91835,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-36a9385d-207d-4895-b02f-8e418b0d4067,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-72316d9c-1048-4e53-aeb7-e90867e3b902,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-f89bbef2-f35e-4b7c-a4d8-aed96a2e84f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-1d59405b-9223-46ea-9bca-59720391dcd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188646575-172.17.0.20-1595646510472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43752,DS-5cf7f9a9-a03c-4507-8be7-ca1a5ebeaf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-ea3f6d9a-30b9-4aec-9a66-4632dd6cd4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-150cacb0-c0b0-4798-bd39-e75adb5ad841,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-8dc69eef-b81b-468d-8197-6ad4fed998d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-4703d1d2-94cd-448c-9524-4d1273429f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-14114617-c1f8-4fd4-abf1-15729a44bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-071cba27-95b2-4b7a-86f2-8b8072454c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-4ea45cc6-fc86-4063-8f5f-1eeb46178ee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188646575-172.17.0.20-1595646510472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43752,DS-5cf7f9a9-a03c-4507-8be7-ca1a5ebeaf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-ea3f6d9a-30b9-4aec-9a66-4632dd6cd4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-150cacb0-c0b0-4798-bd39-e75adb5ad841,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-8dc69eef-b81b-468d-8197-6ad4fed998d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-4703d1d2-94cd-448c-9524-4d1273429f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-14114617-c1f8-4fd4-abf1-15729a44bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-071cba27-95b2-4b7a-86f2-8b8072454c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-4ea45cc6-fc86-4063-8f5f-1eeb46178ee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066606780-172.17.0.20-1595646808046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39215,DS-47f39b7d-cc2f-4a51-9844-18c518976010,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-298fbc08-cf93-426b-807a-58f280f3ed11,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-c141b516-2cde-40b3-bcbf-5525ab8ed6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d7b07c1e-cc1a-4db0-9913-10a30df179e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-c595bc99-03d2-4705-bf4b-55f6052c3a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-d41b6bbe-a927-4459-83ff-24f011e414d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-4460172e-816d-4f53-ad7b-664d25e05479,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-f8dc008b-66f1-46f2-8c88-a51f115ca8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066606780-172.17.0.20-1595646808046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39215,DS-47f39b7d-cc2f-4a51-9844-18c518976010,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-298fbc08-cf93-426b-807a-58f280f3ed11,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-c141b516-2cde-40b3-bcbf-5525ab8ed6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d7b07c1e-cc1a-4db0-9913-10a30df179e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-c595bc99-03d2-4705-bf4b-55f6052c3a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-d41b6bbe-a927-4459-83ff-24f011e414d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-4460172e-816d-4f53-ad7b-664d25e05479,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-f8dc008b-66f1-46f2-8c88-a51f115ca8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1052396482-172.17.0.20-1595646981190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46016,DS-ea3a1844-adf7-4877-a8ee-cc5471df49c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-0f74099e-3ebc-4e99-a261-35b45c582c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e26d8755-33d0-4501-8400-178a3e20830a,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-f3174bd1-c13a-42ec-9cba-d672da54cbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-a31bf364-2555-4a4e-aaa9-e3ad8f51a143,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-9a30bb47-5771-4305-9b70-f53c479c93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-681cf9d1-4c3e-4f18-bb6b-b73d4dcced24,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-14cc4cd5-008e-4d03-96da-aa5fa5a4fd88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1052396482-172.17.0.20-1595646981190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46016,DS-ea3a1844-adf7-4877-a8ee-cc5471df49c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-0f74099e-3ebc-4e99-a261-35b45c582c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e26d8755-33d0-4501-8400-178a3e20830a,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-f3174bd1-c13a-42ec-9cba-d672da54cbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-a31bf364-2555-4a4e-aaa9-e3ad8f51a143,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-9a30bb47-5771-4305-9b70-f53c479c93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-681cf9d1-4c3e-4f18-bb6b-b73d4dcced24,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-14cc4cd5-008e-4d03-96da-aa5fa5a4fd88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111838860-172.17.0.20-1595647745206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-7b1dca90-5948-49e1-896b-dd916fb256c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-66b9c838-7b3b-4df7-94bd-63b3bc5524fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-bd930e04-04db-4b9c-96ed-2107e49a86fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-0e4567c4-3451-4eed-9908-300fae7695e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-8cd29235-8d6c-4d1b-ba62-ced7ec826130,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-f4215cb8-5398-42c6-af6f-3247ea990020,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-f9440fa8-a386-4d4f-8ae2-09705a0fbf86,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-b0718cbd-4be5-4996-b59f-aa083a287c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111838860-172.17.0.20-1595647745206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-7b1dca90-5948-49e1-896b-dd916fb256c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-66b9c838-7b3b-4df7-94bd-63b3bc5524fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-bd930e04-04db-4b9c-96ed-2107e49a86fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-0e4567c4-3451-4eed-9908-300fae7695e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-8cd29235-8d6c-4d1b-ba62-ced7ec826130,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-f4215cb8-5398-42c6-af6f-3247ea990020,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-f9440fa8-a386-4d4f-8ae2-09705a0fbf86,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-b0718cbd-4be5-4996-b59f-aa083a287c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106469703-172.17.0.20-1595648048046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-b1421daf-7b6e-4771-8aed-dc93d04b94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-d799baf8-5ecd-4875-8106-2781b3265470,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-6865c336-7498-471c-b1d6-efbb672f8471,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-9e78f783-ba40-4ad4-9476-48cfe3a89675,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-98a9a28f-b229-4b7b-84a7-781d700d8f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-7d3a98f2-a1ff-4ff7-af6e-f35555577958,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-2dc7fc61-c975-4ecd-8a0b-d58ef71b4c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-2a06d861-a569-4a4d-8d44-0f0be35ccb88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106469703-172.17.0.20-1595648048046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-b1421daf-7b6e-4771-8aed-dc93d04b94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-d799baf8-5ecd-4875-8106-2781b3265470,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-6865c336-7498-471c-b1d6-efbb672f8471,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-9e78f783-ba40-4ad4-9476-48cfe3a89675,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-98a9a28f-b229-4b7b-84a7-781d700d8f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-7d3a98f2-a1ff-4ff7-af6e-f35555577958,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-2dc7fc61-c975-4ecd-8a0b-d58ef71b4c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-2a06d861-a569-4a4d-8d44-0f0be35ccb88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5214
