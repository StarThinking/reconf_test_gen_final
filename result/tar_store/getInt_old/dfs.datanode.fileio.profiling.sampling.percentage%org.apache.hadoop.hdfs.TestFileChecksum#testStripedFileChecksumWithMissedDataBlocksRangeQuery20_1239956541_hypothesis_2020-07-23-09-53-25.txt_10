reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081102060-172.17.0.20-1595498100972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-b6d76d9c-d4fc-4118-88c7-04efbbb8c155,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-5f570701-a122-400a-9636-b7b36cde5299,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-b9ba84c9-01ff-4ac0-94be-77bca270ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-f45c9a24-f4c8-4cbd-94aa-d0c1b64253c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-574bae13-8f97-4662-a5e0-8d09f2f35c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-783b0bac-a5c1-43a1-b739-4da52abc3135,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-7678b70d-8a9c-43ad-960d-9a35439721ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-fd8c98ae-d48a-44a2-9d41-1ac4b98e48a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081102060-172.17.0.20-1595498100972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-b6d76d9c-d4fc-4118-88c7-04efbbb8c155,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-5f570701-a122-400a-9636-b7b36cde5299,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-b9ba84c9-01ff-4ac0-94be-77bca270ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-f45c9a24-f4c8-4cbd-94aa-d0c1b64253c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-574bae13-8f97-4662-a5e0-8d09f2f35c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-783b0bac-a5c1-43a1-b739-4da52abc3135,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-7678b70d-8a9c-43ad-960d-9a35439721ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-fd8c98ae-d48a-44a2-9d41-1ac4b98e48a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810324968-172.17.0.20-1595498541215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-d7685569-c746-41cd-9022-4191c7444567,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-697c58c3-f398-4042-bd16-47a80180c1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-ff195b97-96db-4401-9a15-4e958bb41f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-9347d4c2-12a4-4350-b5f5-dc994ec92350,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-233daf98-5a9f-485c-ba0b-71daa74527b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-043901b9-6eac-437f-bbeb-834b4c04e529,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-0b799776-83d4-43c3-9261-0e4ec0cf7d03,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-1d58b181-d0d8-411f-b9b1-b1598182f29b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810324968-172.17.0.20-1595498541215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-d7685569-c746-41cd-9022-4191c7444567,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-697c58c3-f398-4042-bd16-47a80180c1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-ff195b97-96db-4401-9a15-4e958bb41f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-9347d4c2-12a4-4350-b5f5-dc994ec92350,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-233daf98-5a9f-485c-ba0b-71daa74527b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-043901b9-6eac-437f-bbeb-834b4c04e529,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-0b799776-83d4-43c3-9261-0e4ec0cf7d03,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-1d58b181-d0d8-411f-b9b1-b1598182f29b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582661234-172.17.0.20-1595498600383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33685,DS-75bacc95-d730-4591-bb18-c62df3638e19,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-a8fcd1b2-7f70-4833-bae8-334695650084,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-81f35e72-7388-44af-b4aa-81b472bd3c68,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-fc35a553-f353-4dba-8e25-6433800d9275,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-3bf3e76d-5001-4d64-85b0-9f11f0453ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-18dc3c57-7584-4c08-ba67-cd78039a6c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-9867b3f1-22ca-4a4b-b252-8487866639ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-38cfdfe6-67c8-4de9-8ef9-a8f76732d3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582661234-172.17.0.20-1595498600383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33685,DS-75bacc95-d730-4591-bb18-c62df3638e19,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-a8fcd1b2-7f70-4833-bae8-334695650084,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-81f35e72-7388-44af-b4aa-81b472bd3c68,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-fc35a553-f353-4dba-8e25-6433800d9275,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-3bf3e76d-5001-4d64-85b0-9f11f0453ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-18dc3c57-7584-4c08-ba67-cd78039a6c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-9867b3f1-22ca-4a4b-b252-8487866639ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-38cfdfe6-67c8-4de9-8ef9-a8f76732d3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196827087-172.17.0.20-1595498671271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-2063c4f4-a4fb-4465-9268-39f153f4ceba,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-54b1d163-a887-4b95-bd3a-66e146efeb85,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-1bbe2dac-7d17-4404-a975-1b621e15cf93,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-0987d099-e000-4eb4-85d7-e5998cc04f90,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-86b2e2d2-29ad-4275-adb0-6546f4ba4ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-12f91d31-277e-4595-836a-6ad5cb674f03,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-0da8eb32-745a-46d1-8c56-8174083426c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-753ecf1a-9f82-4918-9f44-e0c4a4286118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196827087-172.17.0.20-1595498671271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-2063c4f4-a4fb-4465-9268-39f153f4ceba,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-54b1d163-a887-4b95-bd3a-66e146efeb85,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-1bbe2dac-7d17-4404-a975-1b621e15cf93,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-0987d099-e000-4eb4-85d7-e5998cc04f90,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-86b2e2d2-29ad-4275-adb0-6546f4ba4ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-12f91d31-277e-4595-836a-6ad5cb674f03,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-0da8eb32-745a-46d1-8c56-8174083426c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-753ecf1a-9f82-4918-9f44-e0c4a4286118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222636603-172.17.0.20-1595499080221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43970,DS-90ea70dd-8f73-49c0-b1da-cc971d18ee73,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-9eda6ec4-3106-4d11-9ad3-eb5fc2e72a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-9b9e0f74-a0ee-47e1-92ba-97da62d40aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-de46555c-6392-45d6-ae5a-20d1a29267bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-a0df7af2-d5f1-41c0-83a1-cc809f8d9038,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-7514763a-0795-4f84-bc3b-b4dd0a4e76f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-f75136b3-c22e-410c-bf8b-d960fb183cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-91379778-adec-4ec6-b202-afbac97a2888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222636603-172.17.0.20-1595499080221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43970,DS-90ea70dd-8f73-49c0-b1da-cc971d18ee73,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-9eda6ec4-3106-4d11-9ad3-eb5fc2e72a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-9b9e0f74-a0ee-47e1-92ba-97da62d40aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-de46555c-6392-45d6-ae5a-20d1a29267bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-a0df7af2-d5f1-41c0-83a1-cc809f8d9038,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-7514763a-0795-4f84-bc3b-b4dd0a4e76f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-f75136b3-c22e-410c-bf8b-d960fb183cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-91379778-adec-4ec6-b202-afbac97a2888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887210364-172.17.0.20-1595499117983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-e8512684-ca35-454d-a6e1-ede8384d3587,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-d7c9026e-48d4-47fa-ae9f-1ea0233f6009,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-4269383e-0ff3-43e9-8c2d-428aed94da7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-d4fbcee9-4cda-443f-a3d8-fb99ffe6f210,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-bc93fd3e-048d-4505-a08d-e42fa4cee3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-2c935e92-0736-4be2-a137-f8b9df434a50,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-95be4d7d-2557-4bac-8cb5-a12ad40994cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-bf94c1c7-fd89-4acf-9ddc-46f9b5c265e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887210364-172.17.0.20-1595499117983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-e8512684-ca35-454d-a6e1-ede8384d3587,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-d7c9026e-48d4-47fa-ae9f-1ea0233f6009,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-4269383e-0ff3-43e9-8c2d-428aed94da7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-d4fbcee9-4cda-443f-a3d8-fb99ffe6f210,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-bc93fd3e-048d-4505-a08d-e42fa4cee3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-2c935e92-0736-4be2-a137-f8b9df434a50,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-95be4d7d-2557-4bac-8cb5-a12ad40994cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-bf94c1c7-fd89-4acf-9ddc-46f9b5c265e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224159804-172.17.0.20-1595499464106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33866,DS-3c1af5b9-c054-4127-b837-f3fbfaf6e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-70642621-f34f-428b-ba64-cf23288671c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-3bb3d015-306d-42ea-81f9-990d025a0b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-ca385608-200e-4836-8370-7b207558ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-e5e06e28-150d-4b5d-8448-fac2fb967c21,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-7e959391-9766-4273-a464-85079cae0a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-9ff762b2-1a2b-4bab-941b-2b62a49e255f,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-736318ef-75a5-40a7-b02a-d0df4920061b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224159804-172.17.0.20-1595499464106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33866,DS-3c1af5b9-c054-4127-b837-f3fbfaf6e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-70642621-f34f-428b-ba64-cf23288671c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-3bb3d015-306d-42ea-81f9-990d025a0b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-ca385608-200e-4836-8370-7b207558ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-e5e06e28-150d-4b5d-8448-fac2fb967c21,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-7e959391-9766-4273-a464-85079cae0a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-9ff762b2-1a2b-4bab-941b-2b62a49e255f,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-736318ef-75a5-40a7-b02a-d0df4920061b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145736809-172.17.0.20-1595500183687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42270,DS-6d256920-0e99-4598-95e5-bb691fd761df,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-c5133efa-4453-4e0a-99c4-290c3a595ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-03860277-332d-4787-8a43-6a072c7bb381,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-f90b5731-40ba-47a6-8035-cef56f98beae,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-b7fe70e6-cbb7-4bd5-b014-a11134e9dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-f9e85b61-c468-4474-a908-f166cb26e1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-4810211c-7378-45d0-896e-471a0e9d8ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-22eff72c-2703-40b3-be3f-80baea2ae2ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145736809-172.17.0.20-1595500183687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42270,DS-6d256920-0e99-4598-95e5-bb691fd761df,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-c5133efa-4453-4e0a-99c4-290c3a595ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-03860277-332d-4787-8a43-6a072c7bb381,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-f90b5731-40ba-47a6-8035-cef56f98beae,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-b7fe70e6-cbb7-4bd5-b014-a11134e9dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-f9e85b61-c468-4474-a908-f166cb26e1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-4810211c-7378-45d0-896e-471a0e9d8ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-22eff72c-2703-40b3-be3f-80baea2ae2ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344018716-172.17.0.20-1595500352958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-2169aa09-e1d9-487b-a94e-708279ed9ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-32e0970e-8c35-463e-a311-8d6a1e824741,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-1e605b29-6c71-41a6-9ea1-bd416589c179,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-2ade9fc6-26a3-4383-ae8e-d2a65b1f3bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-1dda4e4f-492f-4f55-aad1-c5af77ea60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-64033971-5917-4d4d-b0c9-48f5652c73f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-de52118e-2ec8-4b47-aeb7-d0d3335397a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-8c80e9ab-4641-4f86-81a1-3c52687b7378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344018716-172.17.0.20-1595500352958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-2169aa09-e1d9-487b-a94e-708279ed9ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-32e0970e-8c35-463e-a311-8d6a1e824741,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-1e605b29-6c71-41a6-9ea1-bd416589c179,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-2ade9fc6-26a3-4383-ae8e-d2a65b1f3bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-1dda4e4f-492f-4f55-aad1-c5af77ea60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-64033971-5917-4d4d-b0c9-48f5652c73f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-de52118e-2ec8-4b47-aeb7-d0d3335397a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-8c80e9ab-4641-4f86-81a1-3c52687b7378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274623220-172.17.0.20-1595500574343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-c61ae011-06b6-4537-ac45-c522ed551525,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-ec4fdbaa-9548-4490-8cdb-977b4b7e98df,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-fe3a422e-b5e2-4f73-8592-cc94e3d5ee28,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-d407c4f1-123c-4afb-8cc7-b7c2cf22fde5,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-e1058598-3957-492a-92e6-a2a0ead14216,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-8fffcb1a-bbf1-4114-8bdc-1efb850c0eda,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-4a820794-e522-4f11-9e14-2c757a67843d,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-ef4ea9ce-0350-452c-9935-92a10a987b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274623220-172.17.0.20-1595500574343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-c61ae011-06b6-4537-ac45-c522ed551525,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-ec4fdbaa-9548-4490-8cdb-977b4b7e98df,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-fe3a422e-b5e2-4f73-8592-cc94e3d5ee28,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-d407c4f1-123c-4afb-8cc7-b7c2cf22fde5,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-e1058598-3957-492a-92e6-a2a0ead14216,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-8fffcb1a-bbf1-4114-8bdc-1efb850c0eda,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-4a820794-e522-4f11-9e14-2c757a67843d,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-ef4ea9ce-0350-452c-9935-92a10a987b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807251057-172.17.0.20-1595500778032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-d4c30722-49a1-45b7-949f-8b7daae4d104,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-8cc225e1-3ddc-4e2d-b6eb-bffb5266058e,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-3266cb0d-8b89-4a22-be74-a4030f541f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-1e709d2f-614e-442b-84ff-c633f4242e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-7c6411f5-daa4-4def-af36-984fb2ceda3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-58ab3666-195f-4496-af73-519633c3e760,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-8ea6a259-3222-400b-b651-0604b1fdcb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-2ce90eb2-9f01-4fe2-9948-0ab5cc342e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807251057-172.17.0.20-1595500778032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-d4c30722-49a1-45b7-949f-8b7daae4d104,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-8cc225e1-3ddc-4e2d-b6eb-bffb5266058e,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-3266cb0d-8b89-4a22-be74-a4030f541f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-1e709d2f-614e-442b-84ff-c633f4242e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-7c6411f5-daa4-4def-af36-984fb2ceda3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-58ab3666-195f-4496-af73-519633c3e760,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-8ea6a259-3222-400b-b651-0604b1fdcb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-2ce90eb2-9f01-4fe2-9948-0ab5cc342e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956429648-172.17.0.20-1595500980611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-46f08123-6619-43ea-84c3-59a3ba6ace21,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-ffbd45b2-b236-4b24-a512-7971764d623a,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-31fe4a0f-311e-4d89-9468-563758e9422b,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-1cb4f22f-353b-4c8a-8279-6e952d15222d,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-81809285-6f97-4549-8df5-d823f1610c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-4fb2baf2-f3d1-43bd-863e-45d3b5f51820,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-53eb3451-60a0-426b-9237-feed85a3622c,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-55d71009-2508-4751-8c4b-60a9bdb9ee18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956429648-172.17.0.20-1595500980611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-46f08123-6619-43ea-84c3-59a3ba6ace21,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-ffbd45b2-b236-4b24-a512-7971764d623a,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-31fe4a0f-311e-4d89-9468-563758e9422b,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-1cb4f22f-353b-4c8a-8279-6e952d15222d,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-81809285-6f97-4549-8df5-d823f1610c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-4fb2baf2-f3d1-43bd-863e-45d3b5f51820,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-53eb3451-60a0-426b-9237-feed85a3622c,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-55d71009-2508-4751-8c4b-60a9bdb9ee18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904311655-172.17.0.20-1595501240199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-9f909a42-6e75-4fef-a268-7d3bdd687a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-eedfc3dd-bbb3-4ce2-8758-cfbbdc79176a,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-da33aaae-19e2-467f-969c-78999a27297e,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-29de931a-ff93-4d60-9746-2df0e42feb09,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-0b819a3b-7cae-4b6f-ab60-e489f40ef7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-ba2b0b58-f501-4a2f-94c8-bfae17a71d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-444c882e-ead9-4599-820b-4f593a594380,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-5a7d92eb-8448-4fe1-ba70-316b99d78f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904311655-172.17.0.20-1595501240199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-9f909a42-6e75-4fef-a268-7d3bdd687a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-eedfc3dd-bbb3-4ce2-8758-cfbbdc79176a,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-da33aaae-19e2-467f-969c-78999a27297e,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-29de931a-ff93-4d60-9746-2df0e42feb09,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-0b819a3b-7cae-4b6f-ab60-e489f40ef7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-ba2b0b58-f501-4a2f-94c8-bfae17a71d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-444c882e-ead9-4599-820b-4f593a594380,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-5a7d92eb-8448-4fe1-ba70-316b99d78f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900151627-172.17.0.20-1595501476389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-d132b7e0-d921-4322-bc4e-029685af473f,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-a5e7f6f5-43cc-4720-88fa-da5ca4672d96,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-33df45d7-3e55-4b80-8d76-682d733784a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-155d7477-9208-4776-ab21-d01905c0b134,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-d403ddec-4af0-4bf4-8b0b-0506381707d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-d092e918-d288-436e-9884-5b378b82f02c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-71f86f6c-24ab-497f-8743-8949628e5edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-06586b85-d7b5-4002-beae-a55dd2e33e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900151627-172.17.0.20-1595501476389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-d132b7e0-d921-4322-bc4e-029685af473f,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-a5e7f6f5-43cc-4720-88fa-da5ca4672d96,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-33df45d7-3e55-4b80-8d76-682d733784a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-155d7477-9208-4776-ab21-d01905c0b134,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-d403ddec-4af0-4bf4-8b0b-0506381707d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-d092e918-d288-436e-9884-5b378b82f02c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-71f86f6c-24ab-497f-8743-8949628e5edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-06586b85-d7b5-4002-beae-a55dd2e33e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-739563927-172.17.0.20-1595501514659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35588,DS-bde80e15-9d2c-4068-ac87-ac6e30ecae50,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-ca2c3ddd-61c0-4e80-be48-364d1b17222f,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-fe12c2db-732e-4592-b558-d669ad8988b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-d5dfe4f5-2dcc-4664-bcb6-3014e81cba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-4947d7a2-0359-4c03-9a52-01c870cc65cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-324b2e18-36c4-4d72-911b-867b237b577f,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-937ea39e-a5d4-4a6d-a5ef-09c2412e9cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-0709ad16-7b85-4ec6-a556-8ac051fef8bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-739563927-172.17.0.20-1595501514659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35588,DS-bde80e15-9d2c-4068-ac87-ac6e30ecae50,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-ca2c3ddd-61c0-4e80-be48-364d1b17222f,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-fe12c2db-732e-4592-b558-d669ad8988b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-d5dfe4f5-2dcc-4664-bcb6-3014e81cba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-4947d7a2-0359-4c03-9a52-01c870cc65cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-324b2e18-36c4-4d72-911b-867b237b577f,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-937ea39e-a5d4-4a6d-a5ef-09c2412e9cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-0709ad16-7b85-4ec6-a556-8ac051fef8bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224835368-172.17.0.20-1595501830163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39252,DS-35a5847f-1d6f-4255-9845-a90cb631938c,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-b56b60e9-54d5-4e94-adf6-bf0edbb4a27d,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-ba7584a8-ed13-4e5d-8339-f5588e498d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-4b2b3319-0142-463e-9ada-ec9d7659b230,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-0e320f1f-9d04-4293-a691-a86b0dca5598,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-710ff212-24a2-4fc2-87b5-042e9781015f,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-86f47aa5-ba7d-4b01-b841-9bb9cfbfa6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-58eee784-72a5-4be2-9437-6fd16595bc64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224835368-172.17.0.20-1595501830163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39252,DS-35a5847f-1d6f-4255-9845-a90cb631938c,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-b56b60e9-54d5-4e94-adf6-bf0edbb4a27d,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-ba7584a8-ed13-4e5d-8339-f5588e498d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-4b2b3319-0142-463e-9ada-ec9d7659b230,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-0e320f1f-9d04-4293-a691-a86b0dca5598,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-710ff212-24a2-4fc2-87b5-042e9781015f,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-86f47aa5-ba7d-4b01-b841-9bb9cfbfa6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-58eee784-72a5-4be2-9437-6fd16595bc64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2170070-172.17.0.20-1595502578170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34254,DS-5e72dad6-75ae-408f-9366-0c4ccc7ff689,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-77d1eb5c-95f0-42cd-91bb-bd54e0f070cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-d680dc38-d48f-4def-87b6-3b68d68d0981,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-1417815a-9bb7-46b3-9655-be9c8a01f8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-39e19a50-391a-42af-abb5-b8da61e3e95c,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-c985759e-de3d-42d6-b980-155b3d95371b,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-ef5e250d-ba56-43ed-ba3a-2e79744ab512,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-f4c5ca0b-339f-474f-b979-2a8d217913e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2170070-172.17.0.20-1595502578170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34254,DS-5e72dad6-75ae-408f-9366-0c4ccc7ff689,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-77d1eb5c-95f0-42cd-91bb-bd54e0f070cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-d680dc38-d48f-4def-87b6-3b68d68d0981,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-1417815a-9bb7-46b3-9655-be9c8a01f8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-39e19a50-391a-42af-abb5-b8da61e3e95c,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-c985759e-de3d-42d6-b980-155b3d95371b,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-ef5e250d-ba56-43ed-ba3a-2e79744ab512,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-f4c5ca0b-339f-474f-b979-2a8d217913e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776187086-172.17.0.20-1595502615561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-b5e7b62b-5d2f-46e1-9359-5a93c6ff558d,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-5415a489-e4e3-4119-a7e3-2a11a3603e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-e03495cd-f2ea-4187-9fc1-958665bc04c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-5356f50c-dd9d-4525-9bb0-4ac479dbad88,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-f2a747c0-789b-4803-9a02-fbc4f52643a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-6a538e67-e5ca-444d-8448-f6d780f8869f,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-65c069da-1ddf-496a-8d2e-09ad2315eb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-9a20998f-06da-4059-b08f-386f46b588f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776187086-172.17.0.20-1595502615561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-b5e7b62b-5d2f-46e1-9359-5a93c6ff558d,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-5415a489-e4e3-4119-a7e3-2a11a3603e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-e03495cd-f2ea-4187-9fc1-958665bc04c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-5356f50c-dd9d-4525-9bb0-4ac479dbad88,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-f2a747c0-789b-4803-9a02-fbc4f52643a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-6a538e67-e5ca-444d-8448-f6d780f8869f,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-65c069da-1ddf-496a-8d2e-09ad2315eb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-9a20998f-06da-4059-b08f-386f46b588f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919884924-172.17.0.20-1595502885551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-a0cecad9-4bc0-4b8d-b45d-d0cca600cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-121990df-729e-42dd-947b-54e61223e1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-3d85e2dc-5bc2-4180-9703-306016cf448d,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-01c6b468-b6f2-480d-899d-ddb0d6fe0288,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-4d47e1af-836e-4f4d-ab61-1aaae47fa5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-9ec986b5-29a5-48ea-9b3f-bb7caa45dd12,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-ee6df0a2-bf4f-4170-b383-e60ad18838f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-315b8191-0b9f-46f7-bb3c-24c0a65f1b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919884924-172.17.0.20-1595502885551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-a0cecad9-4bc0-4b8d-b45d-d0cca600cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-121990df-729e-42dd-947b-54e61223e1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-3d85e2dc-5bc2-4180-9703-306016cf448d,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-01c6b468-b6f2-480d-899d-ddb0d6fe0288,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-4d47e1af-836e-4f4d-ab61-1aaae47fa5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-9ec986b5-29a5-48ea-9b3f-bb7caa45dd12,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-ee6df0a2-bf4f-4170-b383-e60ad18838f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-315b8191-0b9f-46f7-bb3c-24c0a65f1b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280113754-172.17.0.20-1595503019879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-7b12e24a-2eac-426c-9a76-ced372716ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-07ee8242-904a-41e1-b4f8-4952b779121a,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-0408204a-6ad0-4d93-920b-2b9352a79202,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-d3881cce-f152-4d10-8849-7cc8d9d24ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-75bff1b1-1bea-4457-8ba3-6519929c446d,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-c48ae9ab-b134-4d08-811f-ab1f70305e31,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-b2958b0f-9efb-4fbb-96c2-9965a42f108e,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-80dd6c66-93f5-4fd5-b301-4b40220d0f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280113754-172.17.0.20-1595503019879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-7b12e24a-2eac-426c-9a76-ced372716ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-07ee8242-904a-41e1-b4f8-4952b779121a,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-0408204a-6ad0-4d93-920b-2b9352a79202,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-d3881cce-f152-4d10-8849-7cc8d9d24ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-75bff1b1-1bea-4457-8ba3-6519929c446d,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-c48ae9ab-b134-4d08-811f-ab1f70305e31,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-b2958b0f-9efb-4fbb-96c2-9965a42f108e,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-80dd6c66-93f5-4fd5-b301-4b40220d0f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5069
