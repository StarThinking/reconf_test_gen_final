reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314262556-172.17.0.4-1595620841340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35287,DS-d9afd12e-c379-4f29-b98e-9a7a5f1c7cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-b22fd636-f82f-47e4-8813-5be0fda5c246,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-fe83f2e0-a608-44c1-8c18-e639fdb91c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-dba4aa57-3546-40a1-a5f2-d3e5bf87ee9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-32e447da-23ca-4736-9dee-73aba3c8c266,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-44ec9f41-366e-4a8d-8260-7e2df59cc700,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-51c47a3e-9f7d-40c1-b87a-37a550bb7fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-a02dcdd4-f5ee-4e80-9ca4-dfa58248b0aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314262556-172.17.0.4-1595620841340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35287,DS-d9afd12e-c379-4f29-b98e-9a7a5f1c7cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-b22fd636-f82f-47e4-8813-5be0fda5c246,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-fe83f2e0-a608-44c1-8c18-e639fdb91c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-dba4aa57-3546-40a1-a5f2-d3e5bf87ee9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-32e447da-23ca-4736-9dee-73aba3c8c266,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-44ec9f41-366e-4a8d-8260-7e2df59cc700,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-51c47a3e-9f7d-40c1-b87a-37a550bb7fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-a02dcdd4-f5ee-4e80-9ca4-dfa58248b0aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114575587-172.17.0.4-1595621130615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33041,DS-6293757b-e6a6-4f29-8217-408c05974dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-bb2a5a66-2527-4a03-be6b-e45cc78c4dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-e19557bb-60b7-4ae6-98a5-e66d083144e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-3bd7808a-3f88-450f-b619-05513137eef1,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-f4a74640-084d-4314-a793-f214282c62cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-662463bc-891b-4fd7-892c-e3200ed3b8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-b47c6a04-7429-42eb-a575-8471ee0ef291,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-1d2abd06-7c74-4b7d-9b8f-9f0b393b27d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114575587-172.17.0.4-1595621130615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33041,DS-6293757b-e6a6-4f29-8217-408c05974dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-bb2a5a66-2527-4a03-be6b-e45cc78c4dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-e19557bb-60b7-4ae6-98a5-e66d083144e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-3bd7808a-3f88-450f-b619-05513137eef1,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-f4a74640-084d-4314-a793-f214282c62cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-662463bc-891b-4fd7-892c-e3200ed3b8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-b47c6a04-7429-42eb-a575-8471ee0ef291,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-1d2abd06-7c74-4b7d-9b8f-9f0b393b27d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709149272-172.17.0.4-1595621381088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-2decff58-484d-416d-ba07-4f8e0a7bde39,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-37894fa9-4535-4b16-9ac1-4263f868011b,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-be2440b4-07cb-4362-9cef-5dce4b610767,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-3bd3e6b9-7ed6-4542-82dd-fe3ca75d525c,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-8c9371bb-581a-46db-a207-e7085750a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-20a8c8ab-a78f-4a3c-9d41-b9c62902126c,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-78ef373f-e93e-4521-a000-f1d3e2ad9e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-2b28ed2c-9073-419b-aec5-6bcbbe76b34b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709149272-172.17.0.4-1595621381088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-2decff58-484d-416d-ba07-4f8e0a7bde39,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-37894fa9-4535-4b16-9ac1-4263f868011b,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-be2440b4-07cb-4362-9cef-5dce4b610767,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-3bd3e6b9-7ed6-4542-82dd-fe3ca75d525c,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-8c9371bb-581a-46db-a207-e7085750a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-20a8c8ab-a78f-4a3c-9d41-b9c62902126c,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-78ef373f-e93e-4521-a000-f1d3e2ad9e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-2b28ed2c-9073-419b-aec5-6bcbbe76b34b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948529195-172.17.0.4-1595621854163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37902,DS-c1f768b1-1922-4561-9bbc-2a8d40806013,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-dc66d4a6-79ad-411a-9db9-68d078206443,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-3539b4ea-1f53-46e0-a234-1f2389698b02,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-a366203a-4fda-47a2-9dc2-5e82d0b45543,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-e500502e-b95d-4099-87d1-215610a3ea14,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-6e2df78a-2c47-4389-9337-1c3c8905461a,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-02900476-8804-4da4-9bf4-010d9adf08bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-f2d7c473-c4ff-4e94-b499-d6575c2622e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948529195-172.17.0.4-1595621854163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37902,DS-c1f768b1-1922-4561-9bbc-2a8d40806013,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-dc66d4a6-79ad-411a-9db9-68d078206443,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-3539b4ea-1f53-46e0-a234-1f2389698b02,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-a366203a-4fda-47a2-9dc2-5e82d0b45543,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-e500502e-b95d-4099-87d1-215610a3ea14,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-6e2df78a-2c47-4389-9337-1c3c8905461a,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-02900476-8804-4da4-9bf4-010d9adf08bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-f2d7c473-c4ff-4e94-b499-d6575c2622e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471622871-172.17.0.4-1595622062658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-37860ec8-dc11-4205-818f-171249c44622,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-ccab6b9f-d918-40e3-ab07-d5ef56a57828,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-a573b9d8-3b4d-400c-b08d-8d932cfab990,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-900b4220-c5cc-4a01-807e-46f7e99a8e19,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-fcd5d56a-1397-442c-8305-23280da7dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-440295a7-2a76-4abb-bee5-0d5b40ae3398,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a5feae41-af5b-4501-8656-756f5dd357d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-f8ce2e33-16c6-477b-b0b7-2139c9648afc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471622871-172.17.0.4-1595622062658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-37860ec8-dc11-4205-818f-171249c44622,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-ccab6b9f-d918-40e3-ab07-d5ef56a57828,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-a573b9d8-3b4d-400c-b08d-8d932cfab990,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-900b4220-c5cc-4a01-807e-46f7e99a8e19,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-fcd5d56a-1397-442c-8305-23280da7dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-440295a7-2a76-4abb-bee5-0d5b40ae3398,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a5feae41-af5b-4501-8656-756f5dd357d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-f8ce2e33-16c6-477b-b0b7-2139c9648afc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606575927-172.17.0.4-1595622288853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-729fa581-76c9-4542-b47a-45a94f5a8aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-bd97c2f6-52c8-4414-bccd-5f81dec2d565,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-e730613f-3558-48ab-9341-b580ac527501,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-9960e7a3-26be-4772-b37d-794b5a274a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-0d856762-04fb-43cb-acb6-5312addeb966,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-0d5bb1d1-d098-4399-a292-0bf12a71aade,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-d2f74d96-2e2f-4c0e-a95f-97b044520b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-917efb99-b25f-46ea-835f-c071442ac243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606575927-172.17.0.4-1595622288853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-729fa581-76c9-4542-b47a-45a94f5a8aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-bd97c2f6-52c8-4414-bccd-5f81dec2d565,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-e730613f-3558-48ab-9341-b580ac527501,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-9960e7a3-26be-4772-b37d-794b5a274a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-0d856762-04fb-43cb-acb6-5312addeb966,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-0d5bb1d1-d098-4399-a292-0bf12a71aade,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-d2f74d96-2e2f-4c0e-a95f-97b044520b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-917efb99-b25f-46ea-835f-c071442ac243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934819300-172.17.0.4-1595622707148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46513,DS-532a52ca-5409-4034-acd6-1ff9b98e2c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-77c7a98f-f57a-4971-86e7-dae3c5aa5a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-b44d666e-0e45-4a07-b259-9c869533d652,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-abafcc6e-e738-4b00-af60-ee496ee294f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-ca140c90-5bc4-4152-9392-884d94913d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-bb60e7de-2090-4867-9d8a-541a7fc68b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-7005b013-97e1-48b7-a452-74820eb72201,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-f50dda21-e9ac-4381-8452-a304a6313cf5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934819300-172.17.0.4-1595622707148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46513,DS-532a52ca-5409-4034-acd6-1ff9b98e2c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-77c7a98f-f57a-4971-86e7-dae3c5aa5a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-b44d666e-0e45-4a07-b259-9c869533d652,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-abafcc6e-e738-4b00-af60-ee496ee294f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-ca140c90-5bc4-4152-9392-884d94913d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-bb60e7de-2090-4867-9d8a-541a7fc68b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-7005b013-97e1-48b7-a452-74820eb72201,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-f50dda21-e9ac-4381-8452-a304a6313cf5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679183507-172.17.0.4-1595623212288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-1cf4d42a-a044-4624-ad33-d05c391de782,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-3828c774-c6db-44c7-9c11-cd7b2457062f,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-6a424aa8-01c0-46f6-992e-5488cd5f95d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-91b5f531-18a2-4b54-8115-7d414fc82d43,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-4d2cc348-c2aa-4a27-aba2-d31e05effe22,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-c109be6d-b4d6-4344-a7f3-d351c20dd715,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-720f03fb-a3b4-438c-a1f1-0a67306aa39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-bd6c6b28-4f5c-4954-8be5-eda49b4b0f93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679183507-172.17.0.4-1595623212288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-1cf4d42a-a044-4624-ad33-d05c391de782,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-3828c774-c6db-44c7-9c11-cd7b2457062f,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-6a424aa8-01c0-46f6-992e-5488cd5f95d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-91b5f531-18a2-4b54-8115-7d414fc82d43,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-4d2cc348-c2aa-4a27-aba2-d31e05effe22,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-c109be6d-b4d6-4344-a7f3-d351c20dd715,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-720f03fb-a3b4-438c-a1f1-0a67306aa39a,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-bd6c6b28-4f5c-4954-8be5-eda49b4b0f93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371980352-172.17.0.4-1595623646488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-2fe28dab-03d6-488a-ad17-5ed0665a463f,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-5e601fbc-2ad4-429b-8b27-f9f33c9d0360,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-fb8dfa60-1b31-43cc-9f33-4859c6331166,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-23559ae2-573c-43b0-80b5-f2307735cf38,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e125d1fa-e05f-4afe-88d0-4010809ccf44,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-a35c9ae7-6fda-48de-88ce-52bbf3820d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-18b0a15e-feb0-49ce-84c2-b7fc4a814ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-ce822974-ecbc-4f7a-8ad4-2764d5f4660f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371980352-172.17.0.4-1595623646488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-2fe28dab-03d6-488a-ad17-5ed0665a463f,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-5e601fbc-2ad4-429b-8b27-f9f33c9d0360,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-fb8dfa60-1b31-43cc-9f33-4859c6331166,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-23559ae2-573c-43b0-80b5-f2307735cf38,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e125d1fa-e05f-4afe-88d0-4010809ccf44,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-a35c9ae7-6fda-48de-88ce-52bbf3820d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-18b0a15e-feb0-49ce-84c2-b7fc4a814ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-ce822974-ecbc-4f7a-8ad4-2764d5f4660f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794174982-172.17.0.4-1595623680241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-eeddd5f6-f4f4-482b-a0c6-2b960610c200,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-470d3a5c-801b-4a51-9076-3108ddd3a290,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-78220cf3-2d4d-4210-94e4-b26684127916,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-ec5ad88f-a5fb-4293-bdeb-fa7c83d55743,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-56aa98aa-f798-4c03-9400-22e84e81368a,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-4172b9e4-3ddc-48be-b320-f445f48806a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-5e31d465-37d0-436e-ab00-4c870bd1abb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-63f7eabf-4b9c-4c71-8001-f2eaeb0b9c87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794174982-172.17.0.4-1595623680241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-eeddd5f6-f4f4-482b-a0c6-2b960610c200,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-470d3a5c-801b-4a51-9076-3108ddd3a290,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-78220cf3-2d4d-4210-94e4-b26684127916,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-ec5ad88f-a5fb-4293-bdeb-fa7c83d55743,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-56aa98aa-f798-4c03-9400-22e84e81368a,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-4172b9e4-3ddc-48be-b320-f445f48806a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-5e31d465-37d0-436e-ab00-4c870bd1abb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-63f7eabf-4b9c-4c71-8001-f2eaeb0b9c87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028353991-172.17.0.4-1595623953322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-33184168-ab57-404f-a6e6-f0fef43f9537,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-a52c6ac0-dcd5-441d-87e1-61e18af6dd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-2c559acd-97bc-439e-ac5f-a75313e85141,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-2cdee460-e4f5-4d8e-a66a-5a2bcd11abc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-7dc94e3b-f240-4a57-a1ad-9002ae3b5759,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-b5dc6494-a74b-4869-ac5e-b2ec1f1483b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-d2fd8e1b-43b6-4f83-8741-03c96898568e,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-1eab22d9-f922-485f-b3b4-93337d05c5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028353991-172.17.0.4-1595623953322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-33184168-ab57-404f-a6e6-f0fef43f9537,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-a52c6ac0-dcd5-441d-87e1-61e18af6dd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-2c559acd-97bc-439e-ac5f-a75313e85141,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-2cdee460-e4f5-4d8e-a66a-5a2bcd11abc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-7dc94e3b-f240-4a57-a1ad-9002ae3b5759,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-b5dc6494-a74b-4869-ac5e-b2ec1f1483b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-d2fd8e1b-43b6-4f83-8741-03c96898568e,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-1eab22d9-f922-485f-b3b4-93337d05c5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175025839-172.17.0.4-1595624309245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-f66a90b4-c6a1-4ccd-8243-d88383f6abbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-288cdd09-733e-459b-906b-87ab6c8a6807,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-02565427-66d6-4298-a3da-745fe7c0a0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-dc20f265-2e71-4281-9a3e-06e2bb02f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-d38f5bf7-3f9b-4249-9c2b-324dc284f963,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-ec7192b7-9f74-4e9c-9382-f4dc0c4707ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-84ede66b-f28e-4f17-9b77-d3d758d4e060,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-509bb855-b4a1-40b5-887f-a7cb41ed259e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175025839-172.17.0.4-1595624309245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-f66a90b4-c6a1-4ccd-8243-d88383f6abbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-288cdd09-733e-459b-906b-87ab6c8a6807,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-02565427-66d6-4298-a3da-745fe7c0a0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-dc20f265-2e71-4281-9a3e-06e2bb02f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-d38f5bf7-3f9b-4249-9c2b-324dc284f963,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-ec7192b7-9f74-4e9c-9382-f4dc0c4707ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-84ede66b-f28e-4f17-9b77-d3d758d4e060,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-509bb855-b4a1-40b5-887f-a7cb41ed259e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998611034-172.17.0.4-1595624413597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37951,DS-918ce239-b669-4854-8b9c-300cce0d9592,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-b4a0671e-371b-4ddb-adc7-ef15bef77330,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-66d78a4c-7670-416a-83d6-f21515697599,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-439b2c5a-72f0-47fd-9798-748523ae2afe,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-fd62991a-223c-499e-b0fc-e66698cb9033,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-c26bcd52-1624-43dc-9acc-5b846f6ef9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-634eda22-14d0-443f-a622-740d284beb52,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-1e6b1e5e-6418-4a18-88b9-2aaef81b0443,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998611034-172.17.0.4-1595624413597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37951,DS-918ce239-b669-4854-8b9c-300cce0d9592,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-b4a0671e-371b-4ddb-adc7-ef15bef77330,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-66d78a4c-7670-416a-83d6-f21515697599,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-439b2c5a-72f0-47fd-9798-748523ae2afe,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-fd62991a-223c-499e-b0fc-e66698cb9033,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-c26bcd52-1624-43dc-9acc-5b846f6ef9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-634eda22-14d0-443f-a622-740d284beb52,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-1e6b1e5e-6418-4a18-88b9-2aaef81b0443,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683575840-172.17.0.4-1595624446569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41838,DS-62ea66b3-0c60-4c04-9b24-ac9495433739,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-7bf1070f-42a8-403a-8242-f45820bee18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-2760e4a1-858c-4c1c-b38b-e3994e69d5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-196cad6c-fa05-4341-9be1-50ab89ee3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-c58989e0-a9bc-4872-8b23-87ff430e961d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-1bf7ada5-dca5-46ce-ba1b-4e45a415d138,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-a7376e70-5eef-4e94-bd86-d1d042fa6db1,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-f8034711-2a75-49d6-92b3-5b9d59b58d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683575840-172.17.0.4-1595624446569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41838,DS-62ea66b3-0c60-4c04-9b24-ac9495433739,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-7bf1070f-42a8-403a-8242-f45820bee18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-2760e4a1-858c-4c1c-b38b-e3994e69d5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-196cad6c-fa05-4341-9be1-50ab89ee3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-c58989e0-a9bc-4872-8b23-87ff430e961d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-1bf7ada5-dca5-46ce-ba1b-4e45a415d138,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-a7376e70-5eef-4e94-bd86-d1d042fa6db1,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-f8034711-2a75-49d6-92b3-5b9d59b58d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465438568-172.17.0.4-1595624482237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-54583f02-53a7-4370-9c2d-6280a913299c,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-84eb61ad-f9f0-45b1-9e39-916725d38cae,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-dfb8943f-85a5-480d-a01f-93966a7afd10,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-2d5d17e5-56bb-415d-b810-1cd8a2cf69d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-40d4f72f-e65f-4e74-8dbb-8c6b4b983514,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-67e96f04-abc9-43a6-9882-94bd4261a3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-05e2f6ce-b002-41da-8cd1-66b9a0651eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-01bf1807-22ed-4314-8c50-a01c38822fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465438568-172.17.0.4-1595624482237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-54583f02-53a7-4370-9c2d-6280a913299c,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-84eb61ad-f9f0-45b1-9e39-916725d38cae,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-dfb8943f-85a5-480d-a01f-93966a7afd10,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-2d5d17e5-56bb-415d-b810-1cd8a2cf69d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-40d4f72f-e65f-4e74-8dbb-8c6b4b983514,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-67e96f04-abc9-43a6-9882-94bd4261a3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-05e2f6ce-b002-41da-8cd1-66b9a0651eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-01bf1807-22ed-4314-8c50-a01c38822fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868627576-172.17.0.4-1595624518341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-655d9ef8-328b-4ee4-a40b-9c8e1dce4334,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-be3fec80-cfef-4d7a-959a-5b9d866218c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-65059eda-a109-48c8-a7ab-94bae4e46339,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-27585392-90ef-4c57-bf82-e5b527e4bfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-88dc3fa1-ee9c-4f1c-9d81-4a8566ec1716,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-6fcb64d5-fb37-4792-9aed-e2f29c6053f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-aee17d07-30a0-4707-a995-dbd565cbb1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-1d589f56-511e-455e-978b-9b4d833643bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868627576-172.17.0.4-1595624518341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-655d9ef8-328b-4ee4-a40b-9c8e1dce4334,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-be3fec80-cfef-4d7a-959a-5b9d866218c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-65059eda-a109-48c8-a7ab-94bae4e46339,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-27585392-90ef-4c57-bf82-e5b527e4bfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-88dc3fa1-ee9c-4f1c-9d81-4a8566ec1716,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-6fcb64d5-fb37-4792-9aed-e2f29c6053f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-aee17d07-30a0-4707-a995-dbd565cbb1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-1d589f56-511e-455e-978b-9b4d833643bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494629980-172.17.0.4-1595624628004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43989,DS-368d5732-9e3e-4e88-8c9e-8e0f193c7ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-ac4a3559-97fb-44fa-8c8a-14b42757371e,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-f223dde2-13a6-4135-9b8a-b31ecb7facf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-bc97bcf6-83f9-44ca-82b2-1edf8328ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-20ae5c1b-d35a-454b-82e8-38248eb23977,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-93e7e4c2-6066-4264-97ae-c71fbd1519bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-e81f5412-4a6f-421f-ac0f-1173678d2969,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-cc4eabf0-225b-4eb7-b98e-0ee792325c90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494629980-172.17.0.4-1595624628004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43989,DS-368d5732-9e3e-4e88-8c9e-8e0f193c7ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-ac4a3559-97fb-44fa-8c8a-14b42757371e,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-f223dde2-13a6-4135-9b8a-b31ecb7facf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-bc97bcf6-83f9-44ca-82b2-1edf8328ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-20ae5c1b-d35a-454b-82e8-38248eb23977,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-93e7e4c2-6066-4264-97ae-c71fbd1519bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-e81f5412-4a6f-421f-ac0f-1173678d2969,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-cc4eabf0-225b-4eb7-b98e-0ee792325c90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498311301-172.17.0.4-1595624740994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-0dbfac61-f5a9-4862-be83-5826a97ad85e,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-f60b734e-26d2-4b74-8272-e80295466ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-d760b71c-74a6-434e-8fe4-c470b8e02786,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-345b7591-f983-4d33-acae-fb056d2a9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-37514150-ef3f-4ef1-9326-943957de5150,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-7f8e9c63-2ccd-4b82-8f50-c4581e44f3db,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-d86c6fb7-54ca-4987-8362-6bae54b96fea,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-0f723310-cc30-4690-954e-6306ef2e7009,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498311301-172.17.0.4-1595624740994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-0dbfac61-f5a9-4862-be83-5826a97ad85e,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-f60b734e-26d2-4b74-8272-e80295466ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-d760b71c-74a6-434e-8fe4-c470b8e02786,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-345b7591-f983-4d33-acae-fb056d2a9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-37514150-ef3f-4ef1-9326-943957de5150,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-7f8e9c63-2ccd-4b82-8f50-c4581e44f3db,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-d86c6fb7-54ca-4987-8362-6bae54b96fea,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-0f723310-cc30-4690-954e-6306ef2e7009,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395893107-172.17.0.4-1595624860883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-f3f71ab5-8f45-4976-9132-fc2dcfb0d817,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-6ed0560f-7c41-4f4b-b4ca-470356e40c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-d061c84e-5fce-4bb4-b420-2bfe07f8a6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-69c901f2-2f7c-4f13-ba70-2e26daef5274,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-48fb5918-0245-45ec-a747-b44f230882e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-d196bf33-7362-4961-867a-a795a0f63403,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-123ff3e3-8386-4a4f-8354-6cd301b13c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-5fa727ec-a3cd-4286-bc9d-709b0bad6a5d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395893107-172.17.0.4-1595624860883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-f3f71ab5-8f45-4976-9132-fc2dcfb0d817,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-6ed0560f-7c41-4f4b-b4ca-470356e40c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-d061c84e-5fce-4bb4-b420-2bfe07f8a6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-69c901f2-2f7c-4f13-ba70-2e26daef5274,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-48fb5918-0245-45ec-a747-b44f230882e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-d196bf33-7362-4961-867a-a795a0f63403,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-123ff3e3-8386-4a4f-8354-6cd301b13c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-5fa727ec-a3cd-4286-bc9d-709b0bad6a5d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18369977-172.17.0.4-1595624934777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34816,DS-f5661684-6331-4fc3-9495-6f6060d0abd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-dad4ca65-1564-4387-8f9b-2f4910c1d750,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-68ff4c5e-196c-478f-b52a-99df61ef5884,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-76aaff3a-55f0-4cac-b552-73b3642ad718,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-bb176629-cdac-46d6-bb95-5aa230a1453d,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-c29decc1-0fe2-4d23-9d8d-3505334ad9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-435c53ac-73c4-436a-a28f-7239706ea75b,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-1564e01c-7cba-418e-8a95-f23fee582358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18369977-172.17.0.4-1595624934777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34816,DS-f5661684-6331-4fc3-9495-6f6060d0abd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-dad4ca65-1564-4387-8f9b-2f4910c1d750,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-68ff4c5e-196c-478f-b52a-99df61ef5884,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-76aaff3a-55f0-4cac-b552-73b3642ad718,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-bb176629-cdac-46d6-bb95-5aa230a1453d,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-c29decc1-0fe2-4d23-9d8d-3505334ad9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-435c53ac-73c4-436a-a28f-7239706ea75b,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-1564e01c-7cba-418e-8a95-f23fee582358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907373843-172.17.0.4-1595625261980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45183,DS-12d06746-de43-4157-a4be-819c42086ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-383464fe-4745-47d4-a635-144f87a3eae6,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-31c328b2-4735-4b16-86fe-94164ca4b501,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-f842e73b-fbae-4a2e-b0e0-a4243d2f69c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-63b3cee3-9173-43a7-b444-7488605b7cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-ff9a2fab-c065-43c2-bc37-26af2743d203,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-26a7b6c6-d491-472f-bc5e-798111abebff,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-258ab51a-975f-4c56-b336-a0af363a3e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907373843-172.17.0.4-1595625261980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45183,DS-12d06746-de43-4157-a4be-819c42086ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-383464fe-4745-47d4-a635-144f87a3eae6,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-31c328b2-4735-4b16-86fe-94164ca4b501,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-f842e73b-fbae-4a2e-b0e0-a4243d2f69c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-63b3cee3-9173-43a7-b444-7488605b7cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-ff9a2fab-c065-43c2-bc37-26af2743d203,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-26a7b6c6-d491-472f-bc5e-798111abebff,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-258ab51a-975f-4c56-b336-a0af363a3e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512396569-172.17.0.4-1595625448373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38494,DS-290193c5-3f69-4a7c-9a98-be194b486d82,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-006f45f2-e839-44b5-935e-6df4c667e104,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-38e2da06-1067-4920-960f-1ed8734fd37d,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-7a5bdeb5-745f-4775-b116-fc90a9398170,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-5dcbed56-f4e1-4930-860f-d467b358cec4,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-25daed26-d994-4648-9a00-29db9bf06e56,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-7b64c33a-6cc1-4845-a1fc-c6f7c9235c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-82da08af-b2c1-4697-91e3-a04dbc00bed7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512396569-172.17.0.4-1595625448373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38494,DS-290193c5-3f69-4a7c-9a98-be194b486d82,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-006f45f2-e839-44b5-935e-6df4c667e104,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-38e2da06-1067-4920-960f-1ed8734fd37d,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-7a5bdeb5-745f-4775-b116-fc90a9398170,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-5dcbed56-f4e1-4930-860f-d467b358cec4,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-25daed26-d994-4648-9a00-29db9bf06e56,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-7b64c33a-6cc1-4845-a1fc-c6f7c9235c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-82da08af-b2c1-4697-91e3-a04dbc00bed7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990724265-172.17.0.4-1595625815420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45700,DS-640fb71b-85eb-40a3-81d3-414e2c85cf11,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-f12d323e-5fbc-4844-9a2d-2670b2d7f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-c4494839-7811-4ce9-996e-289dcc6b9a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-3dba388c-5f86-4480-914c-775f960df567,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-e31505af-36c3-480b-af48-4990b5bcb76b,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-4d91e7c3-870a-4671-b712-f7ad48efd51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-c36117eb-f1f5-4105-aa5d-1e836f63575b,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-a56603ae-36e2-4aab-92f9-c509c9871ced,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990724265-172.17.0.4-1595625815420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45700,DS-640fb71b-85eb-40a3-81d3-414e2c85cf11,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-f12d323e-5fbc-4844-9a2d-2670b2d7f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-c4494839-7811-4ce9-996e-289dcc6b9a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-3dba388c-5f86-4480-914c-775f960df567,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-e31505af-36c3-480b-af48-4990b5bcb76b,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-4d91e7c3-870a-4671-b712-f7ad48efd51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-c36117eb-f1f5-4105-aa5d-1e836f63575b,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-a56603ae-36e2-4aab-92f9-c509c9871ced,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353783189-172.17.0.4-1595625888704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34500,DS-2f1a0695-568b-4aa4-a224-e62d9a57450d,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-2c8da3e5-1ad4-41ab-bf46-29ae9c0b3621,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-3c04844f-bdc0-4033-b431-3b6d115e385a,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-6295cab3-8a55-45d6-8ab0-7442d3570c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-074abd98-5389-43de-b317-8e15e7e345a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-9e4f2745-871e-4608-b846-dd75f433aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-a91b564b-1f9e-4071-a3a2-b123f5a21869,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-6abe4c7f-90ff-47d8-9c2b-6fb689632ac1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353783189-172.17.0.4-1595625888704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34500,DS-2f1a0695-568b-4aa4-a224-e62d9a57450d,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-2c8da3e5-1ad4-41ab-bf46-29ae9c0b3621,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-3c04844f-bdc0-4033-b431-3b6d115e385a,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-6295cab3-8a55-45d6-8ab0-7442d3570c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-074abd98-5389-43de-b317-8e15e7e345a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-9e4f2745-871e-4608-b846-dd75f433aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-a91b564b-1f9e-4071-a3a2-b123f5a21869,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-6abe4c7f-90ff-47d8-9c2b-6fb689632ac1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5354
