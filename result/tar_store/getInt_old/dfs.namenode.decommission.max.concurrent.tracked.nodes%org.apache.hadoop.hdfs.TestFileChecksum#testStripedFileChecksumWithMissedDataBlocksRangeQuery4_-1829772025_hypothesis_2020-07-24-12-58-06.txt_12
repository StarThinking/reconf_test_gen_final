reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31427192-172.17.0.8-1595595810532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41309,DS-d84d7209-90bb-4fc0-a7cf-3b1b7fe3c498,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-746dca29-3c26-4bbe-a68a-6c46b3817bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-bc1f8299-531d-4d94-a695-bf91ef6d31f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-cc39904d-559c-4798-9bb1-7e840fd368c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-9bd21fb1-ae0a-4ca3-b528-2c3f05a878cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-88cfcac2-8ab2-4c8b-bc45-bdfafb4c3b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-a52093f8-8e73-49bb-baf8-0ede7aea5e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-fa6b14fa-c116-475f-8140-e159a288138c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31427192-172.17.0.8-1595595810532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41309,DS-d84d7209-90bb-4fc0-a7cf-3b1b7fe3c498,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-746dca29-3c26-4bbe-a68a-6c46b3817bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-bc1f8299-531d-4d94-a695-bf91ef6d31f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-cc39904d-559c-4798-9bb1-7e840fd368c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-9bd21fb1-ae0a-4ca3-b528-2c3f05a878cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-88cfcac2-8ab2-4c8b-bc45-bdfafb4c3b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-a52093f8-8e73-49bb-baf8-0ede7aea5e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-fa6b14fa-c116-475f-8140-e159a288138c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241255577-172.17.0.8-1595595849016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-a8df974c-e41b-422a-84f8-25d90f724caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-d2e6d210-e657-439e-b456-c21d1be5b229,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-a780f420-5efd-43d4-af63-eccec52e3196,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-6483bc69-b60f-4c39-9948-349cb4142b98,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-19befcd2-9f5b-4593-af91-2653ced96d22,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-8c27fdba-30aa-4c6e-9146-2f870abeee89,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-d4d14be1-032e-4d8f-948e-456b58543be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-021ade50-b944-4129-a5c7-210633d977b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241255577-172.17.0.8-1595595849016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-a8df974c-e41b-422a-84f8-25d90f724caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-d2e6d210-e657-439e-b456-c21d1be5b229,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-a780f420-5efd-43d4-af63-eccec52e3196,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-6483bc69-b60f-4c39-9948-349cb4142b98,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-19befcd2-9f5b-4593-af91-2653ced96d22,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-8c27fdba-30aa-4c6e-9146-2f870abeee89,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-d4d14be1-032e-4d8f-948e-456b58543be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-021ade50-b944-4129-a5c7-210633d977b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450085296-172.17.0.8-1595595954679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39635,DS-c22b4d83-c33f-4eb5-87e0-fb69842ceee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-709fc85c-cb8f-41e0-964c-22ed58025010,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-4cb156e6-0428-403c-bec1-b785548d73db,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-3a8b05c3-3e0b-4000-90ea-5bc85d0763ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-0a158d17-a571-4a5f-9f82-94a26182b37e,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-c82a1cec-302f-46ae-b9c8-42fb4f29a154,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-92e1b7c7-ac6c-448e-96d6-1dd44ea99dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-b628dbf8-6e47-4220-ac32-a5abce098bc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450085296-172.17.0.8-1595595954679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39635,DS-c22b4d83-c33f-4eb5-87e0-fb69842ceee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-709fc85c-cb8f-41e0-964c-22ed58025010,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-4cb156e6-0428-403c-bec1-b785548d73db,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-3a8b05c3-3e0b-4000-90ea-5bc85d0763ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-0a158d17-a571-4a5f-9f82-94a26182b37e,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-c82a1cec-302f-46ae-b9c8-42fb4f29a154,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-92e1b7c7-ac6c-448e-96d6-1dd44ea99dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-b628dbf8-6e47-4220-ac32-a5abce098bc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469142631-172.17.0.8-1595596060346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-ca0bec1c-2405-4e5b-8c48-00d4e32d27f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-acb28f79-84a6-40e9-9a32-135b13f236bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-93174354-6111-4d27-ab41-f5bc208a2f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-467a0e33-2b97-4190-bdab-34dd049652ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-5bd9d370-0c6a-4538-8073-10ee608148f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-c68c9d82-a027-4d75-89a3-b2f4155b2f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-23b6b3bf-c554-4b8f-8c9c-f7695e8581e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-b269541c-7fd1-4386-b089-b36b1a52a772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469142631-172.17.0.8-1595596060346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-ca0bec1c-2405-4e5b-8c48-00d4e32d27f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-acb28f79-84a6-40e9-9a32-135b13f236bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-93174354-6111-4d27-ab41-f5bc208a2f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-467a0e33-2b97-4190-bdab-34dd049652ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-5bd9d370-0c6a-4538-8073-10ee608148f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-c68c9d82-a027-4d75-89a3-b2f4155b2f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-23b6b3bf-c554-4b8f-8c9c-f7695e8581e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-b269541c-7fd1-4386-b089-b36b1a52a772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817691889-172.17.0.8-1595596864404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-93742c7b-bb68-48ce-b51e-dba5535704f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-de9ca596-f751-46af-88dd-9da3b748c7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-068a3400-777f-4477-9b32-e70559b28273,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-40cdb4c8-382b-497c-afb7-ebedf3ec8df4,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-a9e70c6a-a5c6-4476-9b37-fb4e77653632,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-f7b12f22-d26d-4c45-9b2b-53ac34742cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-a6701f76-9efc-4603-b083-a308b9fb95dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-51114480-fd2f-4989-91e7-a5a26f3f9be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817691889-172.17.0.8-1595596864404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-93742c7b-bb68-48ce-b51e-dba5535704f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-de9ca596-f751-46af-88dd-9da3b748c7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-068a3400-777f-4477-9b32-e70559b28273,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-40cdb4c8-382b-497c-afb7-ebedf3ec8df4,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-a9e70c6a-a5c6-4476-9b37-fb4e77653632,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-f7b12f22-d26d-4c45-9b2b-53ac34742cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-a6701f76-9efc-4603-b083-a308b9fb95dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-51114480-fd2f-4989-91e7-a5a26f3f9be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515871423-172.17.0.8-1595597215045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-b182f268-cfe1-49b8-8754-74784e2f98ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-5b4faf10-ec5c-4d8e-9d56-fa55e6821d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-8285be7a-b481-45d8-8910-c057e907e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-4896ad7f-294b-46f3-9c0e-1109a60ea4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-48490c01-9c22-4d4e-a505-6ffd9bd093a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-2f848a45-18b2-450d-9139-facb5e1ada1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-092efb95-c57e-45aa-b49f-0f5031793f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-aa9d517e-e34d-40ca-8b95-136e99e7b6aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515871423-172.17.0.8-1595597215045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-b182f268-cfe1-49b8-8754-74784e2f98ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-5b4faf10-ec5c-4d8e-9d56-fa55e6821d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-8285be7a-b481-45d8-8910-c057e907e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-4896ad7f-294b-46f3-9c0e-1109a60ea4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-48490c01-9c22-4d4e-a505-6ffd9bd093a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-2f848a45-18b2-450d-9139-facb5e1ada1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-092efb95-c57e-45aa-b49f-0f5031793f32,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-aa9d517e-e34d-40ca-8b95-136e99e7b6aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200920480-172.17.0.8-1595597497141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-35de0111-b8e0-470f-8794-2eda68e0a6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-1d813ed8-52cd-4ddb-b9e8-c750c198c7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-c8e1acd9-6426-461c-b680-c0faede9c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-f674d7c2-7a40-45e4-974a-ec298f10c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-e4b012d5-3fa8-42bf-8358-5f1edb635f93,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-b9a6ea42-7e05-433c-8d27-0675201a5b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-146fe9f8-cb47-430d-b98a-2e96ead7a320,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-5c2206a8-5a9e-4722-adb5-614e19091821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200920480-172.17.0.8-1595597497141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-35de0111-b8e0-470f-8794-2eda68e0a6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-1d813ed8-52cd-4ddb-b9e8-c750c198c7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-c8e1acd9-6426-461c-b680-c0faede9c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-f674d7c2-7a40-45e4-974a-ec298f10c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-e4b012d5-3fa8-42bf-8358-5f1edb635f93,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-b9a6ea42-7e05-433c-8d27-0675201a5b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-146fe9f8-cb47-430d-b98a-2e96ead7a320,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-5c2206a8-5a9e-4722-adb5-614e19091821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531184814-172.17.0.8-1595597761979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38011,DS-e39ad183-820c-4bc1-a7f4-654a93e7dc93,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-5a4c5180-f92b-4515-9dbd-f7c53df6df3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-a286f239-ea4d-4cd4-8a30-e0d34f9f8de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-82f65f09-3729-4a8b-9e6a-25a384731dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-6ada929e-0ead-4ef2-b9e8-2ebf80cc37f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-70884bfd-2c39-48ba-a3db-05547aedf4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-5ebee7fa-94fc-4ff9-8b15-45b3b13ffe79,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-01807d45-bb34-4d35-918d-516398b617a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531184814-172.17.0.8-1595597761979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38011,DS-e39ad183-820c-4bc1-a7f4-654a93e7dc93,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-5a4c5180-f92b-4515-9dbd-f7c53df6df3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-a286f239-ea4d-4cd4-8a30-e0d34f9f8de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-82f65f09-3729-4a8b-9e6a-25a384731dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-6ada929e-0ead-4ef2-b9e8-2ebf80cc37f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-70884bfd-2c39-48ba-a3db-05547aedf4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-5ebee7fa-94fc-4ff9-8b15-45b3b13ffe79,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-01807d45-bb34-4d35-918d-516398b617a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104187098-172.17.0.8-1595597837961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45840,DS-504ab490-78ad-422a-b7e2-c7eeae957ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-217bfb0c-632f-4f46-8734-c5dbe305b682,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-1f565de2-6b45-4e57-bdd4-3fed57dbd085,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-574daabd-da0f-4203-a928-15c312c70575,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-f2a56ae9-6db8-450c-8f3a-abfb6f546992,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-a9409367-6bcd-4957-a8ae-f96e6a6ed3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-fa8390d7-8de6-4d52-b843-47d6d7f54f83,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-320320a4-6d83-450a-a068-5c4c69f76950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104187098-172.17.0.8-1595597837961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45840,DS-504ab490-78ad-422a-b7e2-c7eeae957ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-217bfb0c-632f-4f46-8734-c5dbe305b682,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-1f565de2-6b45-4e57-bdd4-3fed57dbd085,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-574daabd-da0f-4203-a928-15c312c70575,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-f2a56ae9-6db8-450c-8f3a-abfb6f546992,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-a9409367-6bcd-4957-a8ae-f96e6a6ed3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-fa8390d7-8de6-4d52-b843-47d6d7f54f83,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-320320a4-6d83-450a-a068-5c4c69f76950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895374897-172.17.0.8-1595598484405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33907,DS-865d31ed-6b2f-41f5-8772-90dc44c8da76,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-597735aa-2a56-4a0f-8eff-6ee95f2e7770,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-546d8413-b8c4-4b8a-8cac-0b0c4071d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-863f7739-3843-46a5-8491-6087ff7f7307,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-763773c6-1adf-4f6f-ac9b-3e95f04a901a,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-cdbe4e7a-87bb-4a72-92fb-999fbb9c3825,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-e7baeee9-aedf-4b00-82b2-17c5800a046f,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-a2b9ac08-4602-4587-b076-6dedca960adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895374897-172.17.0.8-1595598484405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33907,DS-865d31ed-6b2f-41f5-8772-90dc44c8da76,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-597735aa-2a56-4a0f-8eff-6ee95f2e7770,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-546d8413-b8c4-4b8a-8cac-0b0c4071d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-863f7739-3843-46a5-8491-6087ff7f7307,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-763773c6-1adf-4f6f-ac9b-3e95f04a901a,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-cdbe4e7a-87bb-4a72-92fb-999fbb9c3825,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-e7baeee9-aedf-4b00-82b2-17c5800a046f,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-a2b9ac08-4602-4587-b076-6dedca960adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566793812-172.17.0.8-1595598671896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-91f4fec7-ad0f-40ca-8301-157a16a24a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-68c7f59e-0d53-4c97-bf2f-3658d156bce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-8bb89c67-8452-4c22-afee-7c5cee25931a,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-87b093ca-8060-48e3-90fa-d38c0eee8499,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-1c178343-4271-433c-857b-bfe5c32194ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-d7e88311-03e7-4413-b655-7b3a182c8709,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-6a091baa-be19-46c4-86ca-d54b2628554f,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-2294f6d0-e53c-4ccc-a6b7-6960b4a3160b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566793812-172.17.0.8-1595598671896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-91f4fec7-ad0f-40ca-8301-157a16a24a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-68c7f59e-0d53-4c97-bf2f-3658d156bce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-8bb89c67-8452-4c22-afee-7c5cee25931a,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-87b093ca-8060-48e3-90fa-d38c0eee8499,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-1c178343-4271-433c-857b-bfe5c32194ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-d7e88311-03e7-4413-b655-7b3a182c8709,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-6a091baa-be19-46c4-86ca-d54b2628554f,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-2294f6d0-e53c-4ccc-a6b7-6960b4a3160b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329334255-172.17.0.8-1595598738438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44404,DS-cd544281-172a-4a21-b63f-5acc5d37a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-4ebbcc68-af0b-4c29-8bc7-1cd175e68c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-54dfc9db-ab41-4f8a-aac3-2f9c29e1876e,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-1e884438-419e-4ff1-af43-ab71310b795c,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-fe6a5bf3-ca32-4d32-907b-29944a72be59,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-e911a792-07b3-430d-bafd-1f5a81be19f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-69221c05-1bdb-44eb-a9ab-aa1799cd069f,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-67fc6cd1-bcab-4ab0-a4d2-e7fda7e4241e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329334255-172.17.0.8-1595598738438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44404,DS-cd544281-172a-4a21-b63f-5acc5d37a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-4ebbcc68-af0b-4c29-8bc7-1cd175e68c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-54dfc9db-ab41-4f8a-aac3-2f9c29e1876e,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-1e884438-419e-4ff1-af43-ab71310b795c,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-fe6a5bf3-ca32-4d32-907b-29944a72be59,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-e911a792-07b3-430d-bafd-1f5a81be19f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-69221c05-1bdb-44eb-a9ab-aa1799cd069f,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-67fc6cd1-bcab-4ab0-a4d2-e7fda7e4241e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038078377-172.17.0.8-1595598775482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36505,DS-704b51d5-ba52-4326-af0f-02572fa1f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-3639dc90-6bb7-435b-8111-ddf00635803f,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-7056ea97-35e5-4017-8ca6-169e96aa2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-b82e950e-6115-48f7-b100-cb3d57dfef67,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-b30bab89-6c18-4903-bbbe-faadc8ec99e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-0689e3f3-ffab-4e7b-9ec7-5cc29422dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-c4fd7dbf-73c6-4b17-8681-8ed153c3ccbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-85f2a4d7-6ca3-432e-a923-faaf1e690590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038078377-172.17.0.8-1595598775482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36505,DS-704b51d5-ba52-4326-af0f-02572fa1f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-3639dc90-6bb7-435b-8111-ddf00635803f,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-7056ea97-35e5-4017-8ca6-169e96aa2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-b82e950e-6115-48f7-b100-cb3d57dfef67,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-b30bab89-6c18-4903-bbbe-faadc8ec99e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-0689e3f3-ffab-4e7b-9ec7-5cc29422dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-c4fd7dbf-73c6-4b17-8681-8ed153c3ccbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-85f2a4d7-6ca3-432e-a923-faaf1e690590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432649844-172.17.0.8-1595598804316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46162,DS-70467341-cc69-4184-bf45-2345704403e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-68f71247-70c6-4455-982f-66073b70305d,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-70422644-0058-4a6a-9dca-713b604ef7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-5beeab35-6f26-4816-becb-d72485c3733b,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-3cfd6dc4-e756-4df6-932a-9f9248b5f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-0df8ed43-19d1-40d8-b0ac-ca36e2156594,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-ba8fd845-4e39-4566-a9ff-2ee78a9e261d,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-c4503df7-6e37-4a4b-b33a-f43d574dfc43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432649844-172.17.0.8-1595598804316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46162,DS-70467341-cc69-4184-bf45-2345704403e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-68f71247-70c6-4455-982f-66073b70305d,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-70422644-0058-4a6a-9dca-713b604ef7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-5beeab35-6f26-4816-becb-d72485c3733b,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-3cfd6dc4-e756-4df6-932a-9f9248b5f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-0df8ed43-19d1-40d8-b0ac-ca36e2156594,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-ba8fd845-4e39-4566-a9ff-2ee78a9e261d,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-c4503df7-6e37-4a4b-b33a-f43d574dfc43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905884771-172.17.0.8-1595598908175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-ebba95a4-b147-44b5-9f40-bdc3adb5838a,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-a2d2580f-5fb0-4e8c-a1a8-de94f26160a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-5abfafa9-3328-4b09-80e4-928376f15aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-bd9b2654-7e39-4097-a09a-136748814908,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-d7c58635-a236-49cd-b239-268cbc532b52,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-72a91862-82bd-4e4d-92ef-bd9bbb42112a,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-cd74a102-71e9-4bae-bbf6-3cbfefeaade5,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-32b5b903-91dd-4a67-ac42-b2b3e01e720d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905884771-172.17.0.8-1595598908175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-ebba95a4-b147-44b5-9f40-bdc3adb5838a,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-a2d2580f-5fb0-4e8c-a1a8-de94f26160a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-5abfafa9-3328-4b09-80e4-928376f15aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-bd9b2654-7e39-4097-a09a-136748814908,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-d7c58635-a236-49cd-b239-268cbc532b52,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-72a91862-82bd-4e4d-92ef-bd9bbb42112a,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-cd74a102-71e9-4bae-bbf6-3cbfefeaade5,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-32b5b903-91dd-4a67-ac42-b2b3e01e720d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143075954-172.17.0.8-1595599710158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37347,DS-a78f0ff8-0bc9-4f61-b4f8-4e4aa7cd0b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-71572f7d-8313-4367-af2e-bd6b5db1c6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-87e15704-0cd9-461c-aa6d-53bb5385ebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-d311b12b-497e-4e40-a4c3-5118d996de2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-124a2f39-4f8b-41d6-be15-8dc2311ffcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-fbb525bf-49d2-4e40-81a6-1898dffe2d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-06c915c0-1a58-40de-9074-dd5ec3853a16,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-2e9a9d59-b4fe-4bc4-b37e-d1cc4c453006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143075954-172.17.0.8-1595599710158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37347,DS-a78f0ff8-0bc9-4f61-b4f8-4e4aa7cd0b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-71572f7d-8313-4367-af2e-bd6b5db1c6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-87e15704-0cd9-461c-aa6d-53bb5385ebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-d311b12b-497e-4e40-a4c3-5118d996de2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-124a2f39-4f8b-41d6-be15-8dc2311ffcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-fbb525bf-49d2-4e40-81a6-1898dffe2d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-06c915c0-1a58-40de-9074-dd5ec3853a16,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-2e9a9d59-b4fe-4bc4-b37e-d1cc4c453006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896872479-172.17.0.8-1595599897051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35682,DS-9d1e34c6-5760-443b-b712-ef6bfb025be8,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-d3ce132b-252e-4c4c-9d0c-23faa913372c,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-782822f8-c411-454d-bbae-4bf653fd4214,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-b0378888-00db-40fa-b462-853cd2d09de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-93eb6c02-9d92-4843-b75e-80c8712cf19c,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-bb5ad2e7-63bb-4d05-b466-04aceaa96868,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-ecb678c5-e57c-43ab-ad59-475124145d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-df81c55c-2c25-4efa-90d1-e74e9b8e6dce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896872479-172.17.0.8-1595599897051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35682,DS-9d1e34c6-5760-443b-b712-ef6bfb025be8,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-d3ce132b-252e-4c4c-9d0c-23faa913372c,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-782822f8-c411-454d-bbae-4bf653fd4214,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-b0378888-00db-40fa-b462-853cd2d09de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-93eb6c02-9d92-4843-b75e-80c8712cf19c,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-bb5ad2e7-63bb-4d05-b466-04aceaa96868,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-ecb678c5-e57c-43ab-ad59-475124145d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-df81c55c-2c25-4efa-90d1-e74e9b8e6dce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128714083-172.17.0.8-1595599974510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-796b8b7a-76be-4868-9719-83af70c43307,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-710c1be7-1bde-49a9-aabd-f756c7a04647,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-cc26256c-908b-4fd9-938c-6d05e44da0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-269871f6-e222-4e25-97cc-59e23d6f6e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-244ca4be-9e8d-4716-8c1b-a6afe2c4b454,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-940f967c-ecc0-467a-be2e-93daa2e20b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-9ff35639-988e-4c6b-90fc-977be7a87c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-4a2cbedc-ec1c-44c3-b220-cea1bd525779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128714083-172.17.0.8-1595599974510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-796b8b7a-76be-4868-9719-83af70c43307,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-710c1be7-1bde-49a9-aabd-f756c7a04647,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-cc26256c-908b-4fd9-938c-6d05e44da0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-269871f6-e222-4e25-97cc-59e23d6f6e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-244ca4be-9e8d-4716-8c1b-a6afe2c4b454,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-940f967c-ecc0-467a-be2e-93daa2e20b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-9ff35639-988e-4c6b-90fc-977be7a87c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-4a2cbedc-ec1c-44c3-b220-cea1bd525779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346034656-172.17.0.8-1595600255511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43841,DS-ab054fe2-95a7-48b9-ad25-b6864099930d,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-9c9a8332-2b3e-456c-bdb7-1570a6062d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-82627e96-7e7f-4806-9c70-20161f7015a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-0c3b79e9-f32b-4803-8067-9018bffd37f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-2c1b54fd-2689-4cf7-99c8-5536565f3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-8163336e-2675-4c85-be03-a504ff8c177f,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-e82484d4-9249-422e-b128-3f1ccda66c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-86e9b03e-fc8b-4d17-914c-78ee2cd0965b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346034656-172.17.0.8-1595600255511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43841,DS-ab054fe2-95a7-48b9-ad25-b6864099930d,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-9c9a8332-2b3e-456c-bdb7-1570a6062d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-82627e96-7e7f-4806-9c70-20161f7015a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-0c3b79e9-f32b-4803-8067-9018bffd37f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-2c1b54fd-2689-4cf7-99c8-5536565f3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-8163336e-2675-4c85-be03-a504ff8c177f,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-e82484d4-9249-422e-b128-3f1ccda66c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-86e9b03e-fc8b-4d17-914c-78ee2cd0965b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125880183-172.17.0.8-1595600407016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-b7733e24-cc05-44af-bb63-13a1b06ff34e,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-827c7244-6e2b-4d96-a6c6-400f0d51b25d,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-934c9171-8b84-4285-b44f-1b4a4f508d02,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-0ae5dafc-1801-4b6d-ab4e-d3dc83ca56e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-201bd7a7-c9ba-418b-ac3a-01d80dc494d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-d829a16c-23be-4336-89a7-99326198b91f,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-d14b16fa-1dfe-4ade-bf39-6d67a9ce01be,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-189d7916-c6d4-48b6-9c2e-e2b83ded0643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125880183-172.17.0.8-1595600407016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-b7733e24-cc05-44af-bb63-13a1b06ff34e,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-827c7244-6e2b-4d96-a6c6-400f0d51b25d,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-934c9171-8b84-4285-b44f-1b4a4f508d02,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-0ae5dafc-1801-4b6d-ab4e-d3dc83ca56e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-201bd7a7-c9ba-418b-ac3a-01d80dc494d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-d829a16c-23be-4336-89a7-99326198b91f,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-d14b16fa-1dfe-4ade-bf39-6d67a9ce01be,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-189d7916-c6d4-48b6-9c2e-e2b83ded0643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961077670-172.17.0.8-1595600476526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-179eeda6-5b8a-47c1-b9e0-20fe94b28b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-35a497e0-66df-4f00-be15-f07c01adc495,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-3ea63f47-c138-4436-9218-9216375a3f41,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-b91fb547-b97a-49af-8410-70d7e272e03b,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-c721035d-2bf2-46d5-9fde-00f1a937746c,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-1d9cafc5-1600-40d8-a045-2fdc41d1740e,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-f70f3827-f240-4586-9bec-70c3b707a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-8bea1b63-6805-4579-ac32-d7be4cb7b7d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961077670-172.17.0.8-1595600476526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-179eeda6-5b8a-47c1-b9e0-20fe94b28b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-35a497e0-66df-4f00-be15-f07c01adc495,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-3ea63f47-c138-4436-9218-9216375a3f41,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-b91fb547-b97a-49af-8410-70d7e272e03b,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-c721035d-2bf2-46d5-9fde-00f1a937746c,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-1d9cafc5-1600-40d8-a045-2fdc41d1740e,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-f70f3827-f240-4586-9bec-70c3b707a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-8bea1b63-6805-4579-ac32-d7be4cb7b7d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166693005-172.17.0.8-1595600512820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-3a0078a7-1fb0-4370-bb59-a3ab093c155c,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-3de4fcd5-20a5-4d18-9ac1-e70e81ffa90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-575a61dc-c6c0-4a59-87df-8572ec48f100,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-748e0331-7885-4793-bc76-b05487a848ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-1d702ca7-1ea5-4e07-9403-0503379b1d12,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-efd4183d-2900-4804-93be-b0a1e6ea9adf,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-c5922c51-1827-405d-af40-b756e6ad44ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-212804ce-fc2c-4f79-8425-15f13ba49f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166693005-172.17.0.8-1595600512820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-3a0078a7-1fb0-4370-bb59-a3ab093c155c,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-3de4fcd5-20a5-4d18-9ac1-e70e81ffa90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-575a61dc-c6c0-4a59-87df-8572ec48f100,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-748e0331-7885-4793-bc76-b05487a848ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-1d702ca7-1ea5-4e07-9403-0503379b1d12,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-efd4183d-2900-4804-93be-b0a1e6ea9adf,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-c5922c51-1827-405d-af40-b756e6ad44ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-212804ce-fc2c-4f79-8425-15f13ba49f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183145079-172.17.0.8-1595600553325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-db47d0d0-f848-4d6f-8e54-6cabddadc27d,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-50e6fbc0-0eea-4fa3-8291-c4eaa8ac500c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-cc543cbc-6901-49c7-bdcb-381aefc2185c,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-2f78c473-a4b3-4a18-9d0e-4f0b0d0b331c,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-fe4f0675-9d7a-4dcb-9425-ebd048a5e3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-caa4481f-3548-40ff-827d-79d954a7a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-8f8ae503-7f4e-4ac1-8a6f-3c33d4e6be76,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-44d72905-a549-412e-b1b6-b37c8958538d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183145079-172.17.0.8-1595600553325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-db47d0d0-f848-4d6f-8e54-6cabddadc27d,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-50e6fbc0-0eea-4fa3-8291-c4eaa8ac500c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-cc543cbc-6901-49c7-bdcb-381aefc2185c,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-2f78c473-a4b3-4a18-9d0e-4f0b0d0b331c,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-fe4f0675-9d7a-4dcb-9425-ebd048a5e3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-caa4481f-3548-40ff-827d-79d954a7a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-8f8ae503-7f4e-4ac1-8a6f-3c33d4e6be76,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-44d72905-a549-412e-b1b6-b37c8958538d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5509
