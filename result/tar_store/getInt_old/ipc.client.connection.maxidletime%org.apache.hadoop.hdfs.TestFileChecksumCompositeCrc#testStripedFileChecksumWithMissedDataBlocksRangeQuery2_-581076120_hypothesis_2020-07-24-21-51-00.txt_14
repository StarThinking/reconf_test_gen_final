reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520087777-172.17.0.20-1595627478783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40304,DS-ec483af1-85d5-4f5b-8ddc-fd03556877d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-58759596-7f31-4b14-acc9-453b355d9360,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-94734456-6378-4572-815d-f96983b9f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-29f0d5a1-0b73-429d-92ec-60eda8db192e,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-d1ed2402-4505-4002-8310-34030cf27aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-b3405fef-2c03-491a-a98f-0016655e17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-91d14662-43b5-42f8-afcb-ce351e9e4e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-946c7069-6151-4f17-8d27-6f4474d51f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520087777-172.17.0.20-1595627478783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40304,DS-ec483af1-85d5-4f5b-8ddc-fd03556877d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-58759596-7f31-4b14-acc9-453b355d9360,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-94734456-6378-4572-815d-f96983b9f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-29f0d5a1-0b73-429d-92ec-60eda8db192e,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-d1ed2402-4505-4002-8310-34030cf27aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-b3405fef-2c03-491a-a98f-0016655e17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-91d14662-43b5-42f8-afcb-ce351e9e4e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-946c7069-6151-4f17-8d27-6f4474d51f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381457523-172.17.0.20-1595627717012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38566,DS-9f2faa83-5edf-4f2f-95bd-b4c546fc5d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-9896d65c-da71-40a5-9de5-bf7d766054cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-d2ae5dec-ecdd-4e2e-bbef-ff9e26d73626,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-b8f2289a-b989-45c6-ac71-77586115d101,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-976d16e0-9164-4b77-8f81-c5a3284cf963,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-ac451bb3-1c70-4fba-ae3a-60ce6acf7da3,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-90914746-1d08-4889-a8e6-1f30887263eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-261564fd-7df6-44b3-b0de-1bd649720315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381457523-172.17.0.20-1595627717012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38566,DS-9f2faa83-5edf-4f2f-95bd-b4c546fc5d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-9896d65c-da71-40a5-9de5-bf7d766054cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-d2ae5dec-ecdd-4e2e-bbef-ff9e26d73626,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-b8f2289a-b989-45c6-ac71-77586115d101,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-976d16e0-9164-4b77-8f81-c5a3284cf963,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-ac451bb3-1c70-4fba-ae3a-60ce6acf7da3,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-90914746-1d08-4889-a8e6-1f30887263eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-261564fd-7df6-44b3-b0de-1bd649720315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618444632-172.17.0.20-1595628267443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-84ee2529-03ee-4fe9-8791-a5f52879a8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-ec35e4f1-cab2-40cd-9e43-0256efc1a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-3e0b5bc0-9b09-4928-aa55-961d1cd9f1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-33d661e7-d724-4be1-a938-8e2bb67bbc68,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-4d0858da-8c7e-404f-be3c-538d04e1b25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-46bf218b-1ce1-4aeb-a45e-8c97891b5b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-5e0233e0-ad54-4d86-8f17-0e08917aaf39,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-710d4424-96ff-490c-9ce8-30441416a8d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618444632-172.17.0.20-1595628267443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-84ee2529-03ee-4fe9-8791-a5f52879a8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-ec35e4f1-cab2-40cd-9e43-0256efc1a9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-3e0b5bc0-9b09-4928-aa55-961d1cd9f1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-33d661e7-d724-4be1-a938-8e2bb67bbc68,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-4d0858da-8c7e-404f-be3c-538d04e1b25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-46bf218b-1ce1-4aeb-a45e-8c97891b5b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-5e0233e0-ad54-4d86-8f17-0e08917aaf39,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-710d4424-96ff-490c-9ce8-30441416a8d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016235771-172.17.0.20-1595628306193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43450,DS-d898d631-e86e-4c7c-9827-9514573cffe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-363fa13d-9432-4fc5-bce7-f0ad84b7294b,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-0256f6be-5291-4fc2-80da-22faaedd3f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3ed07b54-e6b8-4e6b-a0a2-4655ee071aed,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-7027ea90-a0be-4859-aefd-cb70e0c02e74,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-1358e109-fe8c-4994-b612-b8c10c0859de,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-ca4cc0c1-7b19-42d9-a24a-1335e971c846,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-6c2c91a3-2d5d-4b03-b731-28ca018f63f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016235771-172.17.0.20-1595628306193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43450,DS-d898d631-e86e-4c7c-9827-9514573cffe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-363fa13d-9432-4fc5-bce7-f0ad84b7294b,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-0256f6be-5291-4fc2-80da-22faaedd3f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3ed07b54-e6b8-4e6b-a0a2-4655ee071aed,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-7027ea90-a0be-4859-aefd-cb70e0c02e74,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-1358e109-fe8c-4994-b612-b8c10c0859de,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-ca4cc0c1-7b19-42d9-a24a-1335e971c846,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-6c2c91a3-2d5d-4b03-b731-28ca018f63f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393305936-172.17.0.20-1595628710545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35109,DS-a65ce4aa-c06b-44b6-8c84-08fb89789e49,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-537320c6-0792-4451-8754-9043be4d32f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-4fc33502-546a-4bb8-9a29-84e20055f390,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-eb330db0-481c-4422-a91f-dfa220cc894e,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-ad38a1cf-0658-4b6a-9e27-d89984ef7a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-c8ec39cd-8b27-4f53-997f-53ffac876d90,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-de72b80b-ac80-4c5c-8920-f6b7176076a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-38495a33-6dce-44b7-8d38-389d51962a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393305936-172.17.0.20-1595628710545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35109,DS-a65ce4aa-c06b-44b6-8c84-08fb89789e49,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-537320c6-0792-4451-8754-9043be4d32f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-4fc33502-546a-4bb8-9a29-84e20055f390,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-eb330db0-481c-4422-a91f-dfa220cc894e,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-ad38a1cf-0658-4b6a-9e27-d89984ef7a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-c8ec39cd-8b27-4f53-997f-53ffac876d90,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-de72b80b-ac80-4c5c-8920-f6b7176076a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-38495a33-6dce-44b7-8d38-389d51962a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891449088-172.17.0.20-1595628971994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-110030a7-18c0-4438-b4b2-e52cfbf49467,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-ff814f9b-32da-4189-89f9-dd30064644fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-e43c79fb-f306-4242-8169-d464dd466aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-d4245867-6189-46cd-8536-dd656b7a833c,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-ddcb798e-3bcd-4776-abce-85bdd3de8c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-017365bf-720c-499e-9759-99622810fc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-f254e5ef-2b7e-4272-836a-d824ef23dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-8323cbd3-ba56-4ab3-8195-f95f2b326346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891449088-172.17.0.20-1595628971994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-110030a7-18c0-4438-b4b2-e52cfbf49467,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-ff814f9b-32da-4189-89f9-dd30064644fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-e43c79fb-f306-4242-8169-d464dd466aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-d4245867-6189-46cd-8536-dd656b7a833c,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-ddcb798e-3bcd-4776-abce-85bdd3de8c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-017365bf-720c-499e-9759-99622810fc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-f254e5ef-2b7e-4272-836a-d824ef23dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-8323cbd3-ba56-4ab3-8195-f95f2b326346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639410323-172.17.0.20-1595629123121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-0ffac2a3-3dbb-4f9d-935b-1dc95b33cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-093f99a8-4343-4f04-b608-7e7ab2a091d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-d9126b1e-ff00-4a13-ba08-a408f7c07ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-92da29e8-a768-46ad-a424-b4d919aa545b,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-682e38c6-da51-4d0a-b904-078d2cfc4363,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-c2e43884-38ea-4e93-964c-57f32800378c,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-72392a0d-f7f2-4261-b4ab-4f8437279cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-38d5b760-49f3-4e67-8ac0-f16dba357ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639410323-172.17.0.20-1595629123121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-0ffac2a3-3dbb-4f9d-935b-1dc95b33cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-093f99a8-4343-4f04-b608-7e7ab2a091d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-d9126b1e-ff00-4a13-ba08-a408f7c07ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-92da29e8-a768-46ad-a424-b4d919aa545b,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-682e38c6-da51-4d0a-b904-078d2cfc4363,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-c2e43884-38ea-4e93-964c-57f32800378c,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-72392a0d-f7f2-4261-b4ab-4f8437279cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-38d5b760-49f3-4e67-8ac0-f16dba357ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921330933-172.17.0.20-1595629208545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38664,DS-035600d4-04b1-469c-bcdc-411c98bc2a18,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-a5332581-0f0c-4f13-81fc-49b6d170a915,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-6079fec8-7f7a-44da-8602-b0dbd1f07057,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-c6871dc7-f736-46c9-a05d-fb552b71d024,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-ce3a770d-519e-4c49-a2f9-f9614b5aeb16,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-23d6d39a-5a5e-43bb-884e-6f8a61590371,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-d6d4a622-5dec-448a-b4a9-203cf91df99d,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-18c3e0bc-e030-4be0-bfb6-8f7130b12df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921330933-172.17.0.20-1595629208545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38664,DS-035600d4-04b1-469c-bcdc-411c98bc2a18,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-a5332581-0f0c-4f13-81fc-49b6d170a915,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-6079fec8-7f7a-44da-8602-b0dbd1f07057,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-c6871dc7-f736-46c9-a05d-fb552b71d024,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-ce3a770d-519e-4c49-a2f9-f9614b5aeb16,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-23d6d39a-5a5e-43bb-884e-6f8a61590371,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-d6d4a622-5dec-448a-b4a9-203cf91df99d,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-18c3e0bc-e030-4be0-bfb6-8f7130b12df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742076702-172.17.0.20-1595629540454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-8783e4c0-3af8-45a3-835d-7d8d14bec526,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-546c5ee5-b83c-4943-ba9e-d5f5a35e4b27,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-446af80d-af25-4d4c-9634-d94ad90d88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-c4bfa3cf-af78-40fd-8aba-34f5ff47009b,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-ffb53d04-4c21-4eab-a6da-a6ef37c10812,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-0a78dfd0-f52e-4574-8158-69935cdf3a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-b1073a49-4cc5-4ba1-b26c-2884dfaec2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-bcd59c0e-3ff4-489c-b599-bd6f7d68b2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742076702-172.17.0.20-1595629540454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-8783e4c0-3af8-45a3-835d-7d8d14bec526,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-546c5ee5-b83c-4943-ba9e-d5f5a35e4b27,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-446af80d-af25-4d4c-9634-d94ad90d88d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-c4bfa3cf-af78-40fd-8aba-34f5ff47009b,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-ffb53d04-4c21-4eab-a6da-a6ef37c10812,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-0a78dfd0-f52e-4574-8158-69935cdf3a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-b1073a49-4cc5-4ba1-b26c-2884dfaec2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-bcd59c0e-3ff4-489c-b599-bd6f7d68b2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22184762-172.17.0.20-1595629764738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-bff78287-7062-42c5-af1e-05f97e14121a,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-d527bbcd-2a5c-4798-8539-c658009155fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-3aa98546-7b36-4579-9884-1499970b12ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-35912de1-82f3-4e0a-9957-49f5e7173f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-225bb025-cff5-4c94-84df-6ebf97a54a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-3b897acf-97f1-466a-b0d3-536a4bdf5dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-1b603e10-c8f9-43b8-a892-4e6a9b48dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-c0721d08-9b02-4168-92fb-3e45d7b5e02f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22184762-172.17.0.20-1595629764738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-bff78287-7062-42c5-af1e-05f97e14121a,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-d527bbcd-2a5c-4798-8539-c658009155fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-3aa98546-7b36-4579-9884-1499970b12ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-35912de1-82f3-4e0a-9957-49f5e7173f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-225bb025-cff5-4c94-84df-6ebf97a54a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-3b897acf-97f1-466a-b0d3-536a4bdf5dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-1b603e10-c8f9-43b8-a892-4e6a9b48dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-c0721d08-9b02-4168-92fb-3e45d7b5e02f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535553576-172.17.0.20-1595629806654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46356,DS-f400af05-bb48-41ce-9950-b4ad2373c493,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-d15d9fab-5d2d-4f3e-9116-9e95a5755ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-1a17655d-220d-4d8c-ae48-38b1c598e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-ead9837e-f9f9-4f51-b002-2f62f3208e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-1cba3dfd-2d1f-4598-a545-f62b8d9233a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-d018b988-97d5-4af8-852f-aec23a265e85,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-6bea4f8a-6949-4799-94a8-2bc360a3e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-c7645ce5-f3b9-46e2-aa48-afa5fce534d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535553576-172.17.0.20-1595629806654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46356,DS-f400af05-bb48-41ce-9950-b4ad2373c493,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-d15d9fab-5d2d-4f3e-9116-9e95a5755ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-1a17655d-220d-4d8c-ae48-38b1c598e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-ead9837e-f9f9-4f51-b002-2f62f3208e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-1cba3dfd-2d1f-4598-a545-f62b8d9233a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-d018b988-97d5-4af8-852f-aec23a265e85,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-6bea4f8a-6949-4799-94a8-2bc360a3e25a,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-c7645ce5-f3b9-46e2-aa48-afa5fce534d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353118551-172.17.0.20-1595630146163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35378,DS-023879b8-5feb-4b44-a8e5-ffed405dcf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-b64ed7b8-6e7c-4993-9a3a-548cf3952a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-5f86d8ef-535e-41aa-8476-d4e16f66d6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-bd82d40a-b7ec-43f0-a643-07c9064877cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-84187812-8d17-43ad-b5da-6e4a79334f08,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-ccd89a0f-75f2-426d-a6a1-538a01acce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-76ad4f53-a1f2-4d52-8c4b-1ac94f3bb91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-ee2bbad9-9f53-4cc9-9ace-5412855b89de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353118551-172.17.0.20-1595630146163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35378,DS-023879b8-5feb-4b44-a8e5-ffed405dcf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-b64ed7b8-6e7c-4993-9a3a-548cf3952a03,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-5f86d8ef-535e-41aa-8476-d4e16f66d6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-bd82d40a-b7ec-43f0-a643-07c9064877cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-84187812-8d17-43ad-b5da-6e4a79334f08,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-ccd89a0f-75f2-426d-a6a1-538a01acce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-76ad4f53-a1f2-4d52-8c4b-1ac94f3bb91d,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-ee2bbad9-9f53-4cc9-9ace-5412855b89de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255935614-172.17.0.20-1595630518201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44784,DS-521422a2-9c39-431e-9f77-7f4e4a7eed15,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-d7e2913f-ba4b-4f19-b45d-66b7ff394415,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-210aa41d-7d6c-4dc0-b571-320f984a8baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-5231db36-2389-4fe3-8644-25fb5a88a987,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-e7f67a83-04a9-4aba-b35c-e8f58d9a6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-cce5e6b3-28c5-4ab4-aa54-8f6711d12f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-a9d8810b-38d5-42bf-8c6b-f5f3d81030f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-880f106a-4b4c-4688-9253-c2ba9d273f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255935614-172.17.0.20-1595630518201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44784,DS-521422a2-9c39-431e-9f77-7f4e4a7eed15,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-d7e2913f-ba4b-4f19-b45d-66b7ff394415,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-210aa41d-7d6c-4dc0-b571-320f984a8baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-5231db36-2389-4fe3-8644-25fb5a88a987,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-e7f67a83-04a9-4aba-b35c-e8f58d9a6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-cce5e6b3-28c5-4ab4-aa54-8f6711d12f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-a9d8810b-38d5-42bf-8c6b-f5f3d81030f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-880f106a-4b4c-4688-9253-c2ba9d273f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604588647-172.17.0.20-1595630739308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-fc7dbc29-1085-4548-a559-2eb962dee9da,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-f3af3664-c0eb-40b1-90a8-bac161ae9fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-ed5de08d-3554-40f3-b544-a032d43aee56,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-ba92d36d-f129-4460-879e-22dabdeb6b46,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-b4412bf2-d042-4424-88c2-515fac0796f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-108dcd41-2474-4854-8850-8b07fae17b46,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-813331db-c195-43b9-8389-52051de41fce,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-ca0930ec-2242-4cec-9ba5-7d5132cdd0e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604588647-172.17.0.20-1595630739308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-fc7dbc29-1085-4548-a559-2eb962dee9da,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-f3af3664-c0eb-40b1-90a8-bac161ae9fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-ed5de08d-3554-40f3-b544-a032d43aee56,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-ba92d36d-f129-4460-879e-22dabdeb6b46,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-b4412bf2-d042-4424-88c2-515fac0796f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-108dcd41-2474-4854-8850-8b07fae17b46,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-813331db-c195-43b9-8389-52051de41fce,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-ca0930ec-2242-4cec-9ba5-7d5132cdd0e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245308516-172.17.0.20-1595631023865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44303,DS-ea1f91f8-252e-4bc9-94b9-d35b2ab5b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-cd4374f2-2384-4cef-ae1f-dc3a61309b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-246ba8ef-d994-484e-8f92-4dc1799ed707,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-d94c497e-114f-459e-b007-950f47334071,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-e2463ae8-01d5-4b7d-8c59-1269cfb10191,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-09e70f8f-b8d8-4220-9f40-2b117d36accf,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-6f0e9c6b-ad21-4819-a442-e985107b3784,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-05a6b6d7-fbbb-468a-94aa-4ae6df13137b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245308516-172.17.0.20-1595631023865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44303,DS-ea1f91f8-252e-4bc9-94b9-d35b2ab5b8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-cd4374f2-2384-4cef-ae1f-dc3a61309b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-246ba8ef-d994-484e-8f92-4dc1799ed707,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-d94c497e-114f-459e-b007-950f47334071,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-e2463ae8-01d5-4b7d-8c59-1269cfb10191,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-09e70f8f-b8d8-4220-9f40-2b117d36accf,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-6f0e9c6b-ad21-4819-a442-e985107b3784,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-05a6b6d7-fbbb-468a-94aa-4ae6df13137b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703614179-172.17.0.20-1595631090887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-d650e05a-f30b-4927-ad4a-c032c36a2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-68edb413-b73e-4e44-9438-03f2b5d60776,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-c37e9e05-04c6-452f-8516-0adc9d556793,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-6aeaeaaf-f6dd-4bd1-b302-9659591e1c40,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-2d466e63-b1de-4f84-9999-59e29be74bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-39a033ea-30e5-48d6-8815-210eb2b0f80f,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-ad3530a7-dbf1-4aa1-9f6d-143bd4945289,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-394a3025-9ca1-43ad-bf5b-8559a77cc6b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703614179-172.17.0.20-1595631090887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-d650e05a-f30b-4927-ad4a-c032c36a2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-68edb413-b73e-4e44-9438-03f2b5d60776,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-c37e9e05-04c6-452f-8516-0adc9d556793,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-6aeaeaaf-f6dd-4bd1-b302-9659591e1c40,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-2d466e63-b1de-4f84-9999-59e29be74bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-39a033ea-30e5-48d6-8815-210eb2b0f80f,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-ad3530a7-dbf1-4aa1-9f6d-143bd4945289,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-394a3025-9ca1-43ad-bf5b-8559a77cc6b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649255460-172.17.0.20-1595631122058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36527,DS-617d31cb-2b5d-44d2-a875-4012d44982f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-2216b6fb-8bdc-4073-b35f-d25ddb4b5d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-4c756db0-68d8-412b-9306-d795232d6f41,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-f933fea2-53d3-4002-a397-1d4f6bb8fc89,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-6be4d904-fcc7-43d9-b98c-d82e641b53e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-d23640da-c192-4451-82cb-faac38c8a0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-fae58565-9d5d-48ac-99c4-b4c9543ba02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-54b589bd-f487-4b63-b6bf-129354bfe25f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649255460-172.17.0.20-1595631122058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36527,DS-617d31cb-2b5d-44d2-a875-4012d44982f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-2216b6fb-8bdc-4073-b35f-d25ddb4b5d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-4c756db0-68d8-412b-9306-d795232d6f41,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-f933fea2-53d3-4002-a397-1d4f6bb8fc89,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-6be4d904-fcc7-43d9-b98c-d82e641b53e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-d23640da-c192-4451-82cb-faac38c8a0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-fae58565-9d5d-48ac-99c4-b4c9543ba02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-54b589bd-f487-4b63-b6bf-129354bfe25f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011211441-172.17.0.20-1595631519453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-267f8ab2-655e-4e71-a345-0dff517b5274,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-b3611ff9-e43a-45fa-b1ea-e08016f30159,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-10eb96c1-2875-4272-8c90-0d1b0dde01bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-129f375a-14df-48df-8482-c68b96f3947f,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-5dbec1c1-37aa-4761-9935-7ad2cacb260c,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-497a7d14-c70f-4ea9-a3a3-8f6fd325a336,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-11546cea-4f47-4812-8b2a-909d05343050,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-dfdc29e6-a4ab-4f66-8cd6-a1e2a0b48f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011211441-172.17.0.20-1595631519453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-267f8ab2-655e-4e71-a345-0dff517b5274,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-b3611ff9-e43a-45fa-b1ea-e08016f30159,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-10eb96c1-2875-4272-8c90-0d1b0dde01bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-129f375a-14df-48df-8482-c68b96f3947f,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-5dbec1c1-37aa-4761-9935-7ad2cacb260c,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-497a7d14-c70f-4ea9-a3a3-8f6fd325a336,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-11546cea-4f47-4812-8b2a-909d05343050,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-dfdc29e6-a4ab-4f66-8cd6-a1e2a0b48f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744980789-172.17.0.20-1595631853655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-4da2d010-b7df-432d-ae32-515f730e40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-370b1b36-ea78-4aa4-a4fb-8fe7ee093820,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-3d0c15e7-24a4-4215-b872-6b0914af26e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-7b1f32f9-5915-443d-985f-dc0fbf4eb0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-7d0fad30-2c01-4cd2-b3c8-3c0e13cfd795,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-d28d8fbc-4f25-4668-945a-80936bd96326,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-94f93117-4965-4327-abd1-3252e5bed32a,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-b1bcadab-05b9-4de5-8b50-02f828cd5ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744980789-172.17.0.20-1595631853655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-4da2d010-b7df-432d-ae32-515f730e40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-370b1b36-ea78-4aa4-a4fb-8fe7ee093820,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-3d0c15e7-24a4-4215-b872-6b0914af26e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-7b1f32f9-5915-443d-985f-dc0fbf4eb0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-7d0fad30-2c01-4cd2-b3c8-3c0e13cfd795,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-d28d8fbc-4f25-4668-945a-80936bd96326,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-94f93117-4965-4327-abd1-3252e5bed32a,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-b1bcadab-05b9-4de5-8b50-02f828cd5ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883037699-172.17.0.20-1595631978029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39341,DS-c37fc80d-fb08-41f0-9da2-3504a4e1b5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-cf8f6b95-56a1-484f-ba97-3758f98f4e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-ae380d74-6d42-4ce3-ad9f-ef11e99b1407,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-a1f19a0e-84c6-4ecc-b0d5-9aa18111dc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-d58bd0e2-430b-4613-b6a5-6cf0794bf43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-080f76f1-5257-4c0d-865e-8738f5eeb1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-3da2ee9f-1929-4e60-8029-7f122db9ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-6a8f7663-d193-4dde-bef0-0b2a2031f742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883037699-172.17.0.20-1595631978029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39341,DS-c37fc80d-fb08-41f0-9da2-3504a4e1b5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-cf8f6b95-56a1-484f-ba97-3758f98f4e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-ae380d74-6d42-4ce3-ad9f-ef11e99b1407,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-a1f19a0e-84c6-4ecc-b0d5-9aa18111dc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-d58bd0e2-430b-4613-b6a5-6cf0794bf43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-080f76f1-5257-4c0d-865e-8738f5eeb1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-3da2ee9f-1929-4e60-8029-7f122db9ef83,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-6a8f7663-d193-4dde-bef0-0b2a2031f742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230074983-172.17.0.20-1595632195444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42677,DS-e254fae5-accc-42e4-8e79-418c334d1afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-5fe073b4-cf65-461d-9af9-75cc88df9e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-025e652e-e30c-4218-8376-8ee9b61334f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-0af57704-92fd-469d-99af-b255a4977e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-19f3f97d-a952-435a-8571-4c0e24a5ba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-bb2ff5e0-5dbb-4a6d-8baa-ad32e1b9190f,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-9608534b-f182-4373-b8e4-a2b1bb1b9710,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-20cf6ec9-d1c5-4ec9-8469-804bc34a3326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230074983-172.17.0.20-1595632195444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42677,DS-e254fae5-accc-42e4-8e79-418c334d1afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-5fe073b4-cf65-461d-9af9-75cc88df9e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-025e652e-e30c-4218-8376-8ee9b61334f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-0af57704-92fd-469d-99af-b255a4977e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-19f3f97d-a952-435a-8571-4c0e24a5ba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-bb2ff5e0-5dbb-4a6d-8baa-ad32e1b9190f,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-9608534b-f182-4373-b8e4-a2b1bb1b9710,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-20cf6ec9-d1c5-4ec9-8469-804bc34a3326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752230595-172.17.0.20-1595632566676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-9e852a8d-5f89-41c6-8768-63056ec0d936,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-a09a3dff-b1d0-4b31-918c-6db538e565bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-7ae097bd-a04a-4067-b617-e003bbe91708,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-29a03b1f-d03d-44d6-9714-f88f15b45a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-a9af54bc-6fff-4e99-8a38-ecad55b3e346,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-faac6a9e-6785-499c-b406-422b5d59bc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-f1c65e01-258e-4b78-bd63-590fcbb9ecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-97fd9c17-4fc1-4905-a10c-01cdfd7bcaa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752230595-172.17.0.20-1595632566676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-9e852a8d-5f89-41c6-8768-63056ec0d936,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-a09a3dff-b1d0-4b31-918c-6db538e565bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-7ae097bd-a04a-4067-b617-e003bbe91708,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-29a03b1f-d03d-44d6-9714-f88f15b45a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-a9af54bc-6fff-4e99-8a38-ecad55b3e346,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-faac6a9e-6785-499c-b406-422b5d59bc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-f1c65e01-258e-4b78-bd63-590fcbb9ecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-97fd9c17-4fc1-4905-a10c-01cdfd7bcaa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524396987-172.17.0.20-1595632831433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35855,DS-62454377-1847-4ed7-a311-0db6661b089b,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-e6709411-2a11-4def-993e-2b03470114a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-dcf2886c-7a70-4d86-bfbb-ae5ed5580205,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-4daaabec-31e7-458e-be4a-a4202d8795af,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-0883930a-e272-497f-8bc4-c8059eccd578,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-9208c72c-a73f-4b21-9e89-148f2bc3f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-6104d633-c75e-4966-b7e2-da37eda90db4,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-89ae7fed-e536-4501-921a-ba5aac6378dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524396987-172.17.0.20-1595632831433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35855,DS-62454377-1847-4ed7-a311-0db6661b089b,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-e6709411-2a11-4def-993e-2b03470114a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-dcf2886c-7a70-4d86-bfbb-ae5ed5580205,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-4daaabec-31e7-458e-be4a-a4202d8795af,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-0883930a-e272-497f-8bc4-c8059eccd578,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-9208c72c-a73f-4b21-9e89-148f2bc3f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-6104d633-c75e-4966-b7e2-da37eda90db4,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-89ae7fed-e536-4501-921a-ba5aac6378dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5717
