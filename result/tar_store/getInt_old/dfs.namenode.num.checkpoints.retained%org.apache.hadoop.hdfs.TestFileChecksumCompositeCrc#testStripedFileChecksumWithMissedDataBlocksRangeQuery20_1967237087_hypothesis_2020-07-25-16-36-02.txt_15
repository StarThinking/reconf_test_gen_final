reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113982346-172.17.0.3-1595694973899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45344,DS-365f8558-c8f0-403d-b05c-b9bf45ead498,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-9050aae5-769f-48f9-915b-3b85e552e603,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-bf55423d-55db-480e-9a07-c5aef7b3b169,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-ff44cf53-2a3b-4e56-8101-2aacd58324f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-3ac7758a-25ae-4b8d-b71d-14efe8d96f50,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-e3cc44b4-5876-40a1-a686-4afa0b6c82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-2cc434c9-4327-4f64-9459-c4a8a93997ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-1759c345-5c94-4c0b-9ac9-d43c9962cf67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113982346-172.17.0.3-1595694973899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45344,DS-365f8558-c8f0-403d-b05c-b9bf45ead498,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-9050aae5-769f-48f9-915b-3b85e552e603,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-bf55423d-55db-480e-9a07-c5aef7b3b169,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-ff44cf53-2a3b-4e56-8101-2aacd58324f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-3ac7758a-25ae-4b8d-b71d-14efe8d96f50,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-e3cc44b4-5876-40a1-a686-4afa0b6c82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-2cc434c9-4327-4f64-9459-c4a8a93997ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-1759c345-5c94-4c0b-9ac9-d43c9962cf67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165864428-172.17.0.3-1595695079458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-a88c86b9-f74e-419d-986c-2421f721a9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-6b165781-21d7-46d1-b688-e2d6c1460844,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-f44541b4-63f8-4d92-856d-456c3e9d26ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-573f911b-a3ef-49c7-96fe-b5c3d4bfcf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-9c2baccc-6870-453d-b283-10b01d8fe134,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-5016a8c7-6391-4956-b2df-0e32f1a8c1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-845a4e16-e426-4cdf-bc47-a93e70471402,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-74b875a7-3ca1-457f-b860-eace86b84082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165864428-172.17.0.3-1595695079458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-a88c86b9-f74e-419d-986c-2421f721a9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-6b165781-21d7-46d1-b688-e2d6c1460844,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-f44541b4-63f8-4d92-856d-456c3e9d26ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-573f911b-a3ef-49c7-96fe-b5c3d4bfcf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-9c2baccc-6870-453d-b283-10b01d8fe134,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-5016a8c7-6391-4956-b2df-0e32f1a8c1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-845a4e16-e426-4cdf-bc47-a93e70471402,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-74b875a7-3ca1-457f-b860-eace86b84082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951629046-172.17.0.3-1595695544403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45408,DS-95ca1eb1-cbdf-47b1-b704-2f8d3924b02c,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-4821b24e-6c58-4fb7-a819-248fa58c249a,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-56f43c56-a626-463d-a208-fe7652f03a56,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-8edf46ab-0016-4fd5-a500-cf54da326e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-92598213-3309-483e-a6b4-8aff75ba6544,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-6ff1f8f2-320f-4b49-b80a-c021718b4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-5d1ac3dd-dad1-4ebe-86d3-91dd96941c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-3e494865-a458-490c-aff1-ffb779fba0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951629046-172.17.0.3-1595695544403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45408,DS-95ca1eb1-cbdf-47b1-b704-2f8d3924b02c,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-4821b24e-6c58-4fb7-a819-248fa58c249a,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-56f43c56-a626-463d-a208-fe7652f03a56,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-8edf46ab-0016-4fd5-a500-cf54da326e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-92598213-3309-483e-a6b4-8aff75ba6544,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-6ff1f8f2-320f-4b49-b80a-c021718b4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-5d1ac3dd-dad1-4ebe-86d3-91dd96941c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-3e494865-a458-490c-aff1-ffb779fba0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483808458-172.17.0.3-1595695652889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-2e883a51-3f98-4f7d-997c-baed2bea816e,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-42db50b8-c0db-4a97-bcd2-850f5a173107,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-154f2c09-ef4c-4ba4-9ddc-d8608002a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-e7b7d6e5-e1e7-4f25-b52f-04bf02411154,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-eff81e61-f12c-4ade-955f-731befdbf0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-4518e77e-9b67-498d-b623-84cc168ac674,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-b7391e05-7a6c-48ae-80b3-60dc17d1b3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-ad2c10b3-81e4-46ee-af89-a5ef06bfca61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483808458-172.17.0.3-1595695652889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-2e883a51-3f98-4f7d-997c-baed2bea816e,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-42db50b8-c0db-4a97-bcd2-850f5a173107,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-154f2c09-ef4c-4ba4-9ddc-d8608002a26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-e7b7d6e5-e1e7-4f25-b52f-04bf02411154,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-eff81e61-f12c-4ade-955f-731befdbf0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-4518e77e-9b67-498d-b623-84cc168ac674,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-b7391e05-7a6c-48ae-80b3-60dc17d1b3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-ad2c10b3-81e4-46ee-af89-a5ef06bfca61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516313120-172.17.0.3-1595696015363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-1dbbe786-fa71-4fcd-9810-ac15a7487b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-ad7651cc-8fd4-48ff-8a47-570325462eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-4e048de9-824b-41cf-a352-393cb637a468,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-0c9d586c-6f0b-4764-bb27-3e063740a33f,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-41f9274f-f0a3-4754-8805-16448fdf706c,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-07a48403-78be-4b57-81d2-b3943733dce7,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-a4da9b40-475a-462f-8690-f6a3884d5ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-52b2a4ee-3f63-47d1-9036-6f919109957e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516313120-172.17.0.3-1595696015363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-1dbbe786-fa71-4fcd-9810-ac15a7487b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-ad7651cc-8fd4-48ff-8a47-570325462eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-4e048de9-824b-41cf-a352-393cb637a468,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-0c9d586c-6f0b-4764-bb27-3e063740a33f,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-41f9274f-f0a3-4754-8805-16448fdf706c,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-07a48403-78be-4b57-81d2-b3943733dce7,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-a4da9b40-475a-462f-8690-f6a3884d5ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-52b2a4ee-3f63-47d1-9036-6f919109957e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193609839-172.17.0.3-1595696372973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-a80791c8-9546-4209-be2a-c5d7b417b36e,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-bf6748dd-917a-45ad-aac3-62c878486f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-6e7d9d18-b365-464a-beef-19913a43dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-1b9e62ab-3b55-4954-bdea-983bf01534ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-45f2c8ca-9083-4b1b-a575-93e2fb60b56d,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-58e3d543-049b-4d2e-9a6a-122cfc3c38f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-ab46139a-f532-4a42-af51-de314c2b0f36,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-d01f7810-0846-464f-912f-75a1d88699bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193609839-172.17.0.3-1595696372973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-a80791c8-9546-4209-be2a-c5d7b417b36e,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-bf6748dd-917a-45ad-aac3-62c878486f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-6e7d9d18-b365-464a-beef-19913a43dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-1b9e62ab-3b55-4954-bdea-983bf01534ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-45f2c8ca-9083-4b1b-a575-93e2fb60b56d,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-58e3d543-049b-4d2e-9a6a-122cfc3c38f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-ab46139a-f532-4a42-af51-de314c2b0f36,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-d01f7810-0846-464f-912f-75a1d88699bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491479329-172.17.0.3-1595696486375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37355,DS-eff6ba43-de6d-4390-bc64-5dcb6b38fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-69311a3d-ed7d-45c8-8a1b-f02706a84e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-a839fefc-0390-47d6-aaa7-ca000fda311f,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-095ee140-81e3-48c4-946d-79d4034eaa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-909d87ec-44b5-4f2a-a887-cc12111fde82,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-3e62e102-13fe-40a2-a272-424f7a9c649b,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-a6432c20-2717-480b-9a9b-eec6ab92495d,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-f8f743ad-72b3-4597-a794-ddb41c2b6bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491479329-172.17.0.3-1595696486375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37355,DS-eff6ba43-de6d-4390-bc64-5dcb6b38fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-69311a3d-ed7d-45c8-8a1b-f02706a84e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-a839fefc-0390-47d6-aaa7-ca000fda311f,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-095ee140-81e3-48c4-946d-79d4034eaa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-909d87ec-44b5-4f2a-a887-cc12111fde82,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-3e62e102-13fe-40a2-a272-424f7a9c649b,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-a6432c20-2717-480b-9a9b-eec6ab92495d,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-f8f743ad-72b3-4597-a794-ddb41c2b6bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250028930-172.17.0.3-1595696816958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34030,DS-5989dfe6-096c-40a1-850c-2fcc66961316,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-b481b5ff-3187-4cbe-946d-211fa3e9b451,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-3b608777-6d23-43b9-bdd9-01df6abedcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-c0968e36-b4bd-496d-8f75-7f6d243c2eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-cc91a4b3-cb11-4421-b7a6-ea9b649c079d,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-6a9519d5-372c-4dcc-a438-772692da24e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-20657904-2c97-4890-a8f2-e9b93315867e,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-5fb75980-9c68-4f79-b048-c49537163157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250028930-172.17.0.3-1595696816958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34030,DS-5989dfe6-096c-40a1-850c-2fcc66961316,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-b481b5ff-3187-4cbe-946d-211fa3e9b451,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-3b608777-6d23-43b9-bdd9-01df6abedcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-c0968e36-b4bd-496d-8f75-7f6d243c2eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-cc91a4b3-cb11-4421-b7a6-ea9b649c079d,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-6a9519d5-372c-4dcc-a438-772692da24e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-20657904-2c97-4890-a8f2-e9b93315867e,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-5fb75980-9c68-4f79-b048-c49537163157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958964309-172.17.0.3-1595696852209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-c1e39533-2b28-4c81-b439-4a398ccbb2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-0a2af75e-1241-474c-8a8e-5f901b89a73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-20a76e15-e107-42c5-8575-b5c6e13333b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-71dcd7fd-ef76-442d-8caf-537f1e4e90e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-8671dd38-49d0-49ff-bfb7-59a0ac6f6743,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-0c762a6d-569c-4876-b31a-a795712337d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-ed5d9891-6a69-42c1-a4ef-a9caac13e8af,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-e86e9b2a-38ba-43c2-bad4-60d7191f7b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958964309-172.17.0.3-1595696852209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33558,DS-c1e39533-2b28-4c81-b439-4a398ccbb2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-0a2af75e-1241-474c-8a8e-5f901b89a73e,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-20a76e15-e107-42c5-8575-b5c6e13333b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-71dcd7fd-ef76-442d-8caf-537f1e4e90e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-8671dd38-49d0-49ff-bfb7-59a0ac6f6743,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-0c762a6d-569c-4876-b31a-a795712337d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-ed5d9891-6a69-42c1-a4ef-a9caac13e8af,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-e86e9b2a-38ba-43c2-bad4-60d7191f7b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91014052-172.17.0.3-1595697185046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34614,DS-3ee6b8ce-9995-4b89-92b4-42f9cd87f8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-330d64d6-d56c-42fc-a378-47d3d2669ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-88e96648-226b-4eba-a261-fa7b2bd9facf,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-1e7899da-fe4a-445a-a318-ac5f6f0d9150,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-cd1566db-1186-452a-be8b-fa65504998d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-cd655524-19d4-4c75-be46-f1020ba9afd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-71efb61c-6c88-4c69-8d07-2bcf6c5dbaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-e5e8f33a-404a-44c7-9d19-63e0a7c4b8a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91014052-172.17.0.3-1595697185046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34614,DS-3ee6b8ce-9995-4b89-92b4-42f9cd87f8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-330d64d6-d56c-42fc-a378-47d3d2669ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-88e96648-226b-4eba-a261-fa7b2bd9facf,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-1e7899da-fe4a-445a-a318-ac5f6f0d9150,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-cd1566db-1186-452a-be8b-fa65504998d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-cd655524-19d4-4c75-be46-f1020ba9afd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-71efb61c-6c88-4c69-8d07-2bcf6c5dbaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-e5e8f33a-404a-44c7-9d19-63e0a7c4b8a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037616860-172.17.0.3-1595697247211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38324,DS-1875fcbb-2095-4e17-bf13-bd51b08574e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-73b4564d-32b9-40be-903b-d2c747769460,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-e806c1ae-422a-40b6-a097-dac94c4de9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-d2487aca-3853-499c-ae9d-deadf0f908f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-fabdba76-8099-4ff0-85ef-3cd448cb77f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-eefc1cc9-d5b4-46d6-81cc-0e3a19149d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-3a0234a6-4273-4cc6-bd7c-3f278249626a,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-667679af-71c7-4454-becb-b7f47dbacd21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037616860-172.17.0.3-1595697247211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38324,DS-1875fcbb-2095-4e17-bf13-bd51b08574e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-73b4564d-32b9-40be-903b-d2c747769460,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-e806c1ae-422a-40b6-a097-dac94c4de9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-d2487aca-3853-499c-ae9d-deadf0f908f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-fabdba76-8099-4ff0-85ef-3cd448cb77f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-eefc1cc9-d5b4-46d6-81cc-0e3a19149d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-3a0234a6-4273-4cc6-bd7c-3f278249626a,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-667679af-71c7-4454-becb-b7f47dbacd21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876634534-172.17.0.3-1595697279739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-4c1b3096-5642-42dc-9c58-08375d6732da,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-176d0fe7-05c1-4a0b-850e-d00106c17147,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-adaedf80-c6f4-4946-8db3-982cde5afe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-bb4c5609-b691-4e74-94f3-81aa20acc516,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-4189c7a7-c7fb-4dc0-a40d-7cd4f8967ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-0dbb2674-cb5f-4303-8a46-7a205065b6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-c1b84cfb-d44b-48ae-98b8-9fccd259e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-3f864c47-8733-4aa4-a560-c3b0f8a704e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876634534-172.17.0.3-1595697279739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-4c1b3096-5642-42dc-9c58-08375d6732da,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-176d0fe7-05c1-4a0b-850e-d00106c17147,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-adaedf80-c6f4-4946-8db3-982cde5afe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-bb4c5609-b691-4e74-94f3-81aa20acc516,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-4189c7a7-c7fb-4dc0-a40d-7cd4f8967ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-0dbb2674-cb5f-4303-8a46-7a205065b6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-c1b84cfb-d44b-48ae-98b8-9fccd259e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-3f864c47-8733-4aa4-a560-c3b0f8a704e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963272761-172.17.0.3-1595697746808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39685,DS-c19590aa-bf6c-4f04-a69c-40339ee2ddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-8fd4458d-c4a8-4a8b-9228-81c031d0af30,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-49bee3eb-8bdc-45ca-a5fb-d2e67d3dbc38,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-a7d6e982-bf15-4009-89d6-4764607aa2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-e0f1b5c1-eb06-46d0-b020-da77cb9d6ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-1408823c-71e4-4e96-986e-d096e963e3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-f87a7c00-7900-42eb-80a0-e3a324061bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-af128625-ff9f-4598-a2b7-37114e891690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963272761-172.17.0.3-1595697746808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39685,DS-c19590aa-bf6c-4f04-a69c-40339ee2ddfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-8fd4458d-c4a8-4a8b-9228-81c031d0af30,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-49bee3eb-8bdc-45ca-a5fb-d2e67d3dbc38,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-a7d6e982-bf15-4009-89d6-4764607aa2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-e0f1b5c1-eb06-46d0-b020-da77cb9d6ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-1408823c-71e4-4e96-986e-d096e963e3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-f87a7c00-7900-42eb-80a0-e3a324061bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-af128625-ff9f-4598-a2b7-37114e891690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904769032-172.17.0.3-1595698328590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36408,DS-6ab23adc-17c7-4596-9920-22dc677f55fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-f4129e47-ca3f-439f-8097-712f1297f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-a5da3172-d592-4a21-b4f7-4ecb8c730027,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-f304cfc8-57ab-4ee5-b07e-1538df576909,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-c16f17b8-bf30-412d-a60d-c90aa13f2920,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-f6008847-aa51-4243-89c0-de311fadd6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-d70ac1a9-f19e-4461-bfe6-327cb2cc2731,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-c080b225-14ce-4700-8ad4-366316965e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904769032-172.17.0.3-1595698328590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36408,DS-6ab23adc-17c7-4596-9920-22dc677f55fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-f4129e47-ca3f-439f-8097-712f1297f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-a5da3172-d592-4a21-b4f7-4ecb8c730027,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-f304cfc8-57ab-4ee5-b07e-1538df576909,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-c16f17b8-bf30-412d-a60d-c90aa13f2920,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-f6008847-aa51-4243-89c0-de311fadd6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-d70ac1a9-f19e-4461-bfe6-327cb2cc2731,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-c080b225-14ce-4700-8ad4-366316965e02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577676004-172.17.0.3-1595698588265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-de1e88d5-7f08-48b9-9c96-adc8d59a2156,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-ba99829c-5428-4722-b8e3-afd2573dc1da,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-b10e6a15-bdaf-4df7-970e-967f3c7d5442,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-ea204674-72a3-4cfb-84e8-7d0fcf556a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-5b5f7fc0-7303-4d10-8b35-683d038a8826,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-989fcfee-589f-4b61-9efe-bd6a04c4feda,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-1eefe65f-1eab-496c-9a44-fc44e0876bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-aa407952-5a24-4e9e-9e0e-eda6bad39d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577676004-172.17.0.3-1595698588265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-de1e88d5-7f08-48b9-9c96-adc8d59a2156,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-ba99829c-5428-4722-b8e3-afd2573dc1da,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-b10e6a15-bdaf-4df7-970e-967f3c7d5442,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-ea204674-72a3-4cfb-84e8-7d0fcf556a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-5b5f7fc0-7303-4d10-8b35-683d038a8826,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-989fcfee-589f-4b61-9efe-bd6a04c4feda,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-1eefe65f-1eab-496c-9a44-fc44e0876bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-aa407952-5a24-4e9e-9e0e-eda6bad39d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408466894-172.17.0.3-1595699235157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35521,DS-ffdc20bd-b133-4138-ba0e-7484ebfe560d,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-43b12162-79a2-41ad-849c-2215fe70d400,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-ffd25539-8f4c-4e6e-be29-09bdb5e6567b,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-297e8690-4092-4e73-ac76-d990f1a772a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-43c66537-d903-4a55-adfe-bac7fda11633,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-01c0e6bc-d8bf-4045-b613-d5182d01160a,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-73ae905f-9171-446b-b56a-8cf42a1a6d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-2e9238fa-8b29-4fba-a26b-3ba1fd79cdb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408466894-172.17.0.3-1595699235157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35521,DS-ffdc20bd-b133-4138-ba0e-7484ebfe560d,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-43b12162-79a2-41ad-849c-2215fe70d400,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-ffd25539-8f4c-4e6e-be29-09bdb5e6567b,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-297e8690-4092-4e73-ac76-d990f1a772a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-43c66537-d903-4a55-adfe-bac7fda11633,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-01c0e6bc-d8bf-4045-b613-d5182d01160a,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-73ae905f-9171-446b-b56a-8cf42a1a6d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-2e9238fa-8b29-4fba-a26b-3ba1fd79cdb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582133627-172.17.0.3-1595699673984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-9e27cc7b-ffcd-442d-8ce3-cbefe1c1c2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-3bb2f4b4-0298-47a6-9ea6-651363f6955f,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-29074e04-7385-4229-8d9e-aa93c8dcd06d,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-635e7107-4746-4dfc-ba28-c75763d769e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-bf28468a-00be-44d9-aa8e-a7c31c2f3704,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-81afd436-fafd-4f25-a721-288d4c78751f,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-a3d62893-80f4-4803-a8ba-dcd9d59e5f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-a6fe5488-427f-443d-87df-718c3ff45bf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-582133627-172.17.0.3-1595699673984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-9e27cc7b-ffcd-442d-8ce3-cbefe1c1c2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-3bb2f4b4-0298-47a6-9ea6-651363f6955f,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-29074e04-7385-4229-8d9e-aa93c8dcd06d,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-635e7107-4746-4dfc-ba28-c75763d769e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-bf28468a-00be-44d9-aa8e-a7c31c2f3704,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-81afd436-fafd-4f25-a721-288d4c78751f,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-a3d62893-80f4-4803-a8ba-dcd9d59e5f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-a6fe5488-427f-443d-87df-718c3ff45bf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475477887-172.17.0.3-1595699775929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38754,DS-eccd08e8-3e98-4bbe-bd58-6f275b8c86a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-3cb55aa8-4336-4771-9843-3e4961b8018c,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-2a2c04dc-72b8-4f17-9d09-438c297c6765,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-f4e37736-0153-420d-a725-0ac3ef4d7f59,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-8247cd47-d98f-4f27-b61b-ce31e35db696,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-4f09fd52-2f52-4d10-8225-8af44c708253,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-c76139a8-1d56-41bc-b672-2622618d7a30,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-89e641e1-08d1-445e-8abc-d3833414c1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475477887-172.17.0.3-1595699775929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38754,DS-eccd08e8-3e98-4bbe-bd58-6f275b8c86a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-3cb55aa8-4336-4771-9843-3e4961b8018c,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-2a2c04dc-72b8-4f17-9d09-438c297c6765,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-f4e37736-0153-420d-a725-0ac3ef4d7f59,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-8247cd47-d98f-4f27-b61b-ce31e35db696,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-4f09fd52-2f52-4d10-8225-8af44c708253,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-c76139a8-1d56-41bc-b672-2622618d7a30,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-89e641e1-08d1-445e-8abc-d3833414c1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546749657-172.17.0.3-1595699976762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-a385b4df-1464-40c7-8797-6dda38dc50e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-553b92a6-6ab1-4194-9f4a-ef2217a4d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-6b7144dc-1bda-41aa-8cc9-7ccaf2dd5731,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-64facf88-5e1f-4383-aaed-847c3a82bbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-7cb86cd2-f39c-4e54-b4d7-bfd839662261,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-c414243d-8f67-40ad-b997-bd1b9e6acb42,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-2621c865-c2a6-42a1-9e9d-4fcc8a364003,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-a551476e-d0d7-495a-aba4-c8b491635d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546749657-172.17.0.3-1595699976762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-a385b4df-1464-40c7-8797-6dda38dc50e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-553b92a6-6ab1-4194-9f4a-ef2217a4d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-6b7144dc-1bda-41aa-8cc9-7ccaf2dd5731,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-64facf88-5e1f-4383-aaed-847c3a82bbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-7cb86cd2-f39c-4e54-b4d7-bfd839662261,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-c414243d-8f67-40ad-b997-bd1b9e6acb42,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-2621c865-c2a6-42a1-9e9d-4fcc8a364003,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-a551476e-d0d7-495a-aba4-c8b491635d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.checkpoints.retained
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845726296-172.17.0.3-1595700291139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44932,DS-9fbb24f9-aa0b-448f-8da9-8c5ac1c756af,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-834579f6-3b13-46aa-a418-577476752154,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-868a06d5-3660-40a3-9342-755ca49e2c09,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-e3abf00b-e9d0-4b46-8a2c-fe4cc4c5e964,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-f69ad27f-9855-49de-bfcd-76957a093130,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-e8d9ae37-a3bf-486f-b1f6-431985651327,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-43b0054a-dd8d-4167-be48-d9f548f85314,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-8dfd0117-00f9-4d51-9175-a9b5e582eea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845726296-172.17.0.3-1595700291139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44932,DS-9fbb24f9-aa0b-448f-8da9-8c5ac1c756af,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-834579f6-3b13-46aa-a418-577476752154,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-868a06d5-3660-40a3-9342-755ca49e2c09,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-e3abf00b-e9d0-4b46-8a2c-fe4cc4c5e964,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-f69ad27f-9855-49de-bfcd-76957a093130,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-e8d9ae37-a3bf-486f-b1f6-431985651327,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-43b0054a-dd8d-4167-be48-d9f548f85314,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-8dfd0117-00f9-4d51-9175-a9b5e582eea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5350
