reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143613546-172.17.0.8-1595583602239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40407,DS-c2be77bb-8b9f-4f91-9710-0b1af010f59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-50683037-6b16-430a-84c2-30d9a3275cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-9456b18c-b191-4028-bd4c-db1894ce9334,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-475192f2-35d5-4445-8bc3-1641d70c5530,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-3c36fe81-6b95-4217-91d3-4c88919d2019,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-cfa9e93b-42b4-491a-8e20-ab9cf52e99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-6caa1ce1-5db7-429d-8ea3-1faec868a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-c9f16ce2-e7a2-4eff-a443-0864aba58480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143613546-172.17.0.8-1595583602239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40407,DS-c2be77bb-8b9f-4f91-9710-0b1af010f59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-50683037-6b16-430a-84c2-30d9a3275cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-9456b18c-b191-4028-bd4c-db1894ce9334,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-475192f2-35d5-4445-8bc3-1641d70c5530,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-3c36fe81-6b95-4217-91d3-4c88919d2019,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-cfa9e93b-42b4-491a-8e20-ab9cf52e99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-6caa1ce1-5db7-429d-8ea3-1faec868a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-c9f16ce2-e7a2-4eff-a443-0864aba58480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273921536-172.17.0.8-1595584102808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-c972dcff-e6f8-4228-99f4-8d05bbaed553,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-9317fefb-9eae-4d41-a5c4-56228f35957d,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-a23869c3-8d68-45a6-bac0-dab01c46b888,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-612fba40-c450-4f1e-859a-3da04cdde3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-ae296f4f-2c65-4986-b083-a05f89e47d18,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-e99e5bfa-a8bf-4054-96be-74d1e0403d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-d1b3ad00-3a21-45d1-b8da-fa22de702864,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-01ec3408-3c93-4306-9285-08971e36fae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273921536-172.17.0.8-1595584102808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-c972dcff-e6f8-4228-99f4-8d05bbaed553,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-9317fefb-9eae-4d41-a5c4-56228f35957d,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-a23869c3-8d68-45a6-bac0-dab01c46b888,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-612fba40-c450-4f1e-859a-3da04cdde3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-ae296f4f-2c65-4986-b083-a05f89e47d18,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-e99e5bfa-a8bf-4054-96be-74d1e0403d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-d1b3ad00-3a21-45d1-b8da-fa22de702864,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-01ec3408-3c93-4306-9285-08971e36fae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477693684-172.17.0.8-1595584207066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-d72bd1e6-1ec2-4790-8c97-1fa2ef01bc09,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-5c1e3eee-dbc4-4ae3-a76d-e00cd750fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-f2fb83a3-fac9-4c02-a7ad-726127a43e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-a71661ac-d855-4481-a966-85d96773a607,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-3bbf70a6-222e-46fb-a3ac-353e3eaf557f,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-66bb643c-431d-480d-87fa-9f68fd3624e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-cc945392-7a6d-43a8-a4c3-34f8d517639f,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-33820b24-aaa3-4078-a8bf-97a5c0377188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477693684-172.17.0.8-1595584207066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-d72bd1e6-1ec2-4790-8c97-1fa2ef01bc09,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-5c1e3eee-dbc4-4ae3-a76d-e00cd750fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-f2fb83a3-fac9-4c02-a7ad-726127a43e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-a71661ac-d855-4481-a966-85d96773a607,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-3bbf70a6-222e-46fb-a3ac-353e3eaf557f,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-66bb643c-431d-480d-87fa-9f68fd3624e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-cc945392-7a6d-43a8-a4c3-34f8d517639f,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-33820b24-aaa3-4078-a8bf-97a5c0377188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755718636-172.17.0.8-1595584661164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-ee213744-8421-456a-ad27-b0dadee34bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-8e8cca5c-6b2f-4419-b391-f073b04f97ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-753ab743-47c4-4155-94bb-79a544ff7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-157990a7-8773-4837-bd80-4f8c6ff81ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-a040400a-1975-46b1-b358-b54e91bd912b,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-520e0729-bc1e-452d-b839-baa1ab14319d,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-2e73678a-e71a-4141-becc-47bbd2233921,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-89d3307c-67ff-45cd-9efc-7a1c42604225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755718636-172.17.0.8-1595584661164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-ee213744-8421-456a-ad27-b0dadee34bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-8e8cca5c-6b2f-4419-b391-f073b04f97ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-753ab743-47c4-4155-94bb-79a544ff7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-157990a7-8773-4837-bd80-4f8c6ff81ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-a040400a-1975-46b1-b358-b54e91bd912b,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-520e0729-bc1e-452d-b839-baa1ab14319d,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-2e73678a-e71a-4141-becc-47bbd2233921,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-89d3307c-67ff-45cd-9efc-7a1c42604225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744197272-172.17.0.8-1595584855157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44347,DS-afd3205d-346e-4bb5-b421-0374b5583b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-4912a462-2891-408e-b16a-60be4cf5efae,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-8b30e9c9-a235-49c9-9700-3dd47bf33237,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-fb853cd8-b0ac-4c19-b8a7-30632b5aefab,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-762f99c6-9d77-4f40-9d64-e95c294628b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-9ffe8f20-ebbc-4f30-9ab5-798c057f27a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-fe45bb1c-23e1-4e8e-96ea-0c8f08614e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-61fe7d68-cd2e-47ad-8807-4f74aa4bf05a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744197272-172.17.0.8-1595584855157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44347,DS-afd3205d-346e-4bb5-b421-0374b5583b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-4912a462-2891-408e-b16a-60be4cf5efae,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-8b30e9c9-a235-49c9-9700-3dd47bf33237,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-fb853cd8-b0ac-4c19-b8a7-30632b5aefab,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-762f99c6-9d77-4f40-9d64-e95c294628b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-9ffe8f20-ebbc-4f30-9ab5-798c057f27a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-fe45bb1c-23e1-4e8e-96ea-0c8f08614e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-61fe7d68-cd2e-47ad-8807-4f74aa4bf05a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643508010-172.17.0.8-1595585616694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44718,DS-e919cc4e-0f3d-42f6-aa2a-f3de2203aef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-591597b2-110b-45f4-ba8c-ebe13c97b793,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-367bc9d5-5700-4618-9d70-bf44545cdd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-63564ba9-f0b3-4a72-805b-0ab5f25cebbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-7d29f1c5-313a-4dfb-ae88-f23e875ce3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-31fbca61-dd7d-494f-85fb-2cca4753b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-ed3c6ba6-1c2a-495a-b2b4-1398f3200a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-e14aac85-282e-4568-9dae-7b030ec77508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643508010-172.17.0.8-1595585616694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44718,DS-e919cc4e-0f3d-42f6-aa2a-f3de2203aef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-591597b2-110b-45f4-ba8c-ebe13c97b793,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-367bc9d5-5700-4618-9d70-bf44545cdd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-63564ba9-f0b3-4a72-805b-0ab5f25cebbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-7d29f1c5-313a-4dfb-ae88-f23e875ce3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-31fbca61-dd7d-494f-85fb-2cca4753b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-ed3c6ba6-1c2a-495a-b2b4-1398f3200a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-e14aac85-282e-4568-9dae-7b030ec77508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31078647-172.17.0.8-1595585724968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41259,DS-6f53aa94-7a80-49a0-bc87-73bd92bff252,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-3434e6fc-cf6f-4676-a496-01f2750feef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-2d94e2b0-8a13-4749-8039-87d4ba3cb911,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-e432fe2d-7465-48d5-9d83-506def403738,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-8affa83f-236f-45e1-a6c1-6d112c70556e,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-e076b732-5a29-4712-9c73-154a919fa8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-4ffcaefc-a034-43c9-b7af-eca7228bdd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-12416ba1-6ddd-4e6a-9696-2e76b7440f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31078647-172.17.0.8-1595585724968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41259,DS-6f53aa94-7a80-49a0-bc87-73bd92bff252,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-3434e6fc-cf6f-4676-a496-01f2750feef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-2d94e2b0-8a13-4749-8039-87d4ba3cb911,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-e432fe2d-7465-48d5-9d83-506def403738,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-8affa83f-236f-45e1-a6c1-6d112c70556e,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-e076b732-5a29-4712-9c73-154a919fa8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-4ffcaefc-a034-43c9-b7af-eca7228bdd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-12416ba1-6ddd-4e6a-9696-2e76b7440f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973119409-172.17.0.8-1595586256101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33953,DS-41caa4ac-785b-41ae-8373-5fe3d66a4d59,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-0d6d519a-5a08-4c1b-b93e-b890e9d85e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-b654355d-61f2-4576-88b0-53e387070449,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-70f24b4f-f674-4aed-897b-120149ce1ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-b5306316-1758-4d58-a826-7ad3be136f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-3e4fc755-0942-4a5e-8229-438aa8fcb794,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-a8376b54-8823-4523-aa55-bd471e958c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-4d0ae9c4-a6a6-42ac-8393-15255630f88a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973119409-172.17.0.8-1595586256101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33953,DS-41caa4ac-785b-41ae-8373-5fe3d66a4d59,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-0d6d519a-5a08-4c1b-b93e-b890e9d85e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-b654355d-61f2-4576-88b0-53e387070449,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-70f24b4f-f674-4aed-897b-120149ce1ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-b5306316-1758-4d58-a826-7ad3be136f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-3e4fc755-0942-4a5e-8229-438aa8fcb794,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-a8376b54-8823-4523-aa55-bd471e958c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-4d0ae9c4-a6a6-42ac-8393-15255630f88a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199715675-172.17.0.8-1595586293351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44885,DS-37d66690-c023-40b0-b817-6711081b8830,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-1f998083-b9c0-4cfe-9fc1-35907acd0032,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-1fdff4ea-bb83-4151-aa87-f4cfaea49467,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-6e597891-3de0-45f8-ab7e-6a1c08184021,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-21cb7aaf-b745-4ca2-9805-7f9a33ae05ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-dd09df2d-03ac-41ee-b224-41040f4f46a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-164d7239-eef6-42a6-a9e4-794ae1960187,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-262e2a9b-445e-4967-b3b2-940fea8e64e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199715675-172.17.0.8-1595586293351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44885,DS-37d66690-c023-40b0-b817-6711081b8830,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-1f998083-b9c0-4cfe-9fc1-35907acd0032,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-1fdff4ea-bb83-4151-aa87-f4cfaea49467,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-6e597891-3de0-45f8-ab7e-6a1c08184021,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-21cb7aaf-b745-4ca2-9805-7f9a33ae05ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-dd09df2d-03ac-41ee-b224-41040f4f46a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-164d7239-eef6-42a6-a9e4-794ae1960187,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-262e2a9b-445e-4967-b3b2-940fea8e64e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22236677-172.17.0.8-1595586372689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36878,DS-38bae0f4-e209-476c-9a45-277a93832670,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-2397ffa7-06d1-4ba2-8acc-af827784bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-3359b715-7aad-4a6b-b7ce-c5867b613128,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-bb13c99f-8887-475c-be47-3a68205368ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-ad2648a9-5e8b-4e2b-a077-65b5cfd28dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-aa6d92c6-7f83-4e91-a589-37ed1fd4907c,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-526b639b-6a36-448d-b7e1-1cd516878805,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-eab40997-c2dc-42d8-a8b7-2f7d1fe88244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22236677-172.17.0.8-1595586372689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36878,DS-38bae0f4-e209-476c-9a45-277a93832670,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-2397ffa7-06d1-4ba2-8acc-af827784bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-3359b715-7aad-4a6b-b7ce-c5867b613128,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-bb13c99f-8887-475c-be47-3a68205368ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-ad2648a9-5e8b-4e2b-a077-65b5cfd28dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-aa6d92c6-7f83-4e91-a589-37ed1fd4907c,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-526b639b-6a36-448d-b7e1-1cd516878805,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-eab40997-c2dc-42d8-a8b7-2f7d1fe88244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528355502-172.17.0.8-1595587077260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-e077266a-c7aa-4d81-9edc-38d4b64db615,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-381d4251-9357-45ed-af7d-f8a5089ed538,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-81df4860-15a7-4202-99ab-e3d7a566e953,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-faf1364d-3a18-492b-8671-4abfc0d6db50,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-b5797321-bf96-41a8-b011-c2d37f0f768d,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-95f8239d-eb17-4b68-b247-c4e3a5644b91,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-a6c728bb-fb2b-4e3f-a669-4b7da816efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-b0a77360-0151-4d3f-9f45-1da61927ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528355502-172.17.0.8-1595587077260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-e077266a-c7aa-4d81-9edc-38d4b64db615,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-381d4251-9357-45ed-af7d-f8a5089ed538,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-81df4860-15a7-4202-99ab-e3d7a566e953,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-faf1364d-3a18-492b-8671-4abfc0d6db50,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-b5797321-bf96-41a8-b011-c2d37f0f768d,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-95f8239d-eb17-4b68-b247-c4e3a5644b91,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-a6c728bb-fb2b-4e3f-a669-4b7da816efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-b0a77360-0151-4d3f-9f45-1da61927ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575556344-172.17.0.8-1595587732231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-81fa79f4-4a11-4fd4-9fb6-69ecff12586d,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-92576763-aad7-40b5-86f6-9d0cc8a4cdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-dc634803-a19c-4059-8f4d-fc35bc6d305f,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-8efda78d-bad0-45df-aa82-60d9662c66de,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-666f32ad-f39e-43e2-b825-56fd3a0b8701,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-dbb5b4ee-9c01-4091-a6c7-8cc6c4dce7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-07d68da7-5e08-4ea7-aa82-dbbd47abced7,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-9db30236-81c8-4dd8-b7e5-4705865c3b9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575556344-172.17.0.8-1595587732231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-81fa79f4-4a11-4fd4-9fb6-69ecff12586d,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-92576763-aad7-40b5-86f6-9d0cc8a4cdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-dc634803-a19c-4059-8f4d-fc35bc6d305f,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-8efda78d-bad0-45df-aa82-60d9662c66de,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-666f32ad-f39e-43e2-b825-56fd3a0b8701,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-dbb5b4ee-9c01-4091-a6c7-8cc6c4dce7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-07d68da7-5e08-4ea7-aa82-dbbd47abced7,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-9db30236-81c8-4dd8-b7e5-4705865c3b9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876683506-172.17.0.8-1595588009172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42913,DS-e8d142a2-a582-45a5-b424-dada66cda8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-e94b2fb6-b966-4b63-9ac6-63cae8125c99,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-34079a26-d2bb-40fb-a892-434873c8199d,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-a917650f-7618-4841-aa99-551039b0af1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-487fdb58-59d2-4a4d-a2a0-f6754905397d,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-70a209f8-3c93-4477-b725-b2746ab5c40b,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-d22c9173-336c-4027-94f1-96e285914ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-17f8085a-8b36-48f3-b92c-b5329759f21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876683506-172.17.0.8-1595588009172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42913,DS-e8d142a2-a582-45a5-b424-dada66cda8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-e94b2fb6-b966-4b63-9ac6-63cae8125c99,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-34079a26-d2bb-40fb-a892-434873c8199d,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-a917650f-7618-4841-aa99-551039b0af1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-487fdb58-59d2-4a4d-a2a0-f6754905397d,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-70a209f8-3c93-4477-b725-b2746ab5c40b,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-d22c9173-336c-4027-94f1-96e285914ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-17f8085a-8b36-48f3-b92c-b5329759f21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5422
