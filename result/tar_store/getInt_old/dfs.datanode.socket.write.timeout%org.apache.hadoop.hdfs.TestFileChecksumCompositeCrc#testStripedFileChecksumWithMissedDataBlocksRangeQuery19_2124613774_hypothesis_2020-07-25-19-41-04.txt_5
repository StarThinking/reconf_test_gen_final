reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280651212-172.17.0.4-1595706534001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-94e3b4f5-cb69-4c8b-99ef-e05e69bb0d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-23cae2d1-efe0-417f-966a-d39dc67bc742,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-1795f390-0528-46e0-8e5e-080c00db9982,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-8a11403e-fd50-4a80-b20d-d40d7d99b267,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-2d750f46-a080-4713-a459-ec0b2d580d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-26914a03-6eb2-45c6-82e4-533580ea3466,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-372187cd-992e-4834-85ea-3bec9de7206b,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-0ea6191d-ad88-48ff-9098-9221aa9d6c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280651212-172.17.0.4-1595706534001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-94e3b4f5-cb69-4c8b-99ef-e05e69bb0d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-23cae2d1-efe0-417f-966a-d39dc67bc742,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-1795f390-0528-46e0-8e5e-080c00db9982,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-8a11403e-fd50-4a80-b20d-d40d7d99b267,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-2d750f46-a080-4713-a459-ec0b2d580d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-26914a03-6eb2-45c6-82e4-533580ea3466,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-372187cd-992e-4834-85ea-3bec9de7206b,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-0ea6191d-ad88-48ff-9098-9221aa9d6c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350831829-172.17.0.4-1595706564107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-5c19e4b8-bdd9-4a56-9954-3d6263e7e473,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-593ef63f-75de-44d3-9e1e-0f58ba049377,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-9ce1a436-e516-4907-8949-dd872c8b11d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-6fee2b13-6db6-4ded-a19a-9acefac5cd27,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-5fcb2d16-c01f-4ad2-9d37-13fe1a52539f,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-95d2dcc6-bf29-4576-bc86-7b9903421757,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-bc76ec14-7b8e-41f3-9927-7e5cabfb4473,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-e95b9ba2-4001-4227-a8da-98835a294223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350831829-172.17.0.4-1595706564107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-5c19e4b8-bdd9-4a56-9954-3d6263e7e473,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-593ef63f-75de-44d3-9e1e-0f58ba049377,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-9ce1a436-e516-4907-8949-dd872c8b11d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-6fee2b13-6db6-4ded-a19a-9acefac5cd27,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-5fcb2d16-c01f-4ad2-9d37-13fe1a52539f,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-95d2dcc6-bf29-4576-bc86-7b9903421757,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-bc76ec14-7b8e-41f3-9927-7e5cabfb4473,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-e95b9ba2-4001-4227-a8da-98835a294223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850487630-172.17.0.4-1595707049414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-7cd9a845-e300-45ec-b09d-797dff699c22,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-44f486fa-cd1f-4cf6-ab23-3600d7a42d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-9d10e4d3-a580-4ada-a4e2-cd35741b33c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-f402701a-7d3c-40ed-bb03-4cbdaa4e4c17,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-5622dbed-5ba8-4e1b-b03c-57509350ab86,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-9e9f2a9f-9645-4379-9a5f-b9a6372da2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-036c5e19-23c2-4b10-96d7-e57a23fce328,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-886ae1b9-5d05-4af4-aa1c-1c9baa232333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850487630-172.17.0.4-1595707049414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-7cd9a845-e300-45ec-b09d-797dff699c22,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-44f486fa-cd1f-4cf6-ab23-3600d7a42d08,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-9d10e4d3-a580-4ada-a4e2-cd35741b33c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-f402701a-7d3c-40ed-bb03-4cbdaa4e4c17,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-5622dbed-5ba8-4e1b-b03c-57509350ab86,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-9e9f2a9f-9645-4379-9a5f-b9a6372da2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-036c5e19-23c2-4b10-96d7-e57a23fce328,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-886ae1b9-5d05-4af4-aa1c-1c9baa232333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973274875-172.17.0.4-1595707930021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-ca207092-77c0-41d9-b2b0-95a3b2085628,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-e54f1405-116a-4af5-b57a-e4f8a6329391,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-83f6bb0b-0193-4d23-889c-3e3b8c5d50a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-56d592ea-538d-47d5-b61c-a0a1564dfe49,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-80f224e3-821e-42fb-b54e-9aa43dabc49d,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-54d5c006-da3e-4aea-a0fe-63c07cf79184,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-421d1277-abfd-423c-b31b-a9c4a93b0ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-622ed73a-d312-434f-9546-232b44d32e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973274875-172.17.0.4-1595707930021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-ca207092-77c0-41d9-b2b0-95a3b2085628,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-e54f1405-116a-4af5-b57a-e4f8a6329391,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-83f6bb0b-0193-4d23-889c-3e3b8c5d50a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-56d592ea-538d-47d5-b61c-a0a1564dfe49,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-80f224e3-821e-42fb-b54e-9aa43dabc49d,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-54d5c006-da3e-4aea-a0fe-63c07cf79184,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-421d1277-abfd-423c-b31b-a9c4a93b0ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-622ed73a-d312-434f-9546-232b44d32e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862407606-172.17.0.4-1595708245843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46807,DS-c9b04c91-2b95-4270-80b6-100334d17c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-4ac8c3b8-5c14-42fd-931f-a6b7f40db935,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-4461eab3-c480-45bf-91c3-44971ca588a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-ef24626a-35ea-4e94-bcf8-c90a956cf550,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-608add77-0895-4696-abe3-49b23d25206e,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-e236f4e7-3ef8-44b2-b330-97f569d5739e,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-100019d4-b76d-475d-9fa5-e35cc69aaed6,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-8eeb9238-0664-4760-9612-7fc77419cf5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862407606-172.17.0.4-1595708245843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46807,DS-c9b04c91-2b95-4270-80b6-100334d17c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-4ac8c3b8-5c14-42fd-931f-a6b7f40db935,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-4461eab3-c480-45bf-91c3-44971ca588a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-ef24626a-35ea-4e94-bcf8-c90a956cf550,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-608add77-0895-4696-abe3-49b23d25206e,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-e236f4e7-3ef8-44b2-b330-97f569d5739e,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-100019d4-b76d-475d-9fa5-e35cc69aaed6,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-8eeb9238-0664-4760-9612-7fc77419cf5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99064201-172.17.0.4-1595708320539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45845,DS-734ebda5-37dd-4ae3-b975-142409eca8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-92d03e4f-4772-4948-aaa7-0f86f7cb8714,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-395e51c4-9289-41d1-bc83-bb3129507426,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-d60d0e01-ab9e-4110-abf6-4e1acc791c23,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-dc08ee37-201c-4122-8d59-61ae23129542,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-10dc310e-72ed-49e1-92c1-1eae4459be05,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-4cd5a300-551c-4ce2-ba84-9ea51b7610d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-ed900eb8-cf56-40a7-ab38-9de4ee8b1260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99064201-172.17.0.4-1595708320539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45845,DS-734ebda5-37dd-4ae3-b975-142409eca8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-92d03e4f-4772-4948-aaa7-0f86f7cb8714,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-395e51c4-9289-41d1-bc83-bb3129507426,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-d60d0e01-ab9e-4110-abf6-4e1acc791c23,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-dc08ee37-201c-4122-8d59-61ae23129542,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-10dc310e-72ed-49e1-92c1-1eae4459be05,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-4cd5a300-551c-4ce2-ba84-9ea51b7610d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-ed900eb8-cf56-40a7-ab38-9de4ee8b1260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973378441-172.17.0.4-1595708528704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35976,DS-9cef9d3a-d576-4c8e-ab13-7ef216be3a14,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-6f6c3265-ed5d-42b7-a05b-3121f409d06f,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-d4dc54ca-697e-43c6-9c53-93f41b6267d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-fa0a46f8-6bb9-4802-ad33-43542c307455,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-d498eab8-1582-48bb-956b-89b10c81b83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-6fca3a97-29dd-42f3-b063-f38535a03db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-8b1d0498-c104-470d-92a5-35c8f537a99e,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-1123e78b-8ca7-4cd5-b1db-81973393e96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973378441-172.17.0.4-1595708528704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35976,DS-9cef9d3a-d576-4c8e-ab13-7ef216be3a14,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-6f6c3265-ed5d-42b7-a05b-3121f409d06f,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-d4dc54ca-697e-43c6-9c53-93f41b6267d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-fa0a46f8-6bb9-4802-ad33-43542c307455,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-d498eab8-1582-48bb-956b-89b10c81b83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-6fca3a97-29dd-42f3-b063-f38535a03db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-8b1d0498-c104-470d-92a5-35c8f537a99e,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-1123e78b-8ca7-4cd5-b1db-81973393e96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562567465-172.17.0.4-1595708634689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36518,DS-acbd06e9-bc96-404a-b5e6-979c52539009,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-99770c7f-af61-4772-9724-0936aa0eef95,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-1601990b-df01-48f8-b3bd-b9822ad24953,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-e51e2daf-2fc7-47b0-bbd5-81d164286539,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-7bda20a9-9639-4a32-89b2-853ac874f9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-7c6c374f-dd87-4206-8673-e479f3f85b66,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-f0934013-7a95-4fd1-a996-163930bf3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-0fef850a-6424-4949-9920-fbf42d7cb40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562567465-172.17.0.4-1595708634689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36518,DS-acbd06e9-bc96-404a-b5e6-979c52539009,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-99770c7f-af61-4772-9724-0936aa0eef95,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-1601990b-df01-48f8-b3bd-b9822ad24953,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-e51e2daf-2fc7-47b0-bbd5-81d164286539,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-7bda20a9-9639-4a32-89b2-853ac874f9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-7c6c374f-dd87-4206-8673-e479f3f85b66,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-f0934013-7a95-4fd1-a996-163930bf3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-0fef850a-6424-4949-9920-fbf42d7cb40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830132990-172.17.0.4-1595709480955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34033,DS-6b26de67-f38e-4d4a-9fc4-db42a264a6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-eb015b8f-060d-43ea-a359-e94ea077d73f,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-b33d546a-108a-4495-b000-618a96d51dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-d3e25eaf-62a1-41d9-9dea-0e58964de6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-672e97f8-f64a-4143-ad56-3d38aec30cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-396e3cd2-e897-4ce2-bbbe-f2ee6a10e3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-0f6a3ef9-344c-4783-b175-37a6ce1624d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-005c704b-bcf2-45d4-a61a-141eb615c968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830132990-172.17.0.4-1595709480955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34033,DS-6b26de67-f38e-4d4a-9fc4-db42a264a6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-eb015b8f-060d-43ea-a359-e94ea077d73f,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-b33d546a-108a-4495-b000-618a96d51dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-d3e25eaf-62a1-41d9-9dea-0e58964de6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-672e97f8-f64a-4143-ad56-3d38aec30cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-396e3cd2-e897-4ce2-bbbe-f2ee6a10e3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-0f6a3ef9-344c-4783-b175-37a6ce1624d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-005c704b-bcf2-45d4-a61a-141eb615c968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904785964-172.17.0.4-1595709707938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-ace18fd8-fbec-4671-89d9-8844e3dbb30e,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-ddeeadb7-cfc4-4db5-8e39-1bd6fcbe5b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-fc3fa999-95bb-4b8f-93da-7e7457dc9dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-e42239fc-8a8d-475b-913b-fe46f45de9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-91668986-5d3a-4c43-ba39-8a7ff96e40aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-5dcb26ec-e946-4595-8bbd-50f5c116e744,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-a6b2635b-8fd2-448c-bbd7-297f4d1740d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-65fd446a-04fc-4f24-bb08-1b8409be52c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904785964-172.17.0.4-1595709707938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33172,DS-ace18fd8-fbec-4671-89d9-8844e3dbb30e,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-ddeeadb7-cfc4-4db5-8e39-1bd6fcbe5b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-fc3fa999-95bb-4b8f-93da-7e7457dc9dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-e42239fc-8a8d-475b-913b-fe46f45de9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-91668986-5d3a-4c43-ba39-8a7ff96e40aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-5dcb26ec-e946-4595-8bbd-50f5c116e744,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-a6b2635b-8fd2-448c-bbd7-297f4d1740d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-65fd446a-04fc-4f24-bb08-1b8409be52c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210283968-172.17.0.4-1595710349112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33760,DS-57f123d0-6be8-455d-843c-c3490c54db2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-6d1d0c15-f3ad-49a3-868c-6cc8b249058e,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-3d15832e-5aa2-4b0b-9ce4-bf6bac32d9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-8f32a00d-8d13-4d91-b280-42520868580f,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-78c048eb-676b-42e9-ad99-40777788f8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-8b334bca-eba8-45fc-b5fc-3bf86287413c,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-68a68f10-1286-4503-ac5c-85d59ec7d9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-e64e1b79-8d11-4ac5-a9e2-b3c8d84136d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210283968-172.17.0.4-1595710349112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33760,DS-57f123d0-6be8-455d-843c-c3490c54db2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-6d1d0c15-f3ad-49a3-868c-6cc8b249058e,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-3d15832e-5aa2-4b0b-9ce4-bf6bac32d9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-8f32a00d-8d13-4d91-b280-42520868580f,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-78c048eb-676b-42e9-ad99-40777788f8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-8b334bca-eba8-45fc-b5fc-3bf86287413c,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-68a68f10-1286-4503-ac5c-85d59ec7d9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-e64e1b79-8d11-4ac5-a9e2-b3c8d84136d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 480000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631261467-172.17.0.4-1595711182930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-3d0464ec-eb51-4eb4-91d7-620b40d85285,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-58a7a7d3-c3e5-4c94-a037-295681693547,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-bb989a00-57cc-448b-8d7d-7f988b2abe3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-774e14f0-ef1e-4ab3-a7e1-088343820930,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-07b3cce8-43d1-4136-812e-7a249e53a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-e12a421e-5c74-4bc2-bdde-24e8f1ff0a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-55957d54-a45c-461d-86c9-02fd259cb1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-89ab169a-8544-4264-8a73-ff34ad1ad199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631261467-172.17.0.4-1595711182930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-3d0464ec-eb51-4eb4-91d7-620b40d85285,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-58a7a7d3-c3e5-4c94-a037-295681693547,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-bb989a00-57cc-448b-8d7d-7f988b2abe3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-774e14f0-ef1e-4ab3-a7e1-088343820930,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-07b3cce8-43d1-4136-812e-7a249e53a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-e12a421e-5c74-4bc2-bdde-24e8f1ff0a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-55957d54-a45c-461d-86c9-02fd259cb1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-89ab169a-8544-4264-8a73-ff34ad1ad199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5359
