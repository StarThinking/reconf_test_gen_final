reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013226575-172.17.0.19-1595697206774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-ccd1f335-cd5a-48c5-b81e-ac1ea91dc2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-8a569364-cb78-4c55-971e-ab1f920c9c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-a21e543e-dc8d-4ea0-861f-40fd409fdcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-da88ca11-f804-4eee-9234-2a6ee6db3241,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-32310036-a44f-44a4-89dd-92ed2279b2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-e83136a4-ef29-48d3-9102-42de99161b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-a117440c-06d4-4eea-b429-c0adcc4c3a44,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-83f652d8-a87f-4d1f-989b-b6275f3e8282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013226575-172.17.0.19-1595697206774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-ccd1f335-cd5a-48c5-b81e-ac1ea91dc2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-8a569364-cb78-4c55-971e-ab1f920c9c67,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-a21e543e-dc8d-4ea0-861f-40fd409fdcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-da88ca11-f804-4eee-9234-2a6ee6db3241,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-32310036-a44f-44a4-89dd-92ed2279b2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-e83136a4-ef29-48d3-9102-42de99161b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-a117440c-06d4-4eea-b429-c0adcc4c3a44,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-83f652d8-a87f-4d1f-989b-b6275f3e8282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191978186-172.17.0.19-1595697821257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38544,DS-fccb1a76-722c-41fd-8fca-846d40f07680,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-b7f94929-ff9b-4754-9fc7-a6399adafe18,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-9fea238d-a847-48d6-9e52-4d76c9931bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-ff10859c-6027-4f6a-b7b8-ba234c7f7b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-31f35df4-e30b-49f1-9bb3-c5a17f985c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-a8b420d7-a5e0-424f-9e67-31bd16d20a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-e3b7d32a-52fe-44cc-9868-0388cd778eea,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-9d8e8a4a-3751-4926-a6eb-abf26b12a3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191978186-172.17.0.19-1595697821257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38544,DS-fccb1a76-722c-41fd-8fca-846d40f07680,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-b7f94929-ff9b-4754-9fc7-a6399adafe18,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-9fea238d-a847-48d6-9e52-4d76c9931bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-ff10859c-6027-4f6a-b7b8-ba234c7f7b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-31f35df4-e30b-49f1-9bb3-c5a17f985c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-a8b420d7-a5e0-424f-9e67-31bd16d20a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-e3b7d32a-52fe-44cc-9868-0388cd778eea,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-9d8e8a4a-3751-4926-a6eb-abf26b12a3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916089451-172.17.0.19-1595697919448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-0787a098-1e89-4d63-b2ae-44efe961f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-17a83d1a-e3e6-480c-b520-e77e5f1ad086,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-32c01b0c-8e26-4404-b803-ae60c876e45a,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-d7adadfb-88b3-4204-8727-91ae0ba61f75,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-410eadb6-41c2-4b3c-9519-ae513ca0dc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-565fbb9c-3338-40f1-9b89-4713b48e9001,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-f1330e9b-fcb2-4b37-a3f7-885b547cc214,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-afe3e0c4-03f6-488e-94df-af020f2c3d63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916089451-172.17.0.19-1595697919448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-0787a098-1e89-4d63-b2ae-44efe961f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-17a83d1a-e3e6-480c-b520-e77e5f1ad086,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-32c01b0c-8e26-4404-b803-ae60c876e45a,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-d7adadfb-88b3-4204-8727-91ae0ba61f75,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-410eadb6-41c2-4b3c-9519-ae513ca0dc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-565fbb9c-3338-40f1-9b89-4713b48e9001,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-f1330e9b-fcb2-4b37-a3f7-885b547cc214,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-afe3e0c4-03f6-488e-94df-af020f2c3d63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593131551-172.17.0.19-1595697985393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-488d4e26-7a67-4337-ac22-1d28f3155d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-7a0adae0-046f-4e4d-8d08-c36283456edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-08ff4929-1204-4f8c-9c11-bde4275a9d60,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-87d1d93e-8e91-404e-a9aa-9695e709a992,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-ceee5ca0-0adb-466c-8f7c-ca693b52801a,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-57864044-1dbc-47d6-a145-cf6ee4dd76a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-5035527a-f17b-4a50-8b88-21394a22dff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a54fa0d2-259b-4144-9b46-17e46e10cfd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593131551-172.17.0.19-1595697985393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-488d4e26-7a67-4337-ac22-1d28f3155d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-7a0adae0-046f-4e4d-8d08-c36283456edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-08ff4929-1204-4f8c-9c11-bde4275a9d60,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-87d1d93e-8e91-404e-a9aa-9695e709a992,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-ceee5ca0-0adb-466c-8f7c-ca693b52801a,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-57864044-1dbc-47d6-a145-cf6ee4dd76a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-5035527a-f17b-4a50-8b88-21394a22dff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a54fa0d2-259b-4144-9b46-17e46e10cfd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295981967-172.17.0.19-1595698947464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33001,DS-7fe0abd1-aca8-4b35-aa98-83e031c86c45,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-9bb2c516-6d8e-4695-81fc-44390de41896,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-fe76775a-5896-4dd7-b9f8-cafb81d03cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-97df8310-ff51-4ab6-8fde-c610c6e03606,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-4dd2104c-a0c6-44e7-a8b8-3331cecaac23,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-d428c13d-d603-4894-9085-3bf7c0e5c462,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-829e8e2e-070d-4c71-bca6-308ead878e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-3e16d1ad-4502-4734-9e65-729632434c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295981967-172.17.0.19-1595698947464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33001,DS-7fe0abd1-aca8-4b35-aa98-83e031c86c45,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-9bb2c516-6d8e-4695-81fc-44390de41896,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-fe76775a-5896-4dd7-b9f8-cafb81d03cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-97df8310-ff51-4ab6-8fde-c610c6e03606,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-4dd2104c-a0c6-44e7-a8b8-3331cecaac23,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-d428c13d-d603-4894-9085-3bf7c0e5c462,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-829e8e2e-070d-4c71-bca6-308ead878e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-3e16d1ad-4502-4734-9e65-729632434c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822089813-172.17.0.19-1595699118794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-0f152a99-e557-4c2d-a470-7c025968f4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-fc86f761-c363-4e01-a6d2-c3e279aff6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-86c340e0-12d3-4f6b-a996-0c2ccc28c8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-c6d9572b-64dc-4559-9be8-1bc74b24ab03,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-391e759b-5752-4e6a-a901-ac7b2a9a60d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-017f34b3-53ea-48ff-abe9-527eb4c7dce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-9aa34f93-c03e-4ead-91c4-8b61806b5fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-219d4989-5e9c-4c95-bd31-df95bdeb5c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822089813-172.17.0.19-1595699118794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-0f152a99-e557-4c2d-a470-7c025968f4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-fc86f761-c363-4e01-a6d2-c3e279aff6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-86c340e0-12d3-4f6b-a996-0c2ccc28c8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-c6d9572b-64dc-4559-9be8-1bc74b24ab03,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-391e759b-5752-4e6a-a901-ac7b2a9a60d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-017f34b3-53ea-48ff-abe9-527eb4c7dce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-9aa34f93-c03e-4ead-91c4-8b61806b5fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-219d4989-5e9c-4c95-bd31-df95bdeb5c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532041395-172.17.0.19-1595699322862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-2bf7813d-0e40-4be9-b873-90c495eeed07,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-96e97ec2-e8b3-46c6-b098-df3c1f2f258f,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-3c786365-a701-4122-87fa-b774133c2ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-afa5d511-89b9-4cd0-9c88-2c2b0c6cfa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-be9f534f-b0a6-49da-93c4-43c9b61c92b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-bf727193-2c66-4dc5-823f-0886ae338885,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-43491345-e38a-4aff-b251-19c714e136af,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-55ec84d8-0799-42f9-8ba2-4fb625e0d16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532041395-172.17.0.19-1595699322862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-2bf7813d-0e40-4be9-b873-90c495eeed07,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-96e97ec2-e8b3-46c6-b098-df3c1f2f258f,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-3c786365-a701-4122-87fa-b774133c2ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-afa5d511-89b9-4cd0-9c88-2c2b0c6cfa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-be9f534f-b0a6-49da-93c4-43c9b61c92b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-bf727193-2c66-4dc5-823f-0886ae338885,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-43491345-e38a-4aff-b251-19c714e136af,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-55ec84d8-0799-42f9-8ba2-4fb625e0d16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220561827-172.17.0.19-1595699514531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39728,DS-06ed92d3-0e9a-498c-a2f7-08e972073703,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-eb24ca53-a760-4674-9a65-4f5147fad14c,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-e302b0a4-3f4f-4e7d-9c96-9eea9e02ce47,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-0dd534ec-3e9d-4b14-b11c-c5762723e37e,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-86ea7f34-7840-4bb5-97cc-af5c4d7eacbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-91ef45f7-6c79-4832-b6cc-fd1e0ad22b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-1b20e4c5-7546-4e4b-a0d4-944307f14ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-888da2e0-4046-4eb8-bc0d-3ea258b47359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220561827-172.17.0.19-1595699514531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39728,DS-06ed92d3-0e9a-498c-a2f7-08e972073703,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-eb24ca53-a760-4674-9a65-4f5147fad14c,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-e302b0a4-3f4f-4e7d-9c96-9eea9e02ce47,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-0dd534ec-3e9d-4b14-b11c-c5762723e37e,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-86ea7f34-7840-4bb5-97cc-af5c4d7eacbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-91ef45f7-6c79-4832-b6cc-fd1e0ad22b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-1b20e4c5-7546-4e4b-a0d4-944307f14ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-888da2e0-4046-4eb8-bc0d-3ea258b47359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966359592-172.17.0.19-1595699660972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46237,DS-0b5de1ce-4685-4e62-a676-dd381bbb1096,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-3490dd83-c662-48ec-983d-62be4a9a88c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-31c338aa-b696-4148-ab36-6c78fa073fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-bd3fae3e-1300-41a1-9a8f-248dec3e94cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-982774bb-6ce9-44af-9a12-c0d04e0ac479,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-132d85b1-f4f5-4a3f-b436-ee5690feb16f,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-3950659a-e445-4bf6-994e-089441f4104f,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-4390c0b6-c478-46dd-a2aa-9031b1a794ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966359592-172.17.0.19-1595699660972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46237,DS-0b5de1ce-4685-4e62-a676-dd381bbb1096,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-3490dd83-c662-48ec-983d-62be4a9a88c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-31c338aa-b696-4148-ab36-6c78fa073fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-bd3fae3e-1300-41a1-9a8f-248dec3e94cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-982774bb-6ce9-44af-9a12-c0d04e0ac479,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-132d85b1-f4f5-4a3f-b436-ee5690feb16f,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-3950659a-e445-4bf6-994e-089441f4104f,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-4390c0b6-c478-46dd-a2aa-9031b1a794ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277927087-172.17.0.19-1595699803431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41908,DS-678cdfda-1288-4e42-9bef-f9e376dd8495,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-a84639e6-af4d-40da-828c-923f9f7577ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-608e3f61-3b85-42ca-b714-c7da7df06c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-98be7e91-18d9-4d9c-b18c-219133cf60a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-be968175-a3c1-4560-af51-31298e0bb6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-9dab4a26-e3b7-4d87-ad5f-14a51b7c3f21,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-8482319b-8ba9-4266-ba3a-aad28536195f,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-fbc2d142-e14a-41f8-804e-e864e40f4453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277927087-172.17.0.19-1595699803431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41908,DS-678cdfda-1288-4e42-9bef-f9e376dd8495,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-a84639e6-af4d-40da-828c-923f9f7577ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-608e3f61-3b85-42ca-b714-c7da7df06c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-98be7e91-18d9-4d9c-b18c-219133cf60a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-be968175-a3c1-4560-af51-31298e0bb6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-9dab4a26-e3b7-4d87-ad5f-14a51b7c3f21,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-8482319b-8ba9-4266-ba3a-aad28536195f,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-fbc2d142-e14a-41f8-804e-e864e40f4453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753604420-172.17.0.19-1595700178466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39651,DS-b6c5211b-50f1-4057-93ca-024699221680,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-d8193194-d6a1-421e-a0da-dedd90fda54a,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-95d9dd8d-329c-474c-a160-699574357c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-85edc511-50f6-404f-bb30-1279475f1299,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-462c4ac2-aadf-4d18-9cf8-52f98b5aabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-291be775-cf67-418d-baf0-9da44fd31aad,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-33a58888-adcc-49cb-9b02-8741cf923828,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-80dc5f0f-8846-4dbc-846d-ea5b48a959a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753604420-172.17.0.19-1595700178466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39651,DS-b6c5211b-50f1-4057-93ca-024699221680,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-d8193194-d6a1-421e-a0da-dedd90fda54a,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-95d9dd8d-329c-474c-a160-699574357c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-85edc511-50f6-404f-bb30-1279475f1299,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-462c4ac2-aadf-4d18-9cf8-52f98b5aabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-291be775-cf67-418d-baf0-9da44fd31aad,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-33a58888-adcc-49cb-9b02-8741cf923828,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-80dc5f0f-8846-4dbc-846d-ea5b48a959a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578783737-172.17.0.19-1595700356601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44133,DS-dc53df17-aa75-4fa5-b71c-bbb5805bddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-08ab10a2-7591-4cc4-9beb-a22777281596,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-779bd4ef-0dd8-4d25-8b01-43584cb94380,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-685fd214-3ad9-4352-ab0f-ab7e32a5fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-472286f1-a546-4d23-9ba0-1e336717590f,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-6f71026c-01e7-4268-9f9a-b5c8bca9dfae,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-1e48f09a-665a-43ed-b183-ef8e05c2603c,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-7d5323b5-c999-47ce-86e6-0b160e954b77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578783737-172.17.0.19-1595700356601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44133,DS-dc53df17-aa75-4fa5-b71c-bbb5805bddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-08ab10a2-7591-4cc4-9beb-a22777281596,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-779bd4ef-0dd8-4d25-8b01-43584cb94380,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-685fd214-3ad9-4352-ab0f-ab7e32a5fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-472286f1-a546-4d23-9ba0-1e336717590f,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-6f71026c-01e7-4268-9f9a-b5c8bca9dfae,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-1e48f09a-665a-43ed-b183-ef8e05c2603c,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-7d5323b5-c999-47ce-86e6-0b160e954b77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350703074-172.17.0.19-1595700424176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-ebed158c-e60d-4048-9d3b-fcf2a76c1354,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-df5ca73d-ac8f-43e7-971b-71a108462304,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-3910dcfa-839e-4b03-9bcb-91d4a7a9a195,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-6d5bb9dc-f82f-4722-bfd2-e104bf9f3a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-e794d893-806c-4ce0-a7f6-a58cbc5bb312,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-b4e24f44-b54d-42af-93c6-3b7233e5407f,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-b09fdab0-26a3-4e3b-ac7b-8aee96e8442a,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-236d2515-8ee7-4f3b-8e16-1c633de99200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350703074-172.17.0.19-1595700424176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-ebed158c-e60d-4048-9d3b-fcf2a76c1354,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-df5ca73d-ac8f-43e7-971b-71a108462304,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-3910dcfa-839e-4b03-9bcb-91d4a7a9a195,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-6d5bb9dc-f82f-4722-bfd2-e104bf9f3a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-e794d893-806c-4ce0-a7f6-a58cbc5bb312,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-b4e24f44-b54d-42af-93c6-3b7233e5407f,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-b09fdab0-26a3-4e3b-ac7b-8aee96e8442a,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-236d2515-8ee7-4f3b-8e16-1c633de99200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324167621-172.17.0.19-1595700462367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33686,DS-c528f66e-735c-4e6c-a3a4-10f51fa8b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-097f7ace-52e0-4095-aa7f-0a062fb2599f,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-6a589089-3a24-4471-8535-33495f7b5927,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-092c3f1f-5999-42a5-85bf-bbb6d4cb560d,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-aed8ec92-1ec2-4fcf-8377-3d985d6de1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-aebf7332-4462-415f-b686-b3423f238c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-a74c8ca0-456c-4a2f-8221-3c3fe843fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-5c733c60-a023-4058-af5e-67f52b92c53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324167621-172.17.0.19-1595700462367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33686,DS-c528f66e-735c-4e6c-a3a4-10f51fa8b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-097f7ace-52e0-4095-aa7f-0a062fb2599f,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-6a589089-3a24-4471-8535-33495f7b5927,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-092c3f1f-5999-42a5-85bf-bbb6d4cb560d,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-aed8ec92-1ec2-4fcf-8377-3d985d6de1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-aebf7332-4462-415f-b686-b3423f238c94,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-a74c8ca0-456c-4a2f-8221-3c3fe843fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-5c733c60-a023-4058-af5e-67f52b92c53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754838989-172.17.0.19-1595700653575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42998,DS-8a7b006b-30a1-4642-9cdb-49d4af7acd64,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-6dadd269-eb7c-43c1-a2c6-bc56a6afadf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-1af5fca1-e5ea-425a-8b02-60b43b911539,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-ad123b95-9eb5-4514-82f5-e32ffc18ac55,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-c7fb44c9-a6dd-4bc6-a94f-83bc6757c7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-c6dbf9bd-48dc-4274-bbb3-de1c27418237,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-73d57511-91c0-4442-82b0-28600d04eec7,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-ecce8a9d-45ec-4558-bd94-1860c254a354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754838989-172.17.0.19-1595700653575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42998,DS-8a7b006b-30a1-4642-9cdb-49d4af7acd64,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-6dadd269-eb7c-43c1-a2c6-bc56a6afadf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-1af5fca1-e5ea-425a-8b02-60b43b911539,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-ad123b95-9eb5-4514-82f5-e32ffc18ac55,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-c7fb44c9-a6dd-4bc6-a94f-83bc6757c7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-c6dbf9bd-48dc-4274-bbb3-de1c27418237,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-73d57511-91c0-4442-82b0-28600d04eec7,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-ecce8a9d-45ec-4558-bd94-1860c254a354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823294757-172.17.0.19-1595701062148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42348,DS-e9c582fe-210f-4071-93f4-13a1c5c7e411,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-766d0bd4-97c1-48ea-b0ab-103be71dfe10,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-bdb3fc60-0618-42f1-b759-81206a495eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-3c5f85e5-5b17-45cd-a363-bb459a8793c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-92d95f8c-3b2e-4428-8e22-7c5e8e474076,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-60be7192-a077-4e54-b900-62240a19e836,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-a5b5e4ca-73b5-49c9-a4c6-e277fe7fddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-ffdd6b38-d876-451a-8326-e4b52bc1c7bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823294757-172.17.0.19-1595701062148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42348,DS-e9c582fe-210f-4071-93f4-13a1c5c7e411,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-766d0bd4-97c1-48ea-b0ab-103be71dfe10,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-bdb3fc60-0618-42f1-b759-81206a495eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-3c5f85e5-5b17-45cd-a363-bb459a8793c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-92d95f8c-3b2e-4428-8e22-7c5e8e474076,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-60be7192-a077-4e54-b900-62240a19e836,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-a5b5e4ca-73b5-49c9-a4c6-e277fe7fddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-ffdd6b38-d876-451a-8326-e4b52bc1c7bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408189338-172.17.0.19-1595701368436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-b146766b-1a19-4421-bf66-0347f12cdbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-7aa35629-5c65-43da-9cd4-6839b64f93c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-8c92cb71-1aad-4e79-bc2e-f59bcc96fe35,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-90e7b051-4d22-467b-979f-e306b88c4211,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-be60acfd-a0d2-44bd-9fec-21323bc6ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-a8923dfa-93f7-431b-b710-b8a851e3c288,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-76332ca7-0c1c-4ff9-a5ff-371e7431cc84,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-1fff1be1-caa9-4481-aaa2-05873bb2e71d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408189338-172.17.0.19-1595701368436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36512,DS-b146766b-1a19-4421-bf66-0347f12cdbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-7aa35629-5c65-43da-9cd4-6839b64f93c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-8c92cb71-1aad-4e79-bc2e-f59bcc96fe35,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-90e7b051-4d22-467b-979f-e306b88c4211,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-be60acfd-a0d2-44bd-9fec-21323bc6ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-a8923dfa-93f7-431b-b710-b8a851e3c288,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-76332ca7-0c1c-4ff9-a5ff-371e7431cc84,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-1fff1be1-caa9-4481-aaa2-05873bb2e71d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626225892-172.17.0.19-1595701514982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39468,DS-f6476cb0-f5db-423b-9198-e95269e3df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-704d9fad-d45f-428a-8198-a71a6b8661b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-bc0ce2cf-1912-46ab-860e-ff80227faed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-c57a3849-a903-4861-aa7d-8ad9ecebabf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-4203cd28-fd8f-4ba2-9d7e-a33c8ec0a06c,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-3920579c-5596-440c-acee-c35a831470ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-afa62ca5-d61b-48fc-b111-6c9c6da8ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-8b585788-1d7b-4482-ae19-ffa59587f7c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626225892-172.17.0.19-1595701514982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39468,DS-f6476cb0-f5db-423b-9198-e95269e3df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-704d9fad-d45f-428a-8198-a71a6b8661b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-bc0ce2cf-1912-46ab-860e-ff80227faed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-c57a3849-a903-4861-aa7d-8ad9ecebabf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-4203cd28-fd8f-4ba2-9d7e-a33c8ec0a06c,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-3920579c-5596-440c-acee-c35a831470ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-afa62ca5-d61b-48fc-b111-6c9c6da8ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-8b585788-1d7b-4482-ae19-ffa59587f7c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872252514-172.17.0.19-1595701554010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41216,DS-a9ad487a-0f73-42f0-935e-6b3fea084f82,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-9ae999a5-e7dc-422b-8c50-18de641efe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-966b3b8b-4816-4b0e-a3f8-86be1a44da00,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-45dd4ea7-0a94-4644-95a5-208cbb34b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-d1ccdf07-5028-4973-8a23-e37fd7f833c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-36e3c401-0fee-42e2-988e-6bb8186adf78,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-ad8c0b5a-bf52-47a9-a969-713c7cf9d07f,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-1ce1fb88-4d42-4101-907c-34c5d75777ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872252514-172.17.0.19-1595701554010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41216,DS-a9ad487a-0f73-42f0-935e-6b3fea084f82,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-9ae999a5-e7dc-422b-8c50-18de641efe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-966b3b8b-4816-4b0e-a3f8-86be1a44da00,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-45dd4ea7-0a94-4644-95a5-208cbb34b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-d1ccdf07-5028-4973-8a23-e37fd7f833c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-36e3c401-0fee-42e2-988e-6bb8186adf78,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-ad8c0b5a-bf52-47a9-a969-713c7cf9d07f,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-1ce1fb88-4d42-4101-907c-34c5d75777ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956966128-172.17.0.19-1595701903927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46729,DS-1bb48003-8e3b-4ac0-8a68-3f29c309ec01,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-47357651-52b0-413a-b471-d1675bec02ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-79b1c1de-6dd1-4aa8-8351-87356c507658,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-008f4c85-e882-47d0-9e13-a61d781f5c13,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-2836ccaf-4cff-4d7e-834a-84a5428e1edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-c69d6836-c507-4fdc-9d13-62cedcf21b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-1b51866d-0702-48ad-8580-eb8c890546e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-41fd2228-9d9a-4947-9f2e-1ed71ff400a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956966128-172.17.0.19-1595701903927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46729,DS-1bb48003-8e3b-4ac0-8a68-3f29c309ec01,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-47357651-52b0-413a-b471-d1675bec02ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-79b1c1de-6dd1-4aa8-8351-87356c507658,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-008f4c85-e882-47d0-9e13-a61d781f5c13,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-2836ccaf-4cff-4d7e-834a-84a5428e1edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-c69d6836-c507-4fdc-9d13-62cedcf21b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-1b51866d-0702-48ad-8580-eb8c890546e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-41fd2228-9d9a-4947-9f2e-1ed71ff400a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852440037-172.17.0.19-1595701938723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-0a8be6a7-11c3-4374-b3bd-79582e031ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-1159d909-d709-4b05-b004-beff2f8cf085,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-3b514bf8-0133-4606-ae0c-10715ef2177a,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-1af5337a-e29d-4e3f-925e-4a469660043b,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-1da032ce-06cc-4a7a-8e7c-d8c01ffe6651,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-be44ae59-0cc6-48bd-8d7f-436982803ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-66ec6cb2-eab9-4d26-8d2f-114f12ea6ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-c7f6c37d-e693-4b37-b477-0facc63ad2bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852440037-172.17.0.19-1595701938723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-0a8be6a7-11c3-4374-b3bd-79582e031ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-1159d909-d709-4b05-b004-beff2f8cf085,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-3b514bf8-0133-4606-ae0c-10715ef2177a,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-1af5337a-e29d-4e3f-925e-4a469660043b,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-1da032ce-06cc-4a7a-8e7c-d8c01ffe6651,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-be44ae59-0cc6-48bd-8d7f-436982803ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-66ec6cb2-eab9-4d26-8d2f-114f12ea6ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-c7f6c37d-e693-4b37-b477-0facc63ad2bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023825218-172.17.0.19-1595702108863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33856,DS-65cd57b4-aaf8-45e0-9b3c-5c385df32b93,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-c906128c-9eff-4036-b42f-3564534a58e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-227c4c00-bdbe-41df-9084-7763f40e9fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-cfdbf36c-0a7e-4577-8ea0-c3f395ee5b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-8c7f7cce-a4ae-4e5e-aa6b-b1213cdf3ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-ae78c8c8-016a-4269-9551-5b8fefbd51e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-9d2ad0d1-252e-42fa-87b6-a9baf61590bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-2c526bce-0d36-4cd8-a079-cdbbc6eb02b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023825218-172.17.0.19-1595702108863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33856,DS-65cd57b4-aaf8-45e0-9b3c-5c385df32b93,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-c906128c-9eff-4036-b42f-3564534a58e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-227c4c00-bdbe-41df-9084-7763f40e9fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-cfdbf36c-0a7e-4577-8ea0-c3f395ee5b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-8c7f7cce-a4ae-4e5e-aa6b-b1213cdf3ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-ae78c8c8-016a-4269-9551-5b8fefbd51e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-9d2ad0d1-252e-42fa-87b6-a9baf61590bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-2c526bce-0d36-4cd8-a079-cdbbc6eb02b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170508736-172.17.0.19-1595702170857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39651,DS-feae490d-5fed-42fa-8dde-5e092fc8738c,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-daf9f240-f59b-400f-a87b-043453afe4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-6999b932-d198-490e-9846-0d90ab7bb6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-a0d0514c-f2f2-4970-a9ef-ac5187cba2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-254d8d84-3ab5-47ee-9f9f-9550767a578e,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-66ca4f5a-0046-4b8b-8c0e-9ad6d73d27c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-17af36fe-d2e3-4124-af55-445bce6f81b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-48f0508c-ad38-4cec-a898-a4189bb493e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170508736-172.17.0.19-1595702170857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39651,DS-feae490d-5fed-42fa-8dde-5e092fc8738c,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-daf9f240-f59b-400f-a87b-043453afe4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-6999b932-d198-490e-9846-0d90ab7bb6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-a0d0514c-f2f2-4970-a9ef-ac5187cba2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-254d8d84-3ab5-47ee-9f9f-9550767a578e,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-66ca4f5a-0046-4b8b-8c0e-9ad6d73d27c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-17af36fe-d2e3-4124-af55-445bce6f81b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-48f0508c-ad38-4cec-a898-a4189bb493e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5061
