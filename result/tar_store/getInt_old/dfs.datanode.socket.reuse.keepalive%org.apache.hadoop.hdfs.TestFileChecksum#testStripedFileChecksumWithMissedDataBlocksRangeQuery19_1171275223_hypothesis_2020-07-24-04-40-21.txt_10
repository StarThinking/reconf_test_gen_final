reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982999064-172.17.0.16-1595565923950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-e1e82c8d-4ada-4ce2-bf2c-30219c5cb352,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-2e273182-a4ba-4594-8b5b-758df2ed25ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-e6203195-ba2a-4167-9850-572afc850afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-def1c040-ec2a-4f10-b446-bd91543c25da,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-a47ddcbf-8fbe-4e47-921f-ee7e93e78010,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-ccd0f633-61bb-4f5e-9b74-4d7cbe920414,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-e8f0bb74-e7a4-4e59-aef3-5ea494ea9383,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-3f28757d-6245-4065-99e9-0e1b05d11c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982999064-172.17.0.16-1595565923950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-e1e82c8d-4ada-4ce2-bf2c-30219c5cb352,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-2e273182-a4ba-4594-8b5b-758df2ed25ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-e6203195-ba2a-4167-9850-572afc850afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-def1c040-ec2a-4f10-b446-bd91543c25da,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-a47ddcbf-8fbe-4e47-921f-ee7e93e78010,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-ccd0f633-61bb-4f5e-9b74-4d7cbe920414,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-e8f0bb74-e7a4-4e59-aef3-5ea494ea9383,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-3f28757d-6245-4065-99e9-0e1b05d11c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549225239-172.17.0.16-1595565961810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36793,DS-02c32395-b89a-4997-9b78-528bb0af78f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-0127476b-e03a-4f0d-8d9c-b808a4f71484,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-de9714dc-2e51-495f-a5b9-017c2ac11186,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-91afbb10-a298-491a-a75b-6677ab23ffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-70f49787-f972-4ef5-a2da-e28bc6e91dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-eeb4aa7e-75ed-40d4-979e-cc5cd87fec42,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-9c103455-1d67-48e6-8351-de168c8cb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-aad078f4-9d7f-4ea1-8361-7d6cf254a3a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549225239-172.17.0.16-1595565961810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36793,DS-02c32395-b89a-4997-9b78-528bb0af78f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-0127476b-e03a-4f0d-8d9c-b808a4f71484,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-de9714dc-2e51-495f-a5b9-017c2ac11186,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-91afbb10-a298-491a-a75b-6677ab23ffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-70f49787-f972-4ef5-a2da-e28bc6e91dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-eeb4aa7e-75ed-40d4-979e-cc5cd87fec42,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-9c103455-1d67-48e6-8351-de168c8cb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-aad078f4-9d7f-4ea1-8361-7d6cf254a3a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957872987-172.17.0.16-1595567120676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-e1150a36-255a-4c0e-93e4-4f70066d73aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-67c87ce4-f93a-46be-b749-4d10419a3c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-f215dcb1-425e-46b7-998f-9b7620e57fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-51227f02-dcf7-4194-8027-17baf8bb67d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-6cd2663d-2e70-4ab7-94db-099a934dba40,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-bb37bc8d-a6e8-4972-a28d-fd21350389ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-0cb7bd56-b98a-46c9-8040-a0b54e563779,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-ebf183bc-8db5-40c2-a663-0c379053e191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957872987-172.17.0.16-1595567120676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-e1150a36-255a-4c0e-93e4-4f70066d73aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-67c87ce4-f93a-46be-b749-4d10419a3c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-f215dcb1-425e-46b7-998f-9b7620e57fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-51227f02-dcf7-4194-8027-17baf8bb67d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-6cd2663d-2e70-4ab7-94db-099a934dba40,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-bb37bc8d-a6e8-4972-a28d-fd21350389ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-0cb7bd56-b98a-46c9-8040-a0b54e563779,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-ebf183bc-8db5-40c2-a663-0c379053e191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600197556-172.17.0.16-1595567435266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-bcc6d06e-2ef7-4500-9b4d-9fac66855c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-18ac5bfd-9c2e-49d0-a053-f98139882605,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-5daf4e56-795e-4a99-95b6-4bce0b21341e,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-94a9f869-57ca-4e8a-b742-28ee68a95378,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-674d1285-a47d-4b8b-a0f6-604c3733941a,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-9f2e3f90-54c4-46f9-a6d6-f56e82d06c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-87f77ea6-b651-4165-8041-261c4085ac08,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-f3b96795-c02f-4c2a-baf8-db5e960b92b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600197556-172.17.0.16-1595567435266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-bcc6d06e-2ef7-4500-9b4d-9fac66855c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-18ac5bfd-9c2e-49d0-a053-f98139882605,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-5daf4e56-795e-4a99-95b6-4bce0b21341e,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-94a9f869-57ca-4e8a-b742-28ee68a95378,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-674d1285-a47d-4b8b-a0f6-604c3733941a,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-9f2e3f90-54c4-46f9-a6d6-f56e82d06c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-87f77ea6-b651-4165-8041-261c4085ac08,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-f3b96795-c02f-4c2a-baf8-db5e960b92b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364178928-172.17.0.16-1595567580321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38557,DS-a14c4036-2bfc-4111-ad9a-230948b02dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-8c7cfd2c-e9ef-48ad-a2a7-c5025aa373ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-5b49c14c-4702-4a8f-a2d0-13abdfd8fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-84d1a4a3-da9f-4c2b-b7d3-9ad424d1537f,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-746b0229-ff48-4532-b4ca-d7d64ab117f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-683229e0-9263-4e2e-a526-95b4a4c781c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-17c9c932-b4b1-4a6e-8712-9170850204c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-6de25611-a294-4eaa-b81f-4f2680b41f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364178928-172.17.0.16-1595567580321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38557,DS-a14c4036-2bfc-4111-ad9a-230948b02dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-8c7cfd2c-e9ef-48ad-a2a7-c5025aa373ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-5b49c14c-4702-4a8f-a2d0-13abdfd8fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-84d1a4a3-da9f-4c2b-b7d3-9ad424d1537f,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-746b0229-ff48-4532-b4ca-d7d64ab117f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-683229e0-9263-4e2e-a526-95b4a4c781c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-17c9c932-b4b1-4a6e-8712-9170850204c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-6de25611-a294-4eaa-b81f-4f2680b41f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122421104-172.17.0.16-1595568609595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-d62c2773-bf7d-466e-b1f1-195e04ba6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-74a43962-c002-4585-bf9e-bdd1b1c506a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-b32aa258-a5e1-4df3-99fe-9b7dff475692,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-11d78697-b739-4497-bb2c-931c8227a9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-981f6d44-0031-4b4c-85ca-ae97175a8913,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-0f2abdad-dd2d-40c9-b1ef-50ed0155926f,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-1ef17b6f-5df9-4ca3-b7a6-142aef2b91cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-828a4a69-6f76-416c-9afd-0debfd96e6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122421104-172.17.0.16-1595568609595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-d62c2773-bf7d-466e-b1f1-195e04ba6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-74a43962-c002-4585-bf9e-bdd1b1c506a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-b32aa258-a5e1-4df3-99fe-9b7dff475692,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-11d78697-b739-4497-bb2c-931c8227a9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-981f6d44-0031-4b4c-85ca-ae97175a8913,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-0f2abdad-dd2d-40c9-b1ef-50ed0155926f,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-1ef17b6f-5df9-4ca3-b7a6-142aef2b91cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-828a4a69-6f76-416c-9afd-0debfd96e6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944619889-172.17.0.16-1595569009815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-dd3c87b4-a83b-4243-9198-89e4d22bae98,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-6c5c31aa-1a16-4dcc-a18f-1c3ef6318a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-337defed-2ce4-4183-b704-dcea49373cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-86af267c-710d-4c76-8614-d8bcb1d75e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-248b66a5-a513-4bb9-a547-a1335685a62d,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-6991fa79-6075-4ec6-bb1e-1fb4ea093ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-7a852c58-2c0e-4ef8-853a-bd820cf71dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-826cdcff-aa4a-49ef-9ae9-93f21e492f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944619889-172.17.0.16-1595569009815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-dd3c87b4-a83b-4243-9198-89e4d22bae98,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-6c5c31aa-1a16-4dcc-a18f-1c3ef6318a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-337defed-2ce4-4183-b704-dcea49373cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-86af267c-710d-4c76-8614-d8bcb1d75e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-248b66a5-a513-4bb9-a547-a1335685a62d,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-6991fa79-6075-4ec6-bb1e-1fb4ea093ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-7a852c58-2c0e-4ef8-853a-bd820cf71dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-826cdcff-aa4a-49ef-9ae9-93f21e492f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201910879-172.17.0.16-1595569241366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-5d57e272-dd9f-4d6d-b8b7-71c3cd21bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-8d78f5d3-1c56-4da9-a8c0-fe4bacb25feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-8c470bf4-d2ff-474e-ac9b-efcf13679ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-8df497fc-d936-4857-91e1-691ad2ef6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-434524bc-d3dc-444c-8b6e-5cf9f7857ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-a0b3b723-6594-4d6a-85c5-83ef85d26d18,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-8d658ccc-32db-44c8-ab5b-2d0087c9375b,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-45cd2b48-02b7-4f57-9af0-d90ab9f6cc18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201910879-172.17.0.16-1595569241366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-5d57e272-dd9f-4d6d-b8b7-71c3cd21bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-8d78f5d3-1c56-4da9-a8c0-fe4bacb25feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-8c470bf4-d2ff-474e-ac9b-efcf13679ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-8df497fc-d936-4857-91e1-691ad2ef6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-434524bc-d3dc-444c-8b6e-5cf9f7857ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-a0b3b723-6594-4d6a-85c5-83ef85d26d18,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-8d658ccc-32db-44c8-ab5b-2d0087c9375b,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-45cd2b48-02b7-4f57-9af0-d90ab9f6cc18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519256018-172.17.0.16-1595569573059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-f2736b12-5284-4d44-b502-68e09363d095,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-a800154b-658b-4ab9-a519-b7c20023da70,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-49fefd57-4bb1-4ed6-b214-0fa9ff34c27d,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-5f3cb59a-ff8c-46a2-97ca-89441f6b4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-dc3dcc78-6f06-4957-b5eb-bd67d6d17f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-9e6fec39-ff79-4909-8e1f-6f4e5cca542b,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-994959fd-5358-4d94-8fe5-8de832cb6536,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-40115e30-f218-42b2-ade8-57beef2c7a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519256018-172.17.0.16-1595569573059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-f2736b12-5284-4d44-b502-68e09363d095,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-a800154b-658b-4ab9-a519-b7c20023da70,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-49fefd57-4bb1-4ed6-b214-0fa9ff34c27d,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-5f3cb59a-ff8c-46a2-97ca-89441f6b4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-dc3dcc78-6f06-4957-b5eb-bd67d6d17f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-9e6fec39-ff79-4909-8e1f-6f4e5cca542b,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-994959fd-5358-4d94-8fe5-8de832cb6536,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-40115e30-f218-42b2-ade8-57beef2c7a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317371689-172.17.0.16-1595569953433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32992,DS-f32fd474-998c-4c10-a795-ecb0a764e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-d56a0b9b-c816-4cbd-8f72-3e70fb732b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-623854f9-f657-4578-89c7-542f45a879ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-50254187-1bd6-41fc-b842-b7d4dbb89920,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-25c2cdee-510a-4ac6-af05-3e3cea20a354,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-aa2ade86-910f-4a82-abd7-a8c071776b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-b0d9afc6-4c8c-48cc-8bcc-645ecf97ed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-56675786-2b23-4e11-a447-ab8040b65881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317371689-172.17.0.16-1595569953433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32992,DS-f32fd474-998c-4c10-a795-ecb0a764e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-d56a0b9b-c816-4cbd-8f72-3e70fb732b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-623854f9-f657-4578-89c7-542f45a879ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-50254187-1bd6-41fc-b842-b7d4dbb89920,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-25c2cdee-510a-4ac6-af05-3e3cea20a354,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-aa2ade86-910f-4a82-abd7-a8c071776b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-b0d9afc6-4c8c-48cc-8bcc-645ecf97ed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-56675786-2b23-4e11-a447-ab8040b65881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000
v2: 4000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155586338-172.17.0.16-1595570638153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44547,DS-40092776-d4b6-440f-a9fd-9c70fe51b38e,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-db78031b-cc27-4c00-8969-823ff445d091,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-3519cb52-e2b4-49ba-879a-6117bf6faf60,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-e4446ce0-72a8-43c6-851a-afe86e21b701,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-c90593f4-3fd0-4b9b-a93d-681e8d1cdb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-8f21eea5-63d7-4679-8ec2-f0d276a29514,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-32ad6981-d1d8-4d88-a73c-f3ac36edfc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-004b98a7-2878-4487-9ccd-480bc74a4cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155586338-172.17.0.16-1595570638153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44547,DS-40092776-d4b6-440f-a9fd-9c70fe51b38e,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-db78031b-cc27-4c00-8969-823ff445d091,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-3519cb52-e2b4-49ba-879a-6117bf6faf60,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-e4446ce0-72a8-43c6-851a-afe86e21b701,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-c90593f4-3fd0-4b9b-a93d-681e8d1cdb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-8f21eea5-63d7-4679-8ec2-f0d276a29514,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-32ad6981-d1d8-4d88-a73c-f3ac36edfc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-004b98a7-2878-4487-9ccd-480bc74a4cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5177
