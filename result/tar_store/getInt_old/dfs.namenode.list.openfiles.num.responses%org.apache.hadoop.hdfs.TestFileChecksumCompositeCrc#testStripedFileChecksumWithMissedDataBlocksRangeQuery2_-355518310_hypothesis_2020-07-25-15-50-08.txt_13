reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338527720-172.17.0.14-1595692994043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-a922891a-e2c9-4f98-9a83-f182f0a5029e,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-c0f4c2c0-b6fa-4184-b653-ef57dbb707b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-b8f85465-d380-4318-b19a-ca1f47fe1346,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-83ad927c-d701-4fe2-9086-dcf8dbfa761c,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-a49bba5f-176a-40f8-bb33-1988563a0515,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-7a6989cf-0c34-429e-bd4a-ed14fcb93de6,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-0cda256d-5394-49d0-9a55-eaddde72a658,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-8e120f23-ccbf-4c39-9dce-da89d0bbf2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338527720-172.17.0.14-1595692994043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-a922891a-e2c9-4f98-9a83-f182f0a5029e,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-c0f4c2c0-b6fa-4184-b653-ef57dbb707b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-b8f85465-d380-4318-b19a-ca1f47fe1346,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-83ad927c-d701-4fe2-9086-dcf8dbfa761c,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-a49bba5f-176a-40f8-bb33-1988563a0515,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-7a6989cf-0c34-429e-bd4a-ed14fcb93de6,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-0cda256d-5394-49d0-9a55-eaddde72a658,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-8e120f23-ccbf-4c39-9dce-da89d0bbf2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257724450-172.17.0.14-1595693107184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46764,DS-a1a83f2a-79b1-4329-8ee4-acc62510cc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-bb666415-c6b4-4c29-9303-7f7f1402679a,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-14f21135-94e0-4130-918a-72290995ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-949da5de-d733-4e96-92de-2b27079aceb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-5e983a3b-64f8-4c57-a3dd-5052dc938744,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-75036819-1fca-4f2a-9753-d4f5d4d4c04c,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-ee381ddc-f260-4f20-a9f1-62500435cc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-1fd5a220-86ab-451e-b38b-18ebd29c315e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257724450-172.17.0.14-1595693107184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46764,DS-a1a83f2a-79b1-4329-8ee4-acc62510cc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-bb666415-c6b4-4c29-9303-7f7f1402679a,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-14f21135-94e0-4130-918a-72290995ceff,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-949da5de-d733-4e96-92de-2b27079aceb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-5e983a3b-64f8-4c57-a3dd-5052dc938744,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-75036819-1fca-4f2a-9753-d4f5d4d4c04c,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-ee381ddc-f260-4f20-a9f1-62500435cc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-1fd5a220-86ab-451e-b38b-18ebd29c315e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941279800-172.17.0.14-1595693356509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43866,DS-6f08f535-1eaa-4037-9ae3-b900ec72f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-9684e5ee-97cb-47a8-b263-5e8b6237fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-56d9011d-ee27-4e07-b1d4-f373cecb6f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-e33940cc-ee48-458d-b4ad-2ee4d9e0445a,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-20d51b25-92a9-468d-82b0-6bf6c5f66cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-d3af4001-21b0-40d4-b122-1828c1038c44,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-23bfb478-6a27-47fc-8d55-8693e14f0bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-61058c8b-e253-4860-83eb-3e753c537cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941279800-172.17.0.14-1595693356509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43866,DS-6f08f535-1eaa-4037-9ae3-b900ec72f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-9684e5ee-97cb-47a8-b263-5e8b6237fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-56d9011d-ee27-4e07-b1d4-f373cecb6f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-e33940cc-ee48-458d-b4ad-2ee4d9e0445a,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-20d51b25-92a9-468d-82b0-6bf6c5f66cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-d3af4001-21b0-40d4-b122-1828c1038c44,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-23bfb478-6a27-47fc-8d55-8693e14f0bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-61058c8b-e253-4860-83eb-3e753c537cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426195064-172.17.0.14-1595693625536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42727,DS-bdcdbc1a-76a9-476e-848d-44fadd8ab11a,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-17a20dc4-dc1e-4189-828d-14e8b29e47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-0370fe60-0092-4164-bb1e-f67a1aa50f43,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-cfe76fb0-8c9d-4ac5-bf84-9df4798e60f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-8becd253-76c4-41df-ae5d-08386bff46eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-670cdedc-4cd8-4060-b00c-4d92704f6070,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-8e473e2d-5082-416c-911c-23b9262df487,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-af694f59-c06c-473e-8bcc-32444e908305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426195064-172.17.0.14-1595693625536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42727,DS-bdcdbc1a-76a9-476e-848d-44fadd8ab11a,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-17a20dc4-dc1e-4189-828d-14e8b29e47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-0370fe60-0092-4164-bb1e-f67a1aa50f43,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-cfe76fb0-8c9d-4ac5-bf84-9df4798e60f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-8becd253-76c4-41df-ae5d-08386bff46eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-670cdedc-4cd8-4060-b00c-4d92704f6070,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-8e473e2d-5082-416c-911c-23b9262df487,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-af694f59-c06c-473e-8bcc-32444e908305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40625185-172.17.0.14-1595694890304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-98e41408-5fb2-4af2-ac6f-e36948c77f14,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-c9431ced-6e56-4b71-98a1-e229f0304667,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-b9b334ba-0829-4107-9622-bba71f314986,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-d521b2e4-498a-425c-b5d0-fb906db4aa54,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-b1f18827-52f9-4f13-908a-db079680e499,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-9f00ee05-f4aa-4713-b03a-82b2b0aeefb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-aa356da3-7596-402f-bf40-483f2e323f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c28b9b90-d2b1-4c77-a0ed-720de6880eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40625185-172.17.0.14-1595694890304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-98e41408-5fb2-4af2-ac6f-e36948c77f14,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-c9431ced-6e56-4b71-98a1-e229f0304667,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-b9b334ba-0829-4107-9622-bba71f314986,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-d521b2e4-498a-425c-b5d0-fb906db4aa54,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-b1f18827-52f9-4f13-908a-db079680e499,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-9f00ee05-f4aa-4713-b03a-82b2b0aeefb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-aa356da3-7596-402f-bf40-483f2e323f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c28b9b90-d2b1-4c77-a0ed-720de6880eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288633098-172.17.0.14-1595695315474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42301,DS-c0f70040-e69d-4907-a460-26fd271e93ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-177d3d73-f226-45da-819c-cdbcdae0a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-f5d293c6-2376-49a4-bc87-1073b1aa5062,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-898e7d09-eae9-45b7-916b-81399e792c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-627970cf-6c61-4bb4-8f64-0d74a46e70af,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-f295073c-9ac0-420e-a3d4-8997fe0f94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-b119ba36-4d7e-4767-95a6-a328b5d05d48,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-ed384c3e-992b-4d88-b196-1d278507254e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288633098-172.17.0.14-1595695315474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42301,DS-c0f70040-e69d-4907-a460-26fd271e93ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-177d3d73-f226-45da-819c-cdbcdae0a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-f5d293c6-2376-49a4-bc87-1073b1aa5062,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-898e7d09-eae9-45b7-916b-81399e792c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-627970cf-6c61-4bb4-8f64-0d74a46e70af,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-f295073c-9ac0-420e-a3d4-8997fe0f94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-b119ba36-4d7e-4767-95a6-a328b5d05d48,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-ed384c3e-992b-4d88-b196-1d278507254e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767474454-172.17.0.14-1595695465205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-43671721-4471-4108-924b-2bfb43908099,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-ec46d2b9-35d1-4204-a7f8-803849c35acb,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-71cd23fe-8a4e-419a-9880-56e4e271b7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-651994e1-da61-4f01-8cc6-7220e0f7dad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-ac3be6e7-4c7a-4512-aff5-b53027035a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-dfe0f7a0-b513-4f25-bb27-ad333d5aa03a,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-26f22eaa-aedd-43d9-bf36-b057aa28c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-c34d797a-e392-4370-8a9c-0a746b1782f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767474454-172.17.0.14-1595695465205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-43671721-4471-4108-924b-2bfb43908099,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-ec46d2b9-35d1-4204-a7f8-803849c35acb,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-71cd23fe-8a4e-419a-9880-56e4e271b7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-651994e1-da61-4f01-8cc6-7220e0f7dad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-ac3be6e7-4c7a-4512-aff5-b53027035a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-dfe0f7a0-b513-4f25-bb27-ad333d5aa03a,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-26f22eaa-aedd-43d9-bf36-b057aa28c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-c34d797a-e392-4370-8a9c-0a746b1782f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336960023-172.17.0.14-1595695540165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-5d211985-3110-4c0b-961e-17c702bf1b42,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-a3feb12d-ca7f-46aa-ad7f-8ef37e6427a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-d2032d01-5b15-4fed-93ca-3ad23250ad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-05a44d8a-3684-4178-905f-146c44f97110,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-d68cd9a7-54f5-4890-82e7-a4f5d47e4c54,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-7cee40de-d31d-4ebf-8ca4-4ef999b74afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-37779af6-d6dd-4ae8-b9cc-04ab88fce708,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-900adabf-42a8-4d1f-a9f8-2955fbb7b7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336960023-172.17.0.14-1595695540165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-5d211985-3110-4c0b-961e-17c702bf1b42,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-a3feb12d-ca7f-46aa-ad7f-8ef37e6427a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-d2032d01-5b15-4fed-93ca-3ad23250ad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-05a44d8a-3684-4178-905f-146c44f97110,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-d68cd9a7-54f5-4890-82e7-a4f5d47e4c54,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-7cee40de-d31d-4ebf-8ca4-4ef999b74afc,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-37779af6-d6dd-4ae8-b9cc-04ab88fce708,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-900adabf-42a8-4d1f-a9f8-2955fbb7b7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974271303-172.17.0.14-1595696126112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35502,DS-685b6983-cbfd-44b6-851b-dbcc17398718,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-fde38585-9f6d-4806-b99d-4045f742a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-a19654a5-a8c8-4464-af9f-24625a9a90d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-aa70936d-41c0-45ab-bb80-a6e1f3dbcb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-9ec32f03-3dec-4d4b-8968-09ffc5d22e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-fe8701a1-7991-4b1c-8bd7-7f530079d986,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-42790f0d-4bb7-4704-bca1-732a41271e33,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-00472a2c-6f57-438c-a34d-12a508382a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974271303-172.17.0.14-1595696126112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35502,DS-685b6983-cbfd-44b6-851b-dbcc17398718,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-fde38585-9f6d-4806-b99d-4045f742a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-a19654a5-a8c8-4464-af9f-24625a9a90d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-aa70936d-41c0-45ab-bb80-a6e1f3dbcb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-9ec32f03-3dec-4d4b-8968-09ffc5d22e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-fe8701a1-7991-4b1c-8bd7-7f530079d986,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-42790f0d-4bb7-4704-bca1-732a41271e33,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-00472a2c-6f57-438c-a34d-12a508382a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845762891-172.17.0.14-1595696319584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-8087eb94-c686-4865-9acf-912df9a675e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-84e02df5-5987-4114-a9a3-08abd679ac61,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-a50b2694-26c9-4a48-b03f-83f9bb5d4959,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-f98729b5-c853-48a8-aa37-4730fd6654c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-0e1ca8db-a851-491b-8808-25d84f044260,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-4b02817f-2320-4845-8406-7ff128938c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-ed4376c8-e5a5-4a5a-861a-1b6da7d5cc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-fd7547c8-703f-417c-8f23-892a8deb2ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845762891-172.17.0.14-1595696319584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-8087eb94-c686-4865-9acf-912df9a675e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-84e02df5-5987-4114-a9a3-08abd679ac61,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-a50b2694-26c9-4a48-b03f-83f9bb5d4959,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-f98729b5-c853-48a8-aa37-4730fd6654c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-0e1ca8db-a851-491b-8808-25d84f044260,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-4b02817f-2320-4845-8406-7ff128938c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-ed4376c8-e5a5-4a5a-861a-1b6da7d5cc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-fd7547c8-703f-417c-8f23-892a8deb2ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971287266-172.17.0.14-1595696669663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-913e1994-2190-4e4a-ae86-c129773e17d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-bfd738ea-6326-4027-bb50-73a4af712400,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-a8a1e697-c384-4f44-942f-f011224fcfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-f1bc5ee6-5555-496d-a0ac-6dba8c9da5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-3743f80c-ae02-4ccc-9c57-2564d0e410ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-03b7b209-761a-4d56-9345-a7e5f683fa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-f5104fcf-4833-4d24-b25a-82b95fc04255,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-9d095584-7041-4376-aa01-057469f5a52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971287266-172.17.0.14-1595696669663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-913e1994-2190-4e4a-ae86-c129773e17d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-bfd738ea-6326-4027-bb50-73a4af712400,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-a8a1e697-c384-4f44-942f-f011224fcfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-f1bc5ee6-5555-496d-a0ac-6dba8c9da5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-3743f80c-ae02-4ccc-9c57-2564d0e410ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-03b7b209-761a-4d56-9345-a7e5f683fa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-f5104fcf-4833-4d24-b25a-82b95fc04255,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-9d095584-7041-4376-aa01-057469f5a52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920658936-172.17.0.14-1595697143790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41442,DS-a6eae021-a6b1-4977-9d58-a08dc0d8c662,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-3234c1c8-4d3b-41d6-b813-1407587dbb47,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-bff5c371-2296-41d2-aa91-788a9f7963b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-1ac8254e-db06-4ca2-bd09-850ffd86e428,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-72802ca1-bd40-4f7d-904f-a9a1a21ffdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-0eb8ef18-728d-4126-a3d0-2a4c8303c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-2820799f-1614-4e58-bb0e-863a62b70fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-15df6f29-cee6-470d-940a-e706fab08b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920658936-172.17.0.14-1595697143790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41442,DS-a6eae021-a6b1-4977-9d58-a08dc0d8c662,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-3234c1c8-4d3b-41d6-b813-1407587dbb47,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-bff5c371-2296-41d2-aa91-788a9f7963b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-1ac8254e-db06-4ca2-bd09-850ffd86e428,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-72802ca1-bd40-4f7d-904f-a9a1a21ffdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-0eb8ef18-728d-4126-a3d0-2a4c8303c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-2820799f-1614-4e58-bb0e-863a62b70fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-15df6f29-cee6-470d-940a-e706fab08b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254730024-172.17.0.14-1595697433406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41476,DS-2bee760a-c3ed-43fb-a7be-89670e65fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-c3486da0-c7c8-4c94-9e49-f226fa8552ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-d9f0ff3d-9752-4fa1-91c0-75c24d628c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-38bf2966-35b5-480a-8d40-25607857a275,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-c3399965-0e48-4ba0-b0a7-fa1e95b205fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-7b285091-5fa1-4fe6-a345-4155bfe510fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-860d849a-15fe-448e-b4ca-820529c715b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-a3334107-cbeb-493e-8dfd-8387ba364aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254730024-172.17.0.14-1595697433406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41476,DS-2bee760a-c3ed-43fb-a7be-89670e65fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-c3486da0-c7c8-4c94-9e49-f226fa8552ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-d9f0ff3d-9752-4fa1-91c0-75c24d628c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-38bf2966-35b5-480a-8d40-25607857a275,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-c3399965-0e48-4ba0-b0a7-fa1e95b205fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-7b285091-5fa1-4fe6-a345-4155bfe510fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-860d849a-15fe-448e-b4ca-820529c715b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-a3334107-cbeb-493e-8dfd-8387ba364aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913415986-172.17.0.14-1595697692822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37756,DS-ea4b1fd1-c908-4e9c-9a72-c26209d866d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-b3b53f0b-b2a4-4f5f-8417-6611a9faa436,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-ebe6f66c-37b3-405f-aa49-1dc816a92893,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-933a5c73-9c5e-41a0-a989-9e2a6aa10191,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-67627fd0-da09-44bc-8d6d-c0f0aa75f37d,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-5ac82912-e2c0-44e7-8ea7-3ebc2f490e59,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-9b3d2e24-04c3-40ef-a59e-409af8f9928a,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-8d08210a-7bd2-4f0b-b4b0-0871cb4bc74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913415986-172.17.0.14-1595697692822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37756,DS-ea4b1fd1-c908-4e9c-9a72-c26209d866d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-b3b53f0b-b2a4-4f5f-8417-6611a9faa436,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-ebe6f66c-37b3-405f-aa49-1dc816a92893,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-933a5c73-9c5e-41a0-a989-9e2a6aa10191,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-67627fd0-da09-44bc-8d6d-c0f0aa75f37d,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-5ac82912-e2c0-44e7-8ea7-3ebc2f490e59,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-9b3d2e24-04c3-40ef-a59e-409af8f9928a,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-8d08210a-7bd2-4f0b-b4b0-0871cb4bc74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392555297-172.17.0.14-1595697732149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36827,DS-bc6264de-531c-45ef-8f24-de1bc4e2a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-b15b13f8-d493-4749-b5a3-e3da90935812,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-d1ad8d0d-d507-4f88-9510-4c2d3272adf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-a0e6263a-fa0c-430e-8f5e-617dfb3f031b,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-cdefeb2e-0966-40ec-9349-a0b793c8384d,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-9a988327-c937-4e9d-95c0-1e4de903a735,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-0d050533-df01-4c84-89cb-7d5bcc74a912,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-6148670b-c2ea-43b5-8646-7d21e3410904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392555297-172.17.0.14-1595697732149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36827,DS-bc6264de-531c-45ef-8f24-de1bc4e2a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-b15b13f8-d493-4749-b5a3-e3da90935812,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-d1ad8d0d-d507-4f88-9510-4c2d3272adf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-a0e6263a-fa0c-430e-8f5e-617dfb3f031b,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-cdefeb2e-0966-40ec-9349-a0b793c8384d,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-9a988327-c937-4e9d-95c0-1e4de903a735,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-0d050533-df01-4c84-89cb-7d5bcc74a912,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-6148670b-c2ea-43b5-8646-7d21e3410904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5543
