reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325754376-172.17.0.8-1595490314336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-243fa94d-074f-4414-bcc2-eb78bb1efebd,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-0b823219-bcc3-4aee-a427-488691b6b9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-fde3cd4c-77ed-4bd3-8707-ee9d8cb0dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-c47df2cc-95b5-409f-ad88-ea69a81dc525,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-684a04cb-978a-4823-9a3a-c36eba62d3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-fe935d6c-4b24-4472-91ae-60a7bddd46b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-6083f5d8-d3f1-490c-94c3-b5fd7507841e,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-f518f4a3-825e-490f-9190-6ed294c25808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325754376-172.17.0.8-1595490314336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-243fa94d-074f-4414-bcc2-eb78bb1efebd,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-0b823219-bcc3-4aee-a427-488691b6b9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-fde3cd4c-77ed-4bd3-8707-ee9d8cb0dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-c47df2cc-95b5-409f-ad88-ea69a81dc525,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-684a04cb-978a-4823-9a3a-c36eba62d3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-fe935d6c-4b24-4472-91ae-60a7bddd46b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-6083f5d8-d3f1-490c-94c3-b5fd7507841e,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-f518f4a3-825e-490f-9190-6ed294c25808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819039849-172.17.0.8-1595490856738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34626,DS-2cce16f8-5fbc-45b4-83ec-bc1fc7c1c840,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-5383bbe2-73a0-4f90-b2ea-30894dd3f234,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-3b4a6770-b279-4f0a-9ae8-a966ca0d60df,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-c9535f5b-8d6f-4e6d-8f4f-3567757e7c41,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-9ebb57ca-6206-47ef-8d8c-a8854faf7cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-21b33ee2-bd9d-4c70-acf3-6ebc2bdc768e,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-26a70103-ed2c-49fc-b255-dd9cc5ab75d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-14799a4a-763c-470a-a09e-6196fd4824fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819039849-172.17.0.8-1595490856738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34626,DS-2cce16f8-5fbc-45b4-83ec-bc1fc7c1c840,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-5383bbe2-73a0-4f90-b2ea-30894dd3f234,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-3b4a6770-b279-4f0a-9ae8-a966ca0d60df,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-c9535f5b-8d6f-4e6d-8f4f-3567757e7c41,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-9ebb57ca-6206-47ef-8d8c-a8854faf7cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-21b33ee2-bd9d-4c70-acf3-6ebc2bdc768e,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-26a70103-ed2c-49fc-b255-dd9cc5ab75d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-14799a4a-763c-470a-a09e-6196fd4824fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628688793-172.17.0.8-1595491563954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37858,DS-99657725-b1ff-4765-af05-3c96b1fb04a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-c430c01d-cc9c-4b6d-9b1e-beb3db8f6e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-ce62ab20-de4f-4784-a4e9-61d2ef273fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-9adabac3-31c5-4351-90da-b78ce7e2500d,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-ef884e73-ea76-43d6-b58b-5a1f37ebcd84,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-856c1517-4120-4655-972a-c145deb87e68,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-31df6f3c-72f3-4eb9-ad1d-138bade9dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-28ef29dc-b1ce-42d0-9ad9-78da54fa9d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628688793-172.17.0.8-1595491563954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37858,DS-99657725-b1ff-4765-af05-3c96b1fb04a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-c430c01d-cc9c-4b6d-9b1e-beb3db8f6e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-ce62ab20-de4f-4784-a4e9-61d2ef273fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-9adabac3-31c5-4351-90da-b78ce7e2500d,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-ef884e73-ea76-43d6-b58b-5a1f37ebcd84,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-856c1517-4120-4655-972a-c145deb87e68,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-31df6f3c-72f3-4eb9-ad1d-138bade9dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-28ef29dc-b1ce-42d0-9ad9-78da54fa9d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554871764-172.17.0.8-1595492011828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33694,DS-85de5ac4-cee5-4a36-97b7-7f5da256394e,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-263acb1f-cc0b-4fe4-9483-5030380807ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-be761021-cbde-41c4-8965-aaa9aa1a31ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-ac4c80e5-9b22-40fc-9986-95fbc0b4ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-a9059f69-b6f6-48d9-bd41-028f17d90787,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-28fd242e-e92f-4ed0-a093-096e2aec5d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-b61c1df0-5422-40db-b545-d14485bb920f,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-d7c6fe71-12e6-4e72-8d0d-6c8883619295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554871764-172.17.0.8-1595492011828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33694,DS-85de5ac4-cee5-4a36-97b7-7f5da256394e,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-263acb1f-cc0b-4fe4-9483-5030380807ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-be761021-cbde-41c4-8965-aaa9aa1a31ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-ac4c80e5-9b22-40fc-9986-95fbc0b4ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-a9059f69-b6f6-48d9-bd41-028f17d90787,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-28fd242e-e92f-4ed0-a093-096e2aec5d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-b61c1df0-5422-40db-b545-d14485bb920f,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-d7c6fe71-12e6-4e72-8d0d-6c8883619295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587736919-172.17.0.8-1595492868198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35233,DS-03cbd72d-91bf-4862-8f97-ccd773ebc2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-c4ec4fe1-c94b-4fe9-b66d-01f4e7cae5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-8b6a201c-a7e5-442c-9c23-178edb42425d,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-6141c2ad-fbd8-4f22-8c7d-2f2dd2a7e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-e10858ad-21ad-47e0-b45d-a22190f6ff29,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-ee3aad23-7d6c-4856-9ce0-17e8056ed178,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-ae4c3c98-bb07-45fb-aa8a-6fc5faf55762,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-d1260322-73b7-4c3d-a023-6a65e4783d52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587736919-172.17.0.8-1595492868198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35233,DS-03cbd72d-91bf-4862-8f97-ccd773ebc2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-c4ec4fe1-c94b-4fe9-b66d-01f4e7cae5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-8b6a201c-a7e5-442c-9c23-178edb42425d,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-6141c2ad-fbd8-4f22-8c7d-2f2dd2a7e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-e10858ad-21ad-47e0-b45d-a22190f6ff29,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-ee3aad23-7d6c-4856-9ce0-17e8056ed178,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-ae4c3c98-bb07-45fb-aa8a-6fc5faf55762,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-d1260322-73b7-4c3d-a023-6a65e4783d52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828742116-172.17.0.8-1595493047793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40233,DS-473ff9cd-ed64-4e17-8475-7f60a934b0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-b3211e70-3a8b-4f83-b907-1f8386717e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-3b06aa93-c7c6-4b17-802a-7ed1c323d575,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-60c10750-3b16-407a-b871-3e71aaf9e568,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-92cf4b54-bc24-45b8-bdaf-2c0e6134158e,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-d1f0abb2-1efb-4ec0-a17b-6b2ec96ad5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-2fc9887a-9582-4caf-bbd2-d6b857d82830,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-c30e0fc1-6371-460f-9af4-678daf21d0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828742116-172.17.0.8-1595493047793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40233,DS-473ff9cd-ed64-4e17-8475-7f60a934b0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-b3211e70-3a8b-4f83-b907-1f8386717e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-3b06aa93-c7c6-4b17-802a-7ed1c323d575,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-60c10750-3b16-407a-b871-3e71aaf9e568,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-92cf4b54-bc24-45b8-bdaf-2c0e6134158e,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-d1f0abb2-1efb-4ec0-a17b-6b2ec96ad5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-2fc9887a-9582-4caf-bbd2-d6b857d82830,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-c30e0fc1-6371-460f-9af4-678daf21d0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572563282-172.17.0.8-1595493189706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44877,DS-87229726-aa00-41c2-8304-146762df0ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-1132fbbe-6d85-4052-94ca-80baa26054af,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-6993369a-e11f-4e1c-9c91-cf03ed697160,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-156775b6-7e82-432a-892d-aaa8ede181ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-ec061d34-3543-4fc5-bbc1-7a1d0ad942cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-0c9a7d11-da37-4bde-9bfb-2402f868ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-0501b2d8-b884-4b50-a3f1-9e32d1b33f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-76c9d08d-c005-4964-bbea-24b75f61ff32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572563282-172.17.0.8-1595493189706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44877,DS-87229726-aa00-41c2-8304-146762df0ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-1132fbbe-6d85-4052-94ca-80baa26054af,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-6993369a-e11f-4e1c-9c91-cf03ed697160,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-156775b6-7e82-432a-892d-aaa8ede181ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-ec061d34-3543-4fc5-bbc1-7a1d0ad942cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-0c9a7d11-da37-4bde-9bfb-2402f868ebbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-0501b2d8-b884-4b50-a3f1-9e32d1b33f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-76c9d08d-c005-4964-bbea-24b75f61ff32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157066244-172.17.0.8-1595493225795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34726,DS-cb82d697-304a-427b-8653-99e88231bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-0b1d6841-f128-43fc-83c9-94f4f35d99f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-f8a4e5b5-6c32-4862-9fa5-36a8fbaf0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-4668ff8a-57fc-44ef-8aa7-2bff1571ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-b978663a-65d3-4015-9828-adb00468e638,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-4d2ae19f-e7fe-4fa7-af33-c04c973231d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-0c9c19b4-7664-431d-8c14-a89899fc9146,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-7ee215f4-788e-459b-839e-8ee284d18b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157066244-172.17.0.8-1595493225795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34726,DS-cb82d697-304a-427b-8653-99e88231bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-0b1d6841-f128-43fc-83c9-94f4f35d99f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-f8a4e5b5-6c32-4862-9fa5-36a8fbaf0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-4668ff8a-57fc-44ef-8aa7-2bff1571ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-b978663a-65d3-4015-9828-adb00468e638,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-4d2ae19f-e7fe-4fa7-af33-c04c973231d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-0c9c19b4-7664-431d-8c14-a89899fc9146,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-7ee215f4-788e-459b-839e-8ee284d18b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508868665-172.17.0.8-1595493251950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44709,DS-679bd0db-8b5c-4041-a621-0edec888b98b,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-d97459db-8a82-4253-8bda-0c6631dba8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-8f1b91bb-8772-4244-9553-0100f2d50f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-d35fd0d2-9c7d-4a4f-b027-f665979fd8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-f70aecdf-3795-4638-bf2d-5bf816465876,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-a64466fe-2fff-4bbf-aa41-a335f8d73ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-bb8ffc34-6c41-4ade-9671-7e1a5232815c,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-daee915b-fbf3-4a1e-beb6-80a0dfcfb136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508868665-172.17.0.8-1595493251950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44709,DS-679bd0db-8b5c-4041-a621-0edec888b98b,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-d97459db-8a82-4253-8bda-0c6631dba8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-8f1b91bb-8772-4244-9553-0100f2d50f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-d35fd0d2-9c7d-4a4f-b027-f665979fd8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-f70aecdf-3795-4638-bf2d-5bf816465876,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-a64466fe-2fff-4bbf-aa41-a335f8d73ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-bb8ffc34-6c41-4ade-9671-7e1a5232815c,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-daee915b-fbf3-4a1e-beb6-80a0dfcfb136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308555328-172.17.0.8-1595493420834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34345,DS-e19f49ef-5681-43e6-b79d-49d65b942833,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-d3832136-b877-4c2b-8475-626f99567c33,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-c7c5539e-fdb7-431b-af76-8c59c2ea6734,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-61dc0013-373b-41c5-96f6-7b61e6706741,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-01d0341a-2fc6-406b-8630-957324be54b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-c07b2203-6e94-4f61-8cc2-48ac30c34bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-38047473-5789-4736-b177-077727bbb5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-e24125c7-53e3-40cd-936e-8abe48384918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308555328-172.17.0.8-1595493420834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34345,DS-e19f49ef-5681-43e6-b79d-49d65b942833,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-d3832136-b877-4c2b-8475-626f99567c33,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-c7c5539e-fdb7-431b-af76-8c59c2ea6734,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-61dc0013-373b-41c5-96f6-7b61e6706741,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-01d0341a-2fc6-406b-8630-957324be54b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-c07b2203-6e94-4f61-8cc2-48ac30c34bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-38047473-5789-4736-b177-077727bbb5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-e24125c7-53e3-40cd-936e-8abe48384918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-455353663-172.17.0.8-1595493523790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-47434410-bb1a-42a2-9fac-680a9f65e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-e3cd2e89-4801-476b-a21a-e3b2fd089083,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-2dda765e-705c-4b01-9491-6c3cf3d4c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-5496292b-6608-4a22-9bf1-10e6170dc110,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-2ec42497-0b30-495f-a18b-a2914d7bd361,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-369d9be3-4f72-4377-94c4-2181effc3dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-cbe6c898-5502-4baf-b99f-68e379c7ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-47ab5b5c-2ad0-45d8-b650-1a1371103c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-455353663-172.17.0.8-1595493523790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-47434410-bb1a-42a2-9fac-680a9f65e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-e3cd2e89-4801-476b-a21a-e3b2fd089083,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-2dda765e-705c-4b01-9491-6c3cf3d4c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-5496292b-6608-4a22-9bf1-10e6170dc110,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-2ec42497-0b30-495f-a18b-a2914d7bd361,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-369d9be3-4f72-4377-94c4-2181effc3dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-cbe6c898-5502-4baf-b99f-68e379c7ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-47ab5b5c-2ad0-45d8-b650-1a1371103c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448752275-172.17.0.8-1595493858672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-7f0a1b6e-4767-480d-a537-c4c1b41363c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-71b6777e-4f77-454a-92be-c925fdf459df,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-2473136c-fadd-4fb6-ae6d-5b261ddd244c,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-3718f206-4f75-4410-b602-92c1c3cca3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-db89fff6-a54a-4a1e-8690-f1a0387b724a,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-ff77eca7-efe2-454b-b5fb-87862e041930,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-f7afeb8a-32cd-453a-b042-b7843781b945,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-5d13a2a5-da0f-4350-b862-e4dfcded7b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448752275-172.17.0.8-1595493858672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-7f0a1b6e-4767-480d-a537-c4c1b41363c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-71b6777e-4f77-454a-92be-c925fdf459df,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-2473136c-fadd-4fb6-ae6d-5b261ddd244c,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-3718f206-4f75-4410-b602-92c1c3cca3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-db89fff6-a54a-4a1e-8690-f1a0387b724a,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-ff77eca7-efe2-454b-b5fb-87862e041930,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-f7afeb8a-32cd-453a-b042-b7843781b945,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-5d13a2a5-da0f-4350-b862-e4dfcded7b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684253943-172.17.0.8-1595494079319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38533,DS-8de2e28a-b757-4d83-872c-fdc21ff4d033,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-b888bbee-c42d-4728-92ac-f8d701bdaca1,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-9b5147f3-6883-4e20-a758-18d4d18881a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-6bd7ff60-d756-4894-a466-aaf761f6438c,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-ff2eb657-4d30-4b5b-bc90-a464c14f4521,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-7349465a-d380-4e79-89f3-13aff0865209,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-cd86e905-3c99-403a-9004-24a221b43097,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-5590b8fd-0914-4b2b-8430-dba56c813aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684253943-172.17.0.8-1595494079319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38533,DS-8de2e28a-b757-4d83-872c-fdc21ff4d033,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-b888bbee-c42d-4728-92ac-f8d701bdaca1,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-9b5147f3-6883-4e20-a758-18d4d18881a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-6bd7ff60-d756-4894-a466-aaf761f6438c,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-ff2eb657-4d30-4b5b-bc90-a464c14f4521,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-7349465a-d380-4e79-89f3-13aff0865209,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-cd86e905-3c99-403a-9004-24a221b43097,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-5590b8fd-0914-4b2b-8430-dba56c813aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747354747-172.17.0.8-1595494253839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-36e03471-bbb6-4161-a2e1-453a0cba31f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-388ecc8f-e8cc-436e-9ca6-503b94980fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-50322847-cdb7-4716-a6b3-b5fbfa0529df,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-0be78aa2-9ee0-45b1-9bd5-1e018c17ff6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-22b95d26-5a88-4d8b-a06f-5e7b1be01a42,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-4c2a833b-c6e9-4793-bc11-716eac18c96e,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-f55d7a74-229f-45f7-b8d1-62867951d297,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-11da888d-aa93-4895-b216-05e01b62993b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747354747-172.17.0.8-1595494253839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-36e03471-bbb6-4161-a2e1-453a0cba31f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-388ecc8f-e8cc-436e-9ca6-503b94980fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-50322847-cdb7-4716-a6b3-b5fbfa0529df,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-0be78aa2-9ee0-45b1-9bd5-1e018c17ff6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-22b95d26-5a88-4d8b-a06f-5e7b1be01a42,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-4c2a833b-c6e9-4793-bc11-716eac18c96e,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-f55d7a74-229f-45f7-b8d1-62867951d297,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-11da888d-aa93-4895-b216-05e01b62993b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947295260-172.17.0.8-1595494325656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42887,DS-9b8a9221-c3ba-4266-b4a3-96242eb09c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-6b86d7d3-7ce0-4f57-9453-6d7ce5d624db,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-affb9c00-2ffe-45ad-8e67-66542c51d623,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-87f24094-56eb-4c71-98f6-e6ed619572ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-3fe8d345-497c-4ebe-9383-2ab0ab94f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-80450061-9d69-4830-a93d-316715a41f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-247a3b4d-7c88-4d73-baac-7c874dd110f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-2dfab285-0bc8-48ec-b4be-7fd1d7f78770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947295260-172.17.0.8-1595494325656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42887,DS-9b8a9221-c3ba-4266-b4a3-96242eb09c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-6b86d7d3-7ce0-4f57-9453-6d7ce5d624db,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-affb9c00-2ffe-45ad-8e67-66542c51d623,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-87f24094-56eb-4c71-98f6-e6ed619572ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-3fe8d345-497c-4ebe-9383-2ab0ab94f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-80450061-9d69-4830-a93d-316715a41f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-247a3b4d-7c88-4d73-baac-7c874dd110f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-2dfab285-0bc8-48ec-b4be-7fd1d7f78770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556729498-172.17.0.8-1595494452761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-0b1d46e5-0312-4478-8432-13ee83506b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-21a3ae28-b045-47f9-80d5-77c83689ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-020a2abd-6d53-4079-b3be-6cd2365c6e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-e4acdad4-9baa-4d0c-bde1-99dc691eb1be,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-6518fb19-c96a-41d6-bb1b-20eed15b88df,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-5a23910d-c485-4ab9-be1b-1ee624e408b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-41891974-9258-496f-ba88-4a8416480ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-185c239b-a98d-468e-a8a7-a9a277332d82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556729498-172.17.0.8-1595494452761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-0b1d46e5-0312-4478-8432-13ee83506b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-21a3ae28-b045-47f9-80d5-77c83689ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-020a2abd-6d53-4079-b3be-6cd2365c6e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-e4acdad4-9baa-4d0c-bde1-99dc691eb1be,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-6518fb19-c96a-41d6-bb1b-20eed15b88df,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-5a23910d-c485-4ab9-be1b-1ee624e408b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-41891974-9258-496f-ba88-4a8416480ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-185c239b-a98d-468e-a8a7-a9a277332d82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648188475-172.17.0.8-1595494606809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39568,DS-a9342b4f-6fef-433d-8f59-59a9adef06e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-a4379150-77a5-4d5d-9991-fafc1d616a41,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-a6713e2c-d061-4c22-a3ca-16ba0ce516da,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-0bca5a50-db4c-4f60-a486-74a45030f018,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-e5e8a977-252f-41de-9823-bcb87a9096a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-aed23e91-1d51-41be-85d1-cb4e990240bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-5934ef0a-80c6-4253-8111-b70090c04a43,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-73519a7e-a1d9-4d02-a1b0-7813a49b7f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648188475-172.17.0.8-1595494606809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39568,DS-a9342b4f-6fef-433d-8f59-59a9adef06e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-a4379150-77a5-4d5d-9991-fafc1d616a41,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-a6713e2c-d061-4c22-a3ca-16ba0ce516da,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-0bca5a50-db4c-4f60-a486-74a45030f018,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-e5e8a977-252f-41de-9823-bcb87a9096a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-aed23e91-1d51-41be-85d1-cb4e990240bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-5934ef0a-80c6-4253-8111-b70090c04a43,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-73519a7e-a1d9-4d02-a1b0-7813a49b7f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16470543-172.17.0.8-1595494741132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-256bd9c4-9f77-4f2e-b3b5-75bb8f395d65,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-8f626490-132b-41d7-b28a-2ade7daab39b,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-46532e0a-8bc8-4f65-b841-ed6cedbffcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-05ed4f3b-4d5f-4e56-abad-71e5a00c19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-36848d12-24b9-4d49-921d-afdfbf35bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-f672a795-85a9-4e57-825c-b76d1d8e5884,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-6a04e816-6c46-41fe-8dc2-a1d2bbccd431,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-14b9244c-f5e1-4d3b-8eba-3e7041b45d3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16470543-172.17.0.8-1595494741132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-256bd9c4-9f77-4f2e-b3b5-75bb8f395d65,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-8f626490-132b-41d7-b28a-2ade7daab39b,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-46532e0a-8bc8-4f65-b841-ed6cedbffcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-05ed4f3b-4d5f-4e56-abad-71e5a00c19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-36848d12-24b9-4d49-921d-afdfbf35bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-f672a795-85a9-4e57-825c-b76d1d8e5884,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-6a04e816-6c46-41fe-8dc2-a1d2bbccd431,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-14b9244c-f5e1-4d3b-8eba-3e7041b45d3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176869199-172.17.0.8-1595494944772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34088,DS-c42eac4e-3fc9-4efc-8484-7a2875b1a7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-44981a90-93cf-49fb-9896-e4a9f248b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-d26889cc-10e3-4831-91d9-79c66521e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-e2bcffb2-070f-432d-8b39-3b79583220ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-8702d242-54cd-4727-bb1c-f1b0ab104cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-75546d3c-b7d4-428e-84e1-af5f5e3c04f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-5ce2057a-ae88-48e6-8ba7-b2a68eff62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-175d1bd4-1ca6-4820-8d25-faa0a4528b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176869199-172.17.0.8-1595494944772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34088,DS-c42eac4e-3fc9-4efc-8484-7a2875b1a7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-44981a90-93cf-49fb-9896-e4a9f248b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-d26889cc-10e3-4831-91d9-79c66521e7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-e2bcffb2-070f-432d-8b39-3b79583220ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-8702d242-54cd-4727-bb1c-f1b0ab104cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-75546d3c-b7d4-428e-84e1-af5f5e3c04f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-5ce2057a-ae88-48e6-8ba7-b2a68eff62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-175d1bd4-1ca6-4820-8d25-faa0a4528b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5222
