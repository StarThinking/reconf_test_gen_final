reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391833061-172.17.0.21-1595495363671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-bbab55b0-cd59-4f58-8aa8-e1cbe929ca63,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-3a55c3bc-c3c5-4968-8346-8d5cb7ad9717,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-00718378-2796-49ed-9fce-212d4dc49752,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-d3cabfe9-78d1-43e7-a17d-b6147c8f7b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-0ec0a6c9-9485-4653-ac2b-2e2a9282ccb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-f80f09af-5cdb-417f-8f4d-f1b88650f3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-bf827790-7892-44f7-9b55-eaa532808e19,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-6455a67c-ab05-4e65-8501-be6cacd51aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391833061-172.17.0.21-1595495363671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-bbab55b0-cd59-4f58-8aa8-e1cbe929ca63,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-3a55c3bc-c3c5-4968-8346-8d5cb7ad9717,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-00718378-2796-49ed-9fce-212d4dc49752,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-d3cabfe9-78d1-43e7-a17d-b6147c8f7b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-0ec0a6c9-9485-4653-ac2b-2e2a9282ccb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-f80f09af-5cdb-417f-8f4d-f1b88650f3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-bf827790-7892-44f7-9b55-eaa532808e19,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-6455a67c-ab05-4e65-8501-be6cacd51aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487568334-172.17.0.21-1595495711331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36931,DS-086226c9-77c9-4711-8ee8-773a47688739,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-8704ac23-0539-4f76-bf40-3a3124b450b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-9e504b9e-127e-46aa-8c3a-58d296dcfab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-894e90b6-4b4e-44b0-8f6a-015d64b112aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-21efe274-6f94-4527-b57e-c6ce0a3b4a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-a6809583-68b4-46ad-bc22-a33e86c73622,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-63f892d4-0d75-4897-af4f-ed7d35b7f839,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-94405685-302d-4e49-86cd-0b0f0674a85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487568334-172.17.0.21-1595495711331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36931,DS-086226c9-77c9-4711-8ee8-773a47688739,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-8704ac23-0539-4f76-bf40-3a3124b450b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-9e504b9e-127e-46aa-8c3a-58d296dcfab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-894e90b6-4b4e-44b0-8f6a-015d64b112aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-21efe274-6f94-4527-b57e-c6ce0a3b4a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-a6809583-68b4-46ad-bc22-a33e86c73622,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-63f892d4-0d75-4897-af4f-ed7d35b7f839,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-94405685-302d-4e49-86cd-0b0f0674a85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428425359-172.17.0.21-1595495742107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-fed65692-129f-4eed-b0f8-12e41a5be0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-58807e56-cd4a-4704-a83d-a5a052f6a30c,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-2344c73e-b30e-40ff-9f25-0e125918d329,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-d63e6753-485c-4eab-a47a-0bf5a7402266,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-2bad3851-30c5-4dca-b5fb-48675fc78d62,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-9649bf65-d921-4af9-9a53-ef81af248f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-a3de1b3c-eaae-4a82-8274-538e76575ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-8f293cae-fd83-4efd-b0e6-b7dbefcff96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428425359-172.17.0.21-1595495742107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-fed65692-129f-4eed-b0f8-12e41a5be0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-58807e56-cd4a-4704-a83d-a5a052f6a30c,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-2344c73e-b30e-40ff-9f25-0e125918d329,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-d63e6753-485c-4eab-a47a-0bf5a7402266,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-2bad3851-30c5-4dca-b5fb-48675fc78d62,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-9649bf65-d921-4af9-9a53-ef81af248f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-a3de1b3c-eaae-4a82-8274-538e76575ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-8f293cae-fd83-4efd-b0e6-b7dbefcff96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507958363-172.17.0.21-1595496178241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-b0d7e49a-2df5-43dc-86c9-39984561b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-4d36160d-2815-4c4c-a40b-31c788dd2823,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-33d3a462-7884-4048-a4dd-601ef8c84f48,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-645f222b-cbbd-467f-96ab-6f030f231646,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-a3d07973-26d6-4ad9-9381-01559cfab1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-84474863-7b67-4c77-9090-80a3b13e54f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-6a88c9e4-9049-40ee-8760-9cf1ec9d57d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-c33e7c41-8cfe-4062-bd62-48e759b3add9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507958363-172.17.0.21-1595496178241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-b0d7e49a-2df5-43dc-86c9-39984561b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-4d36160d-2815-4c4c-a40b-31c788dd2823,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-33d3a462-7884-4048-a4dd-601ef8c84f48,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-645f222b-cbbd-467f-96ab-6f030f231646,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-a3d07973-26d6-4ad9-9381-01559cfab1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-84474863-7b67-4c77-9090-80a3b13e54f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-6a88c9e4-9049-40ee-8760-9cf1ec9d57d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-c33e7c41-8cfe-4062-bd62-48e759b3add9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685039696-172.17.0.21-1595496391084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-17027613-f460-40a7-927d-60ad3d9ca85b,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-c7906202-0c71-4297-b44a-af9923637c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-3826715c-72c2-40a5-8f0e-1316da8e97f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-a8e553f1-5cce-4e70-8594-75cbae3674a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-9090d605-26f0-4d2b-a3ad-250c6349d5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-4abdc0de-8807-49f5-96da-86374c5da4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-261680f6-4fec-4aa5-8a31-cceb72e777ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-1d3560e4-c8e4-49ec-863d-d7116e3886e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685039696-172.17.0.21-1595496391084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-17027613-f460-40a7-927d-60ad3d9ca85b,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-c7906202-0c71-4297-b44a-af9923637c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-3826715c-72c2-40a5-8f0e-1316da8e97f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-a8e553f1-5cce-4e70-8594-75cbae3674a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-9090d605-26f0-4d2b-a3ad-250c6349d5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-4abdc0de-8807-49f5-96da-86374c5da4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-261680f6-4fec-4aa5-8a31-cceb72e777ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-1d3560e4-c8e4-49ec-863d-d7116e3886e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406708562-172.17.0.21-1595496682022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38054,DS-7ffaf0f8-e3e1-4f8b-a90d-7ca56501c537,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-63704700-d404-4173-aaf0-09b4f7c6463f,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-def56a2c-ede3-4e9a-9197-dbd4a71a3ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-cdcac60d-4316-4c0a-8531-4f838b59b06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-810e8387-f798-4697-89d2-375c822c6a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-4df0a5f8-c66b-4448-8568-6d453fada366,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-774fd752-a797-4645-ba3c-880b5c1d1582,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-179ba915-a96a-4e6e-9174-d142c06bf338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406708562-172.17.0.21-1595496682022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38054,DS-7ffaf0f8-e3e1-4f8b-a90d-7ca56501c537,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-63704700-d404-4173-aaf0-09b4f7c6463f,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-def56a2c-ede3-4e9a-9197-dbd4a71a3ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-cdcac60d-4316-4c0a-8531-4f838b59b06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-810e8387-f798-4697-89d2-375c822c6a48,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-4df0a5f8-c66b-4448-8568-6d453fada366,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-774fd752-a797-4645-ba3c-880b5c1d1582,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-179ba915-a96a-4e6e-9174-d142c06bf338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609360977-172.17.0.21-1595496751372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-0a8b8522-6058-4d81-8e58-1d924e67c2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-50fa1bb5-9694-4e6b-be79-c7be8d6f03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-7af66b43-3578-419e-aac2-8179cba7308a,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-a7b4e66d-9378-4415-86a9-d5564df418b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-e574e1e8-c224-4a6d-be1c-da3db2153b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-acfdaef6-4356-4e44-af6e-b3120ac8871b,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-6932c7cc-c54c-4da1-913a-0bca7c753847,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-4a69472d-e753-452d-adc9-6c88401c56c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609360977-172.17.0.21-1595496751372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-0a8b8522-6058-4d81-8e58-1d924e67c2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-50fa1bb5-9694-4e6b-be79-c7be8d6f03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-7af66b43-3578-419e-aac2-8179cba7308a,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-a7b4e66d-9378-4415-86a9-d5564df418b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-e574e1e8-c224-4a6d-be1c-da3db2153b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-acfdaef6-4356-4e44-af6e-b3120ac8871b,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-6932c7cc-c54c-4da1-913a-0bca7c753847,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-4a69472d-e753-452d-adc9-6c88401c56c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141122718-172.17.0.21-1595496828147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41228,DS-200ccfcb-8737-4ad5-90cc-be7a64c0dee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-a4a3fea9-a42f-4b35-a6d1-387ace5e907e,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-d5d7bb3f-f6da-4683-8d40-1150a26ea3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-a167bd07-de31-4d6d-a74d-9c042d6bbbac,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-66931261-cdf5-4b41-9fe8-abf3a9cc9528,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-9daab16f-d4bf-43f2-a6dd-8d9e4362cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-91ec0f22-c6a7-48c0-bb56-10a2af820aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-0746dce3-1935-40f3-a30b-4fa9248d522e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141122718-172.17.0.21-1595496828147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41228,DS-200ccfcb-8737-4ad5-90cc-be7a64c0dee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-a4a3fea9-a42f-4b35-a6d1-387ace5e907e,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-d5d7bb3f-f6da-4683-8d40-1150a26ea3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-a167bd07-de31-4d6d-a74d-9c042d6bbbac,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-66931261-cdf5-4b41-9fe8-abf3a9cc9528,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-9daab16f-d4bf-43f2-a6dd-8d9e4362cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-91ec0f22-c6a7-48c0-bb56-10a2af820aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-0746dce3-1935-40f3-a30b-4fa9248d522e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111445854-172.17.0.21-1595497179760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33101,DS-e11a56db-27a3-4df6-a11d-597e7ffceccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-c5ff1eed-ba56-4d04-88c9-13f2a40fbbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-11c8f323-5bc0-4897-8e01-8875c8dafd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-29399311-3bfc-4bed-9648-214ff93ba634,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-20a30b34-71c7-42d2-b71b-aeba1d9ae37f,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-57c7a3ce-d447-4d08-aeb4-f10b8844c238,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-24a75d8a-f18e-40a0-ad75-1471a8c5d863,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-b14b053b-46ae-4a48-8c95-7b76dae717a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111445854-172.17.0.21-1595497179760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33101,DS-e11a56db-27a3-4df6-a11d-597e7ffceccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-c5ff1eed-ba56-4d04-88c9-13f2a40fbbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-11c8f323-5bc0-4897-8e01-8875c8dafd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-29399311-3bfc-4bed-9648-214ff93ba634,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-20a30b34-71c7-42d2-b71b-aeba1d9ae37f,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-57c7a3ce-d447-4d08-aeb4-f10b8844c238,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-24a75d8a-f18e-40a0-ad75-1471a8c5d863,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-b14b053b-46ae-4a48-8c95-7b76dae717a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223250006-172.17.0.21-1595497282031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-edabff69-e5af-4585-978f-0a5ce96d21e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-5f908f54-5673-444b-957e-f9a663bc92bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-2f76c9e7-2e64-4e47-a0f8-db44890761ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-cd2d6019-d807-4f44-82af-91253ffd4747,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-eada39bc-b127-4a9d-820d-c2fbbd37763a,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-e451d3fa-3e67-492b-ba7c-f884fa3d5b67,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-bf869759-1cc4-4ca8-b76c-04d03f04701d,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-82565e7f-b748-4af4-818a-69d663f0af50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223250006-172.17.0.21-1595497282031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-edabff69-e5af-4585-978f-0a5ce96d21e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-5f908f54-5673-444b-957e-f9a663bc92bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-2f76c9e7-2e64-4e47-a0f8-db44890761ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-cd2d6019-d807-4f44-82af-91253ffd4747,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-eada39bc-b127-4a9d-820d-c2fbbd37763a,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-e451d3fa-3e67-492b-ba7c-f884fa3d5b67,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-bf869759-1cc4-4ca8-b76c-04d03f04701d,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-82565e7f-b748-4af4-818a-69d663f0af50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676122574-172.17.0.21-1595497315667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-dc2ecc18-58a1-4ea4-b87b-e670db868590,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-a27e41a6-61df-4e10-b6a3-64998a76dfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-ba34994a-4b48-40a5-aaa6-b9214bb9a400,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-2d2a21c8-5905-43cd-8809-c4c56c331f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-149d0210-3549-44e8-8b0c-fd0455a6bcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-1d1dc25f-8994-430f-bf9c-ff1b730f0238,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-7df61b21-a5d2-4115-989f-5110fcb0d01d,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-688b04a3-1d35-4b57-9d24-f316b73b1449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676122574-172.17.0.21-1595497315667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-dc2ecc18-58a1-4ea4-b87b-e670db868590,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-a27e41a6-61df-4e10-b6a3-64998a76dfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-ba34994a-4b48-40a5-aaa6-b9214bb9a400,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-2d2a21c8-5905-43cd-8809-c4c56c331f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-149d0210-3549-44e8-8b0c-fd0455a6bcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-1d1dc25f-8994-430f-bf9c-ff1b730f0238,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-7df61b21-a5d2-4115-989f-5110fcb0d01d,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-688b04a3-1d35-4b57-9d24-f316b73b1449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846957989-172.17.0.21-1595497846208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45974,DS-5d88e14a-aea9-4342-9d70-5bd324a63a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-61f77e73-1e11-4c74-bf0c-6c9fb6f36555,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-ea56483e-fea5-4203-bd69-cff67d63f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-32a27789-1c8f-4c31-9a6f-48c54f95361d,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-c1cf21e2-af7a-42c7-af46-6d0b0d12a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-6db0cb2f-7d74-4ffd-a2dc-a7c6059a168d,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-79ed0bbe-19b7-4669-b59e-0ebc5fac8ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-e624b1d7-916e-40b5-bc8f-d22e08842348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846957989-172.17.0.21-1595497846208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45974,DS-5d88e14a-aea9-4342-9d70-5bd324a63a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-61f77e73-1e11-4c74-bf0c-6c9fb6f36555,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-ea56483e-fea5-4203-bd69-cff67d63f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-32a27789-1c8f-4c31-9a6f-48c54f95361d,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-c1cf21e2-af7a-42c7-af46-6d0b0d12a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-6db0cb2f-7d74-4ffd-a2dc-a7c6059a168d,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-79ed0bbe-19b7-4669-b59e-0ebc5fac8ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-e624b1d7-916e-40b5-bc8f-d22e08842348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795746991-172.17.0.21-1595497915936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43931,DS-b2091b68-88cb-41f7-89c3-49bb232c4f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-7a4ae599-6dda-413c-9bb5-80abedeec0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-f86a2131-20af-4852-bc66-ca8c4d3df7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-cbf18290-52e5-4110-aeb0-82c040c23ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-ee448468-25e0-4f6b-8ddb-42de8781f372,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-ff905b10-ffb8-4ecd-84c8-623d7920a4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-83643d93-2a64-40ce-be3e-ff00553910c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-56a7adbb-54db-475c-ae6d-1d105272828d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795746991-172.17.0.21-1595497915936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43931,DS-b2091b68-88cb-41f7-89c3-49bb232c4f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-7a4ae599-6dda-413c-9bb5-80abedeec0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-f86a2131-20af-4852-bc66-ca8c4d3df7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-cbf18290-52e5-4110-aeb0-82c040c23ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-ee448468-25e0-4f6b-8ddb-42de8781f372,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-ff905b10-ffb8-4ecd-84c8-623d7920a4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-83643d93-2a64-40ce-be3e-ff00553910c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-56a7adbb-54db-475c-ae6d-1d105272828d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220703783-172.17.0.21-1595498089431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44003,DS-52ef04c6-73c4-4aa4-8095-26c474108cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-775e22e9-1695-4eb1-8d22-d4cb2db3c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-dc4253c8-127d-4e57-ae47-405500bb5aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-4b25919f-4ba2-4837-9ee1-85ea67474427,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-a4fa5014-8c46-4c35-b070-94122261840e,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-61f8e28a-c01e-4bdc-b9f9-409afb3d868a,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-d74a187c-9710-47d2-9503-f1f0f4ac1f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-ceea4e8b-48a9-4ed6-8608-5fa664cb89a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220703783-172.17.0.21-1595498089431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44003,DS-52ef04c6-73c4-4aa4-8095-26c474108cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-775e22e9-1695-4eb1-8d22-d4cb2db3c07b,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-dc4253c8-127d-4e57-ae47-405500bb5aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-4b25919f-4ba2-4837-9ee1-85ea67474427,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-a4fa5014-8c46-4c35-b070-94122261840e,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-61f8e28a-c01e-4bdc-b9f9-409afb3d868a,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-d74a187c-9710-47d2-9503-f1f0f4ac1f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-ceea4e8b-48a9-4ed6-8608-5fa664cb89a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432886665-172.17.0.21-1595498195285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-0ea6954b-9b50-4aa4-9aec-a57588415bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-ed2feeb5-70a3-44d2-96cb-2842579995fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-188e6797-f4da-42b8-997d-bd7a0c559b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-7bf40813-0296-4ac5-88c4-ab202d3a0e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-cd344a05-d309-44e7-8ef0-2cf350c2ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-276c7cec-e3fb-488d-9878-4d9feebd6c01,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-08620bf4-0153-4776-9ee7-f305813678c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-db07105b-450d-423d-818c-5cc81d80673e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432886665-172.17.0.21-1595498195285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-0ea6954b-9b50-4aa4-9aec-a57588415bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-ed2feeb5-70a3-44d2-96cb-2842579995fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-188e6797-f4da-42b8-997d-bd7a0c559b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-7bf40813-0296-4ac5-88c4-ab202d3a0e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-cd344a05-d309-44e7-8ef0-2cf350c2ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-276c7cec-e3fb-488d-9878-4d9feebd6c01,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-08620bf4-0153-4776-9ee7-f305813678c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-db07105b-450d-423d-818c-5cc81d80673e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643962735-172.17.0.21-1595498231472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-84fa42bf-8f9c-481e-93fd-d56d5ab124cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-4cb0b035-fbf2-4645-9865-14139ef33e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-057181dc-6346-4906-8254-76aab65ebfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-ad539716-6e2c-4fc2-9abe-e79a9333e024,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-1f4770ce-9e3c-476f-b5f7-5089afd91719,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-23f9844d-02ad-4621-89be-1794486d57f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-807bca96-20b6-4e52-a35a-274af0bfc43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-fb11d89a-bef0-47e5-99ff-f1d3b5c460d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643962735-172.17.0.21-1595498231472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-84fa42bf-8f9c-481e-93fd-d56d5ab124cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-4cb0b035-fbf2-4645-9865-14139ef33e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-057181dc-6346-4906-8254-76aab65ebfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-ad539716-6e2c-4fc2-9abe-e79a9333e024,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-1f4770ce-9e3c-476f-b5f7-5089afd91719,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-23f9844d-02ad-4621-89be-1794486d57f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-807bca96-20b6-4e52-a35a-274af0bfc43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-fb11d89a-bef0-47e5-99ff-f1d3b5c460d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799364841-172.17.0.21-1595498549989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35330,DS-73dbacc0-ba63-4131-b406-6196864d15d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-d1a2e4e7-b035-4bf6-9040-74604f6f0c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-0cdf7667-0ea0-4a76-8e3e-5922ca86b75e,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-2573ddc9-1220-4515-955a-e7cfc4713a14,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-a83dd230-601c-4e2b-bdc4-384429ea97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-27ab952d-a464-4b51-9209-b4b0d2ff00cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-e1fc6521-acd6-46e4-b4bf-1ada8512d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-134c8b7d-04a0-45ba-8d1f-35d85f9320bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799364841-172.17.0.21-1595498549989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35330,DS-73dbacc0-ba63-4131-b406-6196864d15d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-d1a2e4e7-b035-4bf6-9040-74604f6f0c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-0cdf7667-0ea0-4a76-8e3e-5922ca86b75e,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-2573ddc9-1220-4515-955a-e7cfc4713a14,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-a83dd230-601c-4e2b-bdc4-384429ea97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-27ab952d-a464-4b51-9209-b4b0d2ff00cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-e1fc6521-acd6-46e4-b4bf-1ada8512d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-134c8b7d-04a0-45ba-8d1f-35d85f9320bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282889726-172.17.0.21-1595498584676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43902,DS-4cc998e6-f675-4770-8e11-c2705e63623b,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-81486ed2-2201-4eed-be7a-3500829137cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-9eff98cb-30a5-489d-899d-cb45471db457,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f7f4d994-e81e-4d34-b5b8-3a020a4445a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-f45b9923-bcaf-4065-a678-f4a5e4dbca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-9c123181-a72a-4fdb-baf6-e3069e0cd88b,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-cfbfae5f-ecc0-4b1e-b8ac-78e414530a58,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-1b439924-aa16-4b65-a4b0-88be9174c5b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282889726-172.17.0.21-1595498584676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43902,DS-4cc998e6-f675-4770-8e11-c2705e63623b,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-81486ed2-2201-4eed-be7a-3500829137cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-9eff98cb-30a5-489d-899d-cb45471db457,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f7f4d994-e81e-4d34-b5b8-3a020a4445a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-f45b9923-bcaf-4065-a678-f4a5e4dbca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-9c123181-a72a-4fdb-baf6-e3069e0cd88b,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-cfbfae5f-ecc0-4b1e-b8ac-78e414530a58,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-1b439924-aa16-4b65-a4b0-88be9174c5b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969592757-172.17.0.21-1595498723813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-dcfc00dd-ddc5-4147-9a1f-619e5dd71be5,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-e9ae3c88-69da-4d0d-a1f2-b84c687372a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-aa1d7bb1-e657-4dff-9392-6e7ee1181ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-e4256143-d01f-4e2d-97ae-3026d1060b55,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-406e86e9-1809-4350-b833-6094cba13124,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-5d920aa8-41ae-46a8-ad3d-530d42518d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-aca3ea32-0171-4001-9805-800bac1945cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-3ddc0edb-07ff-4973-82e2-be6d1e2847ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969592757-172.17.0.21-1595498723813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-dcfc00dd-ddc5-4147-9a1f-619e5dd71be5,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-e9ae3c88-69da-4d0d-a1f2-b84c687372a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-aa1d7bb1-e657-4dff-9392-6e7ee1181ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-e4256143-d01f-4e2d-97ae-3026d1060b55,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-406e86e9-1809-4350-b833-6094cba13124,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-5d920aa8-41ae-46a8-ad3d-530d42518d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-aca3ea32-0171-4001-9805-800bac1945cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-3ddc0edb-07ff-4973-82e2-be6d1e2847ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392898001-172.17.0.21-1595499004704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43212,DS-64fdb494-7b9c-48f1-b915-7dbb4ddfbfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-9a526469-042c-4e54-be1a-9240db411777,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-8e8edbee-3c8b-4902-9a4e-b286b3a5a25d,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-d34cbf4c-5b01-4bd7-946d-04d9946ae344,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-ad619d6e-9222-4216-a228-3ff16468a2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-4bf33d25-bf23-4c8b-8b87-9fa60276d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-33970d46-2b13-48ee-9a83-ee6b7ce340a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-44dbef2d-dede-4640-8fc0-05af36820f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392898001-172.17.0.21-1595499004704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43212,DS-64fdb494-7b9c-48f1-b915-7dbb4ddfbfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-9a526469-042c-4e54-be1a-9240db411777,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-8e8edbee-3c8b-4902-9a4e-b286b3a5a25d,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-d34cbf4c-5b01-4bd7-946d-04d9946ae344,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-ad619d6e-9222-4216-a228-3ff16468a2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-4bf33d25-bf23-4c8b-8b87-9fa60276d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-33970d46-2b13-48ee-9a83-ee6b7ce340a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-44dbef2d-dede-4640-8fc0-05af36820f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947067425-172.17.0.21-1595499079606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43696,DS-a3a1d570-7f78-4a80-8658-6b3711a2c7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-cd4fed32-432a-4153-85b3-309c5ac553ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-009c2ebd-066c-4001-872e-2f43226b8955,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-6f1e3968-22ee-4585-bd64-1383188e3ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-88bff73d-4714-4ddb-8916-06380a812a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-ac4da141-95c6-46b6-91aa-3366403f0c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-a21a3b6a-b6a9-44dd-94c0-6599c8d8ecab,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-6932a7ee-2c66-4120-ad14-2adbc3b01cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947067425-172.17.0.21-1595499079606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43696,DS-a3a1d570-7f78-4a80-8658-6b3711a2c7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-cd4fed32-432a-4153-85b3-309c5ac553ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-009c2ebd-066c-4001-872e-2f43226b8955,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-6f1e3968-22ee-4585-bd64-1383188e3ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-88bff73d-4714-4ddb-8916-06380a812a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-ac4da141-95c6-46b6-91aa-3366403f0c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-a21a3b6a-b6a9-44dd-94c0-6599c8d8ecab,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-6932a7ee-2c66-4120-ad14-2adbc3b01cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196507759-172.17.0.21-1595499152065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40349,DS-e74565d8-2667-45bd-bf4b-291b27410b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-1ab95cb5-7087-4e4c-bc38-a232253e0ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-89c536f4-782e-43be-b24d-0d4f3063e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-d0bb8674-f907-43de-8a33-7d47e50bb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-849e1caa-802a-453b-9359-202063126c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-17357658-5af6-45db-a0aa-e3dec95f9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-da260af1-18c0-4889-a0e3-815a9504249d,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-11de809b-e31b-46d6-89f9-399c24d0c7e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196507759-172.17.0.21-1595499152065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40349,DS-e74565d8-2667-45bd-bf4b-291b27410b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-1ab95cb5-7087-4e4c-bc38-a232253e0ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-89c536f4-782e-43be-b24d-0d4f3063e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-d0bb8674-f907-43de-8a33-7d47e50bb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-849e1caa-802a-453b-9359-202063126c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-17357658-5af6-45db-a0aa-e3dec95f9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-da260af1-18c0-4889-a0e3-815a9504249d,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-11de809b-e31b-46d6-89f9-399c24d0c7e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468214820-172.17.0.21-1595499261171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-78b245ee-d39b-42f8-b5a7-301c1079fc94,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-a28ad1c2-f1e7-4075-b9ac-4d1d795d5507,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-32329079-248e-4d34-ac07-c0f72fad5b83,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-ec17ff17-3f62-4155-8ce5-a18cf706515e,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-660206e2-6287-4152-aaac-687fd3fe2a63,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-3ecc2918-e9d2-4159-a25e-603fbec1b096,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-c5912cd1-cca2-4014-a9e7-439d1f070521,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-b29ece0a-7526-4d0c-93d0-7dcbae8751b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468214820-172.17.0.21-1595499261171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-78b245ee-d39b-42f8-b5a7-301c1079fc94,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-a28ad1c2-f1e7-4075-b9ac-4d1d795d5507,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-32329079-248e-4d34-ac07-c0f72fad5b83,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-ec17ff17-3f62-4155-8ce5-a18cf706515e,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-660206e2-6287-4152-aaac-687fd3fe2a63,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-3ecc2918-e9d2-4159-a25e-603fbec1b096,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-c5912cd1-cca2-4014-a9e7-439d1f070521,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-b29ece0a-7526-4d0c-93d0-7dcbae8751b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560757056-172.17.0.21-1595499589778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41331,DS-d08689fb-8b12-4d25-b2c7-1d77b913dc36,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-a726d6c1-83c4-4648-bcb0-722d2b0f0944,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-f5fbf55f-8ecd-4d2c-98cb-c57411556fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-1c1894eb-3c04-4227-81c0-ef8095bbecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-20606bb0-f72a-4d1f-baad-2566bff0d8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-ac463571-4a3e-4af7-b81d-434abcc6af3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-5a4c17d5-3048-4932-bfad-747ba20ff4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-edaede99-7789-4f25-95c1-d593e7dfc4c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560757056-172.17.0.21-1595499589778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41331,DS-d08689fb-8b12-4d25-b2c7-1d77b913dc36,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-a726d6c1-83c4-4648-bcb0-722d2b0f0944,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-f5fbf55f-8ecd-4d2c-98cb-c57411556fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-1c1894eb-3c04-4227-81c0-ef8095bbecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-20606bb0-f72a-4d1f-baad-2566bff0d8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-ac463571-4a3e-4af7-b81d-434abcc6af3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-5a4c17d5-3048-4932-bfad-747ba20ff4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-edaede99-7789-4f25-95c1-d593e7dfc4c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852388145-172.17.0.21-1595499656470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-d28e75b4-846b-42dd-bb6e-4b989c791808,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-84861ec1-b8a4-48e6-a6e8-18727e53316f,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-89db9909-6151-4bcc-a2f3-99e279d3ae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-2945363c-f0f4-4db5-a8a6-ec3518e71bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-fb2a26fe-02d6-4020-858c-161fad99aad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-bb8b439a-ad6e-474b-9e63-ec242f17d439,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-b214e21d-424c-4094-b3bf-0f66d1f54096,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-945c777f-5bfd-4eb0-9980-bf0dc81d345f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852388145-172.17.0.21-1595499656470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-d28e75b4-846b-42dd-bb6e-4b989c791808,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-84861ec1-b8a4-48e6-a6e8-18727e53316f,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-89db9909-6151-4bcc-a2f3-99e279d3ae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-2945363c-f0f4-4db5-a8a6-ec3518e71bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-fb2a26fe-02d6-4020-858c-161fad99aad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-bb8b439a-ad6e-474b-9e63-ec242f17d439,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-b214e21d-424c-4094-b3bf-0f66d1f54096,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-945c777f-5bfd-4eb0-9980-bf0dc81d345f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1073741824
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9717537-172.17.0.21-1595499817779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32776,DS-b5d430ea-b0ab-4125-ba5b-8efddc00cc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-2c783348-b805-4f7c-951e-482463e8e1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-440b8c90-d49d-472b-a5fe-62033e7f9480,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-989785d3-373e-40dd-8f1e-fa6c941b5305,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-b0ea1bed-917e-44c6-a61f-7cec92df154d,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-4a07715a-9a4c-4617-8767-eba8c4023213,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-80247437-4bc6-40ac-a466-613f0d4f44c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-b6c83670-f710-4d06-99d4-994b644251c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9717537-172.17.0.21-1595499817779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32776,DS-b5d430ea-b0ab-4125-ba5b-8efddc00cc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-2c783348-b805-4f7c-951e-482463e8e1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-440b8c90-d49d-472b-a5fe-62033e7f9480,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-989785d3-373e-40dd-8f1e-fa6c941b5305,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-b0ea1bed-917e-44c6-a61f-7cec92df154d,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-4a07715a-9a4c-4617-8767-eba8c4023213,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-80247437-4bc6-40ac-a466-613f0d4f44c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-b6c83670-f710-4d06-99d4-994b644251c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5247
