reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60951276-172.17.0.17-1595631792397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43615,DS-681305db-fc29-4ee7-aeb6-6fef6badc305,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-7f6a2e35-4053-4f99-8b89-3284df3c8b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-bf68ddc2-51a7-4a80-8e82-12d944d556e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-ff22a8e0-70f1-41b8-9393-eabd71a91a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-caa2b35c-200b-458c-b588-3740ed463123,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-f556aa8d-1e8c-4b78-9684-f01c995ff2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-f966e89b-35cf-45ab-a3cc-0b3691ea9449,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-11d718c7-2cb2-43f1-96ea-33202e62c039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60951276-172.17.0.17-1595631792397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43615,DS-681305db-fc29-4ee7-aeb6-6fef6badc305,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-7f6a2e35-4053-4f99-8b89-3284df3c8b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-bf68ddc2-51a7-4a80-8e82-12d944d556e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-ff22a8e0-70f1-41b8-9393-eabd71a91a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-caa2b35c-200b-458c-b588-3740ed463123,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-f556aa8d-1e8c-4b78-9684-f01c995ff2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-f966e89b-35cf-45ab-a3cc-0b3691ea9449,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-11d718c7-2cb2-43f1-96ea-33202e62c039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482189876-172.17.0.17-1595632689183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33616,DS-b461d47e-605a-4d7d-bf88-876f3735c034,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-6af609f2-3319-4f9c-8daf-28ed96ab167f,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-e077a18d-d31a-4615-a6b5-4b31269c5139,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-af152459-e128-4e2e-b6e1-192e7adc2d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-2acb1619-1a96-4734-b2c2-95cd24e5e135,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-896e34ab-b28c-4a9c-8a2a-f06a174ee658,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-2bb8808f-dda7-48c7-85d1-431dc04f040d,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-1eda9d75-3ae2-46f3-965f-25a64a3341e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482189876-172.17.0.17-1595632689183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33616,DS-b461d47e-605a-4d7d-bf88-876f3735c034,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-6af609f2-3319-4f9c-8daf-28ed96ab167f,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-e077a18d-d31a-4615-a6b5-4b31269c5139,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-af152459-e128-4e2e-b6e1-192e7adc2d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-2acb1619-1a96-4734-b2c2-95cd24e5e135,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-896e34ab-b28c-4a9c-8a2a-f06a174ee658,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-2bb8808f-dda7-48c7-85d1-431dc04f040d,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-1eda9d75-3ae2-46f3-965f-25a64a3341e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905060594-172.17.0.17-1595632805940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-43825e04-ecb2-41db-a0d3-c39e0ea45197,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-68bb05de-d789-4301-9fe6-39a827af1ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-29d31142-c49e-415e-9142-4d991af76462,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-f34c28e1-316e-4736-a00d-16618837ce35,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-04987218-2cb2-45af-9f32-d8066011038a,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-9e665696-3185-4ecf-826f-d7a4cffaaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-0c807933-b5d0-4f4e-932b-e365d070b944,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-8f551787-af0c-477d-b891-eaa2b1a11894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905060594-172.17.0.17-1595632805940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-43825e04-ecb2-41db-a0d3-c39e0ea45197,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-68bb05de-d789-4301-9fe6-39a827af1ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-29d31142-c49e-415e-9142-4d991af76462,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-f34c28e1-316e-4736-a00d-16618837ce35,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-04987218-2cb2-45af-9f32-d8066011038a,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-9e665696-3185-4ecf-826f-d7a4cffaaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-0c807933-b5d0-4f4e-932b-e365d070b944,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-8f551787-af0c-477d-b891-eaa2b1a11894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853921180-172.17.0.17-1595633093550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-4e25d3b6-45a9-4545-9483-37cee5d4571d,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-a0eb12ae-7b4b-413f-a09a-69e991650899,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-07e0047b-f54f-4210-8a6c-1bd43180f837,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-7cb7e2f1-4b43-4a49-8761-d3eff68c5b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-1af07c44-25c6-4fe9-bb88-7e6673104e34,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-3d077e1f-bc78-4576-8e62-39a597d1b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-89da14d3-ef01-4e2e-9149-c03008675cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-d10061da-945a-477b-a377-d0ab227c38f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853921180-172.17.0.17-1595633093550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-4e25d3b6-45a9-4545-9483-37cee5d4571d,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-a0eb12ae-7b4b-413f-a09a-69e991650899,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-07e0047b-f54f-4210-8a6c-1bd43180f837,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-7cb7e2f1-4b43-4a49-8761-d3eff68c5b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-1af07c44-25c6-4fe9-bb88-7e6673104e34,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-3d077e1f-bc78-4576-8e62-39a597d1b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-89da14d3-ef01-4e2e-9149-c03008675cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-d10061da-945a-477b-a377-d0ab227c38f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279131912-172.17.0.17-1595633897503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40130,DS-74344797-3886-40bf-b0de-a6dcf834acb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-ab0fe434-85e4-4233-a981-042d30aff92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-d0be3c14-623e-4a0a-885b-03b2e03ba708,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-da9e1fbb-f2a5-498e-8354-79e6038354b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-a82dda77-0574-4727-a356-1925efe6a040,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-6cb10ca7-213b-443a-842f-9c771ae49ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-c94ba6f2-1527-417e-bd32-4e3112be9c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-0fdc3cfe-555b-4d2c-a5b6-39d00db48c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279131912-172.17.0.17-1595633897503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40130,DS-74344797-3886-40bf-b0de-a6dcf834acb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-ab0fe434-85e4-4233-a981-042d30aff92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-d0be3c14-623e-4a0a-885b-03b2e03ba708,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-da9e1fbb-f2a5-498e-8354-79e6038354b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-a82dda77-0574-4727-a356-1925efe6a040,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-6cb10ca7-213b-443a-842f-9c771ae49ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-c94ba6f2-1527-417e-bd32-4e3112be9c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-0fdc3cfe-555b-4d2c-a5b6-39d00db48c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638790008-172.17.0.17-1595634085396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34707,DS-6c59a133-1970-417e-9f81-63c959412f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-0d50bd33-a2e8-49a1-a92e-b68b50d85519,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-75aa3437-42b5-4bf4-8169-20ca61f22c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-b646191c-6d36-4303-a1c3-7b5716f35fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-59523e3c-8f55-4570-aff7-f482bf778782,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-2d3a2ae5-95a8-43d5-9042-df0a4a436262,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-7ccce426-3e1d-497a-b749-5990b4c19ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-708ef1f5-9c3e-4902-89c9-a89f09c73582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638790008-172.17.0.17-1595634085396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34707,DS-6c59a133-1970-417e-9f81-63c959412f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-0d50bd33-a2e8-49a1-a92e-b68b50d85519,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-75aa3437-42b5-4bf4-8169-20ca61f22c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-b646191c-6d36-4303-a1c3-7b5716f35fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-59523e3c-8f55-4570-aff7-f482bf778782,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-2d3a2ae5-95a8-43d5-9042-df0a4a436262,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-7ccce426-3e1d-497a-b749-5990b4c19ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-708ef1f5-9c3e-4902-89c9-a89f09c73582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867237162-172.17.0.17-1595634231380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-66e2db0e-286b-463a-b2dd-cbac64725ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-418f76b5-7b21-45ef-a34c-5bd62726da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-a3e6fd56-4f22-4ca8-ae65-b6219eb1a84e,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-4938e07b-3c1c-476c-93cd-ea1a5aa69999,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-1d998c63-4b3f-47f4-aa78-4011fad9bd47,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-d22766a6-b9da-40ec-a6aa-08f36fe32f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-18b87d20-6ba6-4634-960a-fe405b051ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-a1645a16-100b-41c3-a22c-3c2956cde401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867237162-172.17.0.17-1595634231380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-66e2db0e-286b-463a-b2dd-cbac64725ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-418f76b5-7b21-45ef-a34c-5bd62726da1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-a3e6fd56-4f22-4ca8-ae65-b6219eb1a84e,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-4938e07b-3c1c-476c-93cd-ea1a5aa69999,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-1d998c63-4b3f-47f4-aa78-4011fad9bd47,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-d22766a6-b9da-40ec-a6aa-08f36fe32f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-18b87d20-6ba6-4634-960a-fe405b051ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-a1645a16-100b-41c3-a22c-3c2956cde401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757940390-172.17.0.17-1595634371156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-bfdece41-d2c6-4eb3-889f-388652c5054e,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-018a8a8f-b821-4149-b112-e6a371c4855c,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-fcfa650a-3736-481f-b213-d4b8d44e38cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-95657014-5881-46b4-82cd-076b04a0fff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-ddd0be4b-eb7a-4ca3-b934-11cb654fb998,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-f876661c-2080-463e-9bfc-f49554fd5dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-30a0010e-2f71-4723-81ce-b3f286e8fe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-65794a7e-6d25-43e4-9d01-3cfd65cfa985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757940390-172.17.0.17-1595634371156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-bfdece41-d2c6-4eb3-889f-388652c5054e,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-018a8a8f-b821-4149-b112-e6a371c4855c,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-fcfa650a-3736-481f-b213-d4b8d44e38cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-95657014-5881-46b4-82cd-076b04a0fff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-ddd0be4b-eb7a-4ca3-b934-11cb654fb998,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-f876661c-2080-463e-9bfc-f49554fd5dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-30a0010e-2f71-4723-81ce-b3f286e8fe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-65794a7e-6d25-43e4-9d01-3cfd65cfa985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597177935-172.17.0.17-1595634411125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40993,DS-54540d5e-5058-464c-8dfe-b6812a19ccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-54c543fb-5671-4023-a6b9-2da77da05740,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-d543c5bb-d948-4a85-9088-cba1f62d268f,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-a2f7da07-2606-4f10-be7c-944573484a57,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-8e04e88b-ce69-497c-9753-ee4b898e39f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-4065c5a5-1296-44d9-84c0-47ab3b65056e,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-e3cf4334-5c05-4b45-b58d-109521d8fe61,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-857f1e57-3a6a-42a9-8d62-c705604fc9b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597177935-172.17.0.17-1595634411125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40993,DS-54540d5e-5058-464c-8dfe-b6812a19ccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-54c543fb-5671-4023-a6b9-2da77da05740,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-d543c5bb-d948-4a85-9088-cba1f62d268f,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-a2f7da07-2606-4f10-be7c-944573484a57,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-8e04e88b-ce69-497c-9753-ee4b898e39f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-4065c5a5-1296-44d9-84c0-47ab3b65056e,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-e3cf4334-5c05-4b45-b58d-109521d8fe61,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-857f1e57-3a6a-42a9-8d62-c705604fc9b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759212078-172.17.0.17-1595634704566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-dd236e69-4e89-4538-ac6b-9ac908506ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-b6cbe045-1eb5-4b8a-9334-bb0c328968f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-b7cfabc7-7209-49f5-8e5c-5a7ad37abdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-8911c5bb-92cc-49cd-9f78-dd04172cd4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-60cf25a8-c7af-43f3-827d-8342f68f8750,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-91498fa6-0928-470e-bba4-3ef658f2d2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-2a06e05c-de42-46fc-a60b-d7904ba4996c,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-40d17683-92ee-48c0-9e85-b7e9fc9cfe6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759212078-172.17.0.17-1595634704566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-dd236e69-4e89-4538-ac6b-9ac908506ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-b6cbe045-1eb5-4b8a-9334-bb0c328968f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-b7cfabc7-7209-49f5-8e5c-5a7ad37abdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-8911c5bb-92cc-49cd-9f78-dd04172cd4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-60cf25a8-c7af-43f3-827d-8342f68f8750,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-91498fa6-0928-470e-bba4-3ef658f2d2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-2a06e05c-de42-46fc-a60b-d7904ba4996c,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-40d17683-92ee-48c0-9e85-b7e9fc9cfe6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205284318-172.17.0.17-1595634765753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45515,DS-fa23841c-3c8b-4634-ac98-f51242a21df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-d2f5e6b0-89bd-4a41-af1c-8908e8c9b917,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-6b241b0f-127e-4617-8314-20936fb173d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-f8cc19b3-49da-4191-86fe-37b368210080,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-7bc20981-09d5-443c-9bf5-649091b9723a,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-5e177ba1-7a2e-4030-8c3d-67b6bf1fe840,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-4d5d7ae1-ac33-40fd-857d-7b1d6b577e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-93efd686-19b0-4b9d-8057-f9a5915321ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205284318-172.17.0.17-1595634765753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45515,DS-fa23841c-3c8b-4634-ac98-f51242a21df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-d2f5e6b0-89bd-4a41-af1c-8908e8c9b917,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-6b241b0f-127e-4617-8314-20936fb173d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-f8cc19b3-49da-4191-86fe-37b368210080,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-7bc20981-09d5-443c-9bf5-649091b9723a,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-5e177ba1-7a2e-4030-8c3d-67b6bf1fe840,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-4d5d7ae1-ac33-40fd-857d-7b1d6b577e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-93efd686-19b0-4b9d-8057-f9a5915321ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576762576-172.17.0.17-1595635148336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46309,DS-63fa18cb-f133-4e2a-b346-c1a79a464abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-7e9bd95e-78ea-4831-b7c9-445a7c364120,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-2bb478d4-3d5d-4598-afba-b93aa55382ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-d4e77e7f-9d66-4632-af55-9a0e4f53cb34,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-525a5aab-d4a8-4412-b8b3-0a9ee473f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-b3bfd42e-058c-414f-b38a-19f304a05b52,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-b7c76763-7bfd-4226-8a8d-0db33794cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-4c1f265b-234f-4258-9082-c336536ddb3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576762576-172.17.0.17-1595635148336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46309,DS-63fa18cb-f133-4e2a-b346-c1a79a464abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-7e9bd95e-78ea-4831-b7c9-445a7c364120,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-2bb478d4-3d5d-4598-afba-b93aa55382ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-d4e77e7f-9d66-4632-af55-9a0e4f53cb34,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-525a5aab-d4a8-4412-b8b3-0a9ee473f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-b3bfd42e-058c-414f-b38a-19f304a05b52,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-b7c76763-7bfd-4226-8a8d-0db33794cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-4c1f265b-234f-4258-9082-c336536ddb3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789550660-172.17.0.17-1595635286004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42525,DS-b4ebaa0c-f635-40b4-8ed6-0f6ec0f792af,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-7794f0de-be11-4bc1-8d3b-5e91694b0bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-60f34bd6-458c-409e-89cc-fb346294c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-5561e02a-f541-4654-9cd2-e030b6411c56,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-048d8096-7bf4-46f4-91cd-99e7020b22d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-dbc38e34-3105-49e3-9dc3-f4d9a6a337e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-1c21307b-4e75-432e-ab70-d83cc1567c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-7a46fa62-c67d-483a-9f0a-8d62e812ae37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789550660-172.17.0.17-1595635286004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42525,DS-b4ebaa0c-f635-40b4-8ed6-0f6ec0f792af,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-7794f0de-be11-4bc1-8d3b-5e91694b0bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-60f34bd6-458c-409e-89cc-fb346294c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-5561e02a-f541-4654-9cd2-e030b6411c56,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-048d8096-7bf4-46f4-91cd-99e7020b22d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-dbc38e34-3105-49e3-9dc3-f4d9a6a337e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-1c21307b-4e75-432e-ab70-d83cc1567c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-7a46fa62-c67d-483a-9f0a-8d62e812ae37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839245303-172.17.0.17-1595636075626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38138,DS-b408efe6-a0c7-49f9-a7c1-11358c77cd74,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-6fa8ed6f-f09d-4b06-8075-ead669cfc833,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-66c0983e-6f43-4623-934a-31a8879d24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-2f342c4f-ab47-408f-b4ef-3e09f85b671f,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-5e53d67c-f146-47e3-9487-f969d2262cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-8ca511f8-fbb4-4646-b14b-1b73b486c350,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-8bbc0e43-913a-45a1-b0e1-f6aa8077659a,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-a1706eb1-2975-499c-8cb6-30deea52faed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839245303-172.17.0.17-1595636075626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38138,DS-b408efe6-a0c7-49f9-a7c1-11358c77cd74,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-6fa8ed6f-f09d-4b06-8075-ead669cfc833,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-66c0983e-6f43-4623-934a-31a8879d24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-2f342c4f-ab47-408f-b4ef-3e09f85b671f,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-5e53d67c-f146-47e3-9487-f969d2262cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-8ca511f8-fbb4-4646-b14b-1b73b486c350,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-8bbc0e43-913a-45a1-b0e1-f6aa8077659a,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-a1706eb1-2975-499c-8cb6-30deea52faed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111993661-172.17.0.17-1595636158716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40459,DS-116d424d-85d5-4fc0-9b51-d51b33ef9af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-28c581fc-c634-4022-95d9-be423734d1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-fdca19b8-3150-4839-92b9-614729a107e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-53b7f744-c909-449a-b449-f519be5db88a,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-7198c008-d081-40d6-ac2a-4fb13c64101c,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-ff7723d9-f34f-4955-b151-16d4c79b9bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-a19a5fe0-e3e5-4cf8-8cc1-95f41162a4db,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-df7beefd-5ecf-487a-8ce2-4b4156e2e437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111993661-172.17.0.17-1595636158716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40459,DS-116d424d-85d5-4fc0-9b51-d51b33ef9af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-28c581fc-c634-4022-95d9-be423734d1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-fdca19b8-3150-4839-92b9-614729a107e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-53b7f744-c909-449a-b449-f519be5db88a,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-7198c008-d081-40d6-ac2a-4fb13c64101c,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-ff7723d9-f34f-4955-b151-16d4c79b9bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-a19a5fe0-e3e5-4cf8-8cc1-95f41162a4db,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-df7beefd-5ecf-487a-8ce2-4b4156e2e437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092927086-172.17.0.17-1595636720384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34696,DS-92c093e5-be7b-4446-8b8d-bd26e317e069,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-f28b1b69-a51a-4d9f-9d4f-7b3bdb6296ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-366c6834-4052-413c-9789-f9da08c23bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-3eeff840-a1fa-480f-8ea7-9f64fcf7d2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-c7e5135e-cd13-45a3-866c-549fc1f92032,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-e5742b42-8354-42e1-a130-885ec9f88da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-f60e270b-815d-4a15-a75d-e7d3c39fd84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-13548c8a-0b3b-4aee-9115-93dcfeae0361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092927086-172.17.0.17-1595636720384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34696,DS-92c093e5-be7b-4446-8b8d-bd26e317e069,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-f28b1b69-a51a-4d9f-9d4f-7b3bdb6296ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-366c6834-4052-413c-9789-f9da08c23bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-3eeff840-a1fa-480f-8ea7-9f64fcf7d2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-c7e5135e-cd13-45a3-866c-549fc1f92032,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-e5742b42-8354-42e1-a130-885ec9f88da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-f60e270b-815d-4a15-a75d-e7d3c39fd84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-13548c8a-0b3b-4aee-9115-93dcfeae0361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829898278-172.17.0.17-1595637232596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-9d199d7d-808a-4f51-8c92-403869e35ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-98594c90-bed8-457a-aa53-66ab53ccf7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-22d2c116-7594-44a4-a0dc-75d59f693c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-61cc8ed4-0e67-47e2-bf9d-526eaf94aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-19475cb6-848c-4493-8653-96694fcbbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-1adef05e-42a6-4926-91e4-49b5232acd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-b616b14a-8fad-43b7-bce0-989dbca261d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-80eefac5-8545-48cb-8b69-d9bbf4f6048e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829898278-172.17.0.17-1595637232596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-9d199d7d-808a-4f51-8c92-403869e35ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-98594c90-bed8-457a-aa53-66ab53ccf7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-22d2c116-7594-44a4-a0dc-75d59f693c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-61cc8ed4-0e67-47e2-bf9d-526eaf94aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-19475cb6-848c-4493-8653-96694fcbbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-1adef05e-42a6-4926-91e4-49b5232acd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-b616b14a-8fad-43b7-bce0-989dbca261d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-80eefac5-8545-48cb-8b69-d9bbf4f6048e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960020112-172.17.0.17-1595637509722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-e5157ede-8b0a-40d0-a187-a68b1cb0a343,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-12cbf8c8-e779-4341-9771-33dcffa09e03,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-2f9cf932-f187-47d8-ba59-35f50858d9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-dc2f516b-dfa8-46b9-a138-9ff0cb71d445,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-03d754b0-7019-499f-8a6b-6af0bc17f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-3725de0a-7881-4b26-9fb3-d03ddb626107,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-c23d89c8-a587-4ffb-93de-3a7e85920994,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-55c195a8-3f60-4f19-92da-7e6499ae5d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960020112-172.17.0.17-1595637509722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-e5157ede-8b0a-40d0-a187-a68b1cb0a343,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-12cbf8c8-e779-4341-9771-33dcffa09e03,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-2f9cf932-f187-47d8-ba59-35f50858d9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-dc2f516b-dfa8-46b9-a138-9ff0cb71d445,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-03d754b0-7019-499f-8a6b-6af0bc17f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-3725de0a-7881-4b26-9fb3-d03ddb626107,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-c23d89c8-a587-4ffb-93de-3a7e85920994,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-55c195a8-3f60-4f19-92da-7e6499ae5d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776875052-172.17.0.17-1595637588664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44764,DS-82009d87-bb5c-4a65-bb97-ed70fded4c60,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-b485cb02-5394-426d-8cfc-701a3cc21445,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-57d2d990-a9db-4644-8003-0f48cc1fd7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-bca7aa18-4553-4ec1-8583-985bfa5dddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-bd108c13-ea95-4dc9-9f26-d4f35aaa6e83,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-df12952d-30fe-4d63-b761-90a08f5889a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-99b80472-871b-4ded-8ebd-dcd9bfa471a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-abe1c558-ad08-4d9e-8381-d0c70664d4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776875052-172.17.0.17-1595637588664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44764,DS-82009d87-bb5c-4a65-bb97-ed70fded4c60,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-b485cb02-5394-426d-8cfc-701a3cc21445,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-57d2d990-a9db-4644-8003-0f48cc1fd7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-bca7aa18-4553-4ec1-8583-985bfa5dddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-bd108c13-ea95-4dc9-9f26-d4f35aaa6e83,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-df12952d-30fe-4d63-b761-90a08f5889a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-99b80472-871b-4ded-8ebd-dcd9bfa471a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-abe1c558-ad08-4d9e-8381-d0c70664d4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 1
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484183151-172.17.0.17-1595638036380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-e7ac1637-db19-418d-8c68-2d9d3ac5aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-7d5b9a2d-9e58-474f-bc0d-a3712de3d017,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-5c363a34-a5a4-4e08-8484-7f1579d35b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-e91f650b-2156-4fc7-aef0-387771d98f44,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-606d32fd-44b4-448e-a357-81bab03c7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-1594e7e7-4293-4661-ae03-acd0e7a22105,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-5ed8c36c-4798-470a-bad8-d75388624244,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-2cc357cd-feb9-49d8-a7bd-10f55acdb10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484183151-172.17.0.17-1595638036380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-e7ac1637-db19-418d-8c68-2d9d3ac5aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-7d5b9a2d-9e58-474f-bc0d-a3712de3d017,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-5c363a34-a5a4-4e08-8484-7f1579d35b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-e91f650b-2156-4fc7-aef0-387771d98f44,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-606d32fd-44b4-448e-a357-81bab03c7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-1594e7e7-4293-4661-ae03-acd0e7a22105,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-5ed8c36c-4798-470a-bad8-d75388624244,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-2cc357cd-feb9-49d8-a7bd-10f55acdb10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6980
