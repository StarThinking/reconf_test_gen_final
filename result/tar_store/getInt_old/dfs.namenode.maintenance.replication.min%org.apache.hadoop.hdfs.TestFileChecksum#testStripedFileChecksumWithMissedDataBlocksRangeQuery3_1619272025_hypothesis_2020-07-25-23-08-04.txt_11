reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666264196-172.17.0.14-1595719196037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46702,DS-24f2f631-7eae-4c0b-ac22-07477c5bb7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-eb7d3bd4-f6ed-42c9-83a9-f34be38333f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-2b497266-3efd-4114-a7f8-7a31f4113db0,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-b005e9bb-1b8e-43ac-b273-39b7366a16ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-b9adca08-ffbf-4b77-9ad1-c111bb842d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-cc725088-598e-4948-a228-3127b610dce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-ca22d10f-e6a4-4c5d-a0d0-f1e675e1c9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-e044f07c-8661-43f6-afe8-342d59aebe37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666264196-172.17.0.14-1595719196037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46702,DS-24f2f631-7eae-4c0b-ac22-07477c5bb7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-eb7d3bd4-f6ed-42c9-83a9-f34be38333f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-2b497266-3efd-4114-a7f8-7a31f4113db0,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-b005e9bb-1b8e-43ac-b273-39b7366a16ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-b9adca08-ffbf-4b77-9ad1-c111bb842d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-cc725088-598e-4948-a228-3127b610dce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-ca22d10f-e6a4-4c5d-a0d0-f1e675e1c9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-e044f07c-8661-43f6-afe8-342d59aebe37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16988240-172.17.0.14-1595719241312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32871,DS-d1651352-eebc-4a0e-8e95-2598e3593e23,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-9c93b6ac-f28f-4d73-bda7-a40da42f1e78,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-36686337-be24-4e3a-9b1c-15b1a3bac778,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-cf184d73-06cc-4642-93c8-9fac2f885db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-d2d8a154-0e02-4902-9bd5-ae244fb1e386,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-758babfe-5a54-421a-9bc5-dcd481068ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-3e300c5d-2774-44be-9ce5-b98d5641521e,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-352720d1-5363-4d61-bf25-5ed5e766f70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16988240-172.17.0.14-1595719241312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32871,DS-d1651352-eebc-4a0e-8e95-2598e3593e23,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-9c93b6ac-f28f-4d73-bda7-a40da42f1e78,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-36686337-be24-4e3a-9b1c-15b1a3bac778,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-cf184d73-06cc-4642-93c8-9fac2f885db6,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-d2d8a154-0e02-4902-9bd5-ae244fb1e386,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-758babfe-5a54-421a-9bc5-dcd481068ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-3e300c5d-2774-44be-9ce5-b98d5641521e,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-352720d1-5363-4d61-bf25-5ed5e766f70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132430395-172.17.0.14-1595719743663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-7030bcf0-d6f1-4c0c-8d64-ca86af96b34b,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-dac537b4-a035-4c8c-87f6-81887d73d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-a3cfe977-e88b-49c8-b3c7-ab5c314ce39d,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-c4e0e544-b2b0-4915-bdc8-a977f901e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-beda61a4-e125-4025-81d0-1e1d0afc65be,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-8d1fa714-f3b3-4f06-88b6-3db2585e90da,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-d5494322-87c5-4f1d-b187-2d217bb7743b,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-68dfc96a-7513-4fb4-b790-0f889e595068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132430395-172.17.0.14-1595719743663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-7030bcf0-d6f1-4c0c-8d64-ca86af96b34b,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-dac537b4-a035-4c8c-87f6-81887d73d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-a3cfe977-e88b-49c8-b3c7-ab5c314ce39d,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-c4e0e544-b2b0-4915-bdc8-a977f901e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-beda61a4-e125-4025-81d0-1e1d0afc65be,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-8d1fa714-f3b3-4f06-88b6-3db2585e90da,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-d5494322-87c5-4f1d-b187-2d217bb7743b,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-68dfc96a-7513-4fb4-b790-0f889e595068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956105620-172.17.0.14-1595719784196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33866,DS-764f3421-4cad-4af9-894a-6476d0f7f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-616b9194-7df8-4af7-99e0-e0cee8b92fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-366092d4-f472-4a90-9e4d-f24ceff2df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-6258d1a3-9f26-4c05-baf9-9cd322709922,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-323f56dd-06bd-4092-a166-e75d412a7677,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-46d7ba0a-6dd7-432f-b49a-e0e25a2ec1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-0604f113-a350-41a8-9e04-5b44e050f759,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-72baa363-8cc5-4258-b656-47e3712041c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956105620-172.17.0.14-1595719784196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33866,DS-764f3421-4cad-4af9-894a-6476d0f7f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-616b9194-7df8-4af7-99e0-e0cee8b92fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-366092d4-f472-4a90-9e4d-f24ceff2df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-6258d1a3-9f26-4c05-baf9-9cd322709922,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-323f56dd-06bd-4092-a166-e75d412a7677,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-46d7ba0a-6dd7-432f-b49a-e0e25a2ec1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-0604f113-a350-41a8-9e04-5b44e050f759,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-72baa363-8cc5-4258-b656-47e3712041c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318042368-172.17.0.14-1595719834326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-f2c9b03c-074d-438f-8ea5-1ffc5cade0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-44cecd58-4cfb-463b-bfc9-06ef2edccd23,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-764eab2d-b2a2-44bc-ad0d-03cc0b11fdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-75e674c7-f529-4a4c-8757-540298faca2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-ee30be06-dc2b-44e2-b831-33fd61d98d13,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-a60d3948-0858-4890-86a0-4bb28836ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-cf95d8a7-eafd-4f54-94ba-ec3077945f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-bbf9c4d0-250d-4efc-99fe-99e5ce769b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318042368-172.17.0.14-1595719834326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-f2c9b03c-074d-438f-8ea5-1ffc5cade0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-44cecd58-4cfb-463b-bfc9-06ef2edccd23,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-764eab2d-b2a2-44bc-ad0d-03cc0b11fdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-75e674c7-f529-4a4c-8757-540298faca2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-ee30be06-dc2b-44e2-b831-33fd61d98d13,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-a60d3948-0858-4890-86a0-4bb28836ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-cf95d8a7-eafd-4f54-94ba-ec3077945f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-bbf9c4d0-250d-4efc-99fe-99e5ce769b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10157970-172.17.0.14-1595719876149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43085,DS-c53300a2-844b-4b31-bc9f-ca18fa13672d,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-81c3f27f-13dc-4468-8f7b-6bd856e311bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-d6efd55f-5c59-4146-9ccc-1e860662c503,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-06ba143d-3873-4402-b6fd-6ca2143d5c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-bc53597c-7a27-4a46-8127-d73698306718,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-66db87e8-f62f-4609-bba5-b3f0faed6503,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-8d9c2cbd-76db-4c55-9664-15e7159d6fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-7fd6ed6c-139c-48b6-b716-d01a6578cb9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10157970-172.17.0.14-1595719876149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43085,DS-c53300a2-844b-4b31-bc9f-ca18fa13672d,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-81c3f27f-13dc-4468-8f7b-6bd856e311bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-d6efd55f-5c59-4146-9ccc-1e860662c503,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-06ba143d-3873-4402-b6fd-6ca2143d5c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-bc53597c-7a27-4a46-8127-d73698306718,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-66db87e8-f62f-4609-bba5-b3f0faed6503,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-8d9c2cbd-76db-4c55-9664-15e7159d6fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-7fd6ed6c-139c-48b6-b716-d01a6578cb9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424894913-172.17.0.14-1595719989590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43951,DS-df0be835-6197-409f-994b-3da4c0272fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-7a83e40e-abbe-4fe0-af42-1b7c0681c7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-3f620e5c-5bd4-4540-9086-e14c43481370,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-3375fe6b-7589-4a9e-97dc-760ccc2a9075,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-0833feec-587a-46c4-acf5-70a95749f16f,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-a1982b31-9662-4638-862b-a42abd668029,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-35cbfde1-049c-4d07-ac21-6f822ab51e12,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-3813261d-f610-448e-8faa-0502da855b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424894913-172.17.0.14-1595719989590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43951,DS-df0be835-6197-409f-994b-3da4c0272fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-7a83e40e-abbe-4fe0-af42-1b7c0681c7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-3f620e5c-5bd4-4540-9086-e14c43481370,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-3375fe6b-7589-4a9e-97dc-760ccc2a9075,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-0833feec-587a-46c4-acf5-70a95749f16f,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-a1982b31-9662-4638-862b-a42abd668029,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-35cbfde1-049c-4d07-ac21-6f822ab51e12,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-3813261d-f610-448e-8faa-0502da855b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098327202-172.17.0.14-1595720612692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-3695707f-47a7-4188-990c-98f9ad862f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-837580eb-0dd2-4bfc-8f56-14e3073d4fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-5a4ed71b-5809-4fc4-bb5e-651e28f4051d,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-ad7a3b84-23ac-4350-a8f6-6f391551201b,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-cf4d9e4b-abc8-4f88-a044-bb6e92199b93,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-fd3ec24e-ff01-475c-a5cf-7dee325fc0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-9082a73c-df64-43bf-a2d7-658890c4f6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-5d11f29e-b98e-4f59-bab2-22b50d6b7b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098327202-172.17.0.14-1595720612692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-3695707f-47a7-4188-990c-98f9ad862f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-837580eb-0dd2-4bfc-8f56-14e3073d4fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-5a4ed71b-5809-4fc4-bb5e-651e28f4051d,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-ad7a3b84-23ac-4350-a8f6-6f391551201b,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-cf4d9e4b-abc8-4f88-a044-bb6e92199b93,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-fd3ec24e-ff01-475c-a5cf-7dee325fc0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-9082a73c-df64-43bf-a2d7-658890c4f6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-5d11f29e-b98e-4f59-bab2-22b50d6b7b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523453377-172.17.0.14-1595720994723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43199,DS-8b1fe343-5b58-4750-b9d7-86b280e5b413,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-0b9acd66-0150-4005-979b-3f7f65308820,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-d6e56ed6-1ee2-485b-822c-246b01ddab16,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-66d61386-091c-490a-8d6c-6a931f72ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-160fc7d6-b426-4e18-9813-6d3d4743c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-957bcfec-8096-44a9-bd32-a9a6b9375f71,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-ecb3fbb4-37e0-402e-8bda-64e87884be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-d82db83b-eb68-4bf7-a333-e51deefcdcda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523453377-172.17.0.14-1595720994723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43199,DS-8b1fe343-5b58-4750-b9d7-86b280e5b413,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-0b9acd66-0150-4005-979b-3f7f65308820,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-d6e56ed6-1ee2-485b-822c-246b01ddab16,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-66d61386-091c-490a-8d6c-6a931f72ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-160fc7d6-b426-4e18-9813-6d3d4743c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-957bcfec-8096-44a9-bd32-a9a6b9375f71,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-ecb3fbb4-37e0-402e-8bda-64e87884be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-d82db83b-eb68-4bf7-a333-e51deefcdcda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590130963-172.17.0.14-1595721081112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44766,DS-ce1122e3-76b6-4cd7-887c-2e39c0315376,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-1196355d-dd46-4795-aac2-65d8f33775be,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-1fd47474-ccd9-4869-8ff3-9c22d5465b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-09e34739-78ab-4710-a768-faa22daa9752,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-16f5ba94-44ea-4a7a-95ea-c996fcfe8e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-3040d73e-8d23-4c45-bbcc-9fca1e21cc36,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-ebc4ceb5-f96c-447c-9492-9923a5ce7c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-ea45d79f-ec60-4493-b937-c10096626b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590130963-172.17.0.14-1595721081112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44766,DS-ce1122e3-76b6-4cd7-887c-2e39c0315376,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-1196355d-dd46-4795-aac2-65d8f33775be,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-1fd47474-ccd9-4869-8ff3-9c22d5465b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-09e34739-78ab-4710-a768-faa22daa9752,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-16f5ba94-44ea-4a7a-95ea-c996fcfe8e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-3040d73e-8d23-4c45-bbcc-9fca1e21cc36,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-ebc4ceb5-f96c-447c-9492-9923a5ce7c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-ea45d79f-ec60-4493-b937-c10096626b9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222201214-172.17.0.14-1595721377633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-47271894-87df-49c0-b182-0a0477cb362a,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-781f6016-1d81-4ccf-aa44-27133b7a2f69,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-938be453-e40a-41ac-b099-52edbeeae239,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-b542f48e-6ad0-42a6-96fe-a48def7da4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-d273397b-00fe-4ff0-9bb4-eb29aa81a520,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-ad4aafc9-1ebb-46f6-bee4-28021b685b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-036bd590-a584-41ef-9370-179a65c6f930,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-d05c08c7-3edf-4261-9b52-1063d30f7422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222201214-172.17.0.14-1595721377633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-47271894-87df-49c0-b182-0a0477cb362a,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-781f6016-1d81-4ccf-aa44-27133b7a2f69,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-938be453-e40a-41ac-b099-52edbeeae239,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-b542f48e-6ad0-42a6-96fe-a48def7da4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-d273397b-00fe-4ff0-9bb4-eb29aa81a520,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-ad4aafc9-1ebb-46f6-bee4-28021b685b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-036bd590-a584-41ef-9370-179a65c6f930,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-d05c08c7-3edf-4261-9b52-1063d30f7422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206480861-172.17.0.14-1595723314143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-409e8e7f-e922-49b0-ad9a-15068c9f9170,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-a6091a1f-f45f-402e-af7b-279194f4e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-6c5fac59-4b7a-44ac-be98-4557c31696de,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-1355f5d2-ae41-423c-8ee1-b7d5228e3bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-77d8d4c6-6c09-4d86-a40f-41346cf923a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-fc6d189e-f9ab-41c4-bb5e-427decfb56b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-0bfc710f-b76f-4d3b-93b4-e154acb7e520,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-0196c016-61e0-4b33-ac65-c160db36fa20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206480861-172.17.0.14-1595723314143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-409e8e7f-e922-49b0-ad9a-15068c9f9170,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-a6091a1f-f45f-402e-af7b-279194f4e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-6c5fac59-4b7a-44ac-be98-4557c31696de,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-1355f5d2-ae41-423c-8ee1-b7d5228e3bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-77d8d4c6-6c09-4d86-a40f-41346cf923a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-fc6d189e-f9ab-41c4-bb5e-427decfb56b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-0bfc710f-b76f-4d3b-93b4-e154acb7e520,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-0196c016-61e0-4b33-ac65-c160db36fa20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796440670-172.17.0.14-1595723522302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38943,DS-ee6881d8-a2d5-4112-ae4a-a4449866ccee,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-ba15d373-9333-4225-b244-d33dd54ce35c,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-a30079e6-8d13-4cf0-8bf7-4c9670665ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-c123ae0e-d7ef-43ea-acca-ec6812bff5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-1c4f52e7-205a-4ab4-862b-f727d438bdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-4445d448-bece-46cb-ad7a-607e93ceceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-3d83d98d-5edd-41e6-a9e9-08ce789c0f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-1d50ebcc-76e9-4f19-9f61-25b77bd58df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796440670-172.17.0.14-1595723522302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38943,DS-ee6881d8-a2d5-4112-ae4a-a4449866ccee,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-ba15d373-9333-4225-b244-d33dd54ce35c,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-a30079e6-8d13-4cf0-8bf7-4c9670665ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-c123ae0e-d7ef-43ea-acca-ec6812bff5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-1c4f52e7-205a-4ab4-862b-f727d438bdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-4445d448-bece-46cb-ad7a-607e93ceceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-3d83d98d-5edd-41e6-a9e9-08ce789c0f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-1d50ebcc-76e9-4f19-9f61-25b77bd58df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346077067-172.17.0.14-1595724215957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39050,DS-c89ea36f-2b67-4554-86c4-4f256853929b,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-b0fc441f-facd-4139-8020-6cd28b098ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-792f4e73-8ab8-4cdf-97c7-f668545c0afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-165443bb-b8ed-4066-98c3-c3306d567a11,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-3a201408-27cd-4c29-b21a-6e0fa1f2ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-86b809f8-6e45-469a-bd6f-31b3027a1263,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-0280b93c-54ca-4b91-b76c-57b2250e1edb,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-32a6de7f-def5-4d7a-b6cd-e7cba4e77ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346077067-172.17.0.14-1595724215957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39050,DS-c89ea36f-2b67-4554-86c4-4f256853929b,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-b0fc441f-facd-4139-8020-6cd28b098ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-792f4e73-8ab8-4cdf-97c7-f668545c0afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-165443bb-b8ed-4066-98c3-c3306d567a11,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-3a201408-27cd-4c29-b21a-6e0fa1f2ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-86b809f8-6e45-469a-bd6f-31b3027a1263,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-0280b93c-54ca-4b91-b76c-57b2250e1edb,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-32a6de7f-def5-4d7a-b6cd-e7cba4e77ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906223616-172.17.0.14-1595724500127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-3af94dac-8698-4c7e-b0fa-bae3b28be4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-7c351225-fe0b-4f6b-babc-2914c4841ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-fad58301-6aa2-4780-a3f9-9e539112f4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-5164881d-57f9-405c-8581-f8816d2de376,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-1b38e3ef-4063-4183-ba1c-007952c128f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-1fbdd854-8924-44f8-ad6b-8b4a6cdff6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-4fd66beb-463d-42ac-b029-ab810a6d3d01,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-b5694f1f-14c1-4f4d-bf96-88284c6b29ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906223616-172.17.0.14-1595724500127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-3af94dac-8698-4c7e-b0fa-bae3b28be4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-7c351225-fe0b-4f6b-babc-2914c4841ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-fad58301-6aa2-4780-a3f9-9e539112f4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-5164881d-57f9-405c-8581-f8816d2de376,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-1b38e3ef-4063-4183-ba1c-007952c128f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-1fbdd854-8924-44f8-ad6b-8b4a6cdff6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-4fd66beb-463d-42ac-b029-ab810a6d3d01,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-b5694f1f-14c1-4f4d-bf96-88284c6b29ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743316581-172.17.0.14-1595724584109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-c8dea938-a1f8-458c-98a1-5ca167acf9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-3dba4ca8-2028-45b1-afef-32835d3a1ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-b68fa2b2-85f4-4ce8-a085-135888ec266f,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-67af10d7-1d27-4e9d-9262-4ff4431f5e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-e773fe70-c7c7-4846-a805-deb02700f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-63123fb4-1f54-4a53-a09f-8050e66e1446,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-f977f0c4-307f-44ca-b257-69dc1cb96d18,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-ce7e9f16-6fe0-4d80-bc8d-cbc67a442c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743316581-172.17.0.14-1595724584109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34425,DS-c8dea938-a1f8-458c-98a1-5ca167acf9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-3dba4ca8-2028-45b1-afef-32835d3a1ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-b68fa2b2-85f4-4ce8-a085-135888ec266f,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-67af10d7-1d27-4e9d-9262-4ff4431f5e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-e773fe70-c7c7-4846-a805-deb02700f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-63123fb4-1f54-4a53-a09f-8050e66e1446,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-f977f0c4-307f-44ca-b257-69dc1cb96d18,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-ce7e9f16-6fe0-4d80-bc8d-cbc67a442c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912419996-172.17.0.14-1595724791502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-507efdb4-af6b-4ba6-b724-62d69685ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-37b20fe8-dcae-4a4a-a1b0-1dc3d625f1be,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-be7982bd-3882-451b-a04b-3e474dabc67d,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-784f7a60-ace1-4bfa-9a86-727754ca37a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-9626c60a-01fb-4697-a8f8-c255032c9984,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-be512586-ed6f-4bf0-bb02-b506bdb55619,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-dc53c05d-07c6-4173-8297-4a2e45d251c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-2f2c7f63-0134-4e0c-8ffe-86d37f6fb08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912419996-172.17.0.14-1595724791502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-507efdb4-af6b-4ba6-b724-62d69685ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-37b20fe8-dcae-4a4a-a1b0-1dc3d625f1be,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-be7982bd-3882-451b-a04b-3e474dabc67d,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-784f7a60-ace1-4bfa-9a86-727754ca37a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-9626c60a-01fb-4697-a8f8-c255032c9984,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-be512586-ed6f-4bf0-bb02-b506bdb55619,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-dc53c05d-07c6-4173-8297-4a2e45d251c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-2f2c7f63-0134-4e0c-8ffe-86d37f6fb08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6342
