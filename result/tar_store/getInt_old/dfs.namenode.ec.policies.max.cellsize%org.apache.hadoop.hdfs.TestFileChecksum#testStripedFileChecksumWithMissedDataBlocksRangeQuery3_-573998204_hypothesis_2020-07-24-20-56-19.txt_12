reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72599797-172.17.0.19-1595624338960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39324,DS-f484710a-485a-46fa-b25a-3f06e4749d85,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-ac09c56f-9862-49db-abe8-b23d69b7abf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-4cff3410-7516-4fe9-9a77-a714991ef9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-2cf64e4f-794a-4983-8f46-35fec18a0434,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-f23cd204-f2bc-4c6f-a59b-270b08c9eb34,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-9bc9dedb-1c6e-46e8-b489-50ac1744d673,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-6d050875-711f-4e84-aa02-e1e30f4094dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-a273bac7-9d63-4033-9d38-88158a060592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72599797-172.17.0.19-1595624338960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39324,DS-f484710a-485a-46fa-b25a-3f06e4749d85,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-ac09c56f-9862-49db-abe8-b23d69b7abf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-4cff3410-7516-4fe9-9a77-a714991ef9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-2cf64e4f-794a-4983-8f46-35fec18a0434,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-f23cd204-f2bc-4c6f-a59b-270b08c9eb34,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-9bc9dedb-1c6e-46e8-b489-50ac1744d673,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-6d050875-711f-4e84-aa02-e1e30f4094dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-a273bac7-9d63-4033-9d38-88158a060592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357128326-172.17.0.19-1595624491061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40551,DS-b5116600-d5cc-4b6b-9400-4a1b59acffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-8334f79b-8f18-4514-b7ec-ea0ee2a63abd,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-0e65ed1b-2a96-4a87-993f-bb51405adb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-76a51bc1-20db-4a3c-ade4-5c9828ac5ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-b2d786f2-2d65-4756-b6ca-e3c93d53ed83,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-ac835594-c93b-4849-80a0-96d5ecd9c052,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-3e9c7311-3082-4ea3-b73b-4777f40dd4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-ee1c8af2-a53d-4943-a162-0ed5a2d079b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357128326-172.17.0.19-1595624491061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40551,DS-b5116600-d5cc-4b6b-9400-4a1b59acffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-8334f79b-8f18-4514-b7ec-ea0ee2a63abd,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-0e65ed1b-2a96-4a87-993f-bb51405adb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-76a51bc1-20db-4a3c-ade4-5c9828ac5ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-b2d786f2-2d65-4756-b6ca-e3c93d53ed83,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-ac835594-c93b-4849-80a0-96d5ecd9c052,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-3e9c7311-3082-4ea3-b73b-4777f40dd4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-ee1c8af2-a53d-4943-a162-0ed5a2d079b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193248587-172.17.0.19-1595624940109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33477,DS-2ca8afbb-c01b-404d-87bc-bb7767ef7670,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-1aba15b0-1c34-4c95-9133-d2ce7271a6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-696ff53b-add9-4ad7-b3f1-99fcd2792877,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-c7ce6c05-6002-492f-9da4-f1b0541920c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-3b543076-ce29-4065-bc75-31e354b267bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-a37ba7ed-a8a6-471f-86b5-c11e8a41b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-37a28b57-dcdf-4c5b-8f42-6dc0e9993ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-26e19979-0f68-4735-8ecc-0ec675df2c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193248587-172.17.0.19-1595624940109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33477,DS-2ca8afbb-c01b-404d-87bc-bb7767ef7670,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-1aba15b0-1c34-4c95-9133-d2ce7271a6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-696ff53b-add9-4ad7-b3f1-99fcd2792877,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-c7ce6c05-6002-492f-9da4-f1b0541920c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-3b543076-ce29-4065-bc75-31e354b267bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-a37ba7ed-a8a6-471f-86b5-c11e8a41b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-37a28b57-dcdf-4c5b-8f42-6dc0e9993ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-26e19979-0f68-4735-8ecc-0ec675df2c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816684280-172.17.0.19-1595625610599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-79d24dc0-6507-4b47-84fe-8a8beac92236,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-8bad0dea-05f2-40ec-a1f2-f860d8af3589,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-8a28377f-6ea8-443a-b143-76b3f477c58d,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-51253e27-e654-491e-b268-7582d1ad0333,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-f36cc6ca-2120-41cb-812c-c460e98d509c,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-1bff0ddb-0e4b-47dd-9b21-d117f773c97c,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-f3f6cf81-3836-4d9b-a94c-33db4d1a65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-7de74891-d887-4b94-84a3-1f165baf6fb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816684280-172.17.0.19-1595625610599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-79d24dc0-6507-4b47-84fe-8a8beac92236,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-8bad0dea-05f2-40ec-a1f2-f860d8af3589,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-8a28377f-6ea8-443a-b143-76b3f477c58d,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-51253e27-e654-491e-b268-7582d1ad0333,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-f36cc6ca-2120-41cb-812c-c460e98d509c,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-1bff0ddb-0e4b-47dd-9b21-d117f773c97c,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-f3f6cf81-3836-4d9b-a94c-33db4d1a65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-7de74891-d887-4b94-84a3-1f165baf6fb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071367137-172.17.0.19-1595625646487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44689,DS-22d574a2-d970-47b1-9fb5-0912ef4b7ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-97e2140a-76b8-4919-a43c-df412819cc29,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-7098bdec-114f-45f6-833c-0abb5a286eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-132141b1-df99-4bf0-99db-449de9d881d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-6a3d84d5-254a-46b0-85fa-7fe124141e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-a6ef6b44-0b2f-4aa9-ac7a-e796ff556e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-3ccf2d9f-337a-4b39-bb65-1db69b4e2892,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-c452189e-c2fe-4744-942c-7f273d6473c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071367137-172.17.0.19-1595625646487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44689,DS-22d574a2-d970-47b1-9fb5-0912ef4b7ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-97e2140a-76b8-4919-a43c-df412819cc29,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-7098bdec-114f-45f6-833c-0abb5a286eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-132141b1-df99-4bf0-99db-449de9d881d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-6a3d84d5-254a-46b0-85fa-7fe124141e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-a6ef6b44-0b2f-4aa9-ac7a-e796ff556e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-3ccf2d9f-337a-4b39-bb65-1db69b4e2892,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-c452189e-c2fe-4744-942c-7f273d6473c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098677712-172.17.0.19-1595625724626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-34ed8aa9-ad8a-4a1b-a99a-b748cf0e8566,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-7e7e8d40-71aa-4b1c-964b-bc3439a3cbed,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-1ef3a2e0-b3fb-4f14-8e9f-b278f3a4084f,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-43064c60-6905-4265-bbce-23c9ec09d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-119e6d93-ccab-4e23-82ff-88ba299acf19,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-7d8f11e7-3949-4f06-907f-546778c43184,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-f50b5fdb-b67c-4192-a610-c0fefa30d0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-8b3e1f7a-4714-4109-b258-e18d6ecf51c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098677712-172.17.0.19-1595625724626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-34ed8aa9-ad8a-4a1b-a99a-b748cf0e8566,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-7e7e8d40-71aa-4b1c-964b-bc3439a3cbed,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-1ef3a2e0-b3fb-4f14-8e9f-b278f3a4084f,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-43064c60-6905-4265-bbce-23c9ec09d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-119e6d93-ccab-4e23-82ff-88ba299acf19,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-7d8f11e7-3949-4f06-907f-546778c43184,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-f50b5fdb-b67c-4192-a610-c0fefa30d0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-8b3e1f7a-4714-4109-b258-e18d6ecf51c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751389280-172.17.0.19-1595625808409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39122,DS-b3732e7f-31fd-4fb1-bafa-e56201de8b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b57b821e-e65e-4a87-9173-88234f2cb723,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-aede36be-c054-43c3-8acd-b6bf776b1ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-e810bb8e-5dc5-4be0-a21a-cf1df2a850b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-0d7c4044-eeb4-41b4-a840-f559749eb129,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-73e3c12e-0a00-4b41-b653-791cf8339b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-975de33c-1d69-4e6d-87e6-95e7e630905a,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-6cb456a0-af53-4748-b6d9-a6d5d3498517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751389280-172.17.0.19-1595625808409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39122,DS-b3732e7f-31fd-4fb1-bafa-e56201de8b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b57b821e-e65e-4a87-9173-88234f2cb723,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-aede36be-c054-43c3-8acd-b6bf776b1ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-e810bb8e-5dc5-4be0-a21a-cf1df2a850b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-0d7c4044-eeb4-41b4-a840-f559749eb129,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-73e3c12e-0a00-4b41-b653-791cf8339b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-975de33c-1d69-4e6d-87e6-95e7e630905a,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-6cb456a0-af53-4748-b6d9-a6d5d3498517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472133936-172.17.0.19-1595625956340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33267,DS-1457a708-ff52-468b-9545-010e8fa32bed,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-569921a0-00c9-48f3-b39a-dbed4260ebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-8dea73a3-2aaa-4381-9a38-8e322f49602e,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-52634f4d-05f0-4b5c-95cf-7ce743d8d7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-da50d50f-8486-4b8e-bd03-e311e347a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-22f02631-9170-4313-86a3-c9ba80787ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-1e0bb1d7-43a9-40c1-a47a-449b42e984d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-b8e7c3c8-05e5-4cd5-b0c3-0238f4390482,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472133936-172.17.0.19-1595625956340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33267,DS-1457a708-ff52-468b-9545-010e8fa32bed,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-569921a0-00c9-48f3-b39a-dbed4260ebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-8dea73a3-2aaa-4381-9a38-8e322f49602e,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-52634f4d-05f0-4b5c-95cf-7ce743d8d7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-da50d50f-8486-4b8e-bd03-e311e347a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-22f02631-9170-4313-86a3-c9ba80787ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-1e0bb1d7-43a9-40c1-a47a-449b42e984d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-b8e7c3c8-05e5-4cd5-b0c3-0238f4390482,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488618115-172.17.0.19-1595626111582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-4025364c-7f70-415b-8ecc-d77abe0098e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-197ff204-1612-4ea5-b765-eb7f346625b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-95c1d1aa-07d7-4de7-af4b-90c356f0befe,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-d22bba19-d14b-476d-afa2-438be0126ded,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-7cceb860-25ef-43d8-9aef-e9106c72c381,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-efa950cc-e2bd-4562-a24a-bcb23520e7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-ff36b043-df29-4f68-8594-77c9616c596b,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-ce5316ce-e9b1-4ab0-9f0f-18d4b0b13cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488618115-172.17.0.19-1595626111582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-4025364c-7f70-415b-8ecc-d77abe0098e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-197ff204-1612-4ea5-b765-eb7f346625b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-95c1d1aa-07d7-4de7-af4b-90c356f0befe,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-d22bba19-d14b-476d-afa2-438be0126ded,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-7cceb860-25ef-43d8-9aef-e9106c72c381,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-efa950cc-e2bd-4562-a24a-bcb23520e7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-ff36b043-df29-4f68-8594-77c9616c596b,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-ce5316ce-e9b1-4ab0-9f0f-18d4b0b13cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694611286-172.17.0.19-1595626144095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44420,DS-7bf3d7bf-5d9c-445a-b6d8-e7612966c010,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-9a4fd207-6f6c-4569-99b7-ed70c7a36b31,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-ba9b546c-298b-43eb-9437-552b9170ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-28fbcbd2-7e27-4e68-8fec-87978b439984,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-2b8fd4c3-b483-4ea3-b2d6-d110e3de1a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-976ad27a-e67a-4b69-89eb-6d1d0f593547,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-641642bb-9dab-4541-b573-09cac3a2a39f,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-0dee7c12-5608-4cc6-84a7-b3377bc6afd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694611286-172.17.0.19-1595626144095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44420,DS-7bf3d7bf-5d9c-445a-b6d8-e7612966c010,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-9a4fd207-6f6c-4569-99b7-ed70c7a36b31,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-ba9b546c-298b-43eb-9437-552b9170ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-28fbcbd2-7e27-4e68-8fec-87978b439984,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-2b8fd4c3-b483-4ea3-b2d6-d110e3de1a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-976ad27a-e67a-4b69-89eb-6d1d0f593547,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-641642bb-9dab-4541-b573-09cac3a2a39f,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-0dee7c12-5608-4cc6-84a7-b3377bc6afd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243932433-172.17.0.19-1595626228158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-08763257-4c19-42f0-9f92-fb392dcfeab5,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-65ec4188-d303-4c6b-b647-ba55f40919fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-723f04b4-16fd-425b-bf9c-d620074a6922,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-144c9032-faff-4476-9c05-a9c99641a4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-cdafac52-c9ed-47dd-948d-25a96abfdb73,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-bb9ea72f-d708-4b50-b8c1-82d987fc437a,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-b1c4c004-49a4-4398-b363-451cd92134f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-5a6be08e-00a4-4a7e-9e39-e54957d2e792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243932433-172.17.0.19-1595626228158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-08763257-4c19-42f0-9f92-fb392dcfeab5,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-65ec4188-d303-4c6b-b647-ba55f40919fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-723f04b4-16fd-425b-bf9c-d620074a6922,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-144c9032-faff-4476-9c05-a9c99641a4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-cdafac52-c9ed-47dd-948d-25a96abfdb73,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-bb9ea72f-d708-4b50-b8c1-82d987fc437a,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-b1c4c004-49a4-4398-b363-451cd92134f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-5a6be08e-00a4-4a7e-9e39-e54957d2e792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859593341-172.17.0.19-1595626345483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-7529f080-4fa4-43c7-a14d-07646f8517ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-11da31b2-b1d4-48b9-b47c-236bbb5e8a12,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-49dce7a4-e057-4143-9e8f-cd5fa373ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-f04d9a05-3346-47b4-b05e-05f6a354ffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-921d4c2c-1401-4ff9-8697-624a99c35e57,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-bb237516-6273-4bf4-a7d3-8b76b40cacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-e53015ec-d004-4809-8fe1-b8c2ceebc897,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-b2e3dd29-f89a-40ba-9444-2759c923e118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859593341-172.17.0.19-1595626345483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-7529f080-4fa4-43c7-a14d-07646f8517ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-11da31b2-b1d4-48b9-b47c-236bbb5e8a12,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-49dce7a4-e057-4143-9e8f-cd5fa373ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-f04d9a05-3346-47b4-b05e-05f6a354ffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-921d4c2c-1401-4ff9-8697-624a99c35e57,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-bb237516-6273-4bf4-a7d3-8b76b40cacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-e53015ec-d004-4809-8fe1-b8c2ceebc897,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-b2e3dd29-f89a-40ba-9444-2759c923e118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310417788-172.17.0.19-1595626688229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37960,DS-23e5e9b0-4713-426b-8cbc-846692ba79b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-72fec06b-9349-4df5-a544-7b9e76273577,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-f9a49a7c-a613-4ed1-a947-a5b9632b7fed,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-af2c6560-dc7a-4fc4-bcb2-1424ccd5247c,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-5ee271eb-bdf3-4298-a2a5-4b7a9aaf79cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-10c56fef-c373-4d9c-9b4f-a434f64f5ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-f3110a4a-2018-4469-a67e-ac1910db5425,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-cbcc4d46-4d2a-4cdb-be9f-c7f14e40ce01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310417788-172.17.0.19-1595626688229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37960,DS-23e5e9b0-4713-426b-8cbc-846692ba79b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-72fec06b-9349-4df5-a544-7b9e76273577,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-f9a49a7c-a613-4ed1-a947-a5b9632b7fed,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-af2c6560-dc7a-4fc4-bcb2-1424ccd5247c,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-5ee271eb-bdf3-4298-a2a5-4b7a9aaf79cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-10c56fef-c373-4d9c-9b4f-a434f64f5ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-f3110a4a-2018-4469-a67e-ac1910db5425,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-cbcc4d46-4d2a-4cdb-be9f-c7f14e40ce01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278483151-172.17.0.19-1595627615271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-f67fffae-d50b-4e44-bc1e-b6ca42e44448,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-4da722d2-86bf-4715-a413-7b85a7b9288c,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-7fb09263-4a31-4836-8def-9b69dc66e6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-16111a56-2f2b-4c9e-91c5-55c7376b632d,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a358a9fe-24e4-49de-988f-d9cc704a5a84,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-f1dfd3ca-d71c-4406-b73e-fc5599ce0535,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-6a2c7c2d-eeb7-40df-9648-0cb8979aaada,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-430d866f-89e6-40b5-9e8e-3a717b85fe82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278483151-172.17.0.19-1595627615271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-f67fffae-d50b-4e44-bc1e-b6ca42e44448,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-4da722d2-86bf-4715-a413-7b85a7b9288c,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-7fb09263-4a31-4836-8def-9b69dc66e6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-16111a56-2f2b-4c9e-91c5-55c7376b632d,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a358a9fe-24e4-49de-988f-d9cc704a5a84,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-f1dfd3ca-d71c-4406-b73e-fc5599ce0535,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-6a2c7c2d-eeb7-40df-9648-0cb8979aaada,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-430d866f-89e6-40b5-9e8e-3a717b85fe82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185448926-172.17.0.19-1595627696475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39253,DS-6fa561a8-cb84-4b78-ae50-470fc6efeaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-aa9c7df7-a0ee-4fa7-afc2-1cf12335b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-e663f0c3-0c2f-42ed-bf90-665904b40602,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-ab3c8a7f-fd6a-48e0-b991-39cbf53f9608,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-2171ed8e-e07b-45b3-b830-95d487b28f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-4013424b-c2cb-423b-8064-a8e23a3b1ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-162c29f3-6347-46f8-8ea0-614fce6a7762,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-ed73a526-1e04-4662-8ca9-403fdf76bda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185448926-172.17.0.19-1595627696475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39253,DS-6fa561a8-cb84-4b78-ae50-470fc6efeaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-aa9c7df7-a0ee-4fa7-afc2-1cf12335b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-e663f0c3-0c2f-42ed-bf90-665904b40602,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-ab3c8a7f-fd6a-48e0-b991-39cbf53f9608,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-2171ed8e-e07b-45b3-b830-95d487b28f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-4013424b-c2cb-423b-8064-a8e23a3b1ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-162c29f3-6347-46f8-8ea0-614fce6a7762,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-ed73a526-1e04-4662-8ca9-403fdf76bda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942608430-172.17.0.19-1595627867853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-81643b44-a572-4622-9c38-587066a15aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-1b64db7b-fe8d-44b4-8d2e-cb174ef3315a,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-e071ed39-9af0-4772-8d83-41882b1df9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-bf225b36-081a-43ab-a77c-c9db76afc3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-ac262c82-1405-4ed1-b7b7-4f1f7643ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-a377bccf-8cd5-4459-a8c6-30b6c5949135,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-0e998d65-56ef-47bc-a236-14e38718f316,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-e277a185-fc0e-4fd1-a16a-69f8069fb2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942608430-172.17.0.19-1595627867853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-81643b44-a572-4622-9c38-587066a15aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-1b64db7b-fe8d-44b4-8d2e-cb174ef3315a,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-e071ed39-9af0-4772-8d83-41882b1df9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-bf225b36-081a-43ab-a77c-c9db76afc3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-ac262c82-1405-4ed1-b7b7-4f1f7643ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-a377bccf-8cd5-4459-a8c6-30b6c5949135,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-0e998d65-56ef-47bc-a236-14e38718f316,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-e277a185-fc0e-4fd1-a16a-69f8069fb2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410796432-172.17.0.19-1595628455191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-2cf30c9c-aced-4145-8ea8-623adb5cd46c,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-7eac9ebe-3b90-439b-8952-b8a4f3cbbb86,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-1f60c2bb-1483-4694-a380-45b71ad49a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-7e7baf97-d1c2-4159-bc7b-df1a53d9754d,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-62f52416-7491-44d7-a18e-8faf552fc01d,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-2734ffe5-2059-4240-8cd8-341648f6cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-3b08b2ac-d589-4595-a7e6-16be25ff4c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-8f3c2180-9132-478b-aec5-942a224a7009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410796432-172.17.0.19-1595628455191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-2cf30c9c-aced-4145-8ea8-623adb5cd46c,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-7eac9ebe-3b90-439b-8952-b8a4f3cbbb86,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-1f60c2bb-1483-4694-a380-45b71ad49a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-7e7baf97-d1c2-4159-bc7b-df1a53d9754d,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-62f52416-7491-44d7-a18e-8faf552fc01d,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-2734ffe5-2059-4240-8cd8-341648f6cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-3b08b2ac-d589-4595-a7e6-16be25ff4c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-8f3c2180-9132-478b-aec5-942a224a7009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188781345-172.17.0.19-1595628570448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-a6dd5b6f-3375-4ea0-92e2-8124d4d383ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-cfc2ef25-a854-4ed3-95d6-19f23e5626d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-a7e54255-af17-407b-acaf-257dac1e0455,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-e1c7bed3-4ab6-4316-9d95-ea88525c173b,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-9ee1e7c0-5d39-494d-bda7-cf421e6dd57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-51530650-eb53-40e7-836b-b167567567fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-209431bd-8eba-47b7-9222-a2406359aa48,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-af40f8d9-aa92-490d-97d2-e0c4e6ebcfac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188781345-172.17.0.19-1595628570448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-a6dd5b6f-3375-4ea0-92e2-8124d4d383ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-cfc2ef25-a854-4ed3-95d6-19f23e5626d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-a7e54255-af17-407b-acaf-257dac1e0455,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-e1c7bed3-4ab6-4316-9d95-ea88525c173b,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-9ee1e7c0-5d39-494d-bda7-cf421e6dd57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-51530650-eb53-40e7-836b-b167567567fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-209431bd-8eba-47b7-9222-a2406359aa48,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-af40f8d9-aa92-490d-97d2-e0c4e6ebcfac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718536336-172.17.0.19-1595628645251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34609,DS-adfbbcc8-5c9a-4450-b035-166c1efa1e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-8019a484-9ed3-4360-8fab-60d84c28fe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-81fb616a-86c5-4154-9cc4-d3ccdfefb157,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-88087739-81f0-4242-9e45-c697ef555a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-360d68a3-11ce-4f2f-85ee-db2a60f8e41d,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-14a1ce88-5381-4f69-9534-8f105ed2d47c,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-0812435d-e8c0-477a-9ad1-14f7983dd13d,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-07538d67-2f63-4555-930d-d3081ad42e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718536336-172.17.0.19-1595628645251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34609,DS-adfbbcc8-5c9a-4450-b035-166c1efa1e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-8019a484-9ed3-4360-8fab-60d84c28fe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-81fb616a-86c5-4154-9cc4-d3ccdfefb157,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-88087739-81f0-4242-9e45-c697ef555a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-360d68a3-11ce-4f2f-85ee-db2a60f8e41d,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-14a1ce88-5381-4f69-9534-8f105ed2d47c,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-0812435d-e8c0-477a-9ad1-14f7983dd13d,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-07538d67-2f63-4555-930d-d3081ad42e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461881977-172.17.0.19-1595629315937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-d69aa312-b541-417b-8e23-46c82347fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-63f302b3-c12b-4a6e-8945-575c473c6efc,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-4cba2337-5cf6-4870-bcd5-86af35752277,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-e82a3936-8d34-439b-8689-eb8b08ebd136,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-3318b28c-f20e-464c-89ba-ce0e93408130,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-2077365a-95ce-4cf9-a5a5-48ece070d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-176d3887-888e-451e-b2cd-0e6d3df74bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-e61d0283-3cf8-483a-ada8-d88536025f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461881977-172.17.0.19-1595629315937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43141,DS-d69aa312-b541-417b-8e23-46c82347fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-63f302b3-c12b-4a6e-8945-575c473c6efc,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-4cba2337-5cf6-4870-bcd5-86af35752277,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-e82a3936-8d34-439b-8689-eb8b08ebd136,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-3318b28c-f20e-464c-89ba-ce0e93408130,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-2077365a-95ce-4cf9-a5a5-48ece070d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-176d3887-888e-451e-b2cd-0e6d3df74bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-e61d0283-3cf8-483a-ada8-d88536025f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 4194304
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110920139-172.17.0.19-1595629409490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36941,DS-0e00ec02-f27b-4932-af87-b5b5ce3371a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-024974c7-d7a4-4d5c-8e40-ee7927303ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-e86ff894-a0b2-4159-a771-c60c4fc7f9da,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-c33f809a-6cc1-4e85-91b9-8f9ce46b3201,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-474a4ebc-571c-45cb-9e22-c70fd569f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-bfa7c7c9-cde3-49b8-b334-ac72c807edac,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-c6b4232c-a2cb-44af-9d3f-cf7c515618b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-df281f28-98fe-4c2e-9090-0f413bafb305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110920139-172.17.0.19-1595629409490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36941,DS-0e00ec02-f27b-4932-af87-b5b5ce3371a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-024974c7-d7a4-4d5c-8e40-ee7927303ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-e86ff894-a0b2-4159-a771-c60c4fc7f9da,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-c33f809a-6cc1-4e85-91b9-8f9ce46b3201,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-474a4ebc-571c-45cb-9e22-c70fd569f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-bfa7c7c9-cde3-49b8-b334-ac72c807edac,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-c6b4232c-a2cb-44af-9d3f-cf7c515618b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-df281f28-98fe-4c2e-9090-0f413bafb305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5410
