reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200600849-172.17.0.6-1595722711104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43462,DS-a6e27807-5bee-4044-9ccb-41ef1e591176,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-a1456c43-da69-47f6-85e0-eedf85d8435f,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-baa3c533-e013-4125-aa3a-fcd24e6b0d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-84b55e9d-4fd5-4711-89e5-de237d153047,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-c55b86ab-62ad-4d3c-a0ca-391088651aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-187b9145-19a2-43cf-9aa2-fb926e3320f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-562a87d4-e959-4efd-8fbd-50505abd5006,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-90b3841f-eddf-44d7-bb2b-ebe560116977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200600849-172.17.0.6-1595722711104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43462,DS-a6e27807-5bee-4044-9ccb-41ef1e591176,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-a1456c43-da69-47f6-85e0-eedf85d8435f,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-baa3c533-e013-4125-aa3a-fcd24e6b0d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-84b55e9d-4fd5-4711-89e5-de237d153047,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-c55b86ab-62ad-4d3c-a0ca-391088651aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-187b9145-19a2-43cf-9aa2-fb926e3320f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-562a87d4-e959-4efd-8fbd-50505abd5006,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-90b3841f-eddf-44d7-bb2b-ebe560116977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929531063-172.17.0.6-1595722789372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44726,DS-80aed87d-56fa-4b73-88cd-6c4d0efbdd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-5f64bcf1-6b9e-4a30-a0ad-f836e8845e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-1cffe470-8499-4ead-94af-5d81a5130473,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-9cac8df9-6ded-441f-8cb9-cdad136eb445,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-797680f1-95d0-4630-86db-e19b98bc5385,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-be1c5040-ddb4-4968-bb61-7a8bf0c544f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-7e948f9d-f38d-4c7f-bf65-14deb2268559,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-274d7f51-bb59-498b-8b5e-cf7012c13827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929531063-172.17.0.6-1595722789372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44726,DS-80aed87d-56fa-4b73-88cd-6c4d0efbdd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-5f64bcf1-6b9e-4a30-a0ad-f836e8845e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-1cffe470-8499-4ead-94af-5d81a5130473,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-9cac8df9-6ded-441f-8cb9-cdad136eb445,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-797680f1-95d0-4630-86db-e19b98bc5385,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-be1c5040-ddb4-4968-bb61-7a8bf0c544f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-7e948f9d-f38d-4c7f-bf65-14deb2268559,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-274d7f51-bb59-498b-8b5e-cf7012c13827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519940451-172.17.0.6-1595722878849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33184,DS-cc41a6d8-212b-4eb0-94c4-7d20eff44d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-324a425b-2bb5-4afd-8b79-7957d95a8728,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-5d839f49-208d-4d7c-ba5c-ebdad5fc3316,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-8ba30759-3f4f-4550-9c41-b44ca5ac96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-33852038-0a31-4347-a9fa-ee1cdee45b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-bb577d98-9558-4ef6-ba47-725a988da55f,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-3a06ac82-3af2-4364-bc99-57e2947949b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-9d14636c-e55f-4ffc-8d7e-ed44fa653091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519940451-172.17.0.6-1595722878849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33184,DS-cc41a6d8-212b-4eb0-94c4-7d20eff44d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-324a425b-2bb5-4afd-8b79-7957d95a8728,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-5d839f49-208d-4d7c-ba5c-ebdad5fc3316,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-8ba30759-3f4f-4550-9c41-b44ca5ac96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-33852038-0a31-4347-a9fa-ee1cdee45b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-bb577d98-9558-4ef6-ba47-725a988da55f,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-3a06ac82-3af2-4364-bc99-57e2947949b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-9d14636c-e55f-4ffc-8d7e-ed44fa653091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261120858-172.17.0.6-1595723265447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-73c44f9d-70b2-4af8-9575-3d94ce1f22ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-1bbe68a8-2fce-46ee-835d-6a6a8a58a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-01b4e982-f36b-447c-829e-0a22f1a6dce0,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-e126e6fd-987f-4247-b3c5-924f86b49d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-b4d171d1-ba5e-41bd-a518-03af4d9fd582,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-418dead3-b431-4956-a0f0-f2c9bf0288d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-eeeef75b-9157-42ce-9f11-955b9d6b91cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-596d0a0e-c995-416b-a0f0-d01c6c531f7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261120858-172.17.0.6-1595723265447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-73c44f9d-70b2-4af8-9575-3d94ce1f22ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-1bbe68a8-2fce-46ee-835d-6a6a8a58a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-01b4e982-f36b-447c-829e-0a22f1a6dce0,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-e126e6fd-987f-4247-b3c5-924f86b49d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-b4d171d1-ba5e-41bd-a518-03af4d9fd582,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-418dead3-b431-4956-a0f0-f2c9bf0288d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-eeeef75b-9157-42ce-9f11-955b9d6b91cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-596d0a0e-c995-416b-a0f0-d01c6c531f7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616823708-172.17.0.6-1595723343983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43118,DS-7b669de9-f282-4bf6-9fc8-88208211db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-ab34459f-8809-459e-9455-f8846bd31acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-43f57b5b-363a-4515-a59a-138682ac5d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-5ec5d088-f8a6-4bae-a7f5-edbe893c5f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-685fdadf-1e9d-4286-bac2-809258e9839a,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-b60934af-3db2-47bc-bf05-9bacf3be5cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-0e3e88c7-d968-4de8-b1ee-b1340bb6a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-9df63dea-0978-4311-81dc-f13a818bca3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616823708-172.17.0.6-1595723343983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43118,DS-7b669de9-f282-4bf6-9fc8-88208211db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-ab34459f-8809-459e-9455-f8846bd31acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-43f57b5b-363a-4515-a59a-138682ac5d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-5ec5d088-f8a6-4bae-a7f5-edbe893c5f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-685fdadf-1e9d-4286-bac2-809258e9839a,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-b60934af-3db2-47bc-bf05-9bacf3be5cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-0e3e88c7-d968-4de8-b1ee-b1340bb6a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-9df63dea-0978-4311-81dc-f13a818bca3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49739693-172.17.0.6-1595723392032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36999,DS-fd90e07d-aad7-4413-9c6a-05730133fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-30c22670-3dc3-4f74-baed-c71a19c18383,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-24d8e46e-7e15-4fdb-99af-3bcd63488f71,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-05fc90e9-18b9-46e6-b3bc-748bab086843,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-0719b5e1-9bec-457f-9eea-d50039b249e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-4570ea54-dcd3-4cae-a4e8-da5713a3afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-5f72793d-361e-43b1-af07-7bf245d65501,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-36d1c8e6-8c7b-4427-affd-3b82d3cbefef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49739693-172.17.0.6-1595723392032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36999,DS-fd90e07d-aad7-4413-9c6a-05730133fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-30c22670-3dc3-4f74-baed-c71a19c18383,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-24d8e46e-7e15-4fdb-99af-3bcd63488f71,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-05fc90e9-18b9-46e6-b3bc-748bab086843,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-0719b5e1-9bec-457f-9eea-d50039b249e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-4570ea54-dcd3-4cae-a4e8-da5713a3afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-5f72793d-361e-43b1-af07-7bf245d65501,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-36d1c8e6-8c7b-4427-affd-3b82d3cbefef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61935348-172.17.0.6-1595724426819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41698,DS-9c860d6c-a1bd-4a6b-a114-4b56f6b4cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-421b16e0-96b4-4ae3-bb6e-7271fb41ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-1f41c66a-7acc-471f-a463-22969e85772b,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-cc74a482-6e25-42f6-b83d-b25cf8c88194,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-2850297f-9334-4fdd-8231-2a3c7184be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-8b0c0b6e-5f7f-4367-a0ca-88677b1b79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-2a5774ef-24c1-4050-b2c1-651411126034,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-22f58f0c-4497-4b8b-9240-a668493cc7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61935348-172.17.0.6-1595724426819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41698,DS-9c860d6c-a1bd-4a6b-a114-4b56f6b4cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-421b16e0-96b4-4ae3-bb6e-7271fb41ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-1f41c66a-7acc-471f-a463-22969e85772b,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-cc74a482-6e25-42f6-b83d-b25cf8c88194,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-2850297f-9334-4fdd-8231-2a3c7184be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-8b0c0b6e-5f7f-4367-a0ca-88677b1b79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-2a5774ef-24c1-4050-b2c1-651411126034,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-22f58f0c-4497-4b8b-9240-a668493cc7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007554106-172.17.0.6-1595724475658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34451,DS-db38445a-2a97-4083-b8fa-2d3a03a88da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-536bfc0d-dc3b-4c5d-b1c5-bf917474e5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-56aa9ad3-b6cd-4077-931d-2fcdfc6bc5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-8c51bd2d-f3d8-4404-8a2f-84c1c9cf2eff,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-15f85b0b-3a37-4a23-8dc0-0f29b28dcbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-73c7cd7d-8875-46e4-8acb-1ad67d61cbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-31c55fbd-26b5-4a92-b540-400d0758500c,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-0e2e88ee-898f-41a1-8764-e360d57d5edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007554106-172.17.0.6-1595724475658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34451,DS-db38445a-2a97-4083-b8fa-2d3a03a88da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-536bfc0d-dc3b-4c5d-b1c5-bf917474e5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-56aa9ad3-b6cd-4077-931d-2fcdfc6bc5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-8c51bd2d-f3d8-4404-8a2f-84c1c9cf2eff,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-15f85b0b-3a37-4a23-8dc0-0f29b28dcbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-73c7cd7d-8875-46e4-8acb-1ad67d61cbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-31c55fbd-26b5-4a92-b540-400d0758500c,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-0e2e88ee-898f-41a1-8764-e360d57d5edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103630892-172.17.0.6-1595724697179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-e7cf8fac-77b6-4810-9cb8-c1075277535a,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-1d832e0b-b029-4ebe-8901-7b34d4d5bc41,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-ff3519dd-3c5e-4362-9b05-d7d87d6cee76,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-1d9cbba3-4289-4ec5-a9ec-0cdc5b92feee,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-863d0602-bdd9-4492-805a-2427599cc713,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-d3a1e282-d285-4246-bac2-fd32fa24aaed,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-15ab6ad7-24d3-422f-ad03-4ae54a6ff21c,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-eac58c6f-3beb-4d45-80e6-6748d2533416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103630892-172.17.0.6-1595724697179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-e7cf8fac-77b6-4810-9cb8-c1075277535a,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-1d832e0b-b029-4ebe-8901-7b34d4d5bc41,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-ff3519dd-3c5e-4362-9b05-d7d87d6cee76,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-1d9cbba3-4289-4ec5-a9ec-0cdc5b92feee,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-863d0602-bdd9-4492-805a-2427599cc713,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-d3a1e282-d285-4246-bac2-fd32fa24aaed,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-15ab6ad7-24d3-422f-ad03-4ae54a6ff21c,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-eac58c6f-3beb-4d45-80e6-6748d2533416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608453612-172.17.0.6-1595725600270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34984,DS-e3af5f19-84b7-4ce0-a1dd-743fc2203ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-6def3ea1-f00f-4b2c-8430-e4989e306cca,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7b5369b2-5525-4e3b-ac65-328169b00994,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-d65c5584-d8b1-48f8-84c0-01cb74e407e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-99fac626-0d92-4269-8b0e-fca5c4159ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-72808418-1854-4beb-9906-9073e5f76025,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-053e056e-260f-4db5-916d-761a114cbca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-65a94037-8051-4ee4-aaf5-c07d2a520d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608453612-172.17.0.6-1595725600270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34984,DS-e3af5f19-84b7-4ce0-a1dd-743fc2203ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-6def3ea1-f00f-4b2c-8430-e4989e306cca,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7b5369b2-5525-4e3b-ac65-328169b00994,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-d65c5584-d8b1-48f8-84c0-01cb74e407e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-99fac626-0d92-4269-8b0e-fca5c4159ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-72808418-1854-4beb-9906-9073e5f76025,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-053e056e-260f-4db5-916d-761a114cbca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-65a94037-8051-4ee4-aaf5-c07d2a520d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784726722-172.17.0.6-1595725830503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45553,DS-3ed29f90-4967-4d7f-94a8-72d91cdc8dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-17e2a3b0-e3d5-4c8e-8eac-374f574c9db9,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-cd2b17e9-1e01-4046-a8ff-a50a872ed5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-8fa800e2-20ad-4aee-9834-ef448091a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-d3af3e16-4725-4226-9a8b-450b897ae9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-003f6536-3f28-4998-86be-bbb4d90ca177,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-4d94b9d0-e76b-4131-b559-623960145b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-16d40525-1290-4665-be53-c9b8b6c222ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784726722-172.17.0.6-1595725830503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45553,DS-3ed29f90-4967-4d7f-94a8-72d91cdc8dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-17e2a3b0-e3d5-4c8e-8eac-374f574c9db9,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-cd2b17e9-1e01-4046-a8ff-a50a872ed5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-8fa800e2-20ad-4aee-9834-ef448091a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-d3af3e16-4725-4226-9a8b-450b897ae9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-003f6536-3f28-4998-86be-bbb4d90ca177,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-4d94b9d0-e76b-4131-b559-623960145b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-16d40525-1290-4665-be53-c9b8b6c222ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447850092-172.17.0.6-1595726155785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-f2cc4f2a-6281-44a7-bac0-514a78d0c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-b7373109-3e3c-4bcb-92b1-90c5e926951c,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-f5d3670e-4e62-4e6a-9404-bea815b149d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-998f06c1-175e-4409-a534-e2d6431ac77d,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-971de7a0-f8cd-4f36-8ce2-c12686b9bf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-460a2dd7-84f0-4e58-aa86-256b44c603fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-9430ba97-db33-46d0-88d6-1ee585f24a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-e9e0206a-4690-4c49-899d-2943d35e7805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447850092-172.17.0.6-1595726155785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-f2cc4f2a-6281-44a7-bac0-514a78d0c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-b7373109-3e3c-4bcb-92b1-90c5e926951c,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-f5d3670e-4e62-4e6a-9404-bea815b149d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-998f06c1-175e-4409-a534-e2d6431ac77d,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-971de7a0-f8cd-4f36-8ce2-c12686b9bf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-460a2dd7-84f0-4e58-aa86-256b44c603fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-9430ba97-db33-46d0-88d6-1ee585f24a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-e9e0206a-4690-4c49-899d-2943d35e7805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136186563-172.17.0.6-1595727390866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35888,DS-5cfeb208-dac7-4fe3-be25-a38a80bf8aba,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-18de8c9c-5a67-4368-9731-cc4a2b2cd2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-bf5029a5-1220-43af-be68-04ef0ad31721,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-5952ad6a-75f4-4e4a-bf77-7bc746e3c466,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-39966977-f1fd-438b-918f-f34ecc255856,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-ade16038-d8d0-4654-9af9-3d2c8b5c17f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-ba3d05c2-9ea3-4882-ace5-69296382fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-59e0ca7c-a4cb-48d9-b4c1-dedbb07d9a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136186563-172.17.0.6-1595727390866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35888,DS-5cfeb208-dac7-4fe3-be25-a38a80bf8aba,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-18de8c9c-5a67-4368-9731-cc4a2b2cd2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-bf5029a5-1220-43af-be68-04ef0ad31721,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-5952ad6a-75f4-4e4a-bf77-7bc746e3c466,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-39966977-f1fd-438b-918f-f34ecc255856,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-ade16038-d8d0-4654-9af9-3d2c8b5c17f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-ba3d05c2-9ea3-4882-ace5-69296382fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-59e0ca7c-a4cb-48d9-b4c1-dedbb07d9a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65486717-172.17.0.6-1595727469523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40344,DS-28c2531f-3887-451f-928f-4469a81c3d30,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-60db3c80-7720-4465-93e0-14e1b501ddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-a34755fc-b239-4736-ab86-877a3cbee74f,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-3122e6f8-3f21-4546-81ea-648cdfed2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-fd71ee3e-28b7-4eb2-9e8c-dbe2491aff13,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-320263ad-2506-4d8e-880e-c5903a7b8387,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-13d0c264-344c-4948-8a37-06724fa084d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-c256a4e7-c5ea-492f-b6de-ad2caf039408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65486717-172.17.0.6-1595727469523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40344,DS-28c2531f-3887-451f-928f-4469a81c3d30,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-60db3c80-7720-4465-93e0-14e1b501ddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-a34755fc-b239-4736-ab86-877a3cbee74f,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-3122e6f8-3f21-4546-81ea-648cdfed2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-fd71ee3e-28b7-4eb2-9e8c-dbe2491aff13,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-320263ad-2506-4d8e-880e-c5903a7b8387,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-13d0c264-344c-4948-8a37-06724fa084d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-c256a4e7-c5ea-492f-b6de-ad2caf039408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356882813-172.17.0.6-1595727696098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36109,DS-03655ee7-8d16-4164-91ff-35ea9cee1a40,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-dc56174d-42a3-4a85-bad9-9c547ee943cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-0271b85d-9e16-46ed-9c7f-070e932388ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-f30e060e-bf75-4193-a1a7-7abdab539bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-ff309def-4c3c-426b-bf17-6c03b97753f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-806da885-e36c-4424-b7e9-40d27590556d,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-48e01bf1-bddf-44b0-a382-4e651d672efc,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-75ec1dad-8077-4b21-8b6e-49888f013b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356882813-172.17.0.6-1595727696098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36109,DS-03655ee7-8d16-4164-91ff-35ea9cee1a40,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-dc56174d-42a3-4a85-bad9-9c547ee943cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-0271b85d-9e16-46ed-9c7f-070e932388ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-f30e060e-bf75-4193-a1a7-7abdab539bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-ff309def-4c3c-426b-bf17-6c03b97753f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-806da885-e36c-4424-b7e9-40d27590556d,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-48e01bf1-bddf-44b0-a382-4e651d672efc,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-75ec1dad-8077-4b21-8b6e-49888f013b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002162584-172.17.0.6-1595727911129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46604,DS-3d8e0fe6-9b93-4d34-a611-4777d1bfc868,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-872dba05-6b75-4714-b7b1-59f30377f9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-2909d488-eac0-44cc-87f6-eff335b43683,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-be0c1019-a121-49dc-8319-64606288ecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-7895849c-fdc3-46c8-80ed-52b44f880004,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-1360c12a-0288-481f-9bc1-2c62808adbad,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-a9b5ad9c-391d-461c-8a86-d2f422119ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-68ef21d1-28aa-425f-8ce6-85fad5d47043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002162584-172.17.0.6-1595727911129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46604,DS-3d8e0fe6-9b93-4d34-a611-4777d1bfc868,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-872dba05-6b75-4714-b7b1-59f30377f9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-2909d488-eac0-44cc-87f6-eff335b43683,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-be0c1019-a121-49dc-8319-64606288ecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-7895849c-fdc3-46c8-80ed-52b44f880004,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-1360c12a-0288-481f-9bc1-2c62808adbad,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-a9b5ad9c-391d-461c-8a86-d2f422119ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-68ef21d1-28aa-425f-8ce6-85fad5d47043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951851121-172.17.0.6-1595728006315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34055,DS-3c9485c7-c34e-4a40-b0ee-0add566b2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-897ec7f2-4fae-411b-9be2-cbca60f08eab,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-dfcaaf33-cf14-4ede-9bc6-6cfddc839384,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-76362f15-bfb4-4edb-bdbf-fce6bf8639b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-38db0442-ee4d-4e39-a27f-19a8d2687892,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-4b9548ea-1f1d-430b-a243-d44c0d8828f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-5154028f-fa68-407b-98bf-172fdbf8bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-bcbb88cc-76e0-4bce-830f-9cf136ecbe8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951851121-172.17.0.6-1595728006315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34055,DS-3c9485c7-c34e-4a40-b0ee-0add566b2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-897ec7f2-4fae-411b-9be2-cbca60f08eab,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-dfcaaf33-cf14-4ede-9bc6-6cfddc839384,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-76362f15-bfb4-4edb-bdbf-fce6bf8639b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-38db0442-ee4d-4e39-a27f-19a8d2687892,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-4b9548ea-1f1d-430b-a243-d44c0d8828f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-5154028f-fa68-407b-98bf-172fdbf8bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-bcbb88cc-76e0-4bce-830f-9cf136ecbe8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659109346-172.17.0.6-1595728295459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32961,DS-faead7f1-ccd1-42b3-92af-7bac64d8eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-498f8e06-f731-4757-bbc0-03a42ff67197,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-551cdf53-c5dd-498b-82e5-7c01cbd3e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-34c84084-6690-4974-8458-14595c29d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-75e452f6-2807-4cad-846a-9e01ec89a200,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-7e046763-e827-449b-9c5c-5549e0a27e76,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-967cb1bb-f6b8-4293-9467-83d770c64073,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-452368fc-e823-4738-bb3e-8058c59ca87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659109346-172.17.0.6-1595728295459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32961,DS-faead7f1-ccd1-42b3-92af-7bac64d8eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-498f8e06-f731-4757-bbc0-03a42ff67197,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-551cdf53-c5dd-498b-82e5-7c01cbd3e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-34c84084-6690-4974-8458-14595c29d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-75e452f6-2807-4cad-846a-9e01ec89a200,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-7e046763-e827-449b-9c5c-5549e0a27e76,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-967cb1bb-f6b8-4293-9467-83d770c64073,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-452368fc-e823-4738-bb3e-8058c59ca87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6786
