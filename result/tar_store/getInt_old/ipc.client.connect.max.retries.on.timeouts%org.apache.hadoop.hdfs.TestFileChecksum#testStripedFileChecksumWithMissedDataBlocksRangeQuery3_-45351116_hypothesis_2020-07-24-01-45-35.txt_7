reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841943647-172.17.0.8-1595556019758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44592,DS-2a22c6e7-90f7-461b-9c1d-2bff44d952ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-a55311c6-8ac7-4cf1-ad33-e40db7e1f574,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-cd962c8d-888d-4934-8cfa-b39846eb0298,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-a3fac556-dd16-4dc0-9faf-739d3d0a502b,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-d3021c63-9644-4a00-895f-51b78cf64834,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-b28de057-4ac6-4e6f-9080-e49a4528d015,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-c780beb5-1354-4a0d-85a8-6616b13ac62e,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-6a5a5686-8f2e-4567-a416-36b85964d1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841943647-172.17.0.8-1595556019758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44592,DS-2a22c6e7-90f7-461b-9c1d-2bff44d952ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-a55311c6-8ac7-4cf1-ad33-e40db7e1f574,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-cd962c8d-888d-4934-8cfa-b39846eb0298,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-a3fac556-dd16-4dc0-9faf-739d3d0a502b,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-d3021c63-9644-4a00-895f-51b78cf64834,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-b28de057-4ac6-4e6f-9080-e49a4528d015,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-c780beb5-1354-4a0d-85a8-6616b13ac62e,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-6a5a5686-8f2e-4567-a416-36b85964d1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540518784-172.17.0.8-1595556118820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-5c431a38-093a-4538-8bd7-5f28411b3bee,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-a2ff94d3-ae3f-465a-b4fd-650de86c77a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-485519fd-68dc-42e5-85e5-51a69d9750e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-0e7d78e0-5876-47a3-abd9-4bf88a2f86a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-0cb3b578-9dfd-4b46-a2ab-0d834622a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-232f8a22-c01c-4325-8b54-ab91334dae49,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-1e7b2a01-8236-4fbb-bf34-e660378d2fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-231268df-f319-40d6-960c-653bef1c838f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540518784-172.17.0.8-1595556118820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-5c431a38-093a-4538-8bd7-5f28411b3bee,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-a2ff94d3-ae3f-465a-b4fd-650de86c77a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-485519fd-68dc-42e5-85e5-51a69d9750e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-0e7d78e0-5876-47a3-abd9-4bf88a2f86a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-0cb3b578-9dfd-4b46-a2ab-0d834622a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-232f8a22-c01c-4325-8b54-ab91334dae49,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-1e7b2a01-8236-4fbb-bf34-e660378d2fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-231268df-f319-40d6-960c-653bef1c838f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728138295-172.17.0.8-1595556231725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-baa151a5-cdc6-4f85-a5ae-f1308219f7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-2d23b28b-b1d1-4198-bcd2-086c96d096ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-ba940f75-c8fd-4fc3-978f-d562bfa759b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-62124fa1-3dd3-4e9b-becd-4012788a1c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-4ff5551b-cc85-4fa3-8765-2b985f3378f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-a5d171d2-d573-49b7-8d6f-1a6c38e75093,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-01337723-4ce1-4167-99af-1d7f8abe37a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-fbda2ebe-7394-4ddc-8a6d-e3d193f6d5e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728138295-172.17.0.8-1595556231725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-baa151a5-cdc6-4f85-a5ae-f1308219f7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-2d23b28b-b1d1-4198-bcd2-086c96d096ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-ba940f75-c8fd-4fc3-978f-d562bfa759b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-62124fa1-3dd3-4e9b-becd-4012788a1c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-4ff5551b-cc85-4fa3-8765-2b985f3378f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-a5d171d2-d573-49b7-8d6f-1a6c38e75093,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-01337723-4ce1-4167-99af-1d7f8abe37a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-fbda2ebe-7394-4ddc-8a6d-e3d193f6d5e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879773043-172.17.0.8-1595556917012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41593,DS-cd512cb1-71fd-416b-9298-649f25679922,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-8dd7d7bd-3982-4ef8-a388-2832bee54ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-40277695-6a38-433d-9709-0380e93abdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-0bf002c3-35f5-4b7a-a57e-817e405de3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-3b01c444-7847-4c0f-aa3f-96db20950e37,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-0d956939-97f0-496a-ba20-6dc79b5ad2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-6fe6cbff-e75d-41b8-87e7-323e011d4864,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-d9920d3b-b142-4532-b062-febd00d0427a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879773043-172.17.0.8-1595556917012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41593,DS-cd512cb1-71fd-416b-9298-649f25679922,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-8dd7d7bd-3982-4ef8-a388-2832bee54ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-40277695-6a38-433d-9709-0380e93abdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-0bf002c3-35f5-4b7a-a57e-817e405de3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-3b01c444-7847-4c0f-aa3f-96db20950e37,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-0d956939-97f0-496a-ba20-6dc79b5ad2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-6fe6cbff-e75d-41b8-87e7-323e011d4864,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-d9920d3b-b142-4532-b062-febd00d0427a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015594902-172.17.0.8-1595556958215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35746,DS-8e00b2d4-4c9e-483c-9476-33873921a223,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-9ef840cf-051f-4b1f-9ffa-deda4dd0f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-a8815423-d62b-4308-84d9-0d248218910a,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-8db4feb7-1c9c-486d-8051-739c771e11c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-5b9aac16-30f8-4503-bbe9-0be490cbdc25,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-e4863477-6e9f-4a25-9787-c1718031a925,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-dffc0c33-8cf5-44a1-bc44-a8eb082054db,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-7e95c6e6-ab92-4ee0-a344-fa90b1231b6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015594902-172.17.0.8-1595556958215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35746,DS-8e00b2d4-4c9e-483c-9476-33873921a223,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-9ef840cf-051f-4b1f-9ffa-deda4dd0f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-a8815423-d62b-4308-84d9-0d248218910a,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-8db4feb7-1c9c-486d-8051-739c771e11c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-5b9aac16-30f8-4503-bbe9-0be490cbdc25,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-e4863477-6e9f-4a25-9787-c1718031a925,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-dffc0c33-8cf5-44a1-bc44-a8eb082054db,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-7e95c6e6-ab92-4ee0-a344-fa90b1231b6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905015338-172.17.0.8-1595556997983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-d8c5a458-75f0-4a68-b323-1e10e3045213,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-b85c0faa-57d0-47b1-a0af-6bc73b19c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-f13ea79d-63a2-4729-b69c-d09eedbbd598,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-1659433b-028a-4769-a979-06e1988005c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-acae9712-9ead-4491-b44c-991eda918f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-9a35f4c3-feda-4216-b608-57e9ec356859,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-a95125f2-e131-41d4-903e-b6e74a7bd2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-1007f187-6dd8-4be2-a095-c0b685701edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905015338-172.17.0.8-1595556997983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-d8c5a458-75f0-4a68-b323-1e10e3045213,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-b85c0faa-57d0-47b1-a0af-6bc73b19c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-f13ea79d-63a2-4729-b69c-d09eedbbd598,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-1659433b-028a-4769-a979-06e1988005c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-acae9712-9ead-4491-b44c-991eda918f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-9a35f4c3-feda-4216-b608-57e9ec356859,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-a95125f2-e131-41d4-903e-b6e74a7bd2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-1007f187-6dd8-4be2-a095-c0b685701edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780830821-172.17.0.8-1595557029773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-b6effcde-bf94-4171-98c2-dd5ce485930d,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-bb7721f9-094c-4a62-b6fa-b0948dda2716,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-c94c9236-e25b-4ea3-b4c7-17e95733f070,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-a23752f8-1006-4729-a0c2-11d4251b3aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-260ccd46-0824-4a02-a3c3-4e3fabcf6c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-c4bc8c95-2ad0-4662-8d87-6c64c58e2e24,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-1cf71518-aa7f-48fa-8638-c1124184a0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-d44240ee-9f5b-4a89-b688-74c9697644e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780830821-172.17.0.8-1595557029773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34579,DS-b6effcde-bf94-4171-98c2-dd5ce485930d,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-bb7721f9-094c-4a62-b6fa-b0948dda2716,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-c94c9236-e25b-4ea3-b4c7-17e95733f070,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-a23752f8-1006-4729-a0c2-11d4251b3aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-260ccd46-0824-4a02-a3c3-4e3fabcf6c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-c4bc8c95-2ad0-4662-8d87-6c64c58e2e24,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-1cf71518-aa7f-48fa-8638-c1124184a0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-d44240ee-9f5b-4a89-b688-74c9697644e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862968863-172.17.0.8-1595557109445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-d9a9bb4f-cc1d-4980-97f2-3f02ab489432,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-aaf0b0d4-4de6-4940-b55c-14cf0b069046,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-a252b254-24ab-422d-86f9-c10bc0965157,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-6f3d2aea-6b08-45f2-afe2-deb381900886,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-7dcbbc90-a7e3-4fc2-8af1-eefb9ea1b107,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-da89edce-24ba-4146-8abe-2a7e6ca72a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-73b2e5b3-e5c1-4fce-af7b-e64f4a4101e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-8481a27c-0e15-4552-921d-00fbb19fc47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862968863-172.17.0.8-1595557109445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-d9a9bb4f-cc1d-4980-97f2-3f02ab489432,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-aaf0b0d4-4de6-4940-b55c-14cf0b069046,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-a252b254-24ab-422d-86f9-c10bc0965157,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-6f3d2aea-6b08-45f2-afe2-deb381900886,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-7dcbbc90-a7e3-4fc2-8af1-eefb9ea1b107,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-da89edce-24ba-4146-8abe-2a7e6ca72a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-73b2e5b3-e5c1-4fce-af7b-e64f4a4101e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-8481a27c-0e15-4552-921d-00fbb19fc47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610433878-172.17.0.8-1595557766596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37932,DS-f9240b0d-c998-420b-8265-0ae31bc8824a,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-51546ae5-dd7d-42f4-9534-2524ff957251,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-d2b8f0d6-3d87-476f-af6e-bf79687f790b,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-85dbd8ad-c523-4de0-b990-8274b5e48694,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-6cec8233-32b1-46ee-8eff-04b52dfd399d,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-dc82836e-b3c9-42c0-a1f3-6983e55aab64,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-2eeb0ea7-7ada-493b-a3ed-275896cbe569,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-2e993609-77cd-4643-9095-9f46c549070c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610433878-172.17.0.8-1595557766596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37932,DS-f9240b0d-c998-420b-8265-0ae31bc8824a,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-51546ae5-dd7d-42f4-9534-2524ff957251,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-d2b8f0d6-3d87-476f-af6e-bf79687f790b,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-85dbd8ad-c523-4de0-b990-8274b5e48694,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-6cec8233-32b1-46ee-8eff-04b52dfd399d,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-dc82836e-b3c9-42c0-a1f3-6983e55aab64,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-2eeb0ea7-7ada-493b-a3ed-275896cbe569,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-2e993609-77cd-4643-9095-9f46c549070c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598374240-172.17.0.8-1595558372228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43072,DS-2340f01a-32ea-4d20-8214-d39e2f6a98e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-f275da65-af14-4dd2-bf67-35c49a79ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-e1fd2898-5d06-4f94-8b3a-8a82ac0846b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-c725a056-295c-45dd-adfe-87288d5199e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-49861f19-4817-4ab8-b7e1-494530a59daa,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-ab96fcc4-1ec1-48e1-810e-33c679d0ca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-2f009490-1ff4-49df-ad11-24a68905ad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-24a731e9-b0fb-42dd-a98e-ffd17bc5fb79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598374240-172.17.0.8-1595558372228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43072,DS-2340f01a-32ea-4d20-8214-d39e2f6a98e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-f275da65-af14-4dd2-bf67-35c49a79ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-e1fd2898-5d06-4f94-8b3a-8a82ac0846b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-c725a056-295c-45dd-adfe-87288d5199e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-49861f19-4817-4ab8-b7e1-494530a59daa,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-ab96fcc4-1ec1-48e1-810e-33c679d0ca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-2f009490-1ff4-49df-ad11-24a68905ad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-24a731e9-b0fb-42dd-a98e-ffd17bc5fb79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301321053-172.17.0.8-1595558674560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42230,DS-ad23aebc-4796-49b6-ad35-ab2e30919982,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-a15cd13a-beaf-4a92-bfbe-7335f68f82ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-595affad-22cd-45d9-b3e9-551df089042e,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-9cb79377-7f63-4993-81a9-edd3061b5d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-5bd7c7a2-6a9f-4fa1-8ad3-9a9aa75b0918,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-f627c425-c965-4fd8-a840-63dd3b908e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-7fa38e28-83b3-4714-8c4d-ab1b9f8fa209,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-5dc78ee0-8a75-4963-8cc0-421058f8b328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301321053-172.17.0.8-1595558674560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42230,DS-ad23aebc-4796-49b6-ad35-ab2e30919982,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-a15cd13a-beaf-4a92-bfbe-7335f68f82ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-595affad-22cd-45d9-b3e9-551df089042e,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-9cb79377-7f63-4993-81a9-edd3061b5d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-5bd7c7a2-6a9f-4fa1-8ad3-9a9aa75b0918,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-f627c425-c965-4fd8-a840-63dd3b908e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-7fa38e28-83b3-4714-8c4d-ab1b9f8fa209,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-5dc78ee0-8a75-4963-8cc0-421058f8b328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162796589-172.17.0.8-1595558895721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34485,DS-f78564a0-3888-4e79-bae3-7948befcabe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-8c321903-6aa9-458e-836b-19acdca92322,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-ee876c37-0b6d-40bb-a1bd-85976c9326c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-db39da09-e4bf-4034-86d5-600dc38150ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-28c626a4-981c-4c71-9935-767d53687e22,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-e9e1e9fa-4785-4d1d-ade3-7e94ebfd8270,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-1ee70237-cf85-4853-b732-d68bd6dc9986,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-9d1403a3-ef31-4625-82e0-e664eacda0d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162796589-172.17.0.8-1595558895721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34485,DS-f78564a0-3888-4e79-bae3-7948befcabe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-8c321903-6aa9-458e-836b-19acdca92322,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-ee876c37-0b6d-40bb-a1bd-85976c9326c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-db39da09-e4bf-4034-86d5-600dc38150ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-28c626a4-981c-4c71-9935-767d53687e22,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-e9e1e9fa-4785-4d1d-ade3-7e94ebfd8270,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-1ee70237-cf85-4853-b732-d68bd6dc9986,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-9d1403a3-ef31-4625-82e0-e664eacda0d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599855604-172.17.0.8-1595558930637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44110,DS-f77ec948-3803-4cd7-932a-c392409617e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-5c983082-dd8c-4dda-b2c4-eb35b086af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-8e592824-d452-4a9b-a884-e61b4433af69,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-bb4aa4f4-1d82-4f76-b668-fa4d7b79b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-a2603853-927a-4cd9-9cc4-c3ce5b6e97cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-a6871495-79e7-40f6-b04d-fe13b4275808,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-dcf01b9e-a574-4875-a233-eea7179281ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-40c66f41-2f4d-455a-afef-241d3e2f7242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599855604-172.17.0.8-1595558930637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44110,DS-f77ec948-3803-4cd7-932a-c392409617e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-5c983082-dd8c-4dda-b2c4-eb35b086af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-8e592824-d452-4a9b-a884-e61b4433af69,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-bb4aa4f4-1d82-4f76-b668-fa4d7b79b95d,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-a2603853-927a-4cd9-9cc4-c3ce5b6e97cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-a6871495-79e7-40f6-b04d-fe13b4275808,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-dcf01b9e-a574-4875-a233-eea7179281ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-40c66f41-2f4d-455a-afef-241d3e2f7242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117738188-172.17.0.8-1595559226668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-7e7a76fc-8275-4f85-8d00-8135b6d68f25,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-145a2e02-86c9-444e-8180-b36b92ff7312,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-b6a76c13-60e9-4b55-8680-36d53a12b7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-52183d6c-9a9c-4db5-a5a7-241bb52b6ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-a1085025-666e-4359-9cec-67d9e704b59b,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-cd7895ce-8bc5-4069-8557-1bf7fa321306,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-2e2ec2ac-c1f2-434e-a692-f44a744e2c51,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-7b2f2644-83f2-42aa-b797-f27c38162d5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117738188-172.17.0.8-1595559226668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-7e7a76fc-8275-4f85-8d00-8135b6d68f25,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-145a2e02-86c9-444e-8180-b36b92ff7312,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-b6a76c13-60e9-4b55-8680-36d53a12b7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-52183d6c-9a9c-4db5-a5a7-241bb52b6ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-a1085025-666e-4359-9cec-67d9e704b59b,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-cd7895ce-8bc5-4069-8557-1bf7fa321306,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-2e2ec2ac-c1f2-434e-a692-f44a744e2c51,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-7b2f2644-83f2-42aa-b797-f27c38162d5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675007990-172.17.0.8-1595559461935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45888,DS-691a825d-899d-4fe4-842d-5bd4c3578f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-e9301191-d050-4074-a423-8620f6402ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-8b72b9f5-9c76-468f-bd08-e70ae5f41642,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-17e630fa-600a-4b1b-ac1e-11a8af18f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-e1ecaf6d-28bd-4cc5-84f9-7da9c6815034,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-77306ea5-1237-42f6-9033-a767378ef2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-aa4fc1f7-2b7d-4fa6-b4b2-9939322ae47d,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-03915ddc-e8b1-4277-810d-24669c4f470e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675007990-172.17.0.8-1595559461935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45888,DS-691a825d-899d-4fe4-842d-5bd4c3578f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-e9301191-d050-4074-a423-8620f6402ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-8b72b9f5-9c76-468f-bd08-e70ae5f41642,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-17e630fa-600a-4b1b-ac1e-11a8af18f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-e1ecaf6d-28bd-4cc5-84f9-7da9c6815034,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-77306ea5-1237-42f6-9033-a767378ef2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-aa4fc1f7-2b7d-4fa6-b4b2-9939322ae47d,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-03915ddc-e8b1-4277-810d-24669c4f470e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056954767-172.17.0.8-1595559606200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-4c87f964-a846-4fd6-80cd-c72e350755b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-d0d5c531-9f16-424b-a8c8-7b395fb0196e,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-27c68c32-42a9-46cf-a87b-2ae9bea89448,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-8df163c5-a866-4aa3-a219-ca337c3c8710,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-0d856e38-23a9-46a1-9a95-179990209cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-7ee1fe30-3957-4b56-a5ab-547d6b253754,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-acb29261-658b-44d8-b243-e1f987b7a6de,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-2cc0b5c2-d321-4695-9b32-237cfc09869f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056954767-172.17.0.8-1595559606200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-4c87f964-a846-4fd6-80cd-c72e350755b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-d0d5c531-9f16-424b-a8c8-7b395fb0196e,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-27c68c32-42a9-46cf-a87b-2ae9bea89448,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-8df163c5-a866-4aa3-a219-ca337c3c8710,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-0d856e38-23a9-46a1-9a95-179990209cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-7ee1fe30-3957-4b56-a5ab-547d6b253754,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-acb29261-658b-44d8-b243-e1f987b7a6de,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-2cc0b5c2-d321-4695-9b32-237cfc09869f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606944374-172.17.0.8-1595559721581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44505,DS-3849798d-2246-40c9-9d24-7dce11afd051,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-603ceb01-8dc1-4396-b64f-5b3e88966660,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-c20210cb-8fec-498b-8043-7f85818fdbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-32f2ce25-ea13-4fed-a7e9-2714a8b5f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-60156b5a-ca53-445f-9d69-c81c73023a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-b0bc195d-d075-47bf-af39-7243080a85bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-fc74c5ee-2e1c-408a-a059-3431ad49251a,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-bd5bf2bd-73fa-4788-a569-70a9dcb7ce55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606944374-172.17.0.8-1595559721581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44505,DS-3849798d-2246-40c9-9d24-7dce11afd051,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-603ceb01-8dc1-4396-b64f-5b3e88966660,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-c20210cb-8fec-498b-8043-7f85818fdbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-32f2ce25-ea13-4fed-a7e9-2714a8b5f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-60156b5a-ca53-445f-9d69-c81c73023a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-b0bc195d-d075-47bf-af39-7243080a85bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-fc74c5ee-2e1c-408a-a059-3431ad49251a,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-bd5bf2bd-73fa-4788-a569-70a9dcb7ce55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146949391-172.17.0.8-1595559763552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46558,DS-f1278698-32fe-480b-8fa0-95d56705d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-0cbb8bf3-c7f3-4f5b-b9fd-56665044c583,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-68d0e9da-34e1-4232-8b81-2c3df43a9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-3e209302-3601-4929-afda-87cb179745d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-e44195d4-9e72-49d9-8e7f-4c9d8a1c25c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-5cd0dbcf-9127-423b-a13d-abe7ff370fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-11f22dc4-16a1-4bf5-b87a-61840e1b76d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-5df0d3c4-9cc9-4694-bec4-0037a088c021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146949391-172.17.0.8-1595559763552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46558,DS-f1278698-32fe-480b-8fa0-95d56705d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-0cbb8bf3-c7f3-4f5b-b9fd-56665044c583,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-68d0e9da-34e1-4232-8b81-2c3df43a9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-3e209302-3601-4929-afda-87cb179745d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-e44195d4-9e72-49d9-8e7f-4c9d8a1c25c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-5cd0dbcf-9127-423b-a13d-abe7ff370fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-11f22dc4-16a1-4bf5-b87a-61840e1b76d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-5df0d3c4-9cc9-4694-bec4-0037a088c021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293555061-172.17.0.8-1595560285807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-6812f552-0c97-4d2e-b704-e30fe15512fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-0f5fbbd7-1dd8-4158-9dd0-10eff6a1de00,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-ac5e4541-63c0-464c-bb02-6df03ac43ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-9811a17c-b3bf-4fc3-858e-0a4e8fcc8fca,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-10db7338-50af-4c02-aec7-ac286b65f6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-21cc634e-0fe4-422e-9ace-b077511e7cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-fc8dc317-bf4c-47b8-9564-0104a5ba255a,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-8ab1ac52-dc43-441d-99af-1da5172ec62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293555061-172.17.0.8-1595560285807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-6812f552-0c97-4d2e-b704-e30fe15512fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-0f5fbbd7-1dd8-4158-9dd0-10eff6a1de00,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-ac5e4541-63c0-464c-bb02-6df03ac43ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-9811a17c-b3bf-4fc3-858e-0a4e8fcc8fca,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-10db7338-50af-4c02-aec7-ac286b65f6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-21cc634e-0fe4-422e-9ace-b077511e7cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-fc8dc317-bf4c-47b8-9564-0104a5ba255a,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-8ab1ac52-dc43-441d-99af-1da5172ec62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437288621-172.17.0.8-1595560406088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41458,DS-ffe17a23-5283-4896-82c1-87650dc1b01e,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-353d3907-bcf1-46ef-bc90-233546b2163d,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-ac2d49a5-6b89-4d6e-9e86-ca3249ec0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-1647ee44-4ac3-4176-9892-b94a39d927fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-355a05d1-3ee6-4100-b3e9-57c0ed76bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-6aa343e3-0f51-4770-a205-5b779565199e,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-ad620dd4-1ee9-41f2-81fa-07eea6ab7483,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-31fbf412-5421-4254-a20b-fb7cc6cc4278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437288621-172.17.0.8-1595560406088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41458,DS-ffe17a23-5283-4896-82c1-87650dc1b01e,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-353d3907-bcf1-46ef-bc90-233546b2163d,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-ac2d49a5-6b89-4d6e-9e86-ca3249ec0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-1647ee44-4ac3-4176-9892-b94a39d927fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-355a05d1-3ee6-4100-b3e9-57c0ed76bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-6aa343e3-0f51-4770-a205-5b779565199e,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-ad620dd4-1ee9-41f2-81fa-07eea6ab7483,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-31fbf412-5421-4254-a20b-fb7cc6cc4278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488111340-172.17.0.8-1595560470462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35976,DS-697d35d0-e522-471f-8531-be627df5fe05,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-59308d26-5cf3-4dd7-9ba1-6ff4eaa76142,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-814a58e8-2210-4f96-8960-cf2158de1758,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-7d1fcba6-00ef-459d-a998-48b47e596301,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-fe69611f-3b9e-4a4a-b634-92f98f6a7d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-b50f3b0f-88e2-4d06-849b-9d1cfabf92f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-fd20d314-2cc9-4346-b01b-98179e1781aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-701a810d-e493-4cb1-9296-e1bd3e6c5f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488111340-172.17.0.8-1595560470462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35976,DS-697d35d0-e522-471f-8531-be627df5fe05,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-59308d26-5cf3-4dd7-9ba1-6ff4eaa76142,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-814a58e8-2210-4f96-8960-cf2158de1758,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-7d1fcba6-00ef-459d-a998-48b47e596301,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-fe69611f-3b9e-4a4a-b634-92f98f6a7d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-b50f3b0f-88e2-4d06-849b-9d1cfabf92f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-fd20d314-2cc9-4346-b01b-98179e1781aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-701a810d-e493-4cb1-9296-e1bd3e6c5f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758549426-172.17.0.8-1595560547369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45447,DS-f1970b0d-16bd-4cf3-b7f2-c39811a66501,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-845ca567-ba4e-4687-93eb-daaf0a249d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-cc3b4460-96a6-4c5f-bc74-64d744161522,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-36c46754-8ce9-429e-91a2-fc9359db3874,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-76af2c1f-acd4-4a6e-9e07-2d80dc511e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-13d18313-9bba-4257-90e5-04243e43a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-ef418283-63c1-409d-843f-68d31d5763a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-820e39ff-9a30-430c-a98f-366577d179ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758549426-172.17.0.8-1595560547369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45447,DS-f1970b0d-16bd-4cf3-b7f2-c39811a66501,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-845ca567-ba4e-4687-93eb-daaf0a249d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-cc3b4460-96a6-4c5f-bc74-64d744161522,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-36c46754-8ce9-429e-91a2-fc9359db3874,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-76af2c1f-acd4-4a6e-9e07-2d80dc511e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-13d18313-9bba-4257-90e5-04243e43a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-ef418283-63c1-409d-843f-68d31d5763a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-820e39ff-9a30-430c-a98f-366577d179ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928087775-172.17.0.8-1595560578467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-43933bf6-9cda-4f36-8aab-36cda1a2dd91,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-328f7603-ad60-4c88-8f8b-6c30e7c457e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-b7853e3a-0d04-4ac4-86fb-3eee036627b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-597b82cd-a652-4903-8803-35964a71d621,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-31ce2d10-02a9-486d-b8c8-477ed5f35feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-aa3f11ac-65cf-4318-a176-e75251e3a933,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-0f1bceb0-6139-49f8-a89d-bf8b161a5af3,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-348ac6f6-6d05-4190-9415-11b268ed7cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928087775-172.17.0.8-1595560578467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-43933bf6-9cda-4f36-8aab-36cda1a2dd91,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-328f7603-ad60-4c88-8f8b-6c30e7c457e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-b7853e3a-0d04-4ac4-86fb-3eee036627b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-597b82cd-a652-4903-8803-35964a71d621,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-31ce2d10-02a9-486d-b8c8-477ed5f35feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-aa3f11ac-65cf-4318-a176-e75251e3a933,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-0f1bceb0-6139-49f8-a89d-bf8b161a5af3,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-348ac6f6-6d05-4190-9415-11b268ed7cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5462
