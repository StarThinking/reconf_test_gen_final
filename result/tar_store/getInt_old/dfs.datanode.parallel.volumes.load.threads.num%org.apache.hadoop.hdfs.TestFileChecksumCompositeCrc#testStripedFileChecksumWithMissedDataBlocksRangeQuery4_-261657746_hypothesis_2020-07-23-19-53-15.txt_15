reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069224369-172.17.0.14-1595534010245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46259,DS-49eb35f4-eafc-47ed-9529-a95a9c212bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-4608a174-df25-48b0-86f8-980cc8ddc15a,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-6f5dd29e-c55c-441b-a74b-f37d715d3fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-dfb96340-2a1f-4977-8fe4-19c78350fd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-21ad0850-b2fb-47e0-8788-06aed49678d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-0d923eb8-ad7f-4c51-a10c-a8c41522a408,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-a9c9e835-05f5-4aad-b945-e59547c61702,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-47da00f0-0938-48e8-a705-27275a7383bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069224369-172.17.0.14-1595534010245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46259,DS-49eb35f4-eafc-47ed-9529-a95a9c212bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-4608a174-df25-48b0-86f8-980cc8ddc15a,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-6f5dd29e-c55c-441b-a74b-f37d715d3fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-dfb96340-2a1f-4977-8fe4-19c78350fd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-21ad0850-b2fb-47e0-8788-06aed49678d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-0d923eb8-ad7f-4c51-a10c-a8c41522a408,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-a9c9e835-05f5-4aad-b945-e59547c61702,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-47da00f0-0938-48e8-a705-27275a7383bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736922415-172.17.0.14-1595534087555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43900,DS-b9d3ea37-e1cc-4e60-a82e-b343ce5091e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-e1dfcb2e-e313-469d-9967-4f41e5bccb25,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-c9a7ab61-c7ab-47a3-9683-cdc52498b9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-7962537e-2f9c-458d-8cb6-47ec4ce3be0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-e3499c33-91f1-4e6b-90ac-08fc94d5c1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-5216239f-cb93-4e31-a10f-31a6b757c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-1d0472fc-ad64-4f0a-98db-7654e7425066,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-ae34ef79-5498-45aa-a72d-69cfbd687a09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736922415-172.17.0.14-1595534087555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43900,DS-b9d3ea37-e1cc-4e60-a82e-b343ce5091e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-e1dfcb2e-e313-469d-9967-4f41e5bccb25,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-c9a7ab61-c7ab-47a3-9683-cdc52498b9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-7962537e-2f9c-458d-8cb6-47ec4ce3be0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-e3499c33-91f1-4e6b-90ac-08fc94d5c1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-5216239f-cb93-4e31-a10f-31a6b757c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-1d0472fc-ad64-4f0a-98db-7654e7425066,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-ae34ef79-5498-45aa-a72d-69cfbd687a09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087708130-172.17.0.14-1595534304316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42215,DS-99678775-7ca1-4816-bc2b-4c7e0e4f6935,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-8d706086-e3c0-4634-909b-1c6ae2ad0e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-d22dc8ed-8601-4bae-b45a-e7c46516635c,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-75480de0-dc8d-4892-926e-f857fc27a9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-1b4ff047-b43c-4cb4-bfa4-119a343024e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-aeb4e690-ef78-45e5-ae51-62d4b3fbbd24,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-5a939ebe-f69c-4780-83d7-44efd326033c,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-7973bc66-30f6-4eff-ab81-b2504222c5aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087708130-172.17.0.14-1595534304316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42215,DS-99678775-7ca1-4816-bc2b-4c7e0e4f6935,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-8d706086-e3c0-4634-909b-1c6ae2ad0e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-d22dc8ed-8601-4bae-b45a-e7c46516635c,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-75480de0-dc8d-4892-926e-f857fc27a9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-1b4ff047-b43c-4cb4-bfa4-119a343024e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-aeb4e690-ef78-45e5-ae51-62d4b3fbbd24,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-5a939ebe-f69c-4780-83d7-44efd326033c,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-7973bc66-30f6-4eff-ab81-b2504222c5aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899012918-172.17.0.14-1595534440706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46512,DS-0a2b806a-9066-49aa-b646-a0c4e9cfb532,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-1daf80d3-debc-4ecb-9327-47d6857ff5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-d15e4f31-7a75-451c-8ba3-3bac0bba4312,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-771b08d4-54a8-4e79-be33-94b47043f1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-e1ab886e-dfaf-47a9-ad5c-223e5d959be4,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-2a721f3b-dd6f-4959-b1fb-f127dfa49cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-d83c6ecf-091c-4dfc-9711-88d950bca333,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-6dcf785e-4a63-431b-8e49-d4480fcc16a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899012918-172.17.0.14-1595534440706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46512,DS-0a2b806a-9066-49aa-b646-a0c4e9cfb532,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-1daf80d3-debc-4ecb-9327-47d6857ff5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-d15e4f31-7a75-451c-8ba3-3bac0bba4312,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-771b08d4-54a8-4e79-be33-94b47043f1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-e1ab886e-dfaf-47a9-ad5c-223e5d959be4,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-2a721f3b-dd6f-4959-b1fb-f127dfa49cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-d83c6ecf-091c-4dfc-9711-88d950bca333,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-6dcf785e-4a63-431b-8e49-d4480fcc16a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570257885-172.17.0.14-1595534984514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-e7ac642f-fea8-4ece-a6bc-ea47d2839f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-1029fafc-b3f9-4c0b-8cb4-2eaeb8bb4d37,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-fb0baf91-0f8f-4668-850e-557b2b7ea5df,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-90f61e11-b8dd-4137-b105-48d09168793f,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-bff20dc9-3942-4074-8fb7-081fcbd1ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-28504a45-fea0-4bc0-a0f8-05bc22a0610b,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-693356de-ba69-421f-9ed3-9c6ae3a6b59e,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-fea68823-18c3-4eb0-8d47-44272bb68230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570257885-172.17.0.14-1595534984514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-e7ac642f-fea8-4ece-a6bc-ea47d2839f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-1029fafc-b3f9-4c0b-8cb4-2eaeb8bb4d37,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-fb0baf91-0f8f-4668-850e-557b2b7ea5df,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-90f61e11-b8dd-4137-b105-48d09168793f,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-bff20dc9-3942-4074-8fb7-081fcbd1ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-28504a45-fea0-4bc0-a0f8-05bc22a0610b,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-693356de-ba69-421f-9ed3-9c6ae3a6b59e,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-fea68823-18c3-4eb0-8d47-44272bb68230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851952824-172.17.0.14-1595535130995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-bce90423-ecc8-48da-9483-46f88979ac02,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-327d6074-7897-4051-8dad-8eaa1403c1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-2054379d-4f10-40db-81e8-a773c837ca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-e1fd383b-321e-4a8a-960b-0a4347fd176e,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-7c2fec49-7349-4943-9809-1885ecb42f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-c5b6f1c1-a646-4610-8191-5b6513b74ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-c491809b-7dc6-43cc-b56a-6b950796d450,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-93ad45e5-ffb1-471a-9567-df38d880174e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851952824-172.17.0.14-1595535130995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-bce90423-ecc8-48da-9483-46f88979ac02,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-327d6074-7897-4051-8dad-8eaa1403c1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-2054379d-4f10-40db-81e8-a773c837ca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-e1fd383b-321e-4a8a-960b-0a4347fd176e,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-7c2fec49-7349-4943-9809-1885ecb42f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-c5b6f1c1-a646-4610-8191-5b6513b74ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-c491809b-7dc6-43cc-b56a-6b950796d450,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-93ad45e5-ffb1-471a-9567-df38d880174e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712680478-172.17.0.14-1595535165491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-b91eb1c4-a6a3-4eb8-94ba-71f3028ad695,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-9e0fcb21-eace-4b29-872b-029aa1ce13dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-32f128a9-822c-4e55-877b-1803feebe46a,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-bd096c3e-746d-4ed0-a80d-9a955e89b4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-41f52406-4cc1-4b91-afc4-7e83128cb583,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-8f9890a5-570c-4332-a119-0ef0c9ae28f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-cb9902cd-d591-4507-993b-b1678de3307e,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-5cb3daae-e1f2-4287-8655-dd6b2e39a764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712680478-172.17.0.14-1595535165491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-b91eb1c4-a6a3-4eb8-94ba-71f3028ad695,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-9e0fcb21-eace-4b29-872b-029aa1ce13dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-32f128a9-822c-4e55-877b-1803feebe46a,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-bd096c3e-746d-4ed0-a80d-9a955e89b4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-41f52406-4cc1-4b91-afc4-7e83128cb583,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-8f9890a5-570c-4332-a119-0ef0c9ae28f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-cb9902cd-d591-4507-993b-b1678de3307e,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-5cb3daae-e1f2-4287-8655-dd6b2e39a764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129565005-172.17.0.14-1595535273221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46444,DS-20fb67cd-dbe8-4760-8833-f4c88985be7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-0fd40b5d-1526-47f8-baaf-f3e1f42fa731,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-9f531844-a251-4aa8-a019-f2d650b682b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-348bbb4f-3d34-4912-846b-959ff83f99a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-950bcc8c-9b2d-4787-8f5e-05bbf31b82df,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-8670e529-41ea-4978-8bbf-cfd054ca1365,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-b5007e47-70ee-41d1-804d-de9bbd44d560,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-c16e312d-9e30-45a5-9efd-855b959b4ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129565005-172.17.0.14-1595535273221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46444,DS-20fb67cd-dbe8-4760-8833-f4c88985be7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-0fd40b5d-1526-47f8-baaf-f3e1f42fa731,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-9f531844-a251-4aa8-a019-f2d650b682b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-348bbb4f-3d34-4912-846b-959ff83f99a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-950bcc8c-9b2d-4787-8f5e-05bbf31b82df,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-8670e529-41ea-4978-8bbf-cfd054ca1365,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-b5007e47-70ee-41d1-804d-de9bbd44d560,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-c16e312d-9e30-45a5-9efd-855b959b4ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235823558-172.17.0.14-1595535337136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-5032bf9d-09af-4016-a54f-332351442ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-35c9b727-3881-4573-879d-94a09a7f46c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-367d3259-1bb3-479e-ae56-1876671b69c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-9b7cc110-8dca-4493-a65f-0b774c1a7679,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-57a37d98-3828-4b5d-ab51-3ca4d9fe71a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-56eb227e-ea36-4bf7-92a2-ef2d10257936,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-ee899deb-2a5c-4341-8c84-cbee9ee63b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-c864f9b7-6c7e-4581-8bc4-678ba4fe54c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235823558-172.17.0.14-1595535337136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-5032bf9d-09af-4016-a54f-332351442ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-35c9b727-3881-4573-879d-94a09a7f46c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-367d3259-1bb3-479e-ae56-1876671b69c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-9b7cc110-8dca-4493-a65f-0b774c1a7679,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-57a37d98-3828-4b5d-ab51-3ca4d9fe71a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-56eb227e-ea36-4bf7-92a2-ef2d10257936,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-ee899deb-2a5c-4341-8c84-cbee9ee63b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-c864f9b7-6c7e-4581-8bc4-678ba4fe54c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439072643-172.17.0.14-1595535458966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-19599c28-7e45-4380-a6b7-af6ffbeb64bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-3f1104e0-b059-4a75-b1bf-cb0c45a906c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-0e45a65b-4add-477e-aeb7-ae664734e3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-fe297d78-9f6f-4fa6-8bba-b75cb8da6779,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-cb174c7c-5c14-49e9-bea1-997c28851f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-247aee87-3494-4cbe-bc02-930bf0a9a222,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-bac5fbb3-c4a0-442b-b0e7-79b82e2c7bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-a27e007f-856b-45e6-8fe8-6cb83f2242ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439072643-172.17.0.14-1595535458966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-19599c28-7e45-4380-a6b7-af6ffbeb64bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-3f1104e0-b059-4a75-b1bf-cb0c45a906c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-0e45a65b-4add-477e-aeb7-ae664734e3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-fe297d78-9f6f-4fa6-8bba-b75cb8da6779,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-cb174c7c-5c14-49e9-bea1-997c28851f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-247aee87-3494-4cbe-bc02-930bf0a9a222,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-bac5fbb3-c4a0-442b-b0e7-79b82e2c7bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-a27e007f-856b-45e6-8fe8-6cb83f2242ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258337298-172.17.0.14-1595535929538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44221,DS-91d4eaea-d02e-4fde-81af-623311c40a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-4f1f528c-80f9-4d79-8e25-b39e91d5f535,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-590e5f1a-3f75-4277-b838-c45c370c1a25,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-c350e4e5-975b-477d-b031-6794a193c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-34a2b56e-25ce-4383-98e9-bd217b3f12c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-fc16da73-d806-404a-8d33-13ff85d17e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-c3dee522-9a89-4a32-8a44-b4e795645b75,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-812849b6-5697-435d-8053-7429182c0b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258337298-172.17.0.14-1595535929538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44221,DS-91d4eaea-d02e-4fde-81af-623311c40a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-4f1f528c-80f9-4d79-8e25-b39e91d5f535,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-590e5f1a-3f75-4277-b838-c45c370c1a25,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-c350e4e5-975b-477d-b031-6794a193c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-34a2b56e-25ce-4383-98e9-bd217b3f12c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-fc16da73-d806-404a-8d33-13ff85d17e69,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-c3dee522-9a89-4a32-8a44-b4e795645b75,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-812849b6-5697-435d-8053-7429182c0b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502869378-172.17.0.14-1595536082499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33017,DS-3232812f-85cd-4160-9080-e5f2c14b38e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-bab74321-3de2-44a9-b057-40f23680efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-b02525e9-63c1-4f81-8fe9-edcf50d69670,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-855695a4-88d7-4153-9052-d163065254f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-3b545653-116e-4644-8a59-38d74cefa75e,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-2a5dcaa5-8fc4-4208-9e63-cc4718e98be9,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-c72c0bb4-fa57-4122-be8f-5030bc643c96,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-d5d04813-5322-4289-a280-d61dd344a170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502869378-172.17.0.14-1595536082499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33017,DS-3232812f-85cd-4160-9080-e5f2c14b38e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-bab74321-3de2-44a9-b057-40f23680efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-b02525e9-63c1-4f81-8fe9-edcf50d69670,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-855695a4-88d7-4153-9052-d163065254f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-3b545653-116e-4644-8a59-38d74cefa75e,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-2a5dcaa5-8fc4-4208-9e63-cc4718e98be9,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-c72c0bb4-fa57-4122-be8f-5030bc643c96,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-d5d04813-5322-4289-a280-d61dd344a170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217181623-172.17.0.14-1595536318038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43460,DS-8b1272cf-f193-424d-b1a3-951f15804ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-5f544bf3-c162-477a-aa71-f13d506085f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-d6122f9e-5db9-4c30-b6e4-74c777dacff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2dfc20cd-c2eb-478c-9a18-07913e4144fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-07a1c563-3f23-4554-bfaf-d3ec337e1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-aa9881f2-e13f-49c3-a254-326a29cb7ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-9d742172-8180-45b8-8058-7c48f211748b,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-96dc8f66-ec9f-4ec7-84ba-9b481807b54d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217181623-172.17.0.14-1595536318038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43460,DS-8b1272cf-f193-424d-b1a3-951f15804ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-5f544bf3-c162-477a-aa71-f13d506085f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-d6122f9e-5db9-4c30-b6e4-74c777dacff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2dfc20cd-c2eb-478c-9a18-07913e4144fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-07a1c563-3f23-4554-bfaf-d3ec337e1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-aa9881f2-e13f-49c3-a254-326a29cb7ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-9d742172-8180-45b8-8058-7c48f211748b,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-96dc8f66-ec9f-4ec7-84ba-9b481807b54d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447299556-172.17.0.14-1595536570920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-ac5bbca9-7f45-430a-b4c5-8a7a1153fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-202ab184-f5db-427d-acf8-11aad513286a,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-9b64dd1e-f77c-451c-9ec2-d41505ae71d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-b96fdcf6-0803-4d28-ae3e-ff55280b181b,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-cd33720b-dd11-4ff2-bc85-b5ba3332a6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-c8ba972d-2997-48b2-91dd-5e7e8788d90b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-691a5ff6-8190-4755-b4ee-0b9ede12f900,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-2d7bb429-885b-4c07-bb67-82a7fc36da80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447299556-172.17.0.14-1595536570920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-ac5bbca9-7f45-430a-b4c5-8a7a1153fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-202ab184-f5db-427d-acf8-11aad513286a,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-9b64dd1e-f77c-451c-9ec2-d41505ae71d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-b96fdcf6-0803-4d28-ae3e-ff55280b181b,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-cd33720b-dd11-4ff2-bc85-b5ba3332a6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-c8ba972d-2997-48b2-91dd-5e7e8788d90b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-691a5ff6-8190-4755-b4ee-0b9ede12f900,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-2d7bb429-885b-4c07-bb67-82a7fc36da80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125563145-172.17.0.14-1595536786714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36475,DS-8014a6cc-3ae5-4a5b-ae92-bfa7b5ae7211,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-d4dcec4d-eef3-4307-93ac-a45715bcc6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-e14936af-baf2-4361-84ad-cdbcc7ebf369,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-47c4366d-36b5-419b-9f87-f6974d570bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-864e9ce4-9a3f-469e-9da7-748dc58e3992,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-08780c55-89ab-4aad-8779-0f50ad480a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-97a64855-dba7-41d0-936f-86bc3c0d4f23,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-72ca66ad-aef6-498f-9f56-369a41ed7e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125563145-172.17.0.14-1595536786714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36475,DS-8014a6cc-3ae5-4a5b-ae92-bfa7b5ae7211,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-d4dcec4d-eef3-4307-93ac-a45715bcc6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-e14936af-baf2-4361-84ad-cdbcc7ebf369,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-47c4366d-36b5-419b-9f87-f6974d570bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-864e9ce4-9a3f-469e-9da7-748dc58e3992,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-08780c55-89ab-4aad-8779-0f50ad480a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-97a64855-dba7-41d0-936f-86bc3c0d4f23,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-72ca66ad-aef6-498f-9f56-369a41ed7e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871235766-172.17.0.14-1595536981942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-3c3fd6b0-01c3-492c-ba8a-4c3c27dc8d46,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-66669ea4-99c2-4710-93d0-506fc2ce91e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-0a5e11c6-ca29-4352-9ad6-d5c0956f09fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-0565251c-4b92-423f-a713-db9e56c20c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e3926651-e3a9-40a7-929e-79127b1219c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-c81b1971-7a7f-4f0e-96d8-e36b578c5aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-02ab1f94-9697-41eb-afd2-e35a013fe7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-7d6d58fb-1315-453c-ad39-cc245e78b384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871235766-172.17.0.14-1595536981942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-3c3fd6b0-01c3-492c-ba8a-4c3c27dc8d46,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-66669ea4-99c2-4710-93d0-506fc2ce91e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-0a5e11c6-ca29-4352-9ad6-d5c0956f09fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-0565251c-4b92-423f-a713-db9e56c20c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e3926651-e3a9-40a7-929e-79127b1219c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-c81b1971-7a7f-4f0e-96d8-e36b578c5aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-02ab1f94-9697-41eb-afd2-e35a013fe7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-7d6d58fb-1315-453c-ad39-cc245e78b384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757485974-172.17.0.14-1595537189312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-ceadf414-16a2-461d-a4d7-c7fe7aff1ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-b9ac1165-6e0e-41e8-bd5b-f3609ef79c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-6f6b4eca-3ec1-4811-acb4-34fda65478a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-74823384-e75e-4460-8219-824c5b63fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-a54e0c0e-e6cc-4d76-ab7f-5c518b2b5431,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-6d45e6e5-b6d0-4c1e-bcee-6accd5b01e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-7ef5e090-054d-4b6f-8eb0-bcc5f75e458f,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-dd664480-1603-432c-afa2-ea777bf4d8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757485974-172.17.0.14-1595537189312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40263,DS-ceadf414-16a2-461d-a4d7-c7fe7aff1ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-b9ac1165-6e0e-41e8-bd5b-f3609ef79c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-6f6b4eca-3ec1-4811-acb4-34fda65478a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-74823384-e75e-4460-8219-824c5b63fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-a54e0c0e-e6cc-4d76-ab7f-5c518b2b5431,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-6d45e6e5-b6d0-4c1e-bcee-6accd5b01e36,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-7ef5e090-054d-4b6f-8eb0-bcc5f75e458f,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-dd664480-1603-432c-afa2-ea777bf4d8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255155159-172.17.0.14-1595537738617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-7bc05c8c-18bb-4c83-bc5e-f28a573cb1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-6d9e3914-593a-43e8-ab29-8a2cf4258dea,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-9f7bfc03-bdcc-4388-b0d3-948cedd8f103,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-d7a4d7d2-6c04-4d86-b558-98d18a582c06,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-9cc7f79a-f480-40fb-bc68-f232637e237c,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-fcb7f22d-295f-4358-a737-f692b95dea36,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-e1cffbd0-55f4-48f7-b419-1ae109e17396,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-549d12cb-cbd4-4a6c-bc25-0e6d08a23d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255155159-172.17.0.14-1595537738617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-7bc05c8c-18bb-4c83-bc5e-f28a573cb1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-6d9e3914-593a-43e8-ab29-8a2cf4258dea,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-9f7bfc03-bdcc-4388-b0d3-948cedd8f103,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-d7a4d7d2-6c04-4d86-b558-98d18a582c06,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-9cc7f79a-f480-40fb-bc68-f232637e237c,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-fcb7f22d-295f-4358-a737-f692b95dea36,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-e1cffbd0-55f4-48f7-b419-1ae109e17396,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-549d12cb-cbd4-4a6c-bc25-0e6d08a23d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074177649-172.17.0.14-1595537801483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-7aa99054-b726-4e6a-940e-a7fcd422915e,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-c1dfaa46-61e9-46f3-add5-af97f7015fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-fb0664d0-8f9c-4fc7-a60b-a45260e2b168,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-33fc6df0-2260-417c-a1df-f8f7ba5daf96,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-89f8f131-d70e-4728-8a33-4927cd8e233e,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-778902fa-2e99-48f5-9f73-7708e262f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-2b2a2b81-54b3-4063-b0b9-d68bc0a9477a,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-870b5e05-2930-41cb-84a1-8faf39c25819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074177649-172.17.0.14-1595537801483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-7aa99054-b726-4e6a-940e-a7fcd422915e,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-c1dfaa46-61e9-46f3-add5-af97f7015fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-fb0664d0-8f9c-4fc7-a60b-a45260e2b168,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-33fc6df0-2260-417c-a1df-f8f7ba5daf96,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-89f8f131-d70e-4728-8a33-4927cd8e233e,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-778902fa-2e99-48f5-9f73-7708e262f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-2b2a2b81-54b3-4063-b0b9-d68bc0a9477a,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-870b5e05-2930-41cb-84a1-8faf39c25819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582875138-172.17.0.14-1595537832898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44751,DS-a552004a-27ab-4b24-a2e5-6946d703196d,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-dd85bf9b-7443-432a-9744-f724fe131e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-d22dadcf-5cd3-483f-a657-98cec2386609,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-4e2670ea-d66f-4842-a924-0889f261e3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-7652fc3d-2fbe-4358-8033-fae6876d887f,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-92bfcab4-8357-4379-b7b3-2fd048454fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-1da5d86a-ab06-4830-8fc9-713eeb6d3529,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-5792d558-f6b1-45c1-a4fb-2d8fbfb1a41b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582875138-172.17.0.14-1595537832898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44751,DS-a552004a-27ab-4b24-a2e5-6946d703196d,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-dd85bf9b-7443-432a-9744-f724fe131e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-d22dadcf-5cd3-483f-a657-98cec2386609,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-4e2670ea-d66f-4842-a924-0889f261e3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-7652fc3d-2fbe-4358-8033-fae6876d887f,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-92bfcab4-8357-4379-b7b3-2fd048454fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-1da5d86a-ab06-4830-8fc9-713eeb6d3529,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-5792d558-f6b1-45c1-a4fb-2d8fbfb1a41b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958143675-172.17.0.14-1595537867710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40248,DS-82b802b9-91ad-46e7-8c37-1e56246c35d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-af08c704-9b40-45f7-a939-b85b53a02988,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-686de735-e6fd-471d-9544-50c9e4d60b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-f559db8e-c978-412e-b992-2721da9048f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-9638bdd5-2346-44ac-be2f-ccf4ab36feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-e6db1a75-2527-4d52-b2a2-64cc49be25d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-847bff30-07c1-4b0e-8426-e08a05ee5a40,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-b2d3e722-83df-4940-8ee9-74c5d8b1cbbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958143675-172.17.0.14-1595537867710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40248,DS-82b802b9-91ad-46e7-8c37-1e56246c35d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-af08c704-9b40-45f7-a939-b85b53a02988,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-686de735-e6fd-471d-9544-50c9e4d60b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-f559db8e-c978-412e-b992-2721da9048f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-9638bdd5-2346-44ac-be2f-ccf4ab36feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-e6db1a75-2527-4d52-b2a2-64cc49be25d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-847bff30-07c1-4b0e-8426-e08a05ee5a40,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-b2d3e722-83df-4940-8ee9-74c5d8b1cbbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066374018-172.17.0.14-1595537969625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-8512e52a-a40f-4186-b460-28365d7da459,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-422f076f-ec14-44ee-a3cb-0f5828ce2d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-817b5b33-f839-4c51-9ace-520d7b9ef451,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-d1cda771-c721-4b7d-9ba6-6043767947ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-157863cf-a335-4b9e-a98d-743f3744e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-6d9138e0-d865-43d1-8666-cfbd4a2390ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-e8cfc931-a04d-4c61-87ea-69ed4394cfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-c553f394-4eec-4de8-b64b-5c74b4c35523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066374018-172.17.0.14-1595537969625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-8512e52a-a40f-4186-b460-28365d7da459,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-422f076f-ec14-44ee-a3cb-0f5828ce2d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-817b5b33-f839-4c51-9ace-520d7b9ef451,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-d1cda771-c721-4b7d-9ba6-6043767947ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-157863cf-a335-4b9e-a98d-743f3744e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-6d9138e0-d865-43d1-8666-cfbd4a2390ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-e8cfc931-a04d-4c61-87ea-69ed4394cfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-c553f394-4eec-4de8-b64b-5c74b4c35523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867499717-172.17.0.14-1595538341936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-001d0b5c-b9e0-4864-9c94-d9b137ba90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-f442f07b-d627-46f2-9ff9-62e0c69c062f,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-f166c47c-3f37-4a58-9afa-a123d4232e92,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-ec1871ed-2c6d-4f80-ac52-1a6e1b4f587c,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-3d41de84-6664-4e83-893e-dff8e1e5ea09,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-c1f0ef40-723d-4a65-bd24-de796effc46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-cc225570-ca36-4e6a-96df-23a80a8b01f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-d2dbbea6-e73b-4cbe-a592-874c26e0e0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867499717-172.17.0.14-1595538341936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-001d0b5c-b9e0-4864-9c94-d9b137ba90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-f442f07b-d627-46f2-9ff9-62e0c69c062f,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-f166c47c-3f37-4a58-9afa-a123d4232e92,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-ec1871ed-2c6d-4f80-ac52-1a6e1b4f587c,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-3d41de84-6664-4e83-893e-dff8e1e5ea09,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-c1f0ef40-723d-4a65-bd24-de796effc46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-cc225570-ca36-4e6a-96df-23a80a8b01f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-d2dbbea6-e73b-4cbe-a592-874c26e0e0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946454251-172.17.0.14-1595538490703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35521,DS-399470c9-08c4-4213-aebc-9404ead7ffce,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-1c927f9d-4ab8-4b75-beda-d5f8b5436e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-bbea8632-824b-4591-9c11-51a292af5429,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-53e8df22-aa3e-473e-a4c8-dab46169746a,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-684c098e-75cd-4830-b667-e9421730cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-7e83f98d-96e7-47ec-922c-e64f26b03706,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-68dbfa1d-8493-41f5-a012-1d131e98eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-31886cae-ab10-4c76-b4ec-c8061f6a4838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946454251-172.17.0.14-1595538490703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35521,DS-399470c9-08c4-4213-aebc-9404ead7ffce,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-1c927f9d-4ab8-4b75-beda-d5f8b5436e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-bbea8632-824b-4591-9c11-51a292af5429,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-53e8df22-aa3e-473e-a4c8-dab46169746a,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-684c098e-75cd-4830-b667-e9421730cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-7e83f98d-96e7-47ec-922c-e64f26b03706,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-68dbfa1d-8493-41f5-a012-1d131e98eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-31886cae-ab10-4c76-b4ec-c8061f6a4838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 10
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462129690-172.17.0.14-1595538600552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35232,DS-085bad6d-a155-4fbf-8b05-96f41726a363,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-176a9adf-ff69-4e14-8b78-8dea3e63b270,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-10eb3535-d22a-4af8-8f2d-4b911671f241,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-73167a2a-96f8-4441-9fc9-bb41991a2c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-da62b337-fa6b-48b0-9411-35f6bd142c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-9113f4a3-574f-45b6-84df-3249c8e32e02,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-5ba6ca66-204d-42be-898b-ba2970b1124b,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-3f73ed4c-6363-4ab1-b6cd-2654741673c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462129690-172.17.0.14-1595538600552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35232,DS-085bad6d-a155-4fbf-8b05-96f41726a363,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-176a9adf-ff69-4e14-8b78-8dea3e63b270,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-10eb3535-d22a-4af8-8f2d-4b911671f241,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-73167a2a-96f8-4441-9fc9-bb41991a2c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-da62b337-fa6b-48b0-9411-35f6bd142c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-9113f4a3-574f-45b6-84df-3249c8e32e02,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-5ba6ca66-204d-42be-898b-ba2970b1124b,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-3f73ed4c-6363-4ab1-b6cd-2654741673c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5425
