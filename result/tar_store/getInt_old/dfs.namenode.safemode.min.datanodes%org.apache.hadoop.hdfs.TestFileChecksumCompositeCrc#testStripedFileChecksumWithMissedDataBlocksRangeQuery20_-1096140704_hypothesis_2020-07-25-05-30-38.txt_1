reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565703547-172.17.0.4-1595655175045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-c7cab3ec-4c93-4ea3-adb6-6823489b4fba,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-9e89f20a-3237-408b-bd11-a02b3408daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-6853bd8a-4478-4d47-8402-abe6c8ff8a77,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-678c1861-f994-42b6-8efb-fa86a2aadfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-8239bfbb-dded-4bd7-96ac-44b3b11839e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-68cff2ef-720e-495a-875c-8fe940c4bbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-681868e7-0ca8-4664-ad8c-df629311d88a,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-4bef8d48-378f-4aed-a9fb-d89f570fabbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565703547-172.17.0.4-1595655175045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-c7cab3ec-4c93-4ea3-adb6-6823489b4fba,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-9e89f20a-3237-408b-bd11-a02b3408daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-6853bd8a-4478-4d47-8402-abe6c8ff8a77,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-678c1861-f994-42b6-8efb-fa86a2aadfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-8239bfbb-dded-4bd7-96ac-44b3b11839e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-68cff2ef-720e-495a-875c-8fe940c4bbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-681868e7-0ca8-4664-ad8c-df629311d88a,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-4bef8d48-378f-4aed-a9fb-d89f570fabbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951560031-172.17.0.4-1595655456980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-ed2d7d7b-715b-4338-94b6-41448eab52e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-d4530f6d-7bee-494e-bd5a-00ddfa5ac941,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-cf329a8a-84cd-4a67-ad0d-0408e8ef8325,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-83aaaab8-e5f4-4865-a1da-2a05381ad81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-b0008b8d-d8b4-4c1b-a1b8-fecc49f96473,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-6b462609-eedd-4266-8123-dd234ee58d14,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-1e3a91cf-b529-4506-83b8-ebb792640a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-f5671a01-6627-467a-8d9f-1639003e1f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951560031-172.17.0.4-1595655456980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-ed2d7d7b-715b-4338-94b6-41448eab52e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-d4530f6d-7bee-494e-bd5a-00ddfa5ac941,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-cf329a8a-84cd-4a67-ad0d-0408e8ef8325,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-83aaaab8-e5f4-4865-a1da-2a05381ad81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-b0008b8d-d8b4-4c1b-a1b8-fecc49f96473,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-6b462609-eedd-4266-8123-dd234ee58d14,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-1e3a91cf-b529-4506-83b8-ebb792640a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-f5671a01-6627-467a-8d9f-1639003e1f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919489649-172.17.0.4-1595655536167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36812,DS-1a3bd26d-3991-45a4-897c-3550d9cfb92a,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-0d4edb25-5734-4095-bb70-79ebc3745a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-25a665b5-d830-47e3-807e-93e3ab593930,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-2e737c68-8617-471d-b41a-3591cc19cea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-79d83d05-c06f-4747-b040-bf5978e7aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-34d7aad9-3df6-4e0e-b6ae-fb4dcb61e614,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-3d437d01-4e9a-4aa3-998f-ebe16aefb3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-90202bb5-6c43-42ba-a173-693b7d221aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919489649-172.17.0.4-1595655536167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36812,DS-1a3bd26d-3991-45a4-897c-3550d9cfb92a,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-0d4edb25-5734-4095-bb70-79ebc3745a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-25a665b5-d830-47e3-807e-93e3ab593930,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-2e737c68-8617-471d-b41a-3591cc19cea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-79d83d05-c06f-4747-b040-bf5978e7aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-34d7aad9-3df6-4e0e-b6ae-fb4dcb61e614,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-3d437d01-4e9a-4aa3-998f-ebe16aefb3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-90202bb5-6c43-42ba-a173-693b7d221aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680806627-172.17.0.4-1595655813133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-d45ee04c-ded7-4ed1-9f2a-346561ea18e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-7ff5f7bc-efc7-4c16-837f-c93b7d6476e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-7165fd72-c42e-4eca-8b7e-3f6d1b792680,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-e9f7f8a5-160a-4382-8197-f4fa02f70e68,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-b0a08beb-cd43-41c4-815a-d3335c8cc7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d7fc1a93-6afd-4554-91c1-53fee56753a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-8709bfda-e106-47ec-89d7-2e7844f69929,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-70c77c94-58bb-440f-aa0f-796e6a5b8476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680806627-172.17.0.4-1595655813133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-d45ee04c-ded7-4ed1-9f2a-346561ea18e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-7ff5f7bc-efc7-4c16-837f-c93b7d6476e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-7165fd72-c42e-4eca-8b7e-3f6d1b792680,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-e9f7f8a5-160a-4382-8197-f4fa02f70e68,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-b0a08beb-cd43-41c4-815a-d3335c8cc7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d7fc1a93-6afd-4554-91c1-53fee56753a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-8709bfda-e106-47ec-89d7-2e7844f69929,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-70c77c94-58bb-440f-aa0f-796e6a5b8476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493778332-172.17.0.4-1595655852921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-f092f993-372f-41be-8098-b3e02669f363,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-4f8ca471-73f0-4545-8d16-dbecf3ba5d28,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-3512c1d5-8e81-4dd0-8999-cc90b6bff9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-a22692bd-35da-43dc-a4ec-b37ddf2225e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-6ba3213b-e6cf-46a3-9684-cd14646b3f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-dcbae244-51f5-4b74-ba86-e9bb3099985b,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-7fde7a77-0611-4277-8795-2d777651f587,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-b22627a1-65c3-48f0-8b1f-e27cc2af358a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493778332-172.17.0.4-1595655852921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-f092f993-372f-41be-8098-b3e02669f363,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-4f8ca471-73f0-4545-8d16-dbecf3ba5d28,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-3512c1d5-8e81-4dd0-8999-cc90b6bff9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-a22692bd-35da-43dc-a4ec-b37ddf2225e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-6ba3213b-e6cf-46a3-9684-cd14646b3f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-dcbae244-51f5-4b74-ba86-e9bb3099985b,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-7fde7a77-0611-4277-8795-2d777651f587,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-b22627a1-65c3-48f0-8b1f-e27cc2af358a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700560699-172.17.0.4-1595655974562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41581,DS-c83f3ee6-05fd-424a-ae2e-6e255c6e93bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-713f0a74-89e8-4092-ab42-82f6c99a3782,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-df47d0ec-6757-4d71-ba26-b33dec5b385f,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-bf175eca-f4f6-4e8b-8244-be99bdddf6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-eaa1119f-ebbc-402d-9448-81724343e3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-53b1379c-cb9a-480f-aaad-58e91e3fb776,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-17e35a0b-7bc9-4395-9b85-8de51411d4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-9cbff657-53fc-43b8-ac6f-a6f02cdea731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700560699-172.17.0.4-1595655974562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41581,DS-c83f3ee6-05fd-424a-ae2e-6e255c6e93bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-713f0a74-89e8-4092-ab42-82f6c99a3782,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-df47d0ec-6757-4d71-ba26-b33dec5b385f,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-bf175eca-f4f6-4e8b-8244-be99bdddf6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-eaa1119f-ebbc-402d-9448-81724343e3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-53b1379c-cb9a-480f-aaad-58e91e3fb776,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-17e35a0b-7bc9-4395-9b85-8de51411d4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-9cbff657-53fc-43b8-ac6f-a6f02cdea731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119778355-172.17.0.4-1595656017094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37116,DS-3ef539bd-cca4-43c6-bd65-5925422a9e49,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-c881756c-fafa-4475-828a-5588204a4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-8881bfa7-4858-4ab3-9eb7-16269409c7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-caff62c3-d552-4bb4-88ea-b5161a98a7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-398bcd0b-bc8f-4e78-aa18-654188d430be,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-cf8d004b-912e-41df-a121-b90168972c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-a9fcacdf-110e-4dcf-9ff6-bb8df5c438e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-4a0f41ca-092d-4661-9b8a-50ae676db6f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119778355-172.17.0.4-1595656017094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37116,DS-3ef539bd-cca4-43c6-bd65-5925422a9e49,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-c881756c-fafa-4475-828a-5588204a4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-8881bfa7-4858-4ab3-9eb7-16269409c7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-caff62c3-d552-4bb4-88ea-b5161a98a7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-398bcd0b-bc8f-4e78-aa18-654188d430be,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-cf8d004b-912e-41df-a121-b90168972c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-a9fcacdf-110e-4dcf-9ff6-bb8df5c438e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-4a0f41ca-092d-4661-9b8a-50ae676db6f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696122991-172.17.0.4-1595656256296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-365b4019-497e-43b2-8eca-25b5f0cf941e,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-b4f5f6ef-8d83-4d44-9d31-d7b787b209c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-3e6cdddb-6748-49b0-a3a0-74bd69a0a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-093715bb-b53f-40fd-b877-41af052acaed,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-c88c8f02-9a83-4aca-8676-a2714342931e,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-ed30393b-8850-4be7-958d-1e6e494ec92d,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-f00955f0-ce22-4da0-a7f9-878d5314e221,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-1649d552-0467-4951-9066-d3383e9130b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696122991-172.17.0.4-1595656256296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-365b4019-497e-43b2-8eca-25b5f0cf941e,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-b4f5f6ef-8d83-4d44-9d31-d7b787b209c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-3e6cdddb-6748-49b0-a3a0-74bd69a0a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-093715bb-b53f-40fd-b877-41af052acaed,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-c88c8f02-9a83-4aca-8676-a2714342931e,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-ed30393b-8850-4be7-958d-1e6e494ec92d,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-f00955f0-ce22-4da0-a7f9-878d5314e221,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-1649d552-0467-4951-9066-d3383e9130b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298253974-172.17.0.4-1595656296639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36531,DS-9ec700ae-e347-4d9f-a1c0-4f43ee5c0460,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-b2b2def3-7a85-491b-8bd1-0056f1835d21,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-a8e49dfe-4bdb-455c-830b-8b0b0dafcabd,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-981b93f7-1069-4798-b2fc-55a9aee7d4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-730b33c0-ac59-4b3a-af52-7508562ea502,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-2ed6ecbd-e86e-4626-bbca-e3e274f3f835,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-2c980933-2acc-4f89-9f34-dd54409cbcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-6f2c9096-4d80-49d9-b806-a3444aaa2039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298253974-172.17.0.4-1595656296639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36531,DS-9ec700ae-e347-4d9f-a1c0-4f43ee5c0460,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-b2b2def3-7a85-491b-8bd1-0056f1835d21,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-a8e49dfe-4bdb-455c-830b-8b0b0dafcabd,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-981b93f7-1069-4798-b2fc-55a9aee7d4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-730b33c0-ac59-4b3a-af52-7508562ea502,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-2ed6ecbd-e86e-4626-bbca-e3e274f3f835,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-2c980933-2acc-4f89-9f34-dd54409cbcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-6f2c9096-4d80-49d9-b806-a3444aaa2039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152540769-172.17.0.4-1595656424494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37204,DS-88a0eadf-4b22-49b1-a47d-32c63bacba3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-fdb6710c-d84b-41b0-9d27-303eb968a284,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-906990ed-5066-422d-a133-147b9cf57dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-8fbbb942-166f-47ad-b784-517b242ad8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-a97c1c10-c334-4ee5-b26d-92e4ad3b94a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-7e36757b-5d12-4a47-ac62-c774588ef7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-1945c46a-abde-4227-be52-d1de19ebbeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-bef86c0f-2b4c-4c63-9c68-3c60944392b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152540769-172.17.0.4-1595656424494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37204,DS-88a0eadf-4b22-49b1-a47d-32c63bacba3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-fdb6710c-d84b-41b0-9d27-303eb968a284,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-906990ed-5066-422d-a133-147b9cf57dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-8fbbb942-166f-47ad-b784-517b242ad8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-a97c1c10-c334-4ee5-b26d-92e4ad3b94a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-7e36757b-5d12-4a47-ac62-c774588ef7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-1945c46a-abde-4227-be52-d1de19ebbeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-bef86c0f-2b4c-4c63-9c68-3c60944392b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874018906-172.17.0.4-1595656919809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44752,DS-482b764d-e4d5-4016-9e3b-2db7927d43e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-bfb61601-3ced-4414-ba00-3a211557a852,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-f2c0e46d-3c6f-4423-b690-e7edf854be32,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-4052bbe1-3b85-49cb-af70-241e827283f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-cb764bed-f95a-4fe4-be30-96868d362c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-b89442cd-009d-4f03-8ed8-556cf39d87d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-0e3719e6-68c4-463f-beb6-615ffffcc309,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-c70ef9e0-20d6-4611-a4e4-2ffb9ae4320a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874018906-172.17.0.4-1595656919809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44752,DS-482b764d-e4d5-4016-9e3b-2db7927d43e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-bfb61601-3ced-4414-ba00-3a211557a852,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-f2c0e46d-3c6f-4423-b690-e7edf854be32,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-4052bbe1-3b85-49cb-af70-241e827283f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-cb764bed-f95a-4fe4-be30-96868d362c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-b89442cd-009d-4f03-8ed8-556cf39d87d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-0e3719e6-68c4-463f-beb6-615ffffcc309,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-c70ef9e0-20d6-4611-a4e4-2ffb9ae4320a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015630904-172.17.0.4-1595657454491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-60149db2-ca17-42b4-85e0-81ab21fc2884,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-259b1ebf-64d8-4833-b47d-ce8bfa07ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-57e07fcd-a3f2-4710-a723-88f412e0a4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-13ba16fc-81b6-43db-be9b-5b21184a9100,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-5991d51f-b465-4687-903b-718f3b104685,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-64986566-c7eb-487b-9e41-1fb6c2ae3644,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-7bd82eae-cb45-4991-989e-b1c185730059,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-72dc7709-70c4-49cf-b5f9-7163fd90e128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015630904-172.17.0.4-1595657454491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-60149db2-ca17-42b4-85e0-81ab21fc2884,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-259b1ebf-64d8-4833-b47d-ce8bfa07ba73,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-57e07fcd-a3f2-4710-a723-88f412e0a4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-13ba16fc-81b6-43db-be9b-5b21184a9100,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-5991d51f-b465-4687-903b-718f3b104685,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-64986566-c7eb-487b-9e41-1fb6c2ae3644,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-7bd82eae-cb45-4991-989e-b1c185730059,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-72dc7709-70c4-49cf-b5f9-7163fd90e128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436708994-172.17.0.4-1595659299891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-aa4af80f-56c4-400a-9ecd-0a436a01686e,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-4c604ff8-139b-450b-b1f1-c86db9204b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-eb2ae245-0bb6-42f0-86b7-1f6a44b65afe,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-ac75003b-9bc2-4ec3-aef7-a6768b7706a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-24519b7e-a8e1-433f-8344-f0763694171b,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-e509276e-7faa-40d7-a509-fb2fddda5dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-7f62775d-1d8a-4c43-a340-bf0f0d462b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-7acc174b-10e1-4096-a173-8726b2cf03f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436708994-172.17.0.4-1595659299891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-aa4af80f-56c4-400a-9ecd-0a436a01686e,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-4c604ff8-139b-450b-b1f1-c86db9204b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-eb2ae245-0bb6-42f0-86b7-1f6a44b65afe,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-ac75003b-9bc2-4ec3-aef7-a6768b7706a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-24519b7e-a8e1-433f-8344-f0763694171b,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-e509276e-7faa-40d7-a509-fb2fddda5dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-7f62775d-1d8a-4c43-a340-bf0f0d462b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-7acc174b-10e1-4096-a173-8726b2cf03f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831274497-172.17.0.4-1595659450714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-8bb0e5ee-6142-47aa-98bb-f696c3426eab,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-29cd7686-973e-46ab-aa94-1f3d752f67e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-831a9942-16b5-4003-9e55-92a128862ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-ec3f0d6c-83d9-4aab-8d69-4215c919fb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-a4831883-2a34-49a1-a242-f509fc9e08f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-67d4e115-1cd6-4799-b187-4060b0f4a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-01d5d35c-b5f4-4b37-a54f-49502d3debf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-29665404-081a-4d5e-9910-105e97d8fa2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831274497-172.17.0.4-1595659450714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-8bb0e5ee-6142-47aa-98bb-f696c3426eab,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-29cd7686-973e-46ab-aa94-1f3d752f67e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-831a9942-16b5-4003-9e55-92a128862ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-ec3f0d6c-83d9-4aab-8d69-4215c919fb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-a4831883-2a34-49a1-a242-f509fc9e08f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-67d4e115-1cd6-4799-b187-4060b0f4a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-01d5d35c-b5f4-4b37-a54f-49502d3debf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-29665404-081a-4d5e-9910-105e97d8fa2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867473026-172.17.0.4-1595659492752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-62f005c0-4d85-4cd6-a301-17ad8a635a45,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-1d7a0cae-b0b5-4879-b73c-6e04cbf38d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-47efd05e-eacb-4b53-b351-38708cd91d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-10d71f0c-d7cb-4f79-9f71-b2c7f8069daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-8f1cc760-6454-46c3-b3c2-c20d31ca51d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-9f497b4c-a5f6-4c8c-bce4-a71babb5a7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-bbace656-dc95-40b5-9d22-f67c70ad9d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-333fbb10-7497-45f2-bd44-a7ec8985ae92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867473026-172.17.0.4-1595659492752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-62f005c0-4d85-4cd6-a301-17ad8a635a45,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-1d7a0cae-b0b5-4879-b73c-6e04cbf38d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-47efd05e-eacb-4b53-b351-38708cd91d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-10d71f0c-d7cb-4f79-9f71-b2c7f8069daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-8f1cc760-6454-46c3-b3c2-c20d31ca51d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-9f497b4c-a5f6-4c8c-bce4-a71babb5a7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-bbace656-dc95-40b5-9d22-f67c70ad9d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-333fbb10-7497-45f2-bd44-a7ec8985ae92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050511617-172.17.0.4-1595660144006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-125be76d-5984-4ace-80fc-0cb41cc392c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-0356bcfa-b042-4e53-8dda-091ae0e02809,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-0dd0348f-72f3-46c8-be73-704cc6f8a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-b6c8df46-f256-4583-b10a-8f9c7e3cb805,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-a8595c02-de73-4fd7-9105-c10dde694b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-f1cfb990-3825-42ec-bd2c-22c702c783ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-933035bc-d9f1-41dd-a314-f1a0340d3011,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-c3a6673b-48e2-4050-aff3-c5f6de1936dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050511617-172.17.0.4-1595660144006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-125be76d-5984-4ace-80fc-0cb41cc392c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-0356bcfa-b042-4e53-8dda-091ae0e02809,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-0dd0348f-72f3-46c8-be73-704cc6f8a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-b6c8df46-f256-4583-b10a-8f9c7e3cb805,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-a8595c02-de73-4fd7-9105-c10dde694b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-f1cfb990-3825-42ec-bd2c-22c702c783ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-933035bc-d9f1-41dd-a314-f1a0340d3011,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-c3a6673b-48e2-4050-aff3-c5f6de1936dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84757685-172.17.0.4-1595660557938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-7157ce19-fc73-4ff7-ade1-c57d43e59bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-aa8db22e-e6c4-421e-9923-b2344f63d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-f2d99a53-f401-491c-ba6f-c8d92991c133,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-62d9e064-7b5e-464f-a88a-43cec4afabee,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-a2e76371-016e-43a2-8c17-3c50ef7ceb73,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-a7ade102-7c26-49ef-902a-b92edf6aa1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-f0f693c5-b398-4f9c-868e-bf51b0e367b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-1433fa6d-d7ae-4e0e-8fd3-64d01101e94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84757685-172.17.0.4-1595660557938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-7157ce19-fc73-4ff7-ade1-c57d43e59bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-aa8db22e-e6c4-421e-9923-b2344f63d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-f2d99a53-f401-491c-ba6f-c8d92991c133,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-62d9e064-7b5e-464f-a88a-43cec4afabee,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-a2e76371-016e-43a2-8c17-3c50ef7ceb73,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-a7ade102-7c26-49ef-902a-b92edf6aa1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-f0f693c5-b398-4f9c-868e-bf51b0e367b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-1433fa6d-d7ae-4e0e-8fd3-64d01101e94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6526
