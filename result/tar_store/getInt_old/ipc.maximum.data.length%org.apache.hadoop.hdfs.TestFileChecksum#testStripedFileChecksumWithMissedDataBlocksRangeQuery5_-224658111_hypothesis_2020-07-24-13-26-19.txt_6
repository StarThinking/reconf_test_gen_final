reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231343787-172.17.0.20-1595597234194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-fcfba271-66f1-42c5-a2cf-26deab06fddf,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-30b8fb78-932c-46c4-9b32-187568847b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-82628b87-8925-4bc8-a8ef-a864d80a91ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-186a7a21-3e28-42dc-a1bf-c49dcff1846b,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-c85094be-2a01-440e-9814-3cc97a184671,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-a5b18b82-f394-44a4-b3da-5825cda8265e,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-3f5a8419-8f94-43ed-aad0-d14c4a756c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-e4e9669a-479e-4563-9f26-80133c42a189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231343787-172.17.0.20-1595597234194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-fcfba271-66f1-42c5-a2cf-26deab06fddf,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-30b8fb78-932c-46c4-9b32-187568847b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-82628b87-8925-4bc8-a8ef-a864d80a91ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-186a7a21-3e28-42dc-a1bf-c49dcff1846b,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-c85094be-2a01-440e-9814-3cc97a184671,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-a5b18b82-f394-44a4-b3da-5825cda8265e,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-3f5a8419-8f94-43ed-aad0-d14c4a756c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-e4e9669a-479e-4563-9f26-80133c42a189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792525995-172.17.0.20-1595598631630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-316855db-962a-4206-bc39-8ba18a763039,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-fb10e6f5-c7c0-4ba9-919b-5a22900bbe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-b8397288-f92f-4431-912a-0e630ff1f737,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-5d471cda-00f5-4a10-b6c4-2e65261b6888,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-f45701d0-afe2-4316-96c8-b4a4ea9a36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-d35b8afd-3a18-46de-97fe-4053ed198e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-eeced530-3fc2-416e-988a-884fcd64dbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-de94086b-7ae2-46fd-adba-5d309e649ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792525995-172.17.0.20-1595598631630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-316855db-962a-4206-bc39-8ba18a763039,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-fb10e6f5-c7c0-4ba9-919b-5a22900bbe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-b8397288-f92f-4431-912a-0e630ff1f737,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-5d471cda-00f5-4a10-b6c4-2e65261b6888,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-f45701d0-afe2-4316-96c8-b4a4ea9a36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-d35b8afd-3a18-46de-97fe-4053ed198e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-eeced530-3fc2-416e-988a-884fcd64dbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-de94086b-7ae2-46fd-adba-5d309e649ea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974387148-172.17.0.20-1595598669826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46517,DS-be2ebcae-0d98-434a-a230-069c1423c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-c88559b0-68f3-498f-bf47-61a9c4a18412,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-2a032462-f72b-44d0-af8f-6971e5e4e170,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-a8ecaa13-0164-47a4-bb23-9f8da83f6bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-3c4fff02-f01d-4b0a-a8a4-4b2b68a7893a,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-342f543e-9975-4355-9ce1-97dbd5f17f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-4e62d0b9-2153-46ff-abf6-89ff4f4081db,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-602e946e-b613-4c7a-b1ce-14c825ee094e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974387148-172.17.0.20-1595598669826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46517,DS-be2ebcae-0d98-434a-a230-069c1423c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-c88559b0-68f3-498f-bf47-61a9c4a18412,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-2a032462-f72b-44d0-af8f-6971e5e4e170,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-a8ecaa13-0164-47a4-bb23-9f8da83f6bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-3c4fff02-f01d-4b0a-a8a4-4b2b68a7893a,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-342f543e-9975-4355-9ce1-97dbd5f17f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-4e62d0b9-2153-46ff-abf6-89ff4f4081db,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-602e946e-b613-4c7a-b1ce-14c825ee094e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383234507-172.17.0.20-1595598915607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45714,DS-a68fc237-6472-425a-b1ac-72e48e3cda8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-990077e7-fdd8-4396-b098-1cfbe5f31803,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-e8d42a98-8f72-4488-877f-bad8479d750c,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-e572fbff-4ed1-4047-9d3a-667a06c8e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-93b72ea0-1fc7-434e-905a-744c41ac86db,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-48c4ed9c-89a4-43f2-83c4-16eea2ca248d,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-d7ace42b-b222-44d2-a5dd-edaac6329e21,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-250807b7-0ddb-406c-a68e-7c8155091c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383234507-172.17.0.20-1595598915607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45714,DS-a68fc237-6472-425a-b1ac-72e48e3cda8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-990077e7-fdd8-4396-b098-1cfbe5f31803,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-e8d42a98-8f72-4488-877f-bad8479d750c,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-e572fbff-4ed1-4047-9d3a-667a06c8e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-93b72ea0-1fc7-434e-905a-744c41ac86db,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-48c4ed9c-89a4-43f2-83c4-16eea2ca248d,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-d7ace42b-b222-44d2-a5dd-edaac6329e21,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-250807b7-0ddb-406c-a68e-7c8155091c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660109010-172.17.0.20-1595599337229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34702,DS-00fc17b0-a6eb-4efc-98d4-7f070fb139f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-a96dfac8-1910-4a90-8e6b-d971cabacf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-31714134-65b1-42a2-82b1-583f112e68e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-1e577140-9808-4cb5-bc50-d18eb020a9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-4bbf1058-3660-47f4-9e07-8fb9a8f1ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-327f63da-b48f-4206-bcf8-81a8a0d379f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-8ed815eb-9c98-4f66-9c8f-f076c36079fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-189cd7c8-492f-44c8-9fd1-89b77068b21a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660109010-172.17.0.20-1595599337229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34702,DS-00fc17b0-a6eb-4efc-98d4-7f070fb139f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-a96dfac8-1910-4a90-8e6b-d971cabacf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-31714134-65b1-42a2-82b1-583f112e68e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-1e577140-9808-4cb5-bc50-d18eb020a9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-4bbf1058-3660-47f4-9e07-8fb9a8f1ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-327f63da-b48f-4206-bcf8-81a8a0d379f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-8ed815eb-9c98-4f66-9c8f-f076c36079fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-189cd7c8-492f-44c8-9fd1-89b77068b21a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512936428-172.17.0.20-1595599489200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-8cae9341-5a93-451e-94b6-8b8b8a320480,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-95ad048f-6265-4361-a35f-1ee2f1b34e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-d9810d8e-34de-4270-8c5f-190bd2d94639,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-22983424-dedc-43ba-bd37-daa0b09e4469,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-e79bed16-49b5-4d23-a9fd-0308ab860e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-0d1810e3-d9d3-4891-b894-5e06eedb5500,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-936a6a2a-8355-4a93-bd82-b3433a9a1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-2a933726-c8bc-4e21-ace2-f205c81b9038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512936428-172.17.0.20-1595599489200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-8cae9341-5a93-451e-94b6-8b8b8a320480,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-95ad048f-6265-4361-a35f-1ee2f1b34e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-d9810d8e-34de-4270-8c5f-190bd2d94639,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-22983424-dedc-43ba-bd37-daa0b09e4469,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-e79bed16-49b5-4d23-a9fd-0308ab860e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-0d1810e3-d9d3-4891-b894-5e06eedb5500,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-936a6a2a-8355-4a93-bd82-b3433a9a1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-2a933726-c8bc-4e21-ace2-f205c81b9038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008095564-172.17.0.20-1595599524183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37770,DS-eaae27d0-9114-4e11-9287-ce7fcf9a0ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-3c0cac90-b918-4651-9572-0ce6a978ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-2c44cb89-447e-4cfe-b37f-b4634bfc058f,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-a5b56f08-c994-4c15-a4a1-b618bb4d6005,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-18cbcbf9-c0e8-4e5b-8ca7-14cd5244f4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-bc8a9e6e-cffb-4da4-bb67-0f777b8120be,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-ac9a85e8-1f02-4864-8692-59ace0384671,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-723423dd-9617-494d-a7a0-bbe7da35f600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008095564-172.17.0.20-1595599524183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37770,DS-eaae27d0-9114-4e11-9287-ce7fcf9a0ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-3c0cac90-b918-4651-9572-0ce6a978ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-2c44cb89-447e-4cfe-b37f-b4634bfc058f,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-a5b56f08-c994-4c15-a4a1-b618bb4d6005,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-18cbcbf9-c0e8-4e5b-8ca7-14cd5244f4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-bc8a9e6e-cffb-4da4-bb67-0f777b8120be,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-ac9a85e8-1f02-4864-8692-59ace0384671,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-723423dd-9617-494d-a7a0-bbe7da35f600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394550249-172.17.0.20-1595600765494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-7bd3f557-1cc2-4b20-84ee-55528d19346e,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-7949109c-8a32-41f8-8efe-288023f8c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-7be37417-c50e-4676-9616-1de9d2b08b70,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-2dbb014b-7073-4a52-98b9-aae30b29cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-a0191112-53d3-4b46-920b-2056f5679222,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-fade6669-64a3-470b-8d92-e6c79d75d1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-3245bfaf-ed07-4fee-9207-4c785c8897f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-e1c9f677-4b08-4740-a4c6-98a6413477bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394550249-172.17.0.20-1595600765494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-7bd3f557-1cc2-4b20-84ee-55528d19346e,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-7949109c-8a32-41f8-8efe-288023f8c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-7be37417-c50e-4676-9616-1de9d2b08b70,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-2dbb014b-7073-4a52-98b9-aae30b29cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-a0191112-53d3-4b46-920b-2056f5679222,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-fade6669-64a3-470b-8d92-e6c79d75d1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-3245bfaf-ed07-4fee-9207-4c785c8897f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-e1c9f677-4b08-4740-a4c6-98a6413477bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689909945-172.17.0.20-1595600925821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-e39b60c7-e2e3-460f-8e81-c6ae11632b34,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-931b94c6-c521-42d0-a488-c635fc3cea08,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-31044c2d-7242-4e17-a2d8-a9bfc1731564,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-9300b75f-d978-49b0-93d8-4aa08634668e,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-3401947b-be11-4275-8d17-6433e132db1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-3cc9d9a1-a2e4-49ff-bfe6-e4c44a5a7e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-cb637ba5-a3c9-44b1-baf8-fb99eed34aee,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-f9f71ace-7113-476c-9533-fabe6f779ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689909945-172.17.0.20-1595600925821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-e39b60c7-e2e3-460f-8e81-c6ae11632b34,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-931b94c6-c521-42d0-a488-c635fc3cea08,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-31044c2d-7242-4e17-a2d8-a9bfc1731564,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-9300b75f-d978-49b0-93d8-4aa08634668e,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-3401947b-be11-4275-8d17-6433e132db1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-3cc9d9a1-a2e4-49ff-bfe6-e4c44a5a7e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-cb637ba5-a3c9-44b1-baf8-fb99eed34aee,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-f9f71ace-7113-476c-9533-fabe6f779ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214781814-172.17.0.20-1595601151501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-3abb7e12-d87f-42cf-9c10-9d021a618204,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-b71a8de6-6168-4ff5-a826-8cc19b8ff819,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-d90d73b1-d23d-4a65-9c1c-909ed4d41811,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-ce171c09-6447-4d71-9c3c-05a6c75a07ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-59a8c183-410e-41fc-8a79-eed5a1d99c38,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-fad7b313-efc3-4084-af60-2885b42a8302,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-7662684a-7dcd-41ce-8049-ca8d089d0f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-e1dad159-c2db-4055-84f7-6d01d1680216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214781814-172.17.0.20-1595601151501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-3abb7e12-d87f-42cf-9c10-9d021a618204,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-b71a8de6-6168-4ff5-a826-8cc19b8ff819,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-d90d73b1-d23d-4a65-9c1c-909ed4d41811,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-ce171c09-6447-4d71-9c3c-05a6c75a07ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-59a8c183-410e-41fc-8a79-eed5a1d99c38,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-fad7b313-efc3-4084-af60-2885b42a8302,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-7662684a-7dcd-41ce-8049-ca8d089d0f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-e1dad159-c2db-4055-84f7-6d01d1680216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264649966-172.17.0.20-1595601193822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39446,DS-80fd757a-8b76-40b7-98e5-f99c12b4a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-31fcabd7-3c19-448e-9041-7471ccb4e9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-ef44d553-59a4-414a-8c36-894589410d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-17efa594-3583-42f4-8229-b6b85790f724,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-091fc84a-d617-44a3-9eda-016688f79ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-7f11613d-d2be-48f4-ab4c-e3feac998deb,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-6f99de28-b962-4412-a001-94baa05a6abf,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-f3cebcae-5255-4e20-8abd-28c1f7582190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264649966-172.17.0.20-1595601193822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39446,DS-80fd757a-8b76-40b7-98e5-f99c12b4a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-31fcabd7-3c19-448e-9041-7471ccb4e9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-ef44d553-59a4-414a-8c36-894589410d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-17efa594-3583-42f4-8229-b6b85790f724,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-091fc84a-d617-44a3-9eda-016688f79ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-7f11613d-d2be-48f4-ab4c-e3feac998deb,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-6f99de28-b962-4412-a001-94baa05a6abf,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-f3cebcae-5255-4e20-8abd-28c1f7582190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324601505-172.17.0.20-1595601233206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-597d944f-9b5a-4c2b-bae8-104cd20a43e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-6c4af615-8c07-482b-be5e-82456627a751,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-1fe9a17a-9dea-4576-b842-d02af3584855,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-1b62c611-4ba1-4bc3-8e88-26a56ed14a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-d4cca48c-8cbb-4d70-8e68-e07b2c0ec266,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-ae2f0a65-7b33-49b4-b84a-7e7f00b068f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-2d3921bd-7416-4a71-88e8-8be96552de37,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-4dc94856-a989-47d1-a046-ab612ebae7cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324601505-172.17.0.20-1595601233206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-597d944f-9b5a-4c2b-bae8-104cd20a43e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-6c4af615-8c07-482b-be5e-82456627a751,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-1fe9a17a-9dea-4576-b842-d02af3584855,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-1b62c611-4ba1-4bc3-8e88-26a56ed14a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-d4cca48c-8cbb-4d70-8e68-e07b2c0ec266,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-ae2f0a65-7b33-49b4-b84a-7e7f00b068f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-2d3921bd-7416-4a71-88e8-8be96552de37,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-4dc94856-a989-47d1-a046-ab612ebae7cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569299663-172.17.0.20-1595601321183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-4d567131-b94d-4f6b-9b92-605b1ec9bee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-0ac74623-2f51-4e67-af74-289b675fc297,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-dda538f4-d7ad-4be7-8bf2-d4b4d437481f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-8948132b-7300-4682-8430-9f873fe4e7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-f89ae353-b2ab-40e8-9902-2f6d36fc7c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-5ca86638-93d8-49c9-a632-7055e462654e,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-886502e0-201d-4fea-9879-550c4008984a,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-91afd1a6-2f74-4e2e-9c87-8334dce84121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569299663-172.17.0.20-1595601321183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-4d567131-b94d-4f6b-9b92-605b1ec9bee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-0ac74623-2f51-4e67-af74-289b675fc297,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-dda538f4-d7ad-4be7-8bf2-d4b4d437481f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-8948132b-7300-4682-8430-9f873fe4e7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-f89ae353-b2ab-40e8-9902-2f6d36fc7c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-5ca86638-93d8-49c9-a632-7055e462654e,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-886502e0-201d-4fea-9879-550c4008984a,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-91afd1a6-2f74-4e2e-9c87-8334dce84121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760115099-172.17.0.20-1595601397388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44059,DS-8c1ef075-2d4d-4331-bdd1-127b8467dd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-ac413706-279c-41ba-a3d8-c73eac3544e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-fa975c62-9e4d-4f35-9c00-487289b2fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-9331528b-22d7-442b-bdfc-4a666fec7a90,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-f45cdf4c-aaab-45cb-8573-8233fc4823e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-b4e2bebc-87be-4d5c-935e-177a7d668026,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-ab6cbec2-f795-491d-944d-1ec61395b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-881cfc49-bfd7-4dec-9af2-df0256191f36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760115099-172.17.0.20-1595601397388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44059,DS-8c1ef075-2d4d-4331-bdd1-127b8467dd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-ac413706-279c-41ba-a3d8-c73eac3544e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-fa975c62-9e4d-4f35-9c00-487289b2fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-9331528b-22d7-442b-bdfc-4a666fec7a90,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-f45cdf4c-aaab-45cb-8573-8233fc4823e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-b4e2bebc-87be-4d5c-935e-177a7d668026,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-ab6cbec2-f795-491d-944d-1ec61395b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-881cfc49-bfd7-4dec-9af2-df0256191f36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330334831-172.17.0.20-1595601975679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38795,DS-3500759e-7e52-43f8-bdd9-9d90c78976f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-e5fbc428-623e-4672-a776-9de8c9c64864,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-cfa0a69a-9465-43c7-838e-c9117e8eb747,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-9ebe1702-f329-433b-be92-6bb0540b3ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-9b1e6de6-7d87-4f5f-b9a6-1691e686d8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-20a18a88-696d-4769-b897-72e38ed97bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-2a678d84-ee3b-4b8b-8b09-4fb0bf1ae96b,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-50e75705-6950-482e-af57-826bd0593ddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330334831-172.17.0.20-1595601975679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38795,DS-3500759e-7e52-43f8-bdd9-9d90c78976f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-e5fbc428-623e-4672-a776-9de8c9c64864,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-cfa0a69a-9465-43c7-838e-c9117e8eb747,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-9ebe1702-f329-433b-be92-6bb0540b3ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-9b1e6de6-7d87-4f5f-b9a6-1691e686d8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-20a18a88-696d-4769-b897-72e38ed97bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-2a678d84-ee3b-4b8b-8b09-4fb0bf1ae96b,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-50e75705-6950-482e-af57-826bd0593ddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178719605-172.17.0.20-1595602451076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-adbb0004-eeec-4111-abf5-c3a5c1b2a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-dca1bd99-b070-4f3d-8b71-c5300deafc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-66911ceb-3cc7-461e-a975-673644cdc6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-38019c85-b550-4cff-9202-896a9cb80511,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-b12fa29a-8efd-4f84-a38e-694c6454215b,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-2efef6a2-5343-4c73-bbda-9fbcee068a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-7ad6c458-a3c3-4f41-8518-fa3a9fefae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-61af1678-22e2-49e7-8e6d-19877d93e2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178719605-172.17.0.20-1595602451076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-adbb0004-eeec-4111-abf5-c3a5c1b2a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-dca1bd99-b070-4f3d-8b71-c5300deafc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-66911ceb-3cc7-461e-a975-673644cdc6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-38019c85-b550-4cff-9202-896a9cb80511,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-b12fa29a-8efd-4f84-a38e-694c6454215b,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-2efef6a2-5343-4c73-bbda-9fbcee068a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-7ad6c458-a3c3-4f41-8518-fa3a9fefae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-61af1678-22e2-49e7-8e6d-19877d93e2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552817935-172.17.0.20-1595602687808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-895c2d81-19ef-4425-a4db-fcf20257992c,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-6730eff2-203a-487f-b48f-1442e912a139,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-ad5ac480-6c1f-40e3-b69a-3ba2a0ca2447,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-57bc0d77-eb28-44c9-9aa2-adde98e634a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-df2539f3-9c2e-4869-b943-755bd702e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-e6f4e48e-7c35-4fd2-a810-2cd1eea95f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-61690ea6-5cf4-459f-9d28-dac2af006339,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-be141efd-df4b-471b-ae9e-bca743c2f4d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552817935-172.17.0.20-1595602687808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-895c2d81-19ef-4425-a4db-fcf20257992c,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-6730eff2-203a-487f-b48f-1442e912a139,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-ad5ac480-6c1f-40e3-b69a-3ba2a0ca2447,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-57bc0d77-eb28-44c9-9aa2-adde98e634a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-df2539f3-9c2e-4869-b943-755bd702e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-e6f4e48e-7c35-4fd2-a810-2cd1eea95f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-61690ea6-5cf4-459f-9d28-dac2af006339,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-be141efd-df4b-471b-ae9e-bca743c2f4d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471578251-172.17.0.20-1595602798946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-4cc26169-92c2-4077-a67f-9ea65981b550,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-707d8a45-093e-4b39-b770-26b395270ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-2942afc5-d68b-4245-8030-689d36922b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-4e7fbb4b-c248-4484-b934-9982a6a135bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-2d5c81a5-ed6e-48e3-80bd-46c09b6b687e,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-9b190670-9300-44c7-ba4b-ca8a24a3ffbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-106504d7-5f30-4b1b-b6d8-9acbac141a48,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-e0848be0-1b72-4264-8bbe-0b952aa6f2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471578251-172.17.0.20-1595602798946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-4cc26169-92c2-4077-a67f-9ea65981b550,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-707d8a45-093e-4b39-b770-26b395270ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-2942afc5-d68b-4245-8030-689d36922b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-4e7fbb4b-c248-4484-b934-9982a6a135bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-2d5c81a5-ed6e-48e3-80bd-46c09b6b687e,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-9b190670-9300-44c7-ba4b-ca8a24a3ffbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-106504d7-5f30-4b1b-b6d8-9acbac141a48,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-e0848be0-1b72-4264-8bbe-0b952aa6f2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 16384
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899632835-172.17.0.20-1595602844046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-380e6bf4-f993-4854-b2d9-ec5551d82626,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-d27ac8cf-a1b4-422c-b8f6-e664c6b4e2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-f699a0f9-3e65-4c49-b7ab-96ccfc22bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-a5af7c0a-759f-4e6e-830f-eac331bd3716,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-110b9ef2-1a00-4a74-999a-71aaf71d6261,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-cd779f36-8f0b-4c5c-bf6d-d8243b7ba2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-894b4a6f-4c99-4dee-9cc8-9ed4b5b09526,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-1ce83dfc-2838-424b-8359-c12273da4b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899632835-172.17.0.20-1595602844046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-380e6bf4-f993-4854-b2d9-ec5551d82626,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-d27ac8cf-a1b4-422c-b8f6-e664c6b4e2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-f699a0f9-3e65-4c49-b7ab-96ccfc22bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-a5af7c0a-759f-4e6e-830f-eac331bd3716,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-110b9ef2-1a00-4a74-999a-71aaf71d6261,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-cd779f36-8f0b-4c5c-bf6d-d8243b7ba2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-894b4a6f-4c99-4dee-9cc8-9ed4b5b09526,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-1ce83dfc-2838-424b-8359-c12273da4b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5718
