reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575462207-172.17.0.17-1595655368475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36141,DS-793f8f34-b956-4f47-9faf-cc96b77687b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-0515c63f-3399-4984-84b6-8b08ad085721,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-55a4b170-d07f-40a9-bfba-a1f4fc84c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-78b7b51d-8f0d-4d57-9127-b962d04994cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-48797044-c25b-4b48-b59f-d2d201f6bb07,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-945eebd4-5acf-4f38-90e2-79b361fa39b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-a12aee93-8b6a-4f29-ad77-a89c2f341c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-e139bc34-c6d8-44c8-ae24-15abda579b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575462207-172.17.0.17-1595655368475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36141,DS-793f8f34-b956-4f47-9faf-cc96b77687b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-0515c63f-3399-4984-84b6-8b08ad085721,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-55a4b170-d07f-40a9-bfba-a1f4fc84c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-78b7b51d-8f0d-4d57-9127-b962d04994cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-48797044-c25b-4b48-b59f-d2d201f6bb07,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-945eebd4-5acf-4f38-90e2-79b361fa39b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-a12aee93-8b6a-4f29-ad77-a89c2f341c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-e139bc34-c6d8-44c8-ae24-15abda579b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194959526-172.17.0.17-1595655585109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-ee6f9cc1-01a1-45b8-a056-0e5128bd5093,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-ca1b7bc5-004e-4010-a922-56d16c719f59,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-75b89048-afa9-497b-ad0c-b3a8af3204e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-8b5719c6-09af-4051-bf77-d4df0eeffad4,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-e950052a-e0f8-4c9e-afab-f8a721bcb27d,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-d215f343-56fb-49ce-8a5e-cd662aedc5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-c7112649-e343-4582-851e-40760a888395,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-6070ba29-3a73-4cb0-8bc2-80131cfae588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194959526-172.17.0.17-1595655585109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-ee6f9cc1-01a1-45b8-a056-0e5128bd5093,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-ca1b7bc5-004e-4010-a922-56d16c719f59,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-75b89048-afa9-497b-ad0c-b3a8af3204e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-8b5719c6-09af-4051-bf77-d4df0eeffad4,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-e950052a-e0f8-4c9e-afab-f8a721bcb27d,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-d215f343-56fb-49ce-8a5e-cd662aedc5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-c7112649-e343-4582-851e-40760a888395,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-6070ba29-3a73-4cb0-8bc2-80131cfae588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975076909-172.17.0.17-1595656092206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36545,DS-0fc6c67a-9412-4bef-9b9f-7f9a41f33bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-5e56dc0c-f498-4011-b481-fe6fa655c991,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-33cca633-006c-4574-b259-f17ccbb8e159,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-9e9906ca-6cd4-4233-b25f-10ca27e96ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-82f5e1d0-0bfc-4b29-9ed9-0e12c6cc014c,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-ad077b08-a9e8-4bef-93d6-4ff931522553,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-362266b8-89e8-4f30-80b3-d92df437fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-262c0c7e-0b60-45a4-93f7-a4ab0bba64f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-975076909-172.17.0.17-1595656092206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36545,DS-0fc6c67a-9412-4bef-9b9f-7f9a41f33bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-5e56dc0c-f498-4011-b481-fe6fa655c991,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-33cca633-006c-4574-b259-f17ccbb8e159,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-9e9906ca-6cd4-4233-b25f-10ca27e96ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-82f5e1d0-0bfc-4b29-9ed9-0e12c6cc014c,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-ad077b08-a9e8-4bef-93d6-4ff931522553,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-362266b8-89e8-4f30-80b3-d92df437fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-262c0c7e-0b60-45a4-93f7-a4ab0bba64f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806821483-172.17.0.17-1595656299059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33784,DS-442884ca-84c9-4e03-b54d-ef0fae94ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-70cd19de-76c0-4cb6-9a11-5bfcc9e729cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-8d4603d1-acae-4d7b-bd15-f09a773f9967,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-a8a2fd68-7c5b-4d54-9c80-97607c1c4398,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-312212d7-e2bd-4540-a6ad-b8d6e99c8ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-da82b70f-4fe8-49e7-8eba-4775e36f6b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-949e2247-19b5-45c6-bf0b-9ed5578a6552,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-960b1307-40cd-4efa-9e10-2a704d02f550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806821483-172.17.0.17-1595656299059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33784,DS-442884ca-84c9-4e03-b54d-ef0fae94ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-70cd19de-76c0-4cb6-9a11-5bfcc9e729cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-8d4603d1-acae-4d7b-bd15-f09a773f9967,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-a8a2fd68-7c5b-4d54-9c80-97607c1c4398,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-312212d7-e2bd-4540-a6ad-b8d6e99c8ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-da82b70f-4fe8-49e7-8eba-4775e36f6b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-949e2247-19b5-45c6-bf0b-9ed5578a6552,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-960b1307-40cd-4efa-9e10-2a704d02f550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765270196-172.17.0.17-1595656581440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40864,DS-43c318b2-a941-4dd2-b5a9-04e6cb4d11bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-001335ae-3ee6-4f99-8fdb-490eea58ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-1f86c159-a4e9-44fa-8198-4538883abe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-8c8e11a3-050a-4063-8325-840a44e6b935,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-88fe92a5-f0ae-4ec2-a736-302ea28b373f,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-85bf1f72-40ac-4f4a-8334-b8636b1952c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-e7d1389a-3df5-42a9-9aa8-fa389b2f1e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-1d28450b-7364-4d23-b4f9-0d4f7af6953b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765270196-172.17.0.17-1595656581440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40864,DS-43c318b2-a941-4dd2-b5a9-04e6cb4d11bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-001335ae-3ee6-4f99-8fdb-490eea58ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-1f86c159-a4e9-44fa-8198-4538883abe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-8c8e11a3-050a-4063-8325-840a44e6b935,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-88fe92a5-f0ae-4ec2-a736-302ea28b373f,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-85bf1f72-40ac-4f4a-8334-b8636b1952c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-e7d1389a-3df5-42a9-9aa8-fa389b2f1e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-1d28450b-7364-4d23-b4f9-0d4f7af6953b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037119884-172.17.0.17-1595656684081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39623,DS-80bdfa42-ab18-4a19-8742-c9eb8f5a5eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-d129395b-2d99-4ad5-8168-87797c7e65b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-64f4c0dd-4919-4faa-aa8f-163dcfe43002,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-c31e560a-9917-4529-b7d1-1eae89336d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-cec7c7b5-3caf-4a9a-870c-5f8966d05256,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-e145c5b5-c19e-4d86-a81d-a956f396512a,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-34ffb7fc-d99e-4aff-a985-32c027db5422,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-75f5e41c-3871-442d-a927-961a869d6669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037119884-172.17.0.17-1595656684081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39623,DS-80bdfa42-ab18-4a19-8742-c9eb8f5a5eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-d129395b-2d99-4ad5-8168-87797c7e65b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-64f4c0dd-4919-4faa-aa8f-163dcfe43002,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-c31e560a-9917-4529-b7d1-1eae89336d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-cec7c7b5-3caf-4a9a-870c-5f8966d05256,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-e145c5b5-c19e-4d86-a81d-a956f396512a,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-34ffb7fc-d99e-4aff-a985-32c027db5422,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-75f5e41c-3871-442d-a927-961a869d6669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656621396-172.17.0.17-1595657066498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44239,DS-8fde123d-992e-4533-83ae-77d4b634571a,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-14ce04df-b141-42d9-9fb2-43218def5598,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-34423c09-dd4a-404c-96c0-9245307c5dff,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-aaa4a779-6be9-472b-8f6f-879942149f78,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-2eebc43d-56de-46d4-88c6-c053dabbca7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-45f8dc9a-4a99-48ec-ac20-c84af256c85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-cef7023c-8769-44d3-a2d6-0f1334afd9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-17f55e67-00ba-491a-be9e-fd2f7d0d660c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656621396-172.17.0.17-1595657066498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44239,DS-8fde123d-992e-4533-83ae-77d4b634571a,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-14ce04df-b141-42d9-9fb2-43218def5598,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-34423c09-dd4a-404c-96c0-9245307c5dff,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-aaa4a779-6be9-472b-8f6f-879942149f78,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-2eebc43d-56de-46d4-88c6-c053dabbca7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-45f8dc9a-4a99-48ec-ac20-c84af256c85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-cef7023c-8769-44d3-a2d6-0f1334afd9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-17f55e67-00ba-491a-be9e-fd2f7d0d660c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010016829-172.17.0.17-1595657356759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39002,DS-2b6e5625-ea46-4262-b9bd-0e2c21ec547b,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-d3aa9b2a-f471-46f4-9307-a4ed26ee791c,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-34844a64-4ce8-4b2a-8563-ff510679a1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-2b22631c-24e2-4c11-b3c3-b2064d340b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-36fc2426-fd85-43aa-a960-c1f713a8c432,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-04082dad-fe7a-411c-ae4d-bcfd9046c9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-45ca6c8a-d9f3-41ea-8914-0255543af6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-3100017a-b6a5-47be-92a2-977732de9f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010016829-172.17.0.17-1595657356759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39002,DS-2b6e5625-ea46-4262-b9bd-0e2c21ec547b,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-d3aa9b2a-f471-46f4-9307-a4ed26ee791c,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-34844a64-4ce8-4b2a-8563-ff510679a1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-2b22631c-24e2-4c11-b3c3-b2064d340b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-36fc2426-fd85-43aa-a960-c1f713a8c432,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-04082dad-fe7a-411c-ae4d-bcfd9046c9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-45ca6c8a-d9f3-41ea-8914-0255543af6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-3100017a-b6a5-47be-92a2-977732de9f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074663725-172.17.0.17-1595657495161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-19cc1c1c-5f3c-4ff3-bdad-648ba41304f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-8eacafc4-b445-4925-ab8a-c902c1dd289a,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-cbd09081-ffd3-4f9d-8a85-e667081ec119,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-a2f79c50-92eb-4591-9fbf-cbaee18f8365,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-32d387fa-c397-4c6b-a95c-1e8bd9cdc138,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-d6d2fb66-9e35-45fb-901e-beea7b322a52,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-1b47352a-4702-447a-b51e-95a227a9a130,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-34c4d4bf-0b09-4e49-b997-affb58136cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074663725-172.17.0.17-1595657495161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-19cc1c1c-5f3c-4ff3-bdad-648ba41304f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-8eacafc4-b445-4925-ab8a-c902c1dd289a,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-cbd09081-ffd3-4f9d-8a85-e667081ec119,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-a2f79c50-92eb-4591-9fbf-cbaee18f8365,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-32d387fa-c397-4c6b-a95c-1e8bd9cdc138,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-d6d2fb66-9e35-45fb-901e-beea7b322a52,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-1b47352a-4702-447a-b51e-95a227a9a130,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-34c4d4bf-0b09-4e49-b997-affb58136cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1809123755-172.17.0.17-1595657524334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38266,DS-151f4ee5-25e5-4fc8-b454-eef4254eeed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-377aad36-76c0-40a5-9703-f3e537160ada,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-9f52e946-dd47-43d3-a550-1c0969eff7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-02a850eb-d718-4be7-995c-022565127c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-99693690-b016-4d14-9092-b8fd02003045,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-1338be5c-50a2-4612-a620-987a8814cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-3a48c363-00a1-4ab4-8eab-a12b4a7c931e,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-2bf83abe-6dfa-4b0d-9ffe-e0638255703b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1809123755-172.17.0.17-1595657524334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38266,DS-151f4ee5-25e5-4fc8-b454-eef4254eeed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-377aad36-76c0-40a5-9703-f3e537160ada,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-9f52e946-dd47-43d3-a550-1c0969eff7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-02a850eb-d718-4be7-995c-022565127c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-99693690-b016-4d14-9092-b8fd02003045,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-1338be5c-50a2-4612-a620-987a8814cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-3a48c363-00a1-4ab4-8eab-a12b4a7c931e,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-2bf83abe-6dfa-4b0d-9ffe-e0638255703b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561677023-172.17.0.17-1595657731180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45523,DS-e771cf4d-64e1-4b85-8bfa-1f079d516d41,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-9a5ddaf2-ccd8-4803-acd0-013eda2b7771,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8272c23f-896d-4809-8c2c-68d864a80430,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-fa4ddb8f-2d61-42ea-b171-b730f5ff673f,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-7f6e33aa-8c3e-49f1-9606-264c8a021025,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-d9a9891b-1c46-43d3-88e7-c205d80d1efa,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-997cbcd4-2b40-4e2f-abf4-6c506386c7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-50cc655f-8d13-471c-9b25-72f69f5d2f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561677023-172.17.0.17-1595657731180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45523,DS-e771cf4d-64e1-4b85-8bfa-1f079d516d41,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-9a5ddaf2-ccd8-4803-acd0-013eda2b7771,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8272c23f-896d-4809-8c2c-68d864a80430,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-fa4ddb8f-2d61-42ea-b171-b730f5ff673f,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-7f6e33aa-8c3e-49f1-9606-264c8a021025,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-d9a9891b-1c46-43d3-88e7-c205d80d1efa,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-997cbcd4-2b40-4e2f-abf4-6c506386c7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-50cc655f-8d13-471c-9b25-72f69f5d2f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285535354-172.17.0.17-1595658051601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-8ecaf47d-455b-485a-a34b-b7708569cb75,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-798ffae4-6226-4ad4-95b5-a28d8ac67f14,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-114ca132-941f-43d9-ad01-373f8c6abd27,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-7ee0343f-c5fe-480c-94a8-af57ab1251d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-2053b9ed-2a60-43e2-8d00-b738b52b5d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-4313aba4-d28b-4286-b9c0-84b0a6b00948,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-0da77408-bcb0-44ac-9321-ce479bc9bbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-17e31fe3-215b-4845-9161-be2554c1d157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285535354-172.17.0.17-1595658051601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-8ecaf47d-455b-485a-a34b-b7708569cb75,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-798ffae4-6226-4ad4-95b5-a28d8ac67f14,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-114ca132-941f-43d9-ad01-373f8c6abd27,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-7ee0343f-c5fe-480c-94a8-af57ab1251d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-2053b9ed-2a60-43e2-8d00-b738b52b5d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-4313aba4-d28b-4286-b9c0-84b0a6b00948,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-0da77408-bcb0-44ac-9321-ce479bc9bbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-17e31fe3-215b-4845-9161-be2554c1d157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48663700-172.17.0.17-1595658270804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46861,DS-899299e8-1a16-4ece-89b1-ef2851c1be95,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-e4a53cc6-8df1-4449-945b-498a39b0ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-c401a6d2-706a-4041-8cba-e430d243165f,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-85ca086a-9a66-4a87-b1a0-6b0a6db7c14f,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-924194aa-26f5-4321-a715-7b4b3f8ff56f,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-746c3d5b-4389-47a3-8d35-a807b8181f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-79ce5413-2aea-454e-8e1f-b9d03d20fa76,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-a9ae8fb9-9693-4ac0-9010-0d49f14c2b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48663700-172.17.0.17-1595658270804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46861,DS-899299e8-1a16-4ece-89b1-ef2851c1be95,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-e4a53cc6-8df1-4449-945b-498a39b0ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-c401a6d2-706a-4041-8cba-e430d243165f,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-85ca086a-9a66-4a87-b1a0-6b0a6db7c14f,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-924194aa-26f5-4321-a715-7b4b3f8ff56f,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-746c3d5b-4389-47a3-8d35-a807b8181f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-79ce5413-2aea-454e-8e1f-b9d03d20fa76,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-a9ae8fb9-9693-4ac0-9010-0d49f14c2b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094646439-172.17.0.17-1595658864749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44808,DS-29f28735-a1e3-410d-b276-0dad1fac5a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-d487b10e-98b5-474b-9193-ea89c930779f,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-e2c8bae4-168e-4087-8d4c-f355601fe6de,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-e51a22b7-3d0a-489f-893e-32b795cb5d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-af0c85d9-6f83-4278-a704-6f4faf2501b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-13af5d70-e091-499c-b303-ce846091afb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-d6030b09-4357-4428-bf17-5673d4646d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-9cb658e1-bf0d-4cf2-aaf6-d9f093e555a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094646439-172.17.0.17-1595658864749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44808,DS-29f28735-a1e3-410d-b276-0dad1fac5a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-d487b10e-98b5-474b-9193-ea89c930779f,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-e2c8bae4-168e-4087-8d4c-f355601fe6de,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-e51a22b7-3d0a-489f-893e-32b795cb5d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-af0c85d9-6f83-4278-a704-6f4faf2501b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-13af5d70-e091-499c-b303-ce846091afb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-d6030b09-4357-4428-bf17-5673d4646d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-9cb658e1-bf0d-4cf2-aaf6-d9f093e555a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928773699-172.17.0.17-1595659881221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-cc4dd756-ab46-4508-9d5e-f1c476c51ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-3dc2ded9-82f8-449d-a8aa-e9fc7c78f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-cfe0b40e-8abb-44fd-9392-95029e906f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-02afc822-0108-448a-a5d1-94f0938ba8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-aeb46a09-a233-454a-821f-c39870942f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-02d5eb0b-391e-4d20-9761-6c84ff52b9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-e4fb2e40-a4ad-48b2-a493-91eedd3b73cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-a001203b-fa3a-4355-a6fb-4107c94a8bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928773699-172.17.0.17-1595659881221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-cc4dd756-ab46-4508-9d5e-f1c476c51ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-3dc2ded9-82f8-449d-a8aa-e9fc7c78f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-cfe0b40e-8abb-44fd-9392-95029e906f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-02afc822-0108-448a-a5d1-94f0938ba8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-aeb46a09-a233-454a-821f-c39870942f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-02d5eb0b-391e-4d20-9761-6c84ff52b9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-e4fb2e40-a4ad-48b2-a493-91eedd3b73cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-a001203b-fa3a-4355-a6fb-4107c94a8bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5272
