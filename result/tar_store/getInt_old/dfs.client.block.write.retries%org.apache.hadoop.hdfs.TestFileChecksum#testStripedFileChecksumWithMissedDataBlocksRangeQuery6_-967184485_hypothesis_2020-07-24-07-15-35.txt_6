reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860583668-172.17.0.7-1595574953093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-2d4319c0-c76e-40ce-90f1-5d8e027d8118,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-e12fa50c-7a47-4d8f-ac08-4589912ae97b,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-85164a86-2dd7-46b5-8cf5-a1ef6cfd9cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-74dc29d1-6e8c-4f36-a5d4-84c3a5b0b957,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-93dc04fc-6bb0-435e-bf8a-c15f908d70f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-83c4a9c8-b605-48f0-a9b2-6f3ed6368ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-8f6d1880-1a9a-4893-83c4-3119d40f533a,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-264d4e52-9517-41b8-94bc-c5495469f5e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860583668-172.17.0.7-1595574953093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-2d4319c0-c76e-40ce-90f1-5d8e027d8118,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-e12fa50c-7a47-4d8f-ac08-4589912ae97b,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-85164a86-2dd7-46b5-8cf5-a1ef6cfd9cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-74dc29d1-6e8c-4f36-a5d4-84c3a5b0b957,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-93dc04fc-6bb0-435e-bf8a-c15f908d70f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-83c4a9c8-b605-48f0-a9b2-6f3ed6368ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-8f6d1880-1a9a-4893-83c4-3119d40f533a,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-264d4e52-9517-41b8-94bc-c5495469f5e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921306478-172.17.0.7-1595575300992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-55c25732-94ec-4a11-87dd-d19af9edddea,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-008a44fe-8d81-4dde-9c5a-f8820c811d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-b5b8c30d-7094-41d2-9810-f6ccc3838ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-2a2971ed-942b-48d3-a1ff-b34db781424a,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-e9dff052-3b96-4881-9951-a6d3a0499d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-eccb68de-8e33-419f-8cd6-cfb3ea51dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-bbc8ed42-9da6-4d6b-a722-7d44971a3853,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-3becedc4-751e-41f2-8301-2425daa44195,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921306478-172.17.0.7-1595575300992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-55c25732-94ec-4a11-87dd-d19af9edddea,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-008a44fe-8d81-4dde-9c5a-f8820c811d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-b5b8c30d-7094-41d2-9810-f6ccc3838ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-2a2971ed-942b-48d3-a1ff-b34db781424a,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-e9dff052-3b96-4881-9951-a6d3a0499d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-eccb68de-8e33-419f-8cd6-cfb3ea51dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-bbc8ed42-9da6-4d6b-a722-7d44971a3853,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-3becedc4-751e-41f2-8301-2425daa44195,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800323448-172.17.0.7-1595575580824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-4e27c690-db99-4452-bcba-7193ffa2eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-466af45a-667b-4333-9ebe-17bb65f0049c,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-e6bcb71a-3c17-4ff9-aff4-130b6e1260a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-b700b6d2-5570-4541-9ff4-998992bb5b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-4fecb72d-bd8b-41d1-b5f6-61cc10be945a,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-86185621-a672-4c63-a84f-bce4500a7ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-dabb3b6c-72ee-471d-84ca-af952fc238b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-e7e76667-79b1-44b3-a0f1-5e1d9a286be2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800323448-172.17.0.7-1595575580824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44022,DS-4e27c690-db99-4452-bcba-7193ffa2eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-466af45a-667b-4333-9ebe-17bb65f0049c,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-e6bcb71a-3c17-4ff9-aff4-130b6e1260a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-b700b6d2-5570-4541-9ff4-998992bb5b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-4fecb72d-bd8b-41d1-b5f6-61cc10be945a,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-86185621-a672-4c63-a84f-bce4500a7ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-dabb3b6c-72ee-471d-84ca-af952fc238b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-e7e76667-79b1-44b3-a0f1-5e1d9a286be2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252213601-172.17.0.7-1595575774281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-7689dfee-c119-45b2-85a9-1cdbb0e9c703,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-2b5f584a-3bba-45a1-a510-ef40391fb931,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-c54c3212-3d85-4385-b373-f7676433e1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-212d7c80-e078-400f-ade2-1989eac00613,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-a5c531c4-c982-4078-8300-bdb07d2f4059,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-5242da23-ce0d-4446-bc6c-9dc455ded9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-3858606e-af32-4cb5-b06f-5ca13fe988ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-46634293-0375-4765-a503-311b5f312c7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252213601-172.17.0.7-1595575774281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-7689dfee-c119-45b2-85a9-1cdbb0e9c703,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-2b5f584a-3bba-45a1-a510-ef40391fb931,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-c54c3212-3d85-4385-b373-f7676433e1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-212d7c80-e078-400f-ade2-1989eac00613,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-a5c531c4-c982-4078-8300-bdb07d2f4059,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-5242da23-ce0d-4446-bc6c-9dc455ded9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-3858606e-af32-4cb5-b06f-5ca13fe988ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-46634293-0375-4765-a503-311b5f312c7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157241525-172.17.0.7-1595575947016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-2c172201-3f5e-4bcf-baf5-450e5b069222,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-eb80f190-ed72-416d-93d2-6c08aae56f37,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-4204f196-1609-48da-b9a5-410fb58b8f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-4c4fe167-4a0e-4e38-9187-19857cc2e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-83979aab-3ee3-45fb-81bf-6eadc8bd65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-0897daa5-cb2c-4032-9db2-85460236e46b,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-fde17d96-c128-49dd-91a3-6f3fdc2c94b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-83121144-7edb-45f5-9e85-4f05aa897cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157241525-172.17.0.7-1595575947016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-2c172201-3f5e-4bcf-baf5-450e5b069222,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-eb80f190-ed72-416d-93d2-6c08aae56f37,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-4204f196-1609-48da-b9a5-410fb58b8f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-4c4fe167-4a0e-4e38-9187-19857cc2e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-83979aab-3ee3-45fb-81bf-6eadc8bd65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-0897daa5-cb2c-4032-9db2-85460236e46b,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-fde17d96-c128-49dd-91a3-6f3fdc2c94b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-83121144-7edb-45f5-9e85-4f05aa897cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843323502-172.17.0.7-1595576405958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45334,DS-0ffe7a61-6070-4db0-9ca9-d1aaee7a5206,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-2877d91d-8b24-4391-8de9-40e8e8743516,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-edb30238-2c69-418d-9950-44c9f4d35f20,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-4c47f124-4d58-4a63-a16c-24c56544b702,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-567e2ecb-1a67-4cf1-ba12-ab4ef5ae5d00,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-7deb5660-aaa5-4903-a421-36d48feee70e,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-c596d82a-4d58-4013-b84f-df937ac6c64e,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-f21b99d8-5423-4eb2-98ce-92d7075fa15e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843323502-172.17.0.7-1595576405958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45334,DS-0ffe7a61-6070-4db0-9ca9-d1aaee7a5206,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-2877d91d-8b24-4391-8de9-40e8e8743516,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-edb30238-2c69-418d-9950-44c9f4d35f20,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-4c47f124-4d58-4a63-a16c-24c56544b702,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-567e2ecb-1a67-4cf1-ba12-ab4ef5ae5d00,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-7deb5660-aaa5-4903-a421-36d48feee70e,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-c596d82a-4d58-4013-b84f-df937ac6c64e,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-f21b99d8-5423-4eb2-98ce-92d7075fa15e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017766745-172.17.0.7-1595576591635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-78cde435-df2c-46d2-bafa-cc552a93c1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-1002fadc-d173-4da6-a48d-7cf9f74b3e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-9f28d18b-46df-44ab-9b00-0d049d8c1129,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-cfd437ca-ebe6-4b32-8602-e757d83f9e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-93cd692a-5de3-491c-836f-7bbd1ebd9d42,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-a2f47ba3-0426-4514-a415-16d9d2b7a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-f8d2e3fd-a1c5-4132-96d9-83a0d29c8c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-6486a78e-56a7-4dfc-80a4-db76e948cd10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017766745-172.17.0.7-1595576591635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-78cde435-df2c-46d2-bafa-cc552a93c1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-1002fadc-d173-4da6-a48d-7cf9f74b3e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-9f28d18b-46df-44ab-9b00-0d049d8c1129,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-cfd437ca-ebe6-4b32-8602-e757d83f9e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-93cd692a-5de3-491c-836f-7bbd1ebd9d42,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-a2f47ba3-0426-4514-a415-16d9d2b7a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-f8d2e3fd-a1c5-4132-96d9-83a0d29c8c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-6486a78e-56a7-4dfc-80a4-db76e948cd10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291950561-172.17.0.7-1595576705039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-913ec3e6-f55d-40ed-850b-17eff4601028,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-6b510f36-696f-48db-97be-73eeec5eaf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-dbcea950-a5dc-4ca1-8232-d1a9933cf73a,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-43a4c6a4-26b2-419e-a169-1f94c64cefa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-84af36ef-5400-4b7a-b7d6-af13d6e16d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-7bdcabd1-e29f-4d5d-879c-0cce93728f56,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-918ff07d-e4a6-4577-b69d-9fefacdb6235,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-1b494b4e-372d-4aea-9a08-f7ed20547433,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291950561-172.17.0.7-1595576705039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-913ec3e6-f55d-40ed-850b-17eff4601028,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-6b510f36-696f-48db-97be-73eeec5eaf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-dbcea950-a5dc-4ca1-8232-d1a9933cf73a,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-43a4c6a4-26b2-419e-a169-1f94c64cefa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-84af36ef-5400-4b7a-b7d6-af13d6e16d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-7bdcabd1-e29f-4d5d-879c-0cce93728f56,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-918ff07d-e4a6-4577-b69d-9fefacdb6235,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-1b494b4e-372d-4aea-9a08-f7ed20547433,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204370016-172.17.0.7-1595576934351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41463,DS-76de0e51-9ea4-4178-9109-5150659305d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-9b1c7f07-8f65-4e9e-ab2e-25864328260d,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-b220002b-c7fd-42db-a5f2-a06d24827d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-261d310e-1c41-4c4e-829a-736dad73e86d,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-0d35fc63-b5e9-49ee-8bcf-3325e2f6cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-76e087ca-7d64-494d-b3ef-33cd57e6cd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-437aebb6-7f8e-4190-a1eb-3bf54e196b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-17265585-9e61-4816-b626-bb20cbbfc6e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204370016-172.17.0.7-1595576934351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41463,DS-76de0e51-9ea4-4178-9109-5150659305d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-9b1c7f07-8f65-4e9e-ab2e-25864328260d,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-b220002b-c7fd-42db-a5f2-a06d24827d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-261d310e-1c41-4c4e-829a-736dad73e86d,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-0d35fc63-b5e9-49ee-8bcf-3325e2f6cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-76e087ca-7d64-494d-b3ef-33cd57e6cd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-437aebb6-7f8e-4190-a1eb-3bf54e196b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-17265585-9e61-4816-b626-bb20cbbfc6e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692520566-172.17.0.7-1595576967403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-d4a66f79-bdc0-43e3-951b-0d3d68e21340,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-1373aad6-67ce-42dc-94fd-ebda7f6e4e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-d5407047-eaa6-4b36-8491-88964d7dca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-059896ff-c966-4490-b5de-b9e20583eea9,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-3dc2ef51-5804-416c-b50e-4b5844170df1,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-fa4e75a2-e90c-4cfa-bbc2-7de50c4733ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-30e05f9f-e060-4f9c-b7aa-80a91ae9445a,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-25020fe7-0854-4dec-a4b2-e12049cd73c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692520566-172.17.0.7-1595576967403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-d4a66f79-bdc0-43e3-951b-0d3d68e21340,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-1373aad6-67ce-42dc-94fd-ebda7f6e4e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-d5407047-eaa6-4b36-8491-88964d7dca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-059896ff-c966-4490-b5de-b9e20583eea9,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-3dc2ef51-5804-416c-b50e-4b5844170df1,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-fa4e75a2-e90c-4cfa-bbc2-7de50c4733ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-30e05f9f-e060-4f9c-b7aa-80a91ae9445a,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-25020fe7-0854-4dec-a4b2-e12049cd73c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561812861-172.17.0.7-1595577147398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40551,DS-ce7f9616-2b9c-499f-b1fa-16510732b886,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-9343a5bd-0fa3-4eb8-a90b-2405c9138241,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-0df39675-546a-42d5-a86a-0f193205b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-cc602b37-178d-4d06-be3b-8178c9e325ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-06881480-1a08-4365-9bb9-e21792fb4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-ac23d945-294b-42ff-b099-cfde04cea4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-a21cb7d8-1871-43f0-9383-8a1a6072bbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-e313e1a6-f569-4591-ae85-b6d78e6fdb47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561812861-172.17.0.7-1595577147398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40551,DS-ce7f9616-2b9c-499f-b1fa-16510732b886,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-9343a5bd-0fa3-4eb8-a90b-2405c9138241,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-0df39675-546a-42d5-a86a-0f193205b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-cc602b37-178d-4d06-be3b-8178c9e325ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-06881480-1a08-4365-9bb9-e21792fb4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-ac23d945-294b-42ff-b099-cfde04cea4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-a21cb7d8-1871-43f0-9383-8a1a6072bbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-e313e1a6-f569-4591-ae85-b6d78e6fdb47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66210365-172.17.0.7-1595577249845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43561,DS-64f381b0-0fd5-4f69-856e-49c528795197,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-a4681520-8476-46a8-bbcf-957fb6fb79e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-e4d4aa61-236f-4d35-bc81-9c1242fa8a07,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-ecbcd07e-4f14-46af-a04f-86c87511bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-5b28e495-a9e3-4447-83e5-38da6d0ee3db,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-129765ff-0f9a-4914-ad55-e795a603fe84,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-f1470e88-7eb4-4ff1-846a-b3ec32ea1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-9f0653f8-67a4-4fed-9630-9d218af339c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66210365-172.17.0.7-1595577249845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43561,DS-64f381b0-0fd5-4f69-856e-49c528795197,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-a4681520-8476-46a8-bbcf-957fb6fb79e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-e4d4aa61-236f-4d35-bc81-9c1242fa8a07,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-ecbcd07e-4f14-46af-a04f-86c87511bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-5b28e495-a9e3-4447-83e5-38da6d0ee3db,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-129765ff-0f9a-4914-ad55-e795a603fe84,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-f1470e88-7eb4-4ff1-846a-b3ec32ea1cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-9f0653f8-67a4-4fed-9630-9d218af339c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769352170-172.17.0.7-1595577283287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-8254e156-6b67-4164-b027-8725012548e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-376db7c0-329a-4785-a8e3-6343b588c677,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-2c9a823a-1042-48f9-9bcd-6ba16e205cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-104a1fe1-5810-478d-a05a-a9332b473aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-a9891325-d96a-4306-b02b-617ca461ceef,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-a36c0f88-9d4d-4d97-88d3-1ce4a8edc984,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-c558ec35-a8c6-4774-8c9f-220776e50348,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-9c86254b-0439-43a6-a52b-d2fd32999a70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769352170-172.17.0.7-1595577283287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-8254e156-6b67-4164-b027-8725012548e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-376db7c0-329a-4785-a8e3-6343b588c677,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-2c9a823a-1042-48f9-9bcd-6ba16e205cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-104a1fe1-5810-478d-a05a-a9332b473aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-a9891325-d96a-4306-b02b-617ca461ceef,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-a36c0f88-9d4d-4d97-88d3-1ce4a8edc984,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-c558ec35-a8c6-4774-8c9f-220776e50348,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-9c86254b-0439-43a6-a52b-d2fd32999a70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581824700-172.17.0.7-1595577351465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-8c7c5201-b15b-484a-8d9f-7390d69da9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-db074907-46c8-4b56-8be8-86a84c018ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-e6c8607b-afff-44e0-8b16-73d872982dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-725fc584-da91-4cb6-9aea-2fa0174ac1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-51545d05-1fb6-4fa0-9060-f8c57083ecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-759df31c-4a29-485f-a750-0370ecb63824,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-228da37f-1f16-449d-bc78-2e7823eb2d42,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-08ae5d05-35ac-4e05-b81b-7e1093fbf256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581824700-172.17.0.7-1595577351465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-8c7c5201-b15b-484a-8d9f-7390d69da9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-db074907-46c8-4b56-8be8-86a84c018ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-e6c8607b-afff-44e0-8b16-73d872982dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-725fc584-da91-4cb6-9aea-2fa0174ac1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-51545d05-1fb6-4fa0-9060-f8c57083ecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-759df31c-4a29-485f-a750-0370ecb63824,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-228da37f-1f16-449d-bc78-2e7823eb2d42,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-08ae5d05-35ac-4e05-b81b-7e1093fbf256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29474941-172.17.0.7-1595577450059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-173a5f39-d56d-4f68-8d7c-6a6a8e37fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-a222b1ee-a064-4ddf-b669-52d9da25bda7,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-b9c2e0fe-fa7e-4e96-a01d-fcdc9aaedb89,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-b4db1988-d8d5-4a5d-b64d-0fccae8f0a74,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-c6bc42d9-4982-4a9d-aae0-ac716b6d8658,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-d1ea58eb-f0d0-4832-ba66-2c6ec05cba11,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-6f69a15a-6ed0-4dd4-b0b3-f7e6d468f51a,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-0e3b919c-b2eb-4b7c-8569-0e5475a83d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29474941-172.17.0.7-1595577450059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-173a5f39-d56d-4f68-8d7c-6a6a8e37fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-a222b1ee-a064-4ddf-b669-52d9da25bda7,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-b9c2e0fe-fa7e-4e96-a01d-fcdc9aaedb89,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-b4db1988-d8d5-4a5d-b64d-0fccae8f0a74,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-c6bc42d9-4982-4a9d-aae0-ac716b6d8658,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-d1ea58eb-f0d0-4832-ba66-2c6ec05cba11,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-6f69a15a-6ed0-4dd4-b0b3-f7e6d468f51a,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-0e3b919c-b2eb-4b7c-8569-0e5475a83d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842091827-172.17.0.7-1595577615207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40772,DS-12058edd-f69c-4433-bcaf-b8db97ff12a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-3c1b0df9-4ab6-4b11-93b1-7221062759b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-4ced9b45-ed20-49c0-9ae7-2d93a1c51a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-93ea0f40-d5d3-4fe0-8344-2c9a5fce1fad,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-3b83fa0f-bced-4b55-8ff2-32cdc8ddc273,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-bde2edc3-0a5e-41aa-bb28-cc18e6696e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-be4c620b-190b-4d3c-910d-d5385b5e2d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-3f19ebf0-a3e5-4ce0-8bc1-b872fe1ae79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842091827-172.17.0.7-1595577615207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40772,DS-12058edd-f69c-4433-bcaf-b8db97ff12a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-3c1b0df9-4ab6-4b11-93b1-7221062759b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-4ced9b45-ed20-49c0-9ae7-2d93a1c51a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-93ea0f40-d5d3-4fe0-8344-2c9a5fce1fad,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-3b83fa0f-bced-4b55-8ff2-32cdc8ddc273,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-bde2edc3-0a5e-41aa-bb28-cc18e6696e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-be4c620b-190b-4d3c-910d-d5385b5e2d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-3f19ebf0-a3e5-4ce0-8bc1-b872fe1ae79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131308652-172.17.0.7-1595577758023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39638,DS-d7740301-6a73-48b4-ac6b-c77399851f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-5c33dec8-f9c3-467d-80d0-6583e9d6152a,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-5f0812f2-7a5a-4ef2-9b22-45c1c67d9c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-59e83d71-deb0-4c51-b934-42a80ef7e953,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-52a52c34-6d88-44d4-9fcd-9727aedafd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-ea061420-cf60-45c0-806e-d223048d7e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-4a249374-dadd-4262-8bdf-39591ec3acad,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-2ed2ea1a-fd91-49be-ad62-b388cca63eb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131308652-172.17.0.7-1595577758023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39638,DS-d7740301-6a73-48b4-ac6b-c77399851f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-5c33dec8-f9c3-467d-80d0-6583e9d6152a,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-5f0812f2-7a5a-4ef2-9b22-45c1c67d9c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-59e83d71-deb0-4c51-b934-42a80ef7e953,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-52a52c34-6d88-44d4-9fcd-9727aedafd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-ea061420-cf60-45c0-806e-d223048d7e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-4a249374-dadd-4262-8bdf-39591ec3acad,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-2ed2ea1a-fd91-49be-ad62-b388cca63eb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17105206-172.17.0.7-1595577790955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-68286022-6254-415e-ada8-22e235f45ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-ab32b356-7a23-4045-bfff-abbdb21418eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-0fb039cb-cb0a-4234-ba3c-e76b904fac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-dd25b8b2-d278-4a4a-9bbf-614689fa55c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-cdd1240e-cf84-453c-80d1-2d2dff50520a,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-e76406a3-5dd5-4d2f-8e6e-6a332734ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-2599b763-546d-42f9-8a67-3b0c7aa2c3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-5cd4da6f-d618-49a9-b01e-3edf41b072c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17105206-172.17.0.7-1595577790955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-68286022-6254-415e-ada8-22e235f45ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-ab32b356-7a23-4045-bfff-abbdb21418eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-0fb039cb-cb0a-4234-ba3c-e76b904fac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-dd25b8b2-d278-4a4a-9bbf-614689fa55c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-cdd1240e-cf84-453c-80d1-2d2dff50520a,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-e76406a3-5dd5-4d2f-8e6e-6a332734ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-2599b763-546d-42f9-8a67-3b0c7aa2c3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-5cd4da6f-d618-49a9-b01e-3edf41b072c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888573229-172.17.0.7-1595578000446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37860,DS-b89048f5-4c37-4806-977a-38f11f499b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-587ede8e-809b-4d89-8a94-f30956c45e93,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-6aafca01-81da-47f4-9ab4-7c216105b086,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-04525650-7b86-4254-9144-01de9ef9694d,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-be51a3d8-500c-4ccd-9d1a-509a70420b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-aa9b8bb7-59d3-4098-9e8a-50da67010fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-1ec01d13-bf96-413b-ae9f-6fc8ae02c930,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-04b43a84-e67c-44de-82bb-27b548312b8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888573229-172.17.0.7-1595578000446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37860,DS-b89048f5-4c37-4806-977a-38f11f499b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-587ede8e-809b-4d89-8a94-f30956c45e93,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-6aafca01-81da-47f4-9ab4-7c216105b086,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-04525650-7b86-4254-9144-01de9ef9694d,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-be51a3d8-500c-4ccd-9d1a-509a70420b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-aa9b8bb7-59d3-4098-9e8a-50da67010fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-1ec01d13-bf96-413b-ae9f-6fc8ae02c930,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-04b43a84-e67c-44de-82bb-27b548312b8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178680088-172.17.0.7-1595578061848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45366,DS-bec9a2c1-229e-4c46-ae7c-2a259af37c20,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-a935bae1-3ff5-4c39-b725-0485df0b3e57,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-bec799bd-f64f-4b88-8ec7-6569ccc4687d,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-369a7490-8c95-4120-8562-27e09913e8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-fc8b8bd9-ecf8-4bf8-80d2-a79ef2986d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-21b0f406-70d0-4d2b-93af-3ccaebe79501,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-9e8b8ffb-70b4-44c2-885b-3e9c83024d81,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-024733ff-61c3-473c-a8dd-b9c311234321,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178680088-172.17.0.7-1595578061848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45366,DS-bec9a2c1-229e-4c46-ae7c-2a259af37c20,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-a935bae1-3ff5-4c39-b725-0485df0b3e57,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-bec799bd-f64f-4b88-8ec7-6569ccc4687d,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-369a7490-8c95-4120-8562-27e09913e8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-fc8b8bd9-ecf8-4bf8-80d2-a79ef2986d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-21b0f406-70d0-4d2b-93af-3ccaebe79501,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-9e8b8ffb-70b4-44c2-885b-3e9c83024d81,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-024733ff-61c3-473c-a8dd-b9c311234321,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293961172-172.17.0.7-1595578205350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42208,DS-d5717315-cdab-4a4d-a4ec-e685e6415c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-23e8b47a-177e-4a04-a464-7044227e7689,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-d8857850-922d-49ad-a5b4-bda987c9ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-ef4f8e5a-94d2-43a7-8826-4282da8b7377,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-b3d6db65-d771-4cdd-a6f4-02a81bdecab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-d13fae52-e3fc-4374-93c7-7b2af5e472c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-e3a1a124-e38e-4296-bea2-8677906665ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-a1a4a3d0-8b0d-4eee-9354-8007d435834b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293961172-172.17.0.7-1595578205350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42208,DS-d5717315-cdab-4a4d-a4ec-e685e6415c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-23e8b47a-177e-4a04-a464-7044227e7689,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-d8857850-922d-49ad-a5b4-bda987c9ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-ef4f8e5a-94d2-43a7-8826-4282da8b7377,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-b3d6db65-d771-4cdd-a6f4-02a81bdecab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-d13fae52-e3fc-4374-93c7-7b2af5e472c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-e3a1a124-e38e-4296-bea2-8677906665ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-a1a4a3d0-8b0d-4eee-9354-8007d435834b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717489692-172.17.0.7-1595578389403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-71c8abe4-240f-490d-b8c0-5581d4a887cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-4be72446-cac4-41e0-b8ca-84e4ce11c72f,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-6491ad0a-1f1c-4293-aa36-c3cb2ee3a8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-1fdfd0ff-b786-4787-8094-f9af2c29248c,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-090356aa-b15c-4cf6-8752-ad16db4884a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-846f0f10-0221-4488-b009-37b8c96e17a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-d9df1681-e2e6-4be7-8227-5453efb65b55,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-b1a1c30c-9bdc-4fd6-bdb8-3d92ad0cf354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717489692-172.17.0.7-1595578389403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-71c8abe4-240f-490d-b8c0-5581d4a887cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-4be72446-cac4-41e0-b8ca-84e4ce11c72f,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-6491ad0a-1f1c-4293-aa36-c3cb2ee3a8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-1fdfd0ff-b786-4787-8094-f9af2c29248c,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-090356aa-b15c-4cf6-8752-ad16db4884a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-846f0f10-0221-4488-b009-37b8c96e17a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-d9df1681-e2e6-4be7-8227-5453efb65b55,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-b1a1c30c-9bdc-4fd6-bdb8-3d92ad0cf354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138076165-172.17.0.7-1595578423248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33852,DS-3b3d153e-9e5d-42e9-bdc8-fe1439863dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-1874595c-4b3d-4a79-9be2-62c62ae4e6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-95eb1c36-d9fd-4812-8e07-b021a7cdd31c,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-165bebb1-8282-446f-843a-2439aa02bc32,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-2544cff4-3885-49bc-bda9-c842cfbc99e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-52071581-dcd1-4940-8f00-232226f9ce22,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-56e6c55c-1932-4a5f-9455-1a27e6e6b9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-2fe9eeff-a51b-4e1f-9bd6-aa6c83e5856e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138076165-172.17.0.7-1595578423248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33852,DS-3b3d153e-9e5d-42e9-bdc8-fe1439863dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-1874595c-4b3d-4a79-9be2-62c62ae4e6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-95eb1c36-d9fd-4812-8e07-b021a7cdd31c,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-165bebb1-8282-446f-843a-2439aa02bc32,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-2544cff4-3885-49bc-bda9-c842cfbc99e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-52071581-dcd1-4940-8f00-232226f9ce22,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-56e6c55c-1932-4a5f-9455-1a27e6e6b9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-2fe9eeff-a51b-4e1f-9bd6-aa6c83e5856e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52247485-172.17.0.7-1595578459233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34074,DS-b9626b57-6534-41dd-a916-9cfd7d7448bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-89439eb0-b9df-407f-be2c-a09e2176a870,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-5ed8aad9-0129-4afe-9d0a-505cff4117af,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-3d5a7c24-b8af-4b25-9c88-b7eab2e584ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-94b6ffe8-8a67-429f-9fe5-60ca6681f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-44a0b61a-dc4d-45cf-b4a7-fc6d4150dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-f6c7b628-961c-4c77-b7ac-d09c55768e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-a17b3801-dad9-43e3-9771-52acf2348048,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52247485-172.17.0.7-1595578459233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34074,DS-b9626b57-6534-41dd-a916-9cfd7d7448bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-89439eb0-b9df-407f-be2c-a09e2176a870,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-5ed8aad9-0129-4afe-9d0a-505cff4117af,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-3d5a7c24-b8af-4b25-9c88-b7eab2e584ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-94b6ffe8-8a67-429f-9fe5-60ca6681f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-44a0b61a-dc4d-45cf-b4a7-fc6d4150dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-f6c7b628-961c-4c77-b7ac-d09c55768e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-a17b3801-dad9-43e3-9771-52acf2348048,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88533844-172.17.0.7-1595578657674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38218,DS-f93e91bc-9707-4267-a825-89caa06ae663,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-999398c7-7022-43ed-82c8-ce1e635545ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-7bc27f15-fd90-4b08-8ea9-23b14326a3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-224fd127-1a58-47a9-91e3-7a999171a80f,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-654fe5a5-f9d8-44b4-8b3c-8ae4d015aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-9bfe51d5-98a4-4bad-a292-3041fc99e185,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-987072a7-63dc-4359-814f-e11ae6586742,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-ea8151bf-e91a-42ac-9058-30b569921563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88533844-172.17.0.7-1595578657674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38218,DS-f93e91bc-9707-4267-a825-89caa06ae663,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-999398c7-7022-43ed-82c8-ce1e635545ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-7bc27f15-fd90-4b08-8ea9-23b14326a3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-224fd127-1a58-47a9-91e3-7a999171a80f,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-654fe5a5-f9d8-44b4-8b3c-8ae4d015aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-9bfe51d5-98a4-4bad-a292-3041fc99e185,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-987072a7-63dc-4359-814f-e11ae6586742,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-ea8151bf-e91a-42ac-9058-30b569921563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600751097-172.17.0.7-1595578915911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-39f5b349-dfe2-4cab-be0a-90d79ace297e,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-58c2fa11-2c4d-4e75-8596-8cc1bb9926c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-566baa20-d82b-42f7-89b3-f08da8e5d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-73f513c5-001f-4c7f-880b-5a6af59f0882,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-5ae9f2d6-fad4-46dd-8572-e3dbd5aab1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-0ec6c00e-5806-4c0d-b0e3-6dd28661eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-238bd329-5c2f-4cab-b697-26e9053085a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-4d28476d-96ef-4179-9f02-d25aba391f0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600751097-172.17.0.7-1595578915911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-39f5b349-dfe2-4cab-be0a-90d79ace297e,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-58c2fa11-2c4d-4e75-8596-8cc1bb9926c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-566baa20-d82b-42f7-89b3-f08da8e5d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-73f513c5-001f-4c7f-880b-5a6af59f0882,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-5ae9f2d6-fad4-46dd-8572-e3dbd5aab1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-0ec6c00e-5806-4c0d-b0e3-6dd28661eb46,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-238bd329-5c2f-4cab-b697-26e9053085a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-4d28476d-96ef-4179-9f02-d25aba391f0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772629470-172.17.0.7-1595578996249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-272ce9b9-af61-49b0-93c3-794cb064fc37,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-e0eca9eb-bf8f-4556-8fce-6cec98e1b434,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-4cc4b88f-945f-4f85-8f7c-664b020da3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-136ad34c-78a5-49fb-bab7-4cb4b0f29186,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-abd5a10a-dd9b-4f1b-a95c-3be22a161a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-73000590-7007-4e30-8bbf-25653ed5c9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-97bf8d95-64a6-4698-98dd-977d4830a41f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-b118cc8c-25d7-4f1d-9559-e0b1762cd13e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772629470-172.17.0.7-1595578996249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-272ce9b9-af61-49b0-93c3-794cb064fc37,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-e0eca9eb-bf8f-4556-8fce-6cec98e1b434,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-4cc4b88f-945f-4f85-8f7c-664b020da3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-136ad34c-78a5-49fb-bab7-4cb4b0f29186,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-abd5a10a-dd9b-4f1b-a95c-3be22a161a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-73000590-7007-4e30-8bbf-25653ed5c9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-97bf8d95-64a6-4698-98dd-977d4830a41f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-b118cc8c-25d7-4f1d-9559-e0b1762cd13e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423595586-172.17.0.7-1595579120231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39357,DS-db6db024-a60a-4603-b1c5-f00c86f9d843,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-307b0c54-eae7-451d-8c18-5d2f3ba008ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-a4d9f356-9cad-4de7-9dc2-0ff22e07328a,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-7e70e190-e499-4e19-a4cf-52fdfb13623a,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-7d0531ff-86ba-47d8-8eb8-1cb7dd3ba63f,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-d76de616-2eaf-4b0e-9a31-debaee382105,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-f84892e4-59a6-4cc1-a544-a37f5ea4cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-c51c62a3-d5fb-4a92-8c26-7d75b3b3a13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423595586-172.17.0.7-1595579120231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39357,DS-db6db024-a60a-4603-b1c5-f00c86f9d843,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-307b0c54-eae7-451d-8c18-5d2f3ba008ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-a4d9f356-9cad-4de7-9dc2-0ff22e07328a,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-7e70e190-e499-4e19-a4cf-52fdfb13623a,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-7d0531ff-86ba-47d8-8eb8-1cb7dd3ba63f,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-d76de616-2eaf-4b0e-9a31-debaee382105,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-f84892e4-59a6-4cc1-a544-a37f5ea4cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-c51c62a3-d5fb-4a92-8c26-7d75b3b3a13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160843348-172.17.0.7-1595579236174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-5d7bd4fe-88b5-45fc-94ee-ebef8c07fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-85394a46-d416-4493-b658-696cb4d1d0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-29d73ab9-4a21-47d9-aa2e-30f6c1d77e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-52a89703-e5af-4b18-a912-57d6901978eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-436f9dcf-7991-4c8e-a534-729566b79f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-e032a990-c137-4c4d-a72f-44a987a37bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-629679af-1e49-4061-a63e-3e60bb77b0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-e72d8680-b19d-4684-be93-45ecc598605c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160843348-172.17.0.7-1595579236174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-5d7bd4fe-88b5-45fc-94ee-ebef8c07fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-85394a46-d416-4493-b658-696cb4d1d0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-29d73ab9-4a21-47d9-aa2e-30f6c1d77e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-52a89703-e5af-4b18-a912-57d6901978eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-436f9dcf-7991-4c8e-a534-729566b79f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-e032a990-c137-4c4d-a72f-44a987a37bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-629679af-1e49-4061-a63e-3e60bb77b0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-e72d8680-b19d-4684-be93-45ecc598605c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76376301-172.17.0.7-1595579472200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-92643ab0-ff70-4c14-8852-b627f1d8c750,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-fab7acc3-31ef-402d-bcda-e6370e22e394,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-7299477d-e28e-460a-9dff-55fc1417101f,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-7667f1c0-3904-48ff-ba5d-e13064b3ee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-f2964ad3-53e0-4043-a2f4-8fce1405da56,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-3739c7ef-171f-4b58-aa73-7740ea18aeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-b75bf253-18c4-4ee0-9d09-d57a4b010085,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-661b1433-70b6-42e7-ae42-9b3cedf6172c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76376301-172.17.0.7-1595579472200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-92643ab0-ff70-4c14-8852-b627f1d8c750,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-fab7acc3-31ef-402d-bcda-e6370e22e394,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-7299477d-e28e-460a-9dff-55fc1417101f,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-7667f1c0-3904-48ff-ba5d-e13064b3ee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-f2964ad3-53e0-4043-a2f4-8fce1405da56,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-3739c7ef-171f-4b58-aa73-7740ea18aeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-b75bf253-18c4-4ee0-9d09-d57a4b010085,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-661b1433-70b6-42e7-ae42-9b3cedf6172c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438395643-172.17.0.7-1595579515742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39561,DS-a43bad38-125d-465a-b5d8-24371e174b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-3afa91ac-ae71-426e-83ef-9e0e9c5ee3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-6cf6a068-acfa-4245-9727-a0d9ec21f503,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-e3c35bda-e4ea-4bf2-9b54-263738af569f,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-140e230f-7950-4332-a7c9-1208c260d444,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-1b7f2da8-e2d4-460c-ad37-4ea2ae8fb820,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-3adf3509-b5d0-46eb-a66d-296bab0a7806,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7fd1e165-60d5-4f8a-962c-5e4f205c98c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438395643-172.17.0.7-1595579515742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39561,DS-a43bad38-125d-465a-b5d8-24371e174b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-3afa91ac-ae71-426e-83ef-9e0e9c5ee3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-6cf6a068-acfa-4245-9727-a0d9ec21f503,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-e3c35bda-e4ea-4bf2-9b54-263738af569f,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-140e230f-7950-4332-a7c9-1208c260d444,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-1b7f2da8-e2d4-460c-ad37-4ea2ae8fb820,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-3adf3509-b5d0-46eb-a66d-296bab0a7806,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7fd1e165-60d5-4f8a-962c-5e4f205c98c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045413577-172.17.0.7-1595579966022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-818ae3ed-f8d8-4ef3-b16d-8b842332c446,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-6f183be5-1f9d-49c1-bad0-f56f2434aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-030f801a-0c37-42e4-b067-324754a59808,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-397fc8b0-80a6-44d7-a796-e2c5739bea37,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-c3cc4b2f-5d72-4f14-81c8-51dbc4eae024,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-af80017c-3174-426b-8232-b8a3013d4f01,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-636e62f5-990b-440f-9435-c2112c1d3906,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-877bcedb-cb56-436c-9bed-a215e37c26ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045413577-172.17.0.7-1595579966022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-818ae3ed-f8d8-4ef3-b16d-8b842332c446,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-6f183be5-1f9d-49c1-bad0-f56f2434aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-030f801a-0c37-42e4-b067-324754a59808,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-397fc8b0-80a6-44d7-a796-e2c5739bea37,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-c3cc4b2f-5d72-4f14-81c8-51dbc4eae024,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-af80017c-3174-426b-8232-b8a3013d4f01,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-636e62f5-990b-440f-9435-c2112c1d3906,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-877bcedb-cb56-436c-9bed-a215e37c26ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709628559-172.17.0.7-1595580049985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-0f59b69b-9c5c-4865-9c95-9068c34b056e,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-77a90ad3-176f-4da2-a9e4-ce8b7760969d,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-b13b46c4-22e8-4611-b1b5-06bcaaf88a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-2dd05fa8-5139-465c-865c-e533e69378db,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-6d899376-e7b7-41bf-b258-9950c7747be8,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-d948f644-9293-42ee-9961-13753cd53bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-b38364d9-3a63-47d8-accb-2c0065ea3dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-c3e36bb5-6e01-45a1-a866-6377b26edb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709628559-172.17.0.7-1595580049985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-0f59b69b-9c5c-4865-9c95-9068c34b056e,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-77a90ad3-176f-4da2-a9e4-ce8b7760969d,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-b13b46c4-22e8-4611-b1b5-06bcaaf88a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-2dd05fa8-5139-465c-865c-e533e69378db,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-6d899376-e7b7-41bf-b258-9950c7747be8,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-d948f644-9293-42ee-9961-13753cd53bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-b38364d9-3a63-47d8-accb-2c0065ea3dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-c3e36bb5-6e01-45a1-a866-6377b26edb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436094066-172.17.0.7-1595580090214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-5696ee0e-578d-4466-8de8-7fd9de4cbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-99dba157-81db-4ada-903e-707cdc3d2ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-6761131e-5e41-4ffc-bc7e-ca7e9ae2daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-b92fae04-366f-447b-964d-91d18c91b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-dc74f58d-c4f5-4df4-b997-4b05b9299d41,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-0b5ec4c3-6009-46e2-b9af-1dace77990b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-f888ab59-1958-4db4-b6e0-91eb04ef0237,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-4858babc-2ec5-4802-8995-3c06f299fe14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436094066-172.17.0.7-1595580090214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-5696ee0e-578d-4466-8de8-7fd9de4cbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-99dba157-81db-4ada-903e-707cdc3d2ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-6761131e-5e41-4ffc-bc7e-ca7e9ae2daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-b92fae04-366f-447b-964d-91d18c91b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-dc74f58d-c4f5-4df4-b997-4b05b9299d41,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-0b5ec4c3-6009-46e2-b9af-1dace77990b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-f888ab59-1958-4db4-b6e0-91eb04ef0237,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-4858babc-2ec5-4802-8995-3c06f299fe14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311194064-172.17.0.7-1595580463602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40352,DS-54cdd1f5-0cc0-4d16-8c8b-28ff4c6629cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-92fb00f4-3820-4cda-955c-927e42b39b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-a97c203a-dcda-442a-8180-af0e45425f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-3b377e0d-327d-4230-b00c-a84002d8b14b,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-9b863946-1ce3-44ea-b9c6-c14aad7786e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-5f35ef0f-958f-445b-85b4-a8bdb0417c49,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-14398865-7e76-4012-a06a-8e20fd5772d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-6e76203e-df6d-46a6-9c23-7456f6318225,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311194064-172.17.0.7-1595580463602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40352,DS-54cdd1f5-0cc0-4d16-8c8b-28ff4c6629cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-92fb00f4-3820-4cda-955c-927e42b39b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-a97c203a-dcda-442a-8180-af0e45425f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-3b377e0d-327d-4230-b00c-a84002d8b14b,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-9b863946-1ce3-44ea-b9c6-c14aad7786e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-5f35ef0f-958f-445b-85b4-a8bdb0417c49,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-14398865-7e76-4012-a06a-8e20fd5772d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-6e76203e-df6d-46a6-9c23-7456f6318225,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5550
