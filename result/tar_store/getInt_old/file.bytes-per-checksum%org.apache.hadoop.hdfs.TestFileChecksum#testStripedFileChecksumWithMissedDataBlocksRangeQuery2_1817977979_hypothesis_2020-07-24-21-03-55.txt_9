reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489599370-172.17.0.12-1595624651909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35684,DS-acb13463-c346-402e-bc79-50419a371b95,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-d2b8c2f0-eda2-471a-82d2-894353adfc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-dc71a7cb-6549-467b-8f70-36d42b93b70f,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-06814b43-0726-4ff1-8a2f-8e42d879232c,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-5240b012-3bae-49c2-b16b-0f203ff6c320,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-ddf6f582-b0e3-4549-b76a-67d039853b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-09179d40-d184-4d09-b6a5-d118bde969a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-9f87c8c6-743d-4251-ab80-f2ef0f33ee72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489599370-172.17.0.12-1595624651909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35684,DS-acb13463-c346-402e-bc79-50419a371b95,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-d2b8c2f0-eda2-471a-82d2-894353adfc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-dc71a7cb-6549-467b-8f70-36d42b93b70f,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-06814b43-0726-4ff1-8a2f-8e42d879232c,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-5240b012-3bae-49c2-b16b-0f203ff6c320,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-ddf6f582-b0e3-4549-b76a-67d039853b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-09179d40-d184-4d09-b6a5-d118bde969a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-9f87c8c6-743d-4251-ab80-f2ef0f33ee72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293625197-172.17.0.12-1595625184329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36765,DS-d6410cff-0a98-4e4e-a06b-4ab0aa5a73c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-37325c8c-0e56-4b35-8788-7ba90f281940,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-5cf5242d-6d4c-4f64-ae76-bab19906199e,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-b267e4ae-db69-4964-925c-9c8024763d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-4c1cd6b6-71a1-4eaa-911f-0400e6abf391,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-ec4c2e9e-dcea-4136-a857-0282e1bf6746,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-f50239b3-2b14-4d03-b4c4-f842353f150f,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-354f7658-1dbd-4d98-96a0-31da0ca1590e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293625197-172.17.0.12-1595625184329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36765,DS-d6410cff-0a98-4e4e-a06b-4ab0aa5a73c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-37325c8c-0e56-4b35-8788-7ba90f281940,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-5cf5242d-6d4c-4f64-ae76-bab19906199e,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-b267e4ae-db69-4964-925c-9c8024763d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-4c1cd6b6-71a1-4eaa-911f-0400e6abf391,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-ec4c2e9e-dcea-4136-a857-0282e1bf6746,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-f50239b3-2b14-4d03-b4c4-f842353f150f,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-354f7658-1dbd-4d98-96a0-31da0ca1590e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103260664-172.17.0.12-1595625497338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42658,DS-2f730b87-da64-44ee-a9a4-c6d09e2f11de,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-75d46af0-def9-4688-8a59-d435c94bd5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-1bbe8e9d-0793-4d4f-8e76-93e1a7aa9609,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-730aaca1-77b9-4e6e-8d54-2db96ffdcca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-896deeca-7cc3-4c0e-94b8-a42d2be1e4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-ad4144b5-91b4-4e16-851f-348838b387df,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-92bb8f0d-e5d6-49cf-bcc6-c36ce3eae367,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-90ad127c-8eb1-43b8-b9f7-5f9085cf5eb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103260664-172.17.0.12-1595625497338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42658,DS-2f730b87-da64-44ee-a9a4-c6d09e2f11de,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-75d46af0-def9-4688-8a59-d435c94bd5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-1bbe8e9d-0793-4d4f-8e76-93e1a7aa9609,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-730aaca1-77b9-4e6e-8d54-2db96ffdcca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-896deeca-7cc3-4c0e-94b8-a42d2be1e4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-ad4144b5-91b4-4e16-851f-348838b387df,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-92bb8f0d-e5d6-49cf-bcc6-c36ce3eae367,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-90ad127c-8eb1-43b8-b9f7-5f9085cf5eb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62653677-172.17.0.12-1595626692221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46848,DS-62abb7b1-9a70-4ed2-9f70-c9394b214a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-c8866feb-d6d2-4bb4-b4fc-0779d01b8ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-c0277ade-3903-4501-8991-85339f097c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-9db20aed-d8ad-45d4-b928-ab526d218402,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-113c402f-bd88-4c66-8d1f-68da8a358cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-c0d0959c-5376-4031-bdee-ff037cd6cafb,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-bec22038-000e-4291-a6f5-5a4150132dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-397f4499-85cc-4439-abfb-608089800776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62653677-172.17.0.12-1595626692221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46848,DS-62abb7b1-9a70-4ed2-9f70-c9394b214a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-c8866feb-d6d2-4bb4-b4fc-0779d01b8ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-c0277ade-3903-4501-8991-85339f097c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-9db20aed-d8ad-45d4-b928-ab526d218402,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-113c402f-bd88-4c66-8d1f-68da8a358cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-c0d0959c-5376-4031-bdee-ff037cd6cafb,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-bec22038-000e-4291-a6f5-5a4150132dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-397f4499-85cc-4439-abfb-608089800776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870891233-172.17.0.12-1595626812994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37619,DS-8464c34d-d8b1-44d6-98df-32fc1a6d4eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-26ca81a3-e08b-43d5-b4d7-8fbec2393ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-67436455-91f4-4bd9-a33f-89e45691cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-64752965-5274-452c-9969-a68d0f4e95de,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-53e58010-42e1-49be-8d18-30d41309321e,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-23e23c22-b874-402c-b8f1-bf3a0989e95d,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-1c5c8f32-ed14-4385-bfea-eb2514117c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-33f0fed0-38f6-4cc7-af26-78126b476669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870891233-172.17.0.12-1595626812994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37619,DS-8464c34d-d8b1-44d6-98df-32fc1a6d4eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-26ca81a3-e08b-43d5-b4d7-8fbec2393ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-67436455-91f4-4bd9-a33f-89e45691cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-64752965-5274-452c-9969-a68d0f4e95de,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-53e58010-42e1-49be-8d18-30d41309321e,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-23e23c22-b874-402c-b8f1-bf3a0989e95d,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-1c5c8f32-ed14-4385-bfea-eb2514117c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-33f0fed0-38f6-4cc7-af26-78126b476669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926567887-172.17.0.12-1595627297222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-bce0def6-0ac9-43f9-bac9-b27e50af414d,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-c0d6a1c2-38f8-4c80-8325-6cc513ce3c43,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-608485bc-0e6c-4e0a-a200-6630ab191157,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-c9f60e42-7360-4835-a5b6-6baa71d765a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-ad547eb0-afc6-4de9-b947-2c1edc50ef12,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-88fffc49-9454-46b7-b15e-07fded0a4278,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-533a6769-defe-49a0-aff7-c6b5ce861620,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-8531205e-c895-4180-ae9e-934600d73650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926567887-172.17.0.12-1595627297222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46813,DS-bce0def6-0ac9-43f9-bac9-b27e50af414d,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-c0d6a1c2-38f8-4c80-8325-6cc513ce3c43,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-608485bc-0e6c-4e0a-a200-6630ab191157,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-c9f60e42-7360-4835-a5b6-6baa71d765a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-ad547eb0-afc6-4de9-b947-2c1edc50ef12,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-88fffc49-9454-46b7-b15e-07fded0a4278,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-533a6769-defe-49a0-aff7-c6b5ce861620,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-8531205e-c895-4180-ae9e-934600d73650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30284178-172.17.0.12-1595627573948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39090,DS-d3abd8dc-d359-4a56-a2bd-7a110e6a0125,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-abdebd71-36a4-4563-ad9e-b682e1cc578b,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-d849005d-e681-486f-be50-c3bc4f6221a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-11a7e78d-7eb4-4a71-a63f-88c4f9259443,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-8be30507-1453-48ac-9e8b-9746b8a58348,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-723506ea-1fd1-4dcc-8f9a-466a599b2275,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-fb9e1aa8-e048-4c69-ab0f-6dc08e3b0031,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-08d879ee-2689-4da0-b05f-58c3df49118b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30284178-172.17.0.12-1595627573948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39090,DS-d3abd8dc-d359-4a56-a2bd-7a110e6a0125,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-abdebd71-36a4-4563-ad9e-b682e1cc578b,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-d849005d-e681-486f-be50-c3bc4f6221a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-11a7e78d-7eb4-4a71-a63f-88c4f9259443,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-8be30507-1453-48ac-9e8b-9746b8a58348,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-723506ea-1fd1-4dcc-8f9a-466a599b2275,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-fb9e1aa8-e048-4c69-ab0f-6dc08e3b0031,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-08d879ee-2689-4da0-b05f-58c3df49118b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969069606-172.17.0.12-1595628519083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40570,DS-c0c675d1-4afe-4703-8271-73f11fb00400,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-a6ffca1d-7813-442e-9b1b-ffe99392eabd,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-16c692ed-5196-4eda-8f3f-e00a1923a305,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-8306e50c-7c29-4581-b724-f81e383405d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-4b5ed3f2-55bc-45a6-989f-89ec0b198f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-eef58202-93b6-4c53-beb9-370bd371e667,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-c50f202d-ada6-46c1-ac11-061018594470,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-f15d8304-2281-42fb-8447-f0a62fced999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969069606-172.17.0.12-1595628519083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40570,DS-c0c675d1-4afe-4703-8271-73f11fb00400,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-a6ffca1d-7813-442e-9b1b-ffe99392eabd,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-16c692ed-5196-4eda-8f3f-e00a1923a305,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-8306e50c-7c29-4581-b724-f81e383405d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-4b5ed3f2-55bc-45a6-989f-89ec0b198f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-eef58202-93b6-4c53-beb9-370bd371e667,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-c50f202d-ada6-46c1-ac11-061018594470,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-f15d8304-2281-42fb-8447-f0a62fced999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102362820-172.17.0.12-1595628557474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39561,DS-c98f6f98-042f-47d4-b77a-d75ce4f4c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-707004ac-8970-4cde-91d7-19bf17809090,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-37340a2c-e157-4ee6-a379-ff17c07b02c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-8e6df1e5-5e44-44ba-ba57-05673a432375,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-db4d9f30-9796-4004-8fc3-4bfc4e693e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-047a5a9a-f245-4110-9f08-2407fcddd1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-8529f5c6-ce8c-4ac7-b640-b209ff3bb768,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-7dadab12-d50b-4889-8899-e2ef7af4e160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102362820-172.17.0.12-1595628557474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39561,DS-c98f6f98-042f-47d4-b77a-d75ce4f4c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-707004ac-8970-4cde-91d7-19bf17809090,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-37340a2c-e157-4ee6-a379-ff17c07b02c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-8e6df1e5-5e44-44ba-ba57-05673a432375,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-db4d9f30-9796-4004-8fc3-4bfc4e693e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-047a5a9a-f245-4110-9f08-2407fcddd1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-8529f5c6-ce8c-4ac7-b640-b209ff3bb768,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-7dadab12-d50b-4889-8899-e2ef7af4e160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523942498-172.17.0.12-1595628786812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43098,DS-facc536d-ed86-4834-bebd-e17a041b3237,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-be54d57e-45bb-48ae-aeda-b4a9ec6c02ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-3d540783-b8ca-418d-84fc-964f2eaafa17,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-4f295850-31b6-4d23-aac1-0c370c2c55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-5f7fa414-d311-41e0-958a-08e982023358,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-ea0b5fe0-c02b-4af0-bc4e-5aff323c6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-3051e49e-1270-485a-a2ac-e75f97132069,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-075d2252-b792-4839-8cb5-3ef6eee73c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523942498-172.17.0.12-1595628786812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43098,DS-facc536d-ed86-4834-bebd-e17a041b3237,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-be54d57e-45bb-48ae-aeda-b4a9ec6c02ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-3d540783-b8ca-418d-84fc-964f2eaafa17,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-4f295850-31b6-4d23-aac1-0c370c2c55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-5f7fa414-d311-41e0-958a-08e982023358,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-ea0b5fe0-c02b-4af0-bc4e-5aff323c6cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-3051e49e-1270-485a-a2ac-e75f97132069,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-075d2252-b792-4839-8cb5-3ef6eee73c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961628720-172.17.0.12-1595628951335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39413,DS-eba9f5f4-d2db-478e-8fd3-dfd826f6c4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-90eeda64-f2a9-4088-9d14-fb3797a50275,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-96bd4c74-f701-4a6b-a119-da8d31f7869e,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-4c65e311-114c-47f1-83dc-afed517ec4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-89da588d-ce8b-4c63-9369-c8c0eca9339d,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-6b02b3a7-2f59-47f7-b503-b360aa232937,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-cb2dfd8d-98ac-4437-b05a-82357e13f7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-ae96625d-91fc-4afc-84c6-bb56911fa30b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961628720-172.17.0.12-1595628951335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39413,DS-eba9f5f4-d2db-478e-8fd3-dfd826f6c4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-90eeda64-f2a9-4088-9d14-fb3797a50275,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-96bd4c74-f701-4a6b-a119-da8d31f7869e,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-4c65e311-114c-47f1-83dc-afed517ec4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-89da588d-ce8b-4c63-9369-c8c0eca9339d,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-6b02b3a7-2f59-47f7-b503-b360aa232937,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-cb2dfd8d-98ac-4437-b05a-82357e13f7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-ae96625d-91fc-4afc-84c6-bb56911fa30b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701177961-172.17.0.12-1595629211205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39332,DS-23ac9298-61f6-4050-9b17-32c6be189056,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-6ad9fd7e-cacc-40b3-bbbb-585062ae9b65,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-8620583b-76fd-4a1a-bd1a-8a3185780e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-54cf3011-2c1f-4258-9a5f-6e0496e882fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-8826139b-ccc6-47dd-ac25-a6c353831d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-d52bc9d9-3d53-4eb8-a75e-7b0bee291850,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-9328b41f-ca91-435f-91a0-ac4183653017,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-f3e5b8c9-1b63-458e-b32f-d2ca9e34130c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701177961-172.17.0.12-1595629211205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39332,DS-23ac9298-61f6-4050-9b17-32c6be189056,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-6ad9fd7e-cacc-40b3-bbbb-585062ae9b65,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-8620583b-76fd-4a1a-bd1a-8a3185780e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-54cf3011-2c1f-4258-9a5f-6e0496e882fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-8826139b-ccc6-47dd-ac25-a6c353831d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-d52bc9d9-3d53-4eb8-a75e-7b0bee291850,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-9328b41f-ca91-435f-91a0-ac4183653017,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-f3e5b8c9-1b63-458e-b32f-d2ca9e34130c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751517222-172.17.0.12-1595629284399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-48a536a6-b4f7-40ad-9305-4a60b04f1bae,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-7751d1bb-56f8-4a2d-94fa-c4fbfeb5b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-2161678a-c3b9-4980-8218-9ba35ce5b5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-7eb68a71-52a3-4f30-a17f-a6234ebe0d98,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-56c04f24-5545-474b-89ba-7291ecea3517,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-27f12b4b-ab22-405a-815d-844a48772614,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-3d870717-c983-4f7f-96a5-8a99a74fa7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-db19424e-1bea-44b9-80a2-7c4cf6e5b24d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751517222-172.17.0.12-1595629284399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-48a536a6-b4f7-40ad-9305-4a60b04f1bae,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-7751d1bb-56f8-4a2d-94fa-c4fbfeb5b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-2161678a-c3b9-4980-8218-9ba35ce5b5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-7eb68a71-52a3-4f30-a17f-a6234ebe0d98,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-56c04f24-5545-474b-89ba-7291ecea3517,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-27f12b4b-ab22-405a-815d-844a48772614,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-3d870717-c983-4f7f-96a5-8a99a74fa7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-db19424e-1bea-44b9-80a2-7c4cf6e5b24d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357894104-172.17.0.12-1595629523423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-7d47758f-0174-4f40-b3d9-eee65bc27f15,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-c3bf8868-c605-4542-b73d-aadfbe6e766c,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-3c9cae88-1c12-4037-a5b6-8303eb86b251,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-ccc27896-a64f-46d2-aeae-47ec73359537,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-649cfe07-4616-4e65-a57e-728bc63ee5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-9d7fb4f7-3c5f-4a99-97d8-dde8d2539d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-4978ffda-2c82-4c08-b8f4-6b590a20283c,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-2528857c-3393-40c5-897f-79baa8edd7a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357894104-172.17.0.12-1595629523423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38683,DS-7d47758f-0174-4f40-b3d9-eee65bc27f15,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-c3bf8868-c605-4542-b73d-aadfbe6e766c,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-3c9cae88-1c12-4037-a5b6-8303eb86b251,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-ccc27896-a64f-46d2-aeae-47ec73359537,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-649cfe07-4616-4e65-a57e-728bc63ee5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-9d7fb4f7-3c5f-4a99-97d8-dde8d2539d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-4978ffda-2c82-4c08-b8f4-6b590a20283c,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-2528857c-3393-40c5-897f-79baa8edd7a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218007144-172.17.0.12-1595629844339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-9f83714e-52cb-49ae-99fb-a5117bbf6266,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-bd669d20-12a5-4e36-83ae-068322d49242,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-80ef99e3-2563-416e-bf32-3351e9395492,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-062bf83a-f8ea-48e7-b974-25d4530ad7df,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-607c4ff2-a84e-4c9c-b0b6-8e3a690a9a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-eb0152e1-6d6e-4452-8735-24ee70d76ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-f76afc38-5445-4319-b1f0-2664d0151af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-a4c3cfac-ae32-43fc-9a37-9585150a520d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218007144-172.17.0.12-1595629844339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-9f83714e-52cb-49ae-99fb-a5117bbf6266,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-bd669d20-12a5-4e36-83ae-068322d49242,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-80ef99e3-2563-416e-bf32-3351e9395492,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-062bf83a-f8ea-48e7-b974-25d4530ad7df,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-607c4ff2-a84e-4c9c-b0b6-8e3a690a9a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-eb0152e1-6d6e-4452-8735-24ee70d76ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-f76afc38-5445-4319-b1f0-2664d0151af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-a4c3cfac-ae32-43fc-9a37-9585150a520d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 4096
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069471472-172.17.0.12-1595630199907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-8abdc162-4a85-4866-a970-d8fbd5243385,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-cc6f96ef-ed76-4b6e-a842-dce17a510cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-dc05537b-2ddb-4b74-839e-e2ca1e0b0693,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-c7dcce14-992a-4167-9e5c-0415b5f07ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-0a3fe865-114f-4881-b15b-08812164c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-57a0afc7-2f97-4be9-a75a-ad037550772d,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-49a0afdb-4a83-4dfe-ad71-2f9ad2083ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-6291acf5-07ee-4433-9095-a86fc4d8a140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069471472-172.17.0.12-1595630199907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-8abdc162-4a85-4866-a970-d8fbd5243385,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-cc6f96ef-ed76-4b6e-a842-dce17a510cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-dc05537b-2ddb-4b74-839e-e2ca1e0b0693,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-c7dcce14-992a-4167-9e5c-0415b5f07ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-0a3fe865-114f-4881-b15b-08812164c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-57a0afc7-2f97-4be9-a75a-ad037550772d,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-49a0afdb-4a83-4dfe-ad71-2f9ad2083ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-6291acf5-07ee-4433-9095-a86fc4d8a140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5911
