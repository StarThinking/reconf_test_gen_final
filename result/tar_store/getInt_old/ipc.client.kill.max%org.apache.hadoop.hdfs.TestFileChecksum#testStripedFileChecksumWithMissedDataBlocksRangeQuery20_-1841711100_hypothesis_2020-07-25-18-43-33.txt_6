reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108584895-172.17.0.10-1595702801165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45747,DS-f7114954-3621-4cc2-8926-fe51897ded0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-586d59d1-5cba-4e63-82e4-2d4941f53fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-c0c4f76d-254a-4953-937a-88c0d772381c,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-e187cc06-4dd5-49aa-a999-b2fc9cd90bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-772e425d-511f-4f57-8f94-14402a046842,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-4af05420-27c3-4e3e-a50f-df2abd79267d,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-94848404-396f-4c95-bd12-79ad093aa76e,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-94e1d742-3a82-43ea-8265-60aef0f43d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108584895-172.17.0.10-1595702801165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45747,DS-f7114954-3621-4cc2-8926-fe51897ded0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-586d59d1-5cba-4e63-82e4-2d4941f53fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-c0c4f76d-254a-4953-937a-88c0d772381c,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-e187cc06-4dd5-49aa-a999-b2fc9cd90bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-772e425d-511f-4f57-8f94-14402a046842,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-4af05420-27c3-4e3e-a50f-df2abd79267d,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-94848404-396f-4c95-bd12-79ad093aa76e,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-94e1d742-3a82-43ea-8265-60aef0f43d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77617992-172.17.0.10-1595703224667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44469,DS-22d560ef-f2ca-41d5-877e-8b969e38b747,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-7e2dc249-768d-489b-9729-8239467091f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d8baa251-745c-4b89-9197-7e65cafa4517,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-cc9fc970-e0f8-4f76-9881-94d5d1fe8184,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-839007d2-f38b-42ab-9801-16ed6491cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-510381e4-c889-482e-a082-522f441304e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-794594f8-42fc-4bc1-8a5e-d67ee8ab1f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-3a0f4291-85ed-4792-9e16-0db7c4f3e2d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77617992-172.17.0.10-1595703224667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44469,DS-22d560ef-f2ca-41d5-877e-8b969e38b747,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-7e2dc249-768d-489b-9729-8239467091f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d8baa251-745c-4b89-9197-7e65cafa4517,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-cc9fc970-e0f8-4f76-9881-94d5d1fe8184,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-839007d2-f38b-42ab-9801-16ed6491cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-510381e4-c889-482e-a082-522f441304e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-794594f8-42fc-4bc1-8a5e-d67ee8ab1f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-3a0f4291-85ed-4792-9e16-0db7c4f3e2d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751636985-172.17.0.10-1595703972355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-039b1e91-0164-43ab-aae7-fb9b5513314f,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-78bff838-d230-4b1a-9f6a-80ec0729601e,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-0b5d8379-256f-46c8-8745-6e8f678d535a,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-391f6e25-deed-475e-849c-3b5e8a07a26a,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-6acf33bf-d1d4-4eaf-b75c-a7f02a8a158c,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-5d32a68e-f170-4f86-8493-45484c0f363f,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-7fc58d17-818d-4c27-be82-c280ee76378b,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-49089341-de32-4ea7-9754-4aaab6c86547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751636985-172.17.0.10-1595703972355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-039b1e91-0164-43ab-aae7-fb9b5513314f,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-78bff838-d230-4b1a-9f6a-80ec0729601e,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-0b5d8379-256f-46c8-8745-6e8f678d535a,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-391f6e25-deed-475e-849c-3b5e8a07a26a,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-6acf33bf-d1d4-4eaf-b75c-a7f02a8a158c,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-5d32a68e-f170-4f86-8493-45484c0f363f,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-7fc58d17-818d-4c27-be82-c280ee76378b,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-49089341-de32-4ea7-9754-4aaab6c86547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119988660-172.17.0.10-1595704188949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33374,DS-a7659e85-33b4-4597-98ae-b8123db1a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-eec99974-93cb-4db8-a12d-81663a6d59ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-bd29b12a-09e3-4824-a2ff-fccef656c071,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-ad3c7c05-a86f-4a86-ac95-180fe93cbe19,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-e9429adf-f5d8-41e7-86da-589f4be13816,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-9ebb2d73-bedd-48f0-84a6-32cb6da73f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-dc3e9d28-068f-4b8f-a156-c78a50fafbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-13225936-edea-4a4a-a699-f06b5a1f613b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119988660-172.17.0.10-1595704188949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33374,DS-a7659e85-33b4-4597-98ae-b8123db1a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-eec99974-93cb-4db8-a12d-81663a6d59ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-bd29b12a-09e3-4824-a2ff-fccef656c071,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-ad3c7c05-a86f-4a86-ac95-180fe93cbe19,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-e9429adf-f5d8-41e7-86da-589f4be13816,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-9ebb2d73-bedd-48f0-84a6-32cb6da73f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-dc3e9d28-068f-4b8f-a156-c78a50fafbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-13225936-edea-4a4a-a699-f06b5a1f613b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427932372-172.17.0.10-1595704321654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-ac2d69e3-7237-4e6d-96c6-f8a4a6121c10,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-bb27d1ee-beba-4162-a6b6-34bbfc895778,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-28c97021-7dd6-4940-b877-99b43ac44dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-f40a763b-34df-4b56-b77f-32fdcd4c0d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-1bef8787-b9eb-4be6-bfdd-7c9d0415c68a,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-d32cab87-224e-4f56-bad4-a089d87bbeee,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-73d0bfe4-a726-418a-a79f-8889f76b696a,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-c5cbead0-44e0-46af-a3dc-8afcc65ba331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427932372-172.17.0.10-1595704321654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-ac2d69e3-7237-4e6d-96c6-f8a4a6121c10,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-bb27d1ee-beba-4162-a6b6-34bbfc895778,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-28c97021-7dd6-4940-b877-99b43ac44dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-f40a763b-34df-4b56-b77f-32fdcd4c0d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-1bef8787-b9eb-4be6-bfdd-7c9d0415c68a,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-d32cab87-224e-4f56-bad4-a089d87bbeee,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-73d0bfe4-a726-418a-a79f-8889f76b696a,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-c5cbead0-44e0-46af-a3dc-8afcc65ba331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533349011-172.17.0.10-1595704675501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40294,DS-82bacce5-f50b-440d-b8db-7cec98429159,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-e48299f2-b4c9-4d86-9ba6-5487fce87a33,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-c66b85d1-268d-4df4-b10a-f5cb0d714ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-acd9bc26-ea14-4fc9-ab43-47e06523f813,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-9b05bd55-17e6-4f32-8564-64f1640ef8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-66b0f943-9378-41ba-9f24-5501c07c6266,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-ebe892fc-c313-48c6-9c05-bda626c97f90,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-fdc0bd13-f5a8-4175-8a3c-49129c85f3d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533349011-172.17.0.10-1595704675501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40294,DS-82bacce5-f50b-440d-b8db-7cec98429159,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-e48299f2-b4c9-4d86-9ba6-5487fce87a33,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-c66b85d1-268d-4df4-b10a-f5cb0d714ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-acd9bc26-ea14-4fc9-ab43-47e06523f813,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-9b05bd55-17e6-4f32-8564-64f1640ef8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-66b0f943-9378-41ba-9f24-5501c07c6266,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-ebe892fc-c313-48c6-9c05-bda626c97f90,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-fdc0bd13-f5a8-4175-8a3c-49129c85f3d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118614421-172.17.0.10-1595705199924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-db06eb75-46e6-4ae9-9c73-e61e5add9810,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-78b9e5e9-ff91-4eee-946b-6cb645a962ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-8349704a-8aa5-4823-86c7-9c3bac393b43,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-2816d1f1-2de4-4c56-a0bb-46bc243a6304,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-1bf3ce83-0109-4020-b572-859a959ad15e,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-0449d8d1-11f5-4086-af6d-b928195aa6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-b1e64a66-e6b3-401b-bd34-1d9a9ab8f7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-65395ea8-5ff9-4cdf-99a2-5424db66af86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118614421-172.17.0.10-1595705199924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-db06eb75-46e6-4ae9-9c73-e61e5add9810,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-78b9e5e9-ff91-4eee-946b-6cb645a962ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-8349704a-8aa5-4823-86c7-9c3bac393b43,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-2816d1f1-2de4-4c56-a0bb-46bc243a6304,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-1bf3ce83-0109-4020-b572-859a959ad15e,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-0449d8d1-11f5-4086-af6d-b928195aa6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-b1e64a66-e6b3-401b-bd34-1d9a9ab8f7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-65395ea8-5ff9-4cdf-99a2-5424db66af86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043558782-172.17.0.10-1595705270639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-fbe7edac-c9f7-451b-99d7-a65877b03356,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-91c56ca4-c87e-4473-8cf5-8ff0d2e1c287,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-044af2b9-4d0d-45d3-a3eb-c206ab670c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-9e286c79-b55a-405f-8107-5e545d7284cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-5d1b0e3d-f232-4117-b8c6-59351ab05534,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-41dcf607-436d-47c4-be4a-19292b01ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-bf758d38-3a26-4b60-a0cd-701b83c852ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-5e4d7306-ee1b-4370-b653-8f971038c259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043558782-172.17.0.10-1595705270639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-fbe7edac-c9f7-451b-99d7-a65877b03356,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-91c56ca4-c87e-4473-8cf5-8ff0d2e1c287,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-044af2b9-4d0d-45d3-a3eb-c206ab670c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-9e286c79-b55a-405f-8107-5e545d7284cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-5d1b0e3d-f232-4117-b8c6-59351ab05534,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-41dcf607-436d-47c4-be4a-19292b01ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-bf758d38-3a26-4b60-a0cd-701b83c852ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-5e4d7306-ee1b-4370-b653-8f971038c259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496126094-172.17.0.10-1595705374330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36258,DS-493c3f1a-f847-44a5-a0e3-ed578cc49c32,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-260b1331-6e02-4abe-a094-f9d6759c3aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-14d7e713-917e-4da1-bb1f-f72d56dc7acb,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-bb1bde6c-05fd-479b-9b39-d93123adb611,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-d17837af-70f0-4642-bf9a-f1602bc5a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-226d6a71-9a0b-44ad-87b9-42b8f403944e,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-dae48b77-8c6d-458c-bb92-c472b816a790,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-9cd8c878-44db-4a30-a7c5-ddc9bb5bb001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496126094-172.17.0.10-1595705374330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36258,DS-493c3f1a-f847-44a5-a0e3-ed578cc49c32,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-260b1331-6e02-4abe-a094-f9d6759c3aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-14d7e713-917e-4da1-bb1f-f72d56dc7acb,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-bb1bde6c-05fd-479b-9b39-d93123adb611,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-d17837af-70f0-4642-bf9a-f1602bc5a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-226d6a71-9a0b-44ad-87b9-42b8f403944e,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-dae48b77-8c6d-458c-bb92-c472b816a790,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-9cd8c878-44db-4a30-a7c5-ddc9bb5bb001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025752660-172.17.0.10-1595705593985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44101,DS-816bc081-e0db-4850-a6f1-b88ae9aa72e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-9c819dd1-43ea-42e0-a13c-b60110b5ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-8c95819a-6ac1-4920-9d79-6f0569138466,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-80390d15-599a-4c8e-9330-2adaa0b7a2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-06ce0f61-3803-4705-8528-520e1f9ee3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-fb7168f7-a77b-4182-af78-fda1082a3fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-31f838cc-9fea-4d08-b520-41bb06b42562,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-eb63ca97-94c4-452a-b87a-ece9d24ec428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025752660-172.17.0.10-1595705593985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44101,DS-816bc081-e0db-4850-a6f1-b88ae9aa72e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-9c819dd1-43ea-42e0-a13c-b60110b5ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-8c95819a-6ac1-4920-9d79-6f0569138466,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-80390d15-599a-4c8e-9330-2adaa0b7a2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-06ce0f61-3803-4705-8528-520e1f9ee3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-fb7168f7-a77b-4182-af78-fda1082a3fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-31f838cc-9fea-4d08-b520-41bb06b42562,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-eb63ca97-94c4-452a-b87a-ece9d24ec428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241996352-172.17.0.10-1595705841050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-95590407-cca6-426e-be11-ba88029a05c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-4e9db885-94c8-4a0a-bac1-0f9c4be5512e,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-dc9755ad-1a5b-413f-903c-301e1fe9cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-8bf462f6-bbc3-4d25-90bf-204144b33a81,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-d8ba0cdc-2d2c-4db4-8e87-a58fba13abea,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-06191e0e-9b7f-477e-a405-ecf2e6d53afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-8c333cc0-478a-4d5c-9986-1c6bab0503f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-437059c4-82e0-4a32-b9d2-83254143e204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241996352-172.17.0.10-1595705841050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-95590407-cca6-426e-be11-ba88029a05c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-4e9db885-94c8-4a0a-bac1-0f9c4be5512e,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-dc9755ad-1a5b-413f-903c-301e1fe9cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-8bf462f6-bbc3-4d25-90bf-204144b33a81,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-d8ba0cdc-2d2c-4db4-8e87-a58fba13abea,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-06191e0e-9b7f-477e-a405-ecf2e6d53afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-8c333cc0-478a-4d5c-9986-1c6bab0503f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-437059c4-82e0-4a32-b9d2-83254143e204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384312903-172.17.0.10-1595706009766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-99e215e6-bb56-4899-8a5d-ab421f8c3e00,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-30d8b9d1-4656-4143-8e00-4466870676a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-0201d0ec-7216-4531-8a57-f5329bfceaad,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-1b301e08-dec3-42c6-873e-b414c53d47fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-c3e25cc0-f600-435a-8e69-56be35ddf0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-a4791df3-6bd3-49f7-983e-f1cf7d806a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-3290d41d-f0f2-4734-a268-2431b9571d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-feff1e16-20e2-4b7c-a894-0b6c3e229dcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384312903-172.17.0.10-1595706009766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-99e215e6-bb56-4899-8a5d-ab421f8c3e00,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-30d8b9d1-4656-4143-8e00-4466870676a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-0201d0ec-7216-4531-8a57-f5329bfceaad,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-1b301e08-dec3-42c6-873e-b414c53d47fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-c3e25cc0-f600-435a-8e69-56be35ddf0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-a4791df3-6bd3-49f7-983e-f1cf7d806a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-3290d41d-f0f2-4734-a268-2431b9571d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-feff1e16-20e2-4b7c-a894-0b6c3e229dcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221493047-172.17.0.10-1595706181755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37726,DS-0b27c4a9-382f-4285-ba4f-d1db6bcc8170,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-46c70137-e139-49a1-ad56-56851e78ab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-493f04fd-014e-458a-a8ce-b234a6c3e046,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-5e0143fa-efc5-473f-8c05-ece9692ccfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-e19e4042-9725-4437-a671-f3fb6c1b1b60,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-2111b8f3-8c1e-408e-9495-c82b1b463bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-585ed2a2-2a33-40af-a706-9a7a19858bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-8f44abb9-86a6-479f-9ba0-6e7bf7d18bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221493047-172.17.0.10-1595706181755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37726,DS-0b27c4a9-382f-4285-ba4f-d1db6bcc8170,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-46c70137-e139-49a1-ad56-56851e78ab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-493f04fd-014e-458a-a8ce-b234a6c3e046,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-5e0143fa-efc5-473f-8c05-ece9692ccfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-e19e4042-9725-4437-a671-f3fb6c1b1b60,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-2111b8f3-8c1e-408e-9495-c82b1b463bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-585ed2a2-2a33-40af-a706-9a7a19858bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-8f44abb9-86a6-479f-9ba0-6e7bf7d18bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709538091-172.17.0.10-1595706888264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34173,DS-34950bd9-7e9b-4c45-b9d2-b9ed9ac522a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-2739c360-6bf8-42d3-a60b-c449e685ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-dad377f0-5543-48ab-8c8b-e54ec8d1ccee,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-c9b5297a-ffad-478f-b9ed-4ac5d79ddedc,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-77b6ef3d-37a8-424b-9ed9-e9775f86456e,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-158369f7-8c53-4fb8-aabe-846a0cf3bfee,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-b9214b2b-367a-41a3-83a3-1e8d25ef7602,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-2459946b-0dea-42fd-bd02-863816142a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709538091-172.17.0.10-1595706888264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34173,DS-34950bd9-7e9b-4c45-b9d2-b9ed9ac522a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-2739c360-6bf8-42d3-a60b-c449e685ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-dad377f0-5543-48ab-8c8b-e54ec8d1ccee,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-c9b5297a-ffad-478f-b9ed-4ac5d79ddedc,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-77b6ef3d-37a8-424b-9ed9-e9775f86456e,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-158369f7-8c53-4fb8-aabe-846a0cf3bfee,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-b9214b2b-367a-41a3-83a3-1e8d25ef7602,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-2459946b-0dea-42fd-bd02-863816142a7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563883005-172.17.0.10-1595706959514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44079,DS-4ab4761c-3133-4e37-aa02-3a282b4a589d,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-9aa072d7-c6d5-4be6-8ed7-5ec1e825e040,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-30f9b1b7-ccd7-421f-be8c-f3e29ca9a292,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-971d6df9-f85f-4751-8bcc-c09918f8174e,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-255b9927-a976-4515-9fe2-753c394bdccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-68bc9c6e-3228-48f4-9aeb-13ebdbc8c966,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-74076fc3-88dc-4c22-bd0d-fd6c5fc7bb68,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-af115484-560b-429e-b1d5-a147a59c0a3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563883005-172.17.0.10-1595706959514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44079,DS-4ab4761c-3133-4e37-aa02-3a282b4a589d,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-9aa072d7-c6d5-4be6-8ed7-5ec1e825e040,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-30f9b1b7-ccd7-421f-be8c-f3e29ca9a292,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-971d6df9-f85f-4751-8bcc-c09918f8174e,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-255b9927-a976-4515-9fe2-753c394bdccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-68bc9c6e-3228-48f4-9aeb-13ebdbc8c966,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-74076fc3-88dc-4c22-bd0d-fd6c5fc7bb68,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-af115484-560b-429e-b1d5-a147a59c0a3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192654599-172.17.0.10-1595707155270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42559,DS-9e869bb0-8bee-40ae-b60a-c8181263c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-7d035625-3e8a-4750-84e3-1e0c498abb73,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-2bc5b444-0298-4bc6-b64c-adf5b703ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-0bc4fca8-c811-4cd0-9529-2649624e718a,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-ccf82a49-916c-4abe-8398-1993e67e196c,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-f69a68f9-d8ff-42d0-9cac-6d9c04e0a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-64226d9e-23f9-4713-9a68-ce5abc5d2991,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-d698825e-5965-4aa7-938e-effedb90f52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192654599-172.17.0.10-1595707155270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42559,DS-9e869bb0-8bee-40ae-b60a-c8181263c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-7d035625-3e8a-4750-84e3-1e0c498abb73,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-2bc5b444-0298-4bc6-b64c-adf5b703ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-0bc4fca8-c811-4cd0-9529-2649624e718a,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-ccf82a49-916c-4abe-8398-1993e67e196c,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-f69a68f9-d8ff-42d0-9cac-6d9c04e0a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-64226d9e-23f9-4713-9a68-ce5abc5d2991,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-d698825e-5965-4aa7-938e-effedb90f52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709783254-172.17.0.10-1595707220334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-a94fd03c-8d38-4d22-84d5-5f5cd6e941b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-48c58aa3-6614-4ac3-a8a9-19d385d83d42,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-5caeeedc-4f47-4dc1-8cd3-ff1a4b9c256d,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-fa6e9d90-fbef-41de-a984-4e51dfe00a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-fe91bc6c-036b-4c64-a48d-98b39e1f58f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-a57b1917-9cfb-4dcc-b700-2b991ad3ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-a963539f-c1bf-4a8f-af1e-0d99c02808ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-89359999-d69c-413c-b7ae-74bfb6bdc217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709783254-172.17.0.10-1595707220334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-a94fd03c-8d38-4d22-84d5-5f5cd6e941b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-48c58aa3-6614-4ac3-a8a9-19d385d83d42,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-5caeeedc-4f47-4dc1-8cd3-ff1a4b9c256d,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-fa6e9d90-fbef-41de-a984-4e51dfe00a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-fe91bc6c-036b-4c64-a48d-98b39e1f58f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-a57b1917-9cfb-4dcc-b700-2b991ad3ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-a963539f-c1bf-4a8f-af1e-0d99c02808ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-89359999-d69c-413c-b7ae-74bfb6bdc217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393129951-172.17.0.10-1595707534807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45220,DS-5c8d3444-31fc-4d8e-88db-b8df687c7d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-2501860d-64c7-4178-9e2b-59c849e413f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-0ac4e3d0-2b84-4096-aeb7-ca0900cd6177,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-89754c02-3b79-4318-b072-d43702faa20a,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-5242640a-e6c5-4397-981a-977d11690547,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-dd44072a-d17d-4b78-8267-97db72c81319,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-4fc21914-b0de-448b-b828-cb88ecc7338f,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-09776786-e900-4557-a9c6-93c8daded3a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393129951-172.17.0.10-1595707534807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45220,DS-5c8d3444-31fc-4d8e-88db-b8df687c7d87,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-2501860d-64c7-4178-9e2b-59c849e413f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-0ac4e3d0-2b84-4096-aeb7-ca0900cd6177,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-89754c02-3b79-4318-b072-d43702faa20a,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-5242640a-e6c5-4397-981a-977d11690547,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-dd44072a-d17d-4b78-8267-97db72c81319,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-4fc21914-b0de-448b-b828-cb88ecc7338f,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-09776786-e900-4557-a9c6-93c8daded3a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4970
