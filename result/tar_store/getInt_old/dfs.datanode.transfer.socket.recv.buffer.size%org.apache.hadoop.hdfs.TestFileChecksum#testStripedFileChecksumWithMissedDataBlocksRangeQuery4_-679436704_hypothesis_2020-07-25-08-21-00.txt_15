reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044683178-172.17.0.13-1595665276530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37470,DS-95fef52e-a67d-4783-a113-7966ce677cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-dcae0319-d5a0-42ec-8ca7-c468db1775fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-b28bd437-41fc-4ad8-ad25-cb06f13991ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-8fda7e7c-2344-46c5-9f0f-58111ee249eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-8f4d6c5e-9edd-41c4-970f-7fab81034c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-499a04e2-7a1d-4f37-a9f3-e50aa479c764,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-56f24e98-6782-451c-9850-bdbfd1428a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-13ff3798-d660-4018-84e1-f754ebf64748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044683178-172.17.0.13-1595665276530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37470,DS-95fef52e-a67d-4783-a113-7966ce677cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-dcae0319-d5a0-42ec-8ca7-c468db1775fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-b28bd437-41fc-4ad8-ad25-cb06f13991ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-8fda7e7c-2344-46c5-9f0f-58111ee249eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-8f4d6c5e-9edd-41c4-970f-7fab81034c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-499a04e2-7a1d-4f37-a9f3-e50aa479c764,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-56f24e98-6782-451c-9850-bdbfd1428a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-13ff3798-d660-4018-84e1-f754ebf64748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262505054-172.17.0.13-1595665493191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40964,DS-4cee6f21-2d22-4f9d-8c4e-e5a259f8c434,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-911a4f6a-0167-42b1-8b19-8f30a2b05948,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-515c0198-9a9e-4f5d-b1f2-b5a668cb3995,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-af04c9c3-7612-42e4-9b0f-3ade857d8b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-d3729136-83aa-4f16-9876-91b2f520a988,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-a126d4e2-cc72-4d66-b612-2d5ff16331d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-7c347673-8c1f-4d9c-9988-310ec3d18c09,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-3353a158-1ac9-4708-aed3-085a06b32d54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262505054-172.17.0.13-1595665493191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40964,DS-4cee6f21-2d22-4f9d-8c4e-e5a259f8c434,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-911a4f6a-0167-42b1-8b19-8f30a2b05948,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-515c0198-9a9e-4f5d-b1f2-b5a668cb3995,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-af04c9c3-7612-42e4-9b0f-3ade857d8b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-d3729136-83aa-4f16-9876-91b2f520a988,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-a126d4e2-cc72-4d66-b612-2d5ff16331d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-7c347673-8c1f-4d9c-9988-310ec3d18c09,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-3353a158-1ac9-4708-aed3-085a06b32d54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461065965-172.17.0.13-1595666531398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-39f8ef8d-ea3f-48dd-910f-497401569b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-965b081d-c396-41fe-b33b-4099f32b436c,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-ed107576-6cff-4155-8fcb-acf4cc6eea02,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-bdf29457-ea9a-4a85-b225-7c19baab2fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-60ad1c8f-7356-4989-a260-fa6ab885db65,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-bd152d08-f905-46aa-8d1e-b8eadb2eb79c,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-f0184f16-fed9-46bb-8d03-b133cbf26de1,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-17eec09c-0a95-49db-971c-c73304ab288d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461065965-172.17.0.13-1595666531398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-39f8ef8d-ea3f-48dd-910f-497401569b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-965b081d-c396-41fe-b33b-4099f32b436c,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-ed107576-6cff-4155-8fcb-acf4cc6eea02,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-bdf29457-ea9a-4a85-b225-7c19baab2fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-60ad1c8f-7356-4989-a260-fa6ab885db65,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-bd152d08-f905-46aa-8d1e-b8eadb2eb79c,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-f0184f16-fed9-46bb-8d03-b133cbf26de1,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-17eec09c-0a95-49db-971c-c73304ab288d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704132055-172.17.0.13-1595667326662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-c898f379-711d-413a-8d19-39003de166bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-9bd788cc-d1cf-47b3-8600-9884e3a4e5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-4f02bea5-f24e-4ca5-b9cb-3a25ca46f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-b9e7b70f-9c62-4c87-baec-46d0e64fa1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-e63274f6-e65b-496b-980a-db6ac1f2641f,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-d3696e63-d41f-4c72-9781-d5957e60b472,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-a77aa4fa-e19c-41f6-803c-6aa6a9602416,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-e9afd474-0889-4f6a-9f8e-e5f9da321a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704132055-172.17.0.13-1595667326662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-c898f379-711d-413a-8d19-39003de166bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-9bd788cc-d1cf-47b3-8600-9884e3a4e5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-4f02bea5-f24e-4ca5-b9cb-3a25ca46f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-b9e7b70f-9c62-4c87-baec-46d0e64fa1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-e63274f6-e65b-496b-980a-db6ac1f2641f,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-d3696e63-d41f-4c72-9781-d5957e60b472,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-a77aa4fa-e19c-41f6-803c-6aa6a9602416,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-e9afd474-0889-4f6a-9f8e-e5f9da321a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983219470-172.17.0.13-1595667834729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38124,DS-741f3647-afa4-49be-ba66-5c870e559974,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-b547a0f7-56bb-48a5-b0c3-0af3eb979148,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-cbc9701f-d510-48db-ac6e-3d3f8601c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-884c148e-b6a0-4646-9e47-9ba99c41c329,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-a8e2f2b8-b9c1-48a1-b639-068076dcb7af,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-a2f22b85-8dc8-4bdd-9935-453e4efa31d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-b6f252a3-00cb-4215-bca1-f94801d997c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-9176ad98-e97b-409c-a115-22fc69bd0576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983219470-172.17.0.13-1595667834729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38124,DS-741f3647-afa4-49be-ba66-5c870e559974,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-b547a0f7-56bb-48a5-b0c3-0af3eb979148,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-cbc9701f-d510-48db-ac6e-3d3f8601c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-884c148e-b6a0-4646-9e47-9ba99c41c329,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-a8e2f2b8-b9c1-48a1-b639-068076dcb7af,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-a2f22b85-8dc8-4bdd-9935-453e4efa31d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-b6f252a3-00cb-4215-bca1-f94801d997c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-9176ad98-e97b-409c-a115-22fc69bd0576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655849828-172.17.0.13-1595667960894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36814,DS-00d6dfa7-012f-4f5d-93c7-d400bce5fe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-43ab4947-ca9e-4469-95ec-18888f5e6951,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-0b49dafc-4a54-48c8-8a8e-aaa361362e90,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-03d047aa-28e5-403e-8a6b-08f88c6537c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-a8801156-ec2d-4217-9f82-d07656dba186,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-772e23f5-575b-4d59-929d-a7c7c6f6c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-f3e20ce4-1973-4728-952d-2ea0b8c495fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-07c18ec9-21f3-4b8f-9438-ac477af81abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655849828-172.17.0.13-1595667960894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36814,DS-00d6dfa7-012f-4f5d-93c7-d400bce5fe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-43ab4947-ca9e-4469-95ec-18888f5e6951,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-0b49dafc-4a54-48c8-8a8e-aaa361362e90,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-03d047aa-28e5-403e-8a6b-08f88c6537c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-a8801156-ec2d-4217-9f82-d07656dba186,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-772e23f5-575b-4d59-929d-a7c7c6f6c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-f3e20ce4-1973-4728-952d-2ea0b8c495fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-07c18ec9-21f3-4b8f-9438-ac477af81abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169876195-172.17.0.13-1595668211912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33890,DS-d5c3b7b3-b4e3-47d9-a229-f87301383994,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-1f9198c0-811e-4b29-a55a-b2ad46d8d046,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-4c5ffb09-f3a9-4905-81b1-2186080cf86a,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-e7d1149d-a50e-4b7d-8454-3d7a0807b66d,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-36d1b0f3-1199-4f8c-9f65-fc3227baab21,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-29c92302-6b0d-4c4c-bfa8-86e8fb1577e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-72688fa9-45b5-4b7f-8932-06861d325dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-f52a6d5d-ab8d-4dac-81be-298ac8e34da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169876195-172.17.0.13-1595668211912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33890,DS-d5c3b7b3-b4e3-47d9-a229-f87301383994,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-1f9198c0-811e-4b29-a55a-b2ad46d8d046,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-4c5ffb09-f3a9-4905-81b1-2186080cf86a,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-e7d1149d-a50e-4b7d-8454-3d7a0807b66d,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-36d1b0f3-1199-4f8c-9f65-fc3227baab21,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-29c92302-6b0d-4c4c-bfa8-86e8fb1577e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-72688fa9-45b5-4b7f-8932-06861d325dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-f52a6d5d-ab8d-4dac-81be-298ac8e34da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940339378-172.17.0.13-1595668515736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42054,DS-5def2ebc-f20b-40cc-8db3-be1964b3616a,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-d82b1ded-f142-4dc0-b39d-b80f9f86068e,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-495598e6-b2e3-4af4-8958-2fbc2697ca68,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-70b4061a-5279-4982-9474-3bb8528c76a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-95dec4d9-83e8-464e-8f4d-34a857710af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-143019a2-a978-42d7-9b71-ae40ca3f240f,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-148b34cb-d9ab-478d-b5e7-ab5289cf6225,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-3b872bf9-4431-4198-8c60-26068cc641b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940339378-172.17.0.13-1595668515736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42054,DS-5def2ebc-f20b-40cc-8db3-be1964b3616a,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-d82b1ded-f142-4dc0-b39d-b80f9f86068e,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-495598e6-b2e3-4af4-8958-2fbc2697ca68,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-70b4061a-5279-4982-9474-3bb8528c76a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-95dec4d9-83e8-464e-8f4d-34a857710af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-143019a2-a978-42d7-9b71-ae40ca3f240f,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-148b34cb-d9ab-478d-b5e7-ab5289cf6225,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-3b872bf9-4431-4198-8c60-26068cc641b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536081833-172.17.0.13-1595668755681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44934,DS-6c48c143-7139-4fb0-a3c8-56da41aab187,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-112f2b97-37a9-40e4-9c6d-85e17db391e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-a71d8192-67d8-400a-8e61-bdf892775e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-6f771fa6-e157-4ff8-b3be-2aaf03c2881c,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-bcdeb5db-6502-4936-a9a4-ff531a443353,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-dfdc6e82-04be-4927-8adf-b25955d937cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-95bc1201-b33e-4fa5-8ba6-d014c604b7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-9161c769-5cbf-4207-9e25-baf53367399b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536081833-172.17.0.13-1595668755681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44934,DS-6c48c143-7139-4fb0-a3c8-56da41aab187,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-112f2b97-37a9-40e4-9c6d-85e17db391e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-a71d8192-67d8-400a-8e61-bdf892775e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-6f771fa6-e157-4ff8-b3be-2aaf03c2881c,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-bcdeb5db-6502-4936-a9a4-ff531a443353,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-dfdc6e82-04be-4927-8adf-b25955d937cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-95bc1201-b33e-4fa5-8ba6-d014c604b7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-9161c769-5cbf-4207-9e25-baf53367399b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471796034-172.17.0.13-1595669288150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-972fd0d1-b038-44c7-b702-8730158e4544,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-8bdf49b5-0d2f-434e-8e4b-177e4853986f,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-12b8cba8-f0c0-4e1d-9000-c613a203e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-45f89b4c-7bcc-4378-a493-6cbdb8340486,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-68b2d115-e1eb-489c-a388-403ee59c5152,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-d55a669f-f92a-4c53-b7d0-dff1951be0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-e5d846bf-7c26-4ff3-806a-a2675d146636,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-fff8a597-79c0-428c-bf28-e552853b86af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471796034-172.17.0.13-1595669288150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-972fd0d1-b038-44c7-b702-8730158e4544,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-8bdf49b5-0d2f-434e-8e4b-177e4853986f,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-12b8cba8-f0c0-4e1d-9000-c613a203e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-45f89b4c-7bcc-4378-a493-6cbdb8340486,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-68b2d115-e1eb-489c-a388-403ee59c5152,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-d55a669f-f92a-4c53-b7d0-dff1951be0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-e5d846bf-7c26-4ff3-806a-a2675d146636,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-fff8a597-79c0-428c-bf28-e552853b86af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744866008-172.17.0.13-1595670058284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44372,DS-e2cfa72f-3474-4512-bb00-61cfd6854cac,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-19bb5d13-a1b0-43a6-a9e1-8f901baafe52,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-f65dae95-bd9d-4826-a7b9-42486fd28926,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-4be20c3f-d571-4e0b-b39b-4255152dc5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-52bab149-9a44-40cf-85a8-6781b400f340,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-d7b6a1c7-a8cf-4783-8057-4ec2712b1d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-9bc7575d-824b-4981-89d6-5b895e3ebf44,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-74df1cb1-6188-454a-bd38-b6d0055da92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744866008-172.17.0.13-1595670058284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44372,DS-e2cfa72f-3474-4512-bb00-61cfd6854cac,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-19bb5d13-a1b0-43a6-a9e1-8f901baafe52,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-f65dae95-bd9d-4826-a7b9-42486fd28926,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-4be20c3f-d571-4e0b-b39b-4255152dc5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-52bab149-9a44-40cf-85a8-6781b400f340,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-d7b6a1c7-a8cf-4783-8057-4ec2712b1d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-9bc7575d-824b-4981-89d6-5b895e3ebf44,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-74df1cb1-6188-454a-bd38-b6d0055da92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5488
