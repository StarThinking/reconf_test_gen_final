reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114849671-172.17.0.17-1595620524975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-d1bfa4e9-9b07-4050-aba9-651d680dc341,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-71e39502-bfb9-4698-802a-1ad0081040e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-9e07f999-277c-4cc9-a76e-4b97b3574d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-57d9361c-cec3-43ce-a62f-a32df84cd64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-81ff7503-bc99-47c4-9195-b7333765846c,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-f457b881-2e53-407a-99d7-86196085ee66,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-1f8b6e63-0073-46e1-ba50-d7aea93765b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-ac8c2c16-3823-45e8-8725-de639d434764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114849671-172.17.0.17-1595620524975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-d1bfa4e9-9b07-4050-aba9-651d680dc341,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-71e39502-bfb9-4698-802a-1ad0081040e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-9e07f999-277c-4cc9-a76e-4b97b3574d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-57d9361c-cec3-43ce-a62f-a32df84cd64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-81ff7503-bc99-47c4-9195-b7333765846c,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-f457b881-2e53-407a-99d7-86196085ee66,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-1f8b6e63-0073-46e1-ba50-d7aea93765b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-ac8c2c16-3823-45e8-8725-de639d434764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098187241-172.17.0.17-1595620797009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-85e16a04-eb6a-4a65-ba5e-6bcd5d599917,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-4d0a95ba-4a6a-4b6e-a597-93333668f653,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-12cd8d5b-5c2a-4787-afb6-1feb661d1eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-19251d93-f31c-49ad-9b92-9d69876c66bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-58d3ddcf-28b2-488d-89fb-980bc8a6b457,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-468b2cbc-840e-4f13-baa7-702bce6a05aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-b89e8364-38ad-4624-b288-30e3b78c70ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-fe9f279c-d2fa-4363-96f3-8a873ea4e063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098187241-172.17.0.17-1595620797009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-85e16a04-eb6a-4a65-ba5e-6bcd5d599917,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-4d0a95ba-4a6a-4b6e-a597-93333668f653,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-12cd8d5b-5c2a-4787-afb6-1feb661d1eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-19251d93-f31c-49ad-9b92-9d69876c66bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-58d3ddcf-28b2-488d-89fb-980bc8a6b457,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-468b2cbc-840e-4f13-baa7-702bce6a05aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-b89e8364-38ad-4624-b288-30e3b78c70ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-fe9f279c-d2fa-4363-96f3-8a873ea4e063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901760813-172.17.0.17-1595620880585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-960a3ec1-e32a-4a7a-9aa2-5c217fb0f380,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-ebdbc686-7198-46fc-85af-90ce05db29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-9f04294f-e958-442e-be2c-96069400176c,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-13b850a0-a006-443a-987e-832f2db46a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-1cfa4b1e-2463-4dca-ae46-dc7bd96d73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-52209add-1b45-4301-9956-30904211b97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-039a7643-1d2e-4b16-b827-611ee764fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-0d8874be-9356-4e42-9e85-6a978cbe50da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901760813-172.17.0.17-1595620880585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-960a3ec1-e32a-4a7a-9aa2-5c217fb0f380,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-ebdbc686-7198-46fc-85af-90ce05db29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-9f04294f-e958-442e-be2c-96069400176c,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-13b850a0-a006-443a-987e-832f2db46a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-1cfa4b1e-2463-4dca-ae46-dc7bd96d73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-52209add-1b45-4301-9956-30904211b97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-039a7643-1d2e-4b16-b827-611ee764fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-0d8874be-9356-4e42-9e85-6a978cbe50da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71938722-172.17.0.17-1595620917830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-7139b315-a5a1-4cce-a3cd-c1ae88c9cf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-8bf820f8-3ad9-497d-9a7b-7bf25af56768,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-14decaec-3495-438e-86ad-f72b66403812,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-bbabc6ac-e2e1-4c6c-98b2-1d116bcc782f,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-6db93ec9-fac2-4e48-8c41-d05f05f24e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-0a558031-2b12-429f-a640-f17bceb7a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-b6b7c160-a0e9-49e2-8485-bedbd467e1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-f5fb04b5-15db-4c84-9b11-a39d93a32223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71938722-172.17.0.17-1595620917830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-7139b315-a5a1-4cce-a3cd-c1ae88c9cf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-8bf820f8-3ad9-497d-9a7b-7bf25af56768,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-14decaec-3495-438e-86ad-f72b66403812,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-bbabc6ac-e2e1-4c6c-98b2-1d116bcc782f,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-6db93ec9-fac2-4e48-8c41-d05f05f24e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-0a558031-2b12-429f-a640-f17bceb7a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-b6b7c160-a0e9-49e2-8485-bedbd467e1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-f5fb04b5-15db-4c84-9b11-a39d93a32223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728599213-172.17.0.17-1595620955500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43873,DS-a515c80e-866c-4f53-a234-5ead00f29844,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-e1407374-a79d-4a7c-a0e9-c1720a77591e,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-728809fe-dbdd-4eb8-b272-ebb77684a0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-ff40ea0c-c6f3-4c85-a320-baaaaf58b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-6b6a6073-1465-4c81-8f97-7cf49a6d8167,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-bd373abe-34e0-4573-b497-eef316fdc553,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-94051412-e766-44fd-8e97-688dd10d8e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-319f4f0b-ed1e-436d-ba78-313e6470a831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728599213-172.17.0.17-1595620955500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43873,DS-a515c80e-866c-4f53-a234-5ead00f29844,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-e1407374-a79d-4a7c-a0e9-c1720a77591e,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-728809fe-dbdd-4eb8-b272-ebb77684a0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-ff40ea0c-c6f3-4c85-a320-baaaaf58b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-6b6a6073-1465-4c81-8f97-7cf49a6d8167,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-bd373abe-34e0-4573-b497-eef316fdc553,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-94051412-e766-44fd-8e97-688dd10d8e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-319f4f0b-ed1e-436d-ba78-313e6470a831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729312343-172.17.0.17-1595621288660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-9cb266e9-4e69-4a3c-ac7b-e6524f3e0c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-08a1c1f6-5a3d-4edf-af01-442fd02fea15,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-8b1361a2-86a4-4269-94f2-7298c8f21683,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-3d8339a6-66f8-40e5-bac1-5bb88f52fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-4d13653b-f17e-4d85-9abd-59656d889b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-b88df094-5c88-4299-9831-136afbffa104,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-2cda50fd-5f1a-4483-8ed4-b698e2373b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-70c8ed1a-73d4-4972-aa29-f5d78e051aef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729312343-172.17.0.17-1595621288660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-9cb266e9-4e69-4a3c-ac7b-e6524f3e0c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-08a1c1f6-5a3d-4edf-af01-442fd02fea15,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-8b1361a2-86a4-4269-94f2-7298c8f21683,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-3d8339a6-66f8-40e5-bac1-5bb88f52fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-4d13653b-f17e-4d85-9abd-59656d889b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-b88df094-5c88-4299-9831-136afbffa104,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-2cda50fd-5f1a-4483-8ed4-b698e2373b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-70c8ed1a-73d4-4972-aa29-f5d78e051aef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646508949-172.17.0.17-1595621669342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34111,DS-53f8851c-098c-4dbb-957a-4186d71927b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-e5c2b1e7-3b81-4d68-ad7c-6b4d773e8f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-7d4c5b6d-2026-4f9f-9d9f-fe821de4c2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-1e266ef3-70a1-4a51-b788-d783b268abb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-af42b932-70c4-4b2f-8d11-f1b8f1df8513,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-64959863-c763-48c3-aae1-8a71d391cf95,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-966ef456-1693-4f94-afc6-2c641293adf5,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-438c9f4f-bcc8-41c3-ba21-58f186aefb92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646508949-172.17.0.17-1595621669342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34111,DS-53f8851c-098c-4dbb-957a-4186d71927b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-e5c2b1e7-3b81-4d68-ad7c-6b4d773e8f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-7d4c5b6d-2026-4f9f-9d9f-fe821de4c2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-1e266ef3-70a1-4a51-b788-d783b268abb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-af42b932-70c4-4b2f-8d11-f1b8f1df8513,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-64959863-c763-48c3-aae1-8a71d391cf95,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-966ef456-1693-4f94-afc6-2c641293adf5,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-438c9f4f-bcc8-41c3-ba21-58f186aefb92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226109910-172.17.0.17-1595621833201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-9d1f9a7f-b05e-427e-b5f2-389a1517f4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-d570e1ee-c015-455f-88b0-d428df701e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-2c2783b9-d58a-423a-a879-4300cead0c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-bb39065d-eece-4546-a693-d390eb52ab08,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-f617adf6-7cd5-4d58-b712-288a0a4fe404,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-c5c875ab-6437-4a7c-8045-5b7addbba87f,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-3779b185-3671-496b-923e-31eb677b9f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-247130e9-1c66-4b11-a9e0-a214ae4087eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226109910-172.17.0.17-1595621833201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-9d1f9a7f-b05e-427e-b5f2-389a1517f4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-d570e1ee-c015-455f-88b0-d428df701e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-2c2783b9-d58a-423a-a879-4300cead0c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-bb39065d-eece-4546-a693-d390eb52ab08,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-f617adf6-7cd5-4d58-b712-288a0a4fe404,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-c5c875ab-6437-4a7c-8045-5b7addbba87f,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-3779b185-3671-496b-923e-31eb677b9f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-247130e9-1c66-4b11-a9e0-a214ae4087eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034509565-172.17.0.17-1595621875443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34638,DS-d4f6a00e-b769-4daa-b1a2-dc6acc33393c,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-90ebed43-c1b4-4941-991b-14cddbf8d1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-1acb86a3-f7df-4422-9444-ba01aebb371e,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-7f3709bb-1d6f-4ec1-bb68-cb6215fe5cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-5e7dbb86-b8e3-4f5d-920e-6540bb2a8efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-34d043be-3403-4ee6-aedf-667d7d05e825,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-95ddd5ba-a640-4853-aabf-601ae9046104,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-e1ecb64c-5dbe-4679-b624-70bd81982d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034509565-172.17.0.17-1595621875443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34638,DS-d4f6a00e-b769-4daa-b1a2-dc6acc33393c,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-90ebed43-c1b4-4941-991b-14cddbf8d1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-1acb86a3-f7df-4422-9444-ba01aebb371e,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-7f3709bb-1d6f-4ec1-bb68-cb6215fe5cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-5e7dbb86-b8e3-4f5d-920e-6540bb2a8efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-34d043be-3403-4ee6-aedf-667d7d05e825,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-95ddd5ba-a640-4853-aabf-601ae9046104,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-e1ecb64c-5dbe-4679-b624-70bd81982d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051450531-172.17.0.17-1595622502714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-c97cf3e1-f4a4-41f1-bf5e-0699dd7af713,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-a65d584e-2020-4827-8c0b-53daf00bae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-e8edb62b-bd69-4df3-9816-fa1d3b210305,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-80aef9ee-ee31-4ec2-b1fe-cf18e4668f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-73a3cc05-032a-437d-991a-6ce05e214390,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-4a9b9c92-00fe-4d64-a854-4541018a0faf,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-ac20dee4-ecb6-4187-933f-f31fba2f445d,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-db1a42a9-b33f-46e3-9cb8-ca76b4816b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051450531-172.17.0.17-1595622502714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-c97cf3e1-f4a4-41f1-bf5e-0699dd7af713,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-a65d584e-2020-4827-8c0b-53daf00bae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-e8edb62b-bd69-4df3-9816-fa1d3b210305,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-80aef9ee-ee31-4ec2-b1fe-cf18e4668f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-73a3cc05-032a-437d-991a-6ce05e214390,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-4a9b9c92-00fe-4d64-a854-4541018a0faf,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-ac20dee4-ecb6-4187-933f-f31fba2f445d,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-db1a42a9-b33f-46e3-9cb8-ca76b4816b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040266314-172.17.0.17-1595622795375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-396d0ad4-6960-477a-9f8c-02ad56ef936b,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-ad26ea24-2d22-44d0-99e0-171fb97aa060,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-c2156867-c115-4bad-86a5-2b7165d51b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-6f8b9688-fb3c-4588-aabe-85a520f946b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-8a74d5fa-045d-4273-afee-19c0ca2ee63b,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-7c3552dc-0325-4356-bbde-54f5996f5d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-363635af-6ee5-40b9-a607-85903cfffff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-cbc1f53b-ab24-4d72-a7ab-6ab1c46a94f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040266314-172.17.0.17-1595622795375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-396d0ad4-6960-477a-9f8c-02ad56ef936b,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-ad26ea24-2d22-44d0-99e0-171fb97aa060,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-c2156867-c115-4bad-86a5-2b7165d51b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-6f8b9688-fb3c-4588-aabe-85a520f946b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-8a74d5fa-045d-4273-afee-19c0ca2ee63b,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-7c3552dc-0325-4356-bbde-54f5996f5d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-363635af-6ee5-40b9-a607-85903cfffff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-cbc1f53b-ab24-4d72-a7ab-6ab1c46a94f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730374288-172.17.0.17-1595623153215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-409af93f-70aa-4278-8af3-5d43f8dd7d58,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-47aafdf6-f50e-46df-afc0-3b1fa9a5bb40,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-a50ce8cc-eb19-4b71-ab5b-b677c2aa54e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-ca851f09-27b9-40ca-b763-7df59f66e43c,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-d5873c93-c871-4e84-84ea-9b2aa96aab96,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-762e2b79-a121-4884-8277-4f73da26ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-5ea1d4e7-dfd2-4f01-a4b6-d9d8f67ee57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-32a78468-72cb-4941-b052-636b2fe29d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730374288-172.17.0.17-1595623153215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-409af93f-70aa-4278-8af3-5d43f8dd7d58,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-47aafdf6-f50e-46df-afc0-3b1fa9a5bb40,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-a50ce8cc-eb19-4b71-ab5b-b677c2aa54e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-ca851f09-27b9-40ca-b763-7df59f66e43c,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-d5873c93-c871-4e84-84ea-9b2aa96aab96,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-762e2b79-a121-4884-8277-4f73da26ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-5ea1d4e7-dfd2-4f01-a4b6-d9d8f67ee57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-32a78468-72cb-4941-b052-636b2fe29d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148668538-172.17.0.17-1595623554784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-c34aa00b-b740-421e-8072-e1f868147836,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-230d21bd-5b7e-4966-9f37-ca03c57a52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-18903259-7da8-491a-abe2-bf3efd646508,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-feca1959-f71b-49ba-abea-2a61fca9f3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-13942a0a-210e-42b4-a587-df144b966259,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-b9e48160-8db9-4dc8-843a-49bcde0cd568,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-dbc6c508-985f-44b9-ae7f-625a746da94a,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-5dd76136-8dbb-48b3-aa59-b9193d6914a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148668538-172.17.0.17-1595623554784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-c34aa00b-b740-421e-8072-e1f868147836,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-230d21bd-5b7e-4966-9f37-ca03c57a52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-18903259-7da8-491a-abe2-bf3efd646508,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-feca1959-f71b-49ba-abea-2a61fca9f3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-13942a0a-210e-42b4-a587-df144b966259,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-b9e48160-8db9-4dc8-843a-49bcde0cd568,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-dbc6c508-985f-44b9-ae7f-625a746da94a,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-5dd76136-8dbb-48b3-aa59-b9193d6914a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819781153-172.17.0.17-1595623696749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-90f498f7-3847-41a8-9752-2c46d7fce73b,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-4707d0f8-1192-4bc8-9457-80421f2c9359,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-a2a4f15a-2aab-42ab-bbb9-3ed5574db1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-b46162cb-b065-4873-b4d3-c7dc1841fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-f34efd90-0a9f-4af3-8828-2fbcc49bf2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-adf4f6ea-4a37-462b-b895-892e4f6395dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-141e319e-9635-4545-bd09-c84bd49c7e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-4b4df06e-b454-422e-9f2e-31c6c08f55b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819781153-172.17.0.17-1595623696749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-90f498f7-3847-41a8-9752-2c46d7fce73b,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-4707d0f8-1192-4bc8-9457-80421f2c9359,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-a2a4f15a-2aab-42ab-bbb9-3ed5574db1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-b46162cb-b065-4873-b4d3-c7dc1841fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-f34efd90-0a9f-4af3-8828-2fbcc49bf2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-adf4f6ea-4a37-462b-b895-892e4f6395dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-141e319e-9635-4545-bd09-c84bd49c7e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-4b4df06e-b454-422e-9f2e-31c6c08f55b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256453686-172.17.0.17-1595623977421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-9a9bc267-b9b1-495d-816c-a59e824bced0,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-5c1f79a9-9951-49a7-8f4c-d9dac5ae9dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-629d78f4-419f-49c3-bf60-e1a3898677af,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-832689a2-5317-4bf2-bb81-e0df9956c42e,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-ae87c1b7-0d89-4d0a-a59c-610e4378d153,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-4b36e85f-2023-4967-b81f-143c94e36e64,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-4b93aad1-180c-4e8e-92c5-945d4146e865,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-2eec9e38-464e-4a69-94f0-29b55040a49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256453686-172.17.0.17-1595623977421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-9a9bc267-b9b1-495d-816c-a59e824bced0,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-5c1f79a9-9951-49a7-8f4c-d9dac5ae9dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-629d78f4-419f-49c3-bf60-e1a3898677af,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-832689a2-5317-4bf2-bb81-e0df9956c42e,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-ae87c1b7-0d89-4d0a-a59c-610e4378d153,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-4b36e85f-2023-4967-b81f-143c94e36e64,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-4b93aad1-180c-4e8e-92c5-945d4146e865,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-2eec9e38-464e-4a69-94f0-29b55040a49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695328071-172.17.0.17-1595624017578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45799,DS-cf10cd2a-f7fb-4196-b366-fe021265e303,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-338aeebd-40ea-4037-8ae1-5d7f83aac14e,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-2be11e93-f578-41b7-80af-d5db46eab9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-8ddd6cad-8c01-42dc-9b72-6b81db895e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-0f19f501-01fd-4afe-88c9-32a98de1657c,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-9e524851-ed3a-44d5-9624-f90d0e3253db,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-017e5405-9779-41ef-a373-e9f87f92b116,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-51fbbd35-9979-4d25-8e8e-26113ef93223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695328071-172.17.0.17-1595624017578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45799,DS-cf10cd2a-f7fb-4196-b366-fe021265e303,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-338aeebd-40ea-4037-8ae1-5d7f83aac14e,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-2be11e93-f578-41b7-80af-d5db46eab9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-8ddd6cad-8c01-42dc-9b72-6b81db895e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-0f19f501-01fd-4afe-88c9-32a98de1657c,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-9e524851-ed3a-44d5-9624-f90d0e3253db,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-017e5405-9779-41ef-a373-e9f87f92b116,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-51fbbd35-9979-4d25-8e8e-26113ef93223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420276712-172.17.0.17-1595624234429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-1b6ee45d-3e56-453f-98e7-1350db22e05e,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-f248ff31-e716-401a-a857-9903834a60f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-9a373fb6-41df-4b15-9f84-abd891264e43,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-1a5ce4ce-c940-4b9a-99f2-26b78dcf6071,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-1e4c8060-2208-4731-882c-da8f17f4c690,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-e504c089-0932-4353-9d5a-886cc980bd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-88bb1229-d830-4878-964b-d56ae98e1147,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-db998912-18b3-45d3-a319-b6c6439e909f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420276712-172.17.0.17-1595624234429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-1b6ee45d-3e56-453f-98e7-1350db22e05e,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-f248ff31-e716-401a-a857-9903834a60f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-9a373fb6-41df-4b15-9f84-abd891264e43,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-1a5ce4ce-c940-4b9a-99f2-26b78dcf6071,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-1e4c8060-2208-4731-882c-da8f17f4c690,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-e504c089-0932-4353-9d5a-886cc980bd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-88bb1229-d830-4878-964b-d56ae98e1147,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-db998912-18b3-45d3-a319-b6c6439e909f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471968006-172.17.0.17-1595624276662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-4d8613b1-d54a-4912-bf24-8c5dced26334,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-b1f4d5a9-6d21-4d1f-9abb-083c7c739234,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-06e38aa5-c4bb-4157-b5c2-fd41190506a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-c251e82a-a09a-4320-8fdb-5e27b85689ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-065a3054-f70b-4e1f-a322-bd61906c60f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-eabf6e16-e074-485d-b9aa-99a302606d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-a12ca407-4891-42e0-8710-5dd12e16cd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-c38e4dfe-28ea-498b-8a5a-5581826359f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471968006-172.17.0.17-1595624276662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-4d8613b1-d54a-4912-bf24-8c5dced26334,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-b1f4d5a9-6d21-4d1f-9abb-083c7c739234,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-06e38aa5-c4bb-4157-b5c2-fd41190506a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-c251e82a-a09a-4320-8fdb-5e27b85689ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-065a3054-f70b-4e1f-a322-bd61906c60f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-eabf6e16-e074-485d-b9aa-99a302606d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-a12ca407-4891-42e0-8710-5dd12e16cd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-c38e4dfe-28ea-498b-8a5a-5581826359f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13777971-172.17.0.17-1595625107269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-380fad67-751a-4a32-ac06-888fab9b7f41,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-08abfff5-45f9-4a91-b122-08fb5879accf,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-e307ee0e-df4d-486d-bdb5-5c242e81258d,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-5712fcca-f6d8-4b03-90bc-3c12d51ba968,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-4e0b0635-d25b-45e1-b95c-9746d0bb5053,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-8c41ae62-6bcc-4934-aef8-79d5dbcfd39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-857e06ed-b7b5-4efa-a296-00475769ea2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-57bed235-a2b3-4db6-a9d7-86989f2a98dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13777971-172.17.0.17-1595625107269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-380fad67-751a-4a32-ac06-888fab9b7f41,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-08abfff5-45f9-4a91-b122-08fb5879accf,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-e307ee0e-df4d-486d-bdb5-5c242e81258d,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-5712fcca-f6d8-4b03-90bc-3c12d51ba968,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-4e0b0635-d25b-45e1-b95c-9746d0bb5053,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-8c41ae62-6bcc-4934-aef8-79d5dbcfd39f,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-857e06ed-b7b5-4efa-a296-00475769ea2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-57bed235-a2b3-4db6-a9d7-86989f2a98dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5463
