reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-389304046-172.17.0.13-1595700155797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38958,DS-29768507-e858-4671-9c34-8187f44ba9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-e2cde5ab-a6ff-42d4-bbdd-7d556b6718e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-8f0ba3ae-cb10-442f-b87b-75539daa17e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-e2040973-4ef9-4e2c-a6ea-728e26888560,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-95eb3fa6-8770-463e-8d50-a7dd997d4772,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-c9dc38b6-dd5f-4a0f-b87c-9a20b03e8e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-9782d3de-3654-4aac-b738-9cdf9e670561,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-84739849-8053-454f-a0af-2bee685a68ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-389304046-172.17.0.13-1595700155797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38958,DS-29768507-e858-4671-9c34-8187f44ba9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-e2cde5ab-a6ff-42d4-bbdd-7d556b6718e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-8f0ba3ae-cb10-442f-b87b-75539daa17e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-e2040973-4ef9-4e2c-a6ea-728e26888560,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-95eb3fa6-8770-463e-8d50-a7dd997d4772,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-c9dc38b6-dd5f-4a0f-b87c-9a20b03e8e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-9782d3de-3654-4aac-b738-9cdf9e670561,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-84739849-8053-454f-a0af-2bee685a68ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651606726-172.17.0.13-1595700193091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-6fba5c42-4a6d-4cf5-bd0d-efdc6a468b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-c088b6ac-08fd-486a-a610-89e7fbef9735,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-6686a01d-732c-42d7-9ed1-5b2caa26d79c,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-08545175-c0ae-4763-9a1d-214d15f8c134,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-5ec2ebaa-994a-428c-afd7-041c7b602525,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-b405cd27-fcd9-4b03-810d-76ed968cb9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-20313028-2d41-4497-9996-28863b573249,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-d97bceef-45fc-46a4-ac76-4e41bbcf2b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651606726-172.17.0.13-1595700193091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-6fba5c42-4a6d-4cf5-bd0d-efdc6a468b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-c088b6ac-08fd-486a-a610-89e7fbef9735,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-6686a01d-732c-42d7-9ed1-5b2caa26d79c,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-08545175-c0ae-4763-9a1d-214d15f8c134,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-5ec2ebaa-994a-428c-afd7-041c7b602525,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-b405cd27-fcd9-4b03-810d-76ed968cb9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-20313028-2d41-4497-9996-28863b573249,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-d97bceef-45fc-46a4-ac76-4e41bbcf2b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223877586-172.17.0.13-1595700406621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-64964213-b27e-4f57-aff1-7210f2637703,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-a87eb75d-47f1-436d-ac8b-f9b158c28dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-fab34dfe-87f0-41cb-8beb-247027247d71,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-bf48971a-5a63-475f-b477-7a38397d1162,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-a0be9f56-0bb8-4594-a210-da38d4d42219,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-b4ec35c1-28f8-4dd7-8a3d-f278a95154df,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-0b05d09b-c0df-44da-a734-d3f2574aa0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-67da974c-f87f-4acd-b1eb-1f03a29c2469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223877586-172.17.0.13-1595700406621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-64964213-b27e-4f57-aff1-7210f2637703,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-a87eb75d-47f1-436d-ac8b-f9b158c28dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-fab34dfe-87f0-41cb-8beb-247027247d71,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-bf48971a-5a63-475f-b477-7a38397d1162,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-a0be9f56-0bb8-4594-a210-da38d4d42219,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-b4ec35c1-28f8-4dd7-8a3d-f278a95154df,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-0b05d09b-c0df-44da-a734-d3f2574aa0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-67da974c-f87f-4acd-b1eb-1f03a29c2469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288672479-172.17.0.13-1595700734772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39379,DS-54faaebd-e774-458d-860f-d63c4c6b711a,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-c1bbda7e-e239-4281-8f60-5678707565a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-fd43eb98-cbec-4024-9326-e21791929ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-4dbf0580-23e4-4f28-a370-47a7d340470b,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-19bee4be-d755-4733-b44d-ca49baf61bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-3b041e3d-758c-4171-8d81-c5c417999f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1bc607d4-f0dc-45c8-90a6-afa7cf730ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-333a16a1-5cd8-4e9a-b35c-4781915a7195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288672479-172.17.0.13-1595700734772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39379,DS-54faaebd-e774-458d-860f-d63c4c6b711a,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-c1bbda7e-e239-4281-8f60-5678707565a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-fd43eb98-cbec-4024-9326-e21791929ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-4dbf0580-23e4-4f28-a370-47a7d340470b,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-19bee4be-d755-4733-b44d-ca49baf61bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-3b041e3d-758c-4171-8d81-c5c417999f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-1bc607d4-f0dc-45c8-90a6-afa7cf730ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-333a16a1-5cd8-4e9a-b35c-4781915a7195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607718058-172.17.0.13-1595700774702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39840,DS-54ef23a7-e9a2-4e26-9463-12d6b2a33044,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-c4b46eef-890f-4b20-aad9-65f2eec86dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-37b371d4-175a-4d52-8a02-ae8423506d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-645f1850-f099-48cd-937c-f3f2d3b3c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-496bdbd7-1696-4a4c-aa81-1ed4d5147d04,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-0cef4cca-a472-4edf-8857-bc46ecbc37a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-8a998242-57e1-4662-b2b7-219b0cf60a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-abeb3f16-5ba8-4dd6-942e-1f602c244b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607718058-172.17.0.13-1595700774702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39840,DS-54ef23a7-e9a2-4e26-9463-12d6b2a33044,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-c4b46eef-890f-4b20-aad9-65f2eec86dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-37b371d4-175a-4d52-8a02-ae8423506d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-645f1850-f099-48cd-937c-f3f2d3b3c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-496bdbd7-1696-4a4c-aa81-1ed4d5147d04,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-0cef4cca-a472-4edf-8857-bc46ecbc37a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-8a998242-57e1-4662-b2b7-219b0cf60a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-abeb3f16-5ba8-4dd6-942e-1f602c244b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586125892-172.17.0.13-1595701113871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42426,DS-a01b51d8-b339-4641-8882-2078dfe62d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-eef3eecf-21e7-4c5e-bf95-48de3fb1520f,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-68e04196-1484-4c7c-9a96-1619fa390f79,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-2854fe81-bccf-48f6-b4db-97bd2acefe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-9b87e3de-7678-4ae3-aefd-25dabad7c2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-a3c3b528-3018-475f-92a1-7c9f7775206b,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-a206235a-3b5d-4457-a69b-938bddbf075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-b1624336-5a0b-438a-8c7b-9fea87b10759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586125892-172.17.0.13-1595701113871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42426,DS-a01b51d8-b339-4641-8882-2078dfe62d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-eef3eecf-21e7-4c5e-bf95-48de3fb1520f,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-68e04196-1484-4c7c-9a96-1619fa390f79,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-2854fe81-bccf-48f6-b4db-97bd2acefe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-9b87e3de-7678-4ae3-aefd-25dabad7c2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-a3c3b528-3018-475f-92a1-7c9f7775206b,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-a206235a-3b5d-4457-a69b-938bddbf075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-b1624336-5a0b-438a-8c7b-9fea87b10759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704136492-172.17.0.13-1595701831363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46797,DS-be59a01f-7ed7-44c5-b7a1-b66ae4f5f3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-d9ee03c0-9eec-47c5-bb85-231580d2bb26,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-ac486fc9-10ef-4049-b3dd-f44e130ab29b,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-c05a4f33-f02c-48e4-8ea4-9eb8b0d7b5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4043b4c2-4ad0-4fae-b8a5-7bc48ad2e595,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-00340737-82c9-441d-84e5-d3ee62d921c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-a1f41515-85da-4b47-b5d7-49054107d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-ca50d672-bae6-42dc-9bdf-0ba5a246f15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704136492-172.17.0.13-1595701831363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46797,DS-be59a01f-7ed7-44c5-b7a1-b66ae4f5f3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-d9ee03c0-9eec-47c5-bb85-231580d2bb26,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-ac486fc9-10ef-4049-b3dd-f44e130ab29b,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-c05a4f33-f02c-48e4-8ea4-9eb8b0d7b5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4043b4c2-4ad0-4fae-b8a5-7bc48ad2e595,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-00340737-82c9-441d-84e5-d3ee62d921c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-a1f41515-85da-4b47-b5d7-49054107d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-ca50d672-bae6-42dc-9bdf-0ba5a246f15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693139973-172.17.0.13-1595702088554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-ee85ff10-dd02-48a6-87ce-b5a280851404,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-97c11539-b3ef-4e1f-8aeb-8db4302a3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-508c5abc-3461-48a5-85d3-31361fa0d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-33c5dff3-a64d-4f52-a0c6-0cffd65b3e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-d2ba7bdf-57e9-47f0-ba79-472cfc29795f,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-99b0b0d1-92d2-48ac-aa23-d675bc339c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-18ee4ee0-11df-4a1e-b197-eb2453098beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-798f7575-436c-4ee1-afed-2fcfbdca7247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693139973-172.17.0.13-1595702088554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-ee85ff10-dd02-48a6-87ce-b5a280851404,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-97c11539-b3ef-4e1f-8aeb-8db4302a3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-508c5abc-3461-48a5-85d3-31361fa0d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-33c5dff3-a64d-4f52-a0c6-0cffd65b3e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-d2ba7bdf-57e9-47f0-ba79-472cfc29795f,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-99b0b0d1-92d2-48ac-aa23-d675bc339c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-18ee4ee0-11df-4a1e-b197-eb2453098beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-798f7575-436c-4ee1-afed-2fcfbdca7247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333004278-172.17.0.13-1595702294566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-ca42ea8d-1f77-4040-975d-422e85ee5092,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-92345784-a092-48e5-b719-e63f29e72988,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-29fad389-402c-4e80-8720-ad76de9fd9da,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-e31ccf73-5f59-4f21-b48d-c612b0517325,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-d0045873-2d1d-48d6-8853-b2c61aaeb403,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-0f7e8e3a-3afa-4edc-a6e2-49b18382d242,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-562f6fe4-4ddd-4b38-98af-07b35d0f0d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-7984d77b-f62f-4b52-90af-0f20dc74e6d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333004278-172.17.0.13-1595702294566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-ca42ea8d-1f77-4040-975d-422e85ee5092,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-92345784-a092-48e5-b719-e63f29e72988,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-29fad389-402c-4e80-8720-ad76de9fd9da,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-e31ccf73-5f59-4f21-b48d-c612b0517325,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-d0045873-2d1d-48d6-8853-b2c61aaeb403,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-0f7e8e3a-3afa-4edc-a6e2-49b18382d242,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-562f6fe4-4ddd-4b38-98af-07b35d0f0d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-7984d77b-f62f-4b52-90af-0f20dc74e6d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550284911-172.17.0.13-1595702934718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-45438821-483b-4dd9-a2b0-243e6a0e55c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-c4afd4c6-e908-485b-add1-4e0fbce77f02,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-c0e61332-118a-491f-9606-ac2f0f9674ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-0c0ffcae-096e-4cd1-a4d0-dec58e61f635,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-541a6a82-0c9d-43f3-a7ca-554a15fd03be,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-fb3e29d5-6f49-477f-b59b-db2723eb0da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2d9667ad-2f30-4dc6-9928-750a8ae8ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-501e3663-d439-4af3-901e-bb30f02c606b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550284911-172.17.0.13-1595702934718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-45438821-483b-4dd9-a2b0-243e6a0e55c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-c4afd4c6-e908-485b-add1-4e0fbce77f02,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-c0e61332-118a-491f-9606-ac2f0f9674ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-0c0ffcae-096e-4cd1-a4d0-dec58e61f635,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-541a6a82-0c9d-43f3-a7ca-554a15fd03be,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-fb3e29d5-6f49-477f-b59b-db2723eb0da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2d9667ad-2f30-4dc6-9928-750a8ae8ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-501e3663-d439-4af3-901e-bb30f02c606b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147294875-172.17.0.13-1595703066414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-bb697d8d-4972-4b13-8a2d-a9d8ecb97508,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-2f837fcc-a49f-421c-9380-8fdb75be5e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-2830f6fa-40d4-46f4-a0c3-057d51078c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-ddfa071f-6af2-47ab-8ef0-763c6d41fa82,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-6007c7cb-7ffe-417d-b01d-b893fa564c44,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-4d362b54-32f5-495f-b0f7-ef926e201c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-fb6add10-c11e-4d52-95ac-fe3ef2186727,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-c4740557-aab3-4591-b0d5-c3478ba02a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147294875-172.17.0.13-1595703066414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-bb697d8d-4972-4b13-8a2d-a9d8ecb97508,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-2f837fcc-a49f-421c-9380-8fdb75be5e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-2830f6fa-40d4-46f4-a0c3-057d51078c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-ddfa071f-6af2-47ab-8ef0-763c6d41fa82,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-6007c7cb-7ffe-417d-b01d-b893fa564c44,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-4d362b54-32f5-495f-b0f7-ef926e201c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-fb6add10-c11e-4d52-95ac-fe3ef2186727,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-c4740557-aab3-4591-b0d5-c3478ba02a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162366519-172.17.0.13-1595703457638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45816,DS-30151ecd-fc54-461c-ba54-f507b52da420,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-98bc5c5d-031d-429c-bfce-aa8560dea63f,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-452bac41-6ce3-4333-bf6a-0cbf33f552a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-e83187c0-4946-4934-b3de-77d712f49f04,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-949bfc13-b916-4514-8c43-e8c8408e069d,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-586ef781-1b7f-41db-801c-01834215f2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-bec5c83a-7d4c-40ff-8b33-ec7f1908c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-68a34338-0243-4b55-99c8-3d613ae158f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162366519-172.17.0.13-1595703457638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45816,DS-30151ecd-fc54-461c-ba54-f507b52da420,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-98bc5c5d-031d-429c-bfce-aa8560dea63f,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-452bac41-6ce3-4333-bf6a-0cbf33f552a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-e83187c0-4946-4934-b3de-77d712f49f04,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-949bfc13-b916-4514-8c43-e8c8408e069d,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-586ef781-1b7f-41db-801c-01834215f2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-bec5c83a-7d4c-40ff-8b33-ec7f1908c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-68a34338-0243-4b55-99c8-3d613ae158f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349452250-172.17.0.13-1595703850710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-6c5ba3e7-ecb7-42f7-8913-b68f099d89ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-4c1daa31-b73d-40ae-958b-49589c840527,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-abea4792-3d96-488d-ab5a-f71868be1c02,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-e89cbd85-aaeb-4f16-9530-beb2d4969836,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-4bd715e4-b439-4fd1-9fad-e4e9bb9477c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-c4001ffd-5dc9-45ab-b894-6b960467e586,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-dc543b6a-54b4-40c5-ac78-ddfb32c81b13,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-73253d1d-1b59-4f00-b432-3074eb60d1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349452250-172.17.0.13-1595703850710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-6c5ba3e7-ecb7-42f7-8913-b68f099d89ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-4c1daa31-b73d-40ae-958b-49589c840527,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-abea4792-3d96-488d-ab5a-f71868be1c02,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-e89cbd85-aaeb-4f16-9530-beb2d4969836,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-4bd715e4-b439-4fd1-9fad-e4e9bb9477c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-c4001ffd-5dc9-45ab-b894-6b960467e586,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-dc543b6a-54b4-40c5-ac78-ddfb32c81b13,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-73253d1d-1b59-4f00-b432-3074eb60d1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763684471-172.17.0.13-1595704680016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39161,DS-975a037c-08cd-4c0f-be4c-3b934b0ae87b,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-ee4afd56-d064-4bc0-8a46-ae042f0eb40e,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-db0597ce-23ab-4196-ac8b-5a5b6b3e6021,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-fbf13f07-f659-4ef9-a0a4-c1c11161f1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-0ffd8ed5-70de-4ec4-98c8-93602502bf90,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-b4492fe8-c676-489a-8fec-4496da7908ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-49b5ab87-ebd3-44e7-86d2-dab0cf916a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-404d5f69-7afa-49db-952a-dabcec3cef0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763684471-172.17.0.13-1595704680016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39161,DS-975a037c-08cd-4c0f-be4c-3b934b0ae87b,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-ee4afd56-d064-4bc0-8a46-ae042f0eb40e,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-db0597ce-23ab-4196-ac8b-5a5b6b3e6021,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-fbf13f07-f659-4ef9-a0a4-c1c11161f1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-0ffd8ed5-70de-4ec4-98c8-93602502bf90,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-b4492fe8-c676-489a-8fec-4496da7908ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-49b5ab87-ebd3-44e7-86d2-dab0cf916a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-404d5f69-7afa-49db-952a-dabcec3cef0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96821254-172.17.0.13-1595705189941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-07a6baaa-fb98-4fe2-97cd-8d88346a5b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-1a05e91a-3a66-4ea0-9a42-e682688e6f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-130d90e5-9f54-4f9c-9875-9f3abd1953dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-ea94fcd6-1bd9-43cd-bacf-1b98dc49f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-3ccebe7b-1daa-4038-a29e-02b6d525236f,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-59afcfff-55de-4eb5-8777-27cbc5821c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-cc9c9d10-641a-4682-be31-7c659542d906,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-6e6837fd-949c-48ee-9ae5-da6d85e38579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96821254-172.17.0.13-1595705189941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-07a6baaa-fb98-4fe2-97cd-8d88346a5b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-1a05e91a-3a66-4ea0-9a42-e682688e6f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-130d90e5-9f54-4f9c-9875-9f3abd1953dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-ea94fcd6-1bd9-43cd-bacf-1b98dc49f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-3ccebe7b-1daa-4038-a29e-02b6d525236f,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-59afcfff-55de-4eb5-8777-27cbc5821c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-cc9c9d10-641a-4682-be31-7c659542d906,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-6e6837fd-949c-48ee-9ae5-da6d85e38579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5261
