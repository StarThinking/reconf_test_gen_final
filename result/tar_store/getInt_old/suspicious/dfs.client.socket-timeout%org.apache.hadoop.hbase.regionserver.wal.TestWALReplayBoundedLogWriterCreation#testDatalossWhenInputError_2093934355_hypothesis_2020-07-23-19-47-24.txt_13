reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-92091023-b97b-4582-834d-33c35eeb0326,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-e0dce940-ac38-442d-a5c2-0025967c1c0a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-92091023-b97b-4582-834d-33c35eeb0326,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-e0dce940-ac38-442d-a5c2-0025967c1c0a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-92091023-b97b-4582-834d-33c35eeb0326,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-e0dce940-ac38-442d-a5c2-0025967c1c0a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-92091023-b97b-4582-834d-33c35eeb0326,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-e0dce940-ac38-442d-a5c2-0025967c1c0a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40785,DS-5b79804a-340c-402d-aff7-7aa702fb4460,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-1c34c714-86ee-4059-a8ab-d72b2b9a2d9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-1c34c714-86ee-4059-a8ab-d72b2b9a2d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-5b79804a-340c-402d-aff7-7aa702fb4460,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40785,DS-5b79804a-340c-402d-aff7-7aa702fb4460,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-1c34c714-86ee-4059-a8ab-d72b2b9a2d9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-1c34c714-86ee-4059-a8ab-d72b2b9a2d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-5b79804a-340c-402d-aff7-7aa702fb4460,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-ef18e81c-91ef-4b05-9391-fb1e9674a3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-72fb9a04-0a4a-46e0-9484-b89a7b24a5a0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45816,DS-72fb9a04-0a4a-46e0-9484-b89a7b24a5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-ef18e81c-91ef-4b05-9391-fb1e9674a3a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33826,DS-ef18e81c-91ef-4b05-9391-fb1e9674a3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-72fb9a04-0a4a-46e0-9484-b89a7b24a5a0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45816,DS-72fb9a04-0a4a-46e0-9484-b89a7b24a5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-ef18e81c-91ef-4b05-9391-fb1e9674a3a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-1e68737a-a8ec-413d-89b4-7c32b60fce22,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-4dab9ae7-d013-491b-acb8-8ca21b1d2d16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-1e68737a-a8ec-413d-89b4-7c32b60fce22,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-4dab9ae7-d013-491b-acb8-8ca21b1d2d16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-1e68737a-a8ec-413d-89b4-7c32b60fce22,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-4dab9ae7-d013-491b-acb8-8ca21b1d2d16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-1e68737a-a8ec-413d-89b4-7c32b60fce22,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-4dab9ae7-d013-491b-acb8-8ca21b1d2d16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45155,DS-3e083ff1-5039-4d52-a489-25b73cd6b5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-d5044d9d-0bf4-4cf5-a24e-8d493b168f3c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45155,DS-3e083ff1-5039-4d52-a489-25b73cd6b5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-d5044d9d-0bf4-4cf5-a24e-8d493b168f3c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45155,DS-3e083ff1-5039-4d52-a489-25b73cd6b5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-d5044d9d-0bf4-4cf5-a24e-8d493b168f3c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45155,DS-3e083ff1-5039-4d52-a489-25b73cd6b5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-d5044d9d-0bf4-4cf5-a24e-8d493b168f3c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-419c1b45-b949-43c7-ad9f-9d3bc0f20810,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-34599375-a673-4073-bac6-be879d619722,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34865,DS-34599375-a673-4073-bac6-be879d619722,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-419c1b45-b949-43c7-ad9f-9d3bc0f20810,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-419c1b45-b949-43c7-ad9f-9d3bc0f20810,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-34599375-a673-4073-bac6-be879d619722,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34865,DS-34599375-a673-4073-bac6-be879d619722,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-419c1b45-b949-43c7-ad9f-9d3bc0f20810,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-06408b6e-f14d-42aa-abf4-2b691163e707,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-16f189c2-732d-4570-bc79-41e816283975,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-16f189c2-732d-4570-bc79-41e816283975,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-06408b6e-f14d-42aa-abf4-2b691163e707,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-06408b6e-f14d-42aa-abf4-2b691163e707,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-16f189c2-732d-4570-bc79-41e816283975,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-16f189c2-732d-4570-bc79-41e816283975,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-06408b6e-f14d-42aa-abf4-2b691163e707,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-671f9835-4ffc-4a66-b267-1f6291fff979,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-df0ed75f-59b1-4ba9-967d-8089ddaa4736,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-671f9835-4ffc-4a66-b267-1f6291fff979,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-df0ed75f-59b1-4ba9-967d-8089ddaa4736,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-671f9835-4ffc-4a66-b267-1f6291fff979,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-df0ed75f-59b1-4ba9-967d-8089ddaa4736,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-671f9835-4ffc-4a66-b267-1f6291fff979,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-df0ed75f-59b1-4ba9-967d-8089ddaa4736,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 0 out of 50
result: might be true error
Total execution time in seconds : 8993
