reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-3a06b42c-89ef-4eb7-91af-b271151401ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-553d3503-d33c-4f41-bdd7-ad886ef8a75c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-3a06b42c-89ef-4eb7-91af-b271151401ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-553d3503-d33c-4f41-bdd7-ad886ef8a75c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-3a06b42c-89ef-4eb7-91af-b271151401ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-553d3503-d33c-4f41-bdd7-ad886ef8a75c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-3a06b42c-89ef-4eb7-91af-b271151401ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-553d3503-d33c-4f41-bdd7-ad886ef8a75c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-921648b9-5284-44c1-b04b-574bd5c5c307,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-3f563953-dd06-407c-9863-64e418f61a87,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-921648b9-5284-44c1-b04b-574bd5c5c307,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-3f563953-dd06-407c-9863-64e418f61a87,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-921648b9-5284-44c1-b04b-574bd5c5c307,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-3f563953-dd06-407c-9863-64e418f61a87,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-921648b9-5284-44c1-b04b-574bd5c5c307,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-3f563953-dd06-407c-9863-64e418f61a87,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-4c94227d-8bdb-49fd-8287-e32360e87225,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4cd91103-92c0-4b3d-9aa9-4d2fc208231f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-4c94227d-8bdb-49fd-8287-e32360e87225,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4cd91103-92c0-4b3d-9aa9-4d2fc208231f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-4c94227d-8bdb-49fd-8287-e32360e87225,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4cd91103-92c0-4b3d-9aa9-4d2fc208231f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-4c94227d-8bdb-49fd-8287-e32360e87225,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4cd91103-92c0-4b3d-9aa9-4d2fc208231f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34602,DS-db28ab44-0c25-488c-9bee-9963973bdf35,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-607061f4-a8d5-4958-8f47-2408c059438e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33994,DS-607061f4-a8d5-4958-8f47-2408c059438e,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-db28ab44-0c25-488c-9bee-9963973bdf35,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34602,DS-db28ab44-0c25-488c-9bee-9963973bdf35,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-607061f4-a8d5-4958-8f47-2408c059438e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33994,DS-607061f4-a8d5-4958-8f47-2408c059438e,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-db28ab44-0c25-488c-9bee-9963973bdf35,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-3335b179-3c57-48cd-9756-72a0e786ce58,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-27b892d8-9763-4ec6-99ca-934cf9a3251a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-3335b179-3c57-48cd-9756-72a0e786ce58,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-27b892d8-9763-4ec6-99ca-934cf9a3251a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-3335b179-3c57-48cd-9756-72a0e786ce58,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-27b892d8-9763-4ec6-99ca-934cf9a3251a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-3335b179-3c57-48cd-9756-72a0e786ce58,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-27b892d8-9763-4ec6-99ca-934cf9a3251a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-e79fd02f-1bb4-473a-943f-417c53545750,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-0f49ae84-4f75-4141-9b99-85fd4c456c18,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33596,DS-0f49ae84-4f75-4141-9b99-85fd4c456c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-e79fd02f-1bb4-473a-943f-417c53545750,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-e79fd02f-1bb4-473a-943f-417c53545750,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-0f49ae84-4f75-4141-9b99-85fd4c456c18,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33596,DS-0f49ae84-4f75-4141-9b99-85fd4c456c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-e79fd02f-1bb4-473a-943f-417c53545750,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-8fb4ffb0-d004-4d14-8bc4-0ef90e66633f,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-a878a148-303f-439f-8bdd-9095e3118cfc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-8fb4ffb0-d004-4d14-8bc4-0ef90e66633f,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-a878a148-303f-439f-8bdd-9095e3118cfc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-8fb4ffb0-d004-4d14-8bc4-0ef90e66633f,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-a878a148-303f-439f-8bdd-9095e3118cfc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-8fb4ffb0-d004-4d14-8bc4-0ef90e66633f,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-a878a148-303f-439f-8bdd-9095e3118cfc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-a806936c-ba28-445c-9079-7c75c6c02b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-a2f4edf5-e781-41a1-9501-5ae65c4ae5e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-a806936c-ba28-445c-9079-7c75c6c02b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-a2f4edf5-e781-41a1-9501-5ae65c4ae5e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-a806936c-ba28-445c-9079-7c75c6c02b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-a2f4edf5-e781-41a1-9501-5ae65c4ae5e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-a806936c-ba28-445c-9079-7c75c6c02b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-a2f4edf5-e781-41a1-9501-5ae65c4ae5e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-52c3be5d-22be-4d57-9992-a64b42908ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-ae5c3d6d-8d74-47d4-90e6-22dc9223ff7b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34537,DS-ae5c3d6d-8d74-47d4-90e6-22dc9223ff7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-52c3be5d-22be-4d57-9992-a64b42908ea0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-52c3be5d-22be-4d57-9992-a64b42908ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-ae5c3d6d-8d74-47d4-90e6-22dc9223ff7b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34537,DS-ae5c3d6d-8d74-47d4-90e6-22dc9223ff7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-52c3be5d-22be-4d57-9992-a64b42908ea0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-33980ee4-d134-4a91-a8d1-c1c41aaa9043,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-c9db68c5-9f9d-4b3d-9556-2a3130f5754f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-33980ee4-d134-4a91-a8d1-c1c41aaa9043,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-c9db68c5-9f9d-4b3d-9556-2a3130f5754f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-33980ee4-d134-4a91-a8d1-c1c41aaa9043,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-c9db68c5-9f9d-4b3d-9556-2a3130f5754f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-33980ee4-d134-4a91-a8d1-c1c41aaa9043,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-c9db68c5-9f9d-4b3d-9556-2a3130f5754f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-195f1efd-29ef-4331-a86b-34427eb3456f,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-4a90c185-c53f-4057-9658-a35d3ffa76de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-195f1efd-29ef-4331-a86b-34427eb3456f,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-4a90c185-c53f-4057-9658-a35d3ffa76de,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-195f1efd-29ef-4331-a86b-34427eb3456f,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-4a90c185-c53f-4057-9658-a35d3ffa76de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-195f1efd-29ef-4331-a86b-34427eb3456f,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-4a90c185-c53f-4057-9658-a35d3ffa76de,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-cb40d20e-feff-4713-bbe3-a936a0a53a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-ab5e3a76-cbed-4953-857a-62c1b03a122c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-cb40d20e-feff-4713-bbe3-a936a0a53a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-ab5e3a76-cbed-4953-857a-62c1b03a122c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-cb40d20e-feff-4713-bbe3-a936a0a53a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-ab5e3a76-cbed-4953-857a-62c1b03a122c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-cb40d20e-feff-4713-bbe3-a936a0a53a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-ab5e3a76-cbed-4953-857a-62c1b03a122c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-fff5d1df-a8be-456d-bc6a-841eaf97d627,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-3c1c9e7b-5d97-433d-960a-b77e1036f74b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-3c1c9e7b-5d97-433d-960a-b77e1036f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-fff5d1df-a8be-456d-bc6a-841eaf97d627,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-fff5d1df-a8be-456d-bc6a-841eaf97d627,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-3c1c9e7b-5d97-433d-960a-b77e1036f74b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-3c1c9e7b-5d97-433d-960a-b77e1036f74b,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-fff5d1df-a8be-456d-bc6a-841eaf97d627,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-3b71039f-2e0d-44b1-ad45-309770596c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-16dc9d04-c7fe-4c84-80f0-4e569fde22e9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-3b71039f-2e0d-44b1-ad45-309770596c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-16dc9d04-c7fe-4c84-80f0-4e569fde22e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-3b71039f-2e0d-44b1-ad45-309770596c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-16dc9d04-c7fe-4c84-80f0-4e569fde22e9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-3b71039f-2e0d-44b1-ad45-309770596c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-16dc9d04-c7fe-4c84-80f0-4e569fde22e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-8a1a94ad-f104-48fe-9e7a-7ace73304308,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-5c0bf0ac-deec-4c62-a457-54d1cec4de7a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-8a1a94ad-f104-48fe-9e7a-7ace73304308,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-5c0bf0ac-deec-4c62-a457-54d1cec4de7a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-8a1a94ad-f104-48fe-9e7a-7ace73304308,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-5c0bf0ac-deec-4c62-a457-54d1cec4de7a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-8a1a94ad-f104-48fe-9e7a-7ace73304308,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-5c0bf0ac-deec-4c62-a457-54d1cec4de7a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-0fa43e2e-f145-4e99-ae53-e483fb937cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-d20579dc-56d5-4bd7-ba37-ea43e9bf1c53,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41172,DS-d20579dc-56d5-4bd7-ba37-ea43e9bf1c53,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-0fa43e2e-f145-4e99-ae53-e483fb937cbb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-0fa43e2e-f145-4e99-ae53-e483fb937cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-d20579dc-56d5-4bd7-ba37-ea43e9bf1c53,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41172,DS-d20579dc-56d5-4bd7-ba37-ea43e9bf1c53,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-0fa43e2e-f145-4e99-ae53-e483fb937cbb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-cd433e5c-7378-4b0e-bf31-f1e0793e229d,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-d7fc14fc-5879-4419-af44-995ae4ab8e72,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-cd433e5c-7378-4b0e-bf31-f1e0793e229d,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-d7fc14fc-5879-4419-af44-995ae4ab8e72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-cd433e5c-7378-4b0e-bf31-f1e0793e229d,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-d7fc14fc-5879-4419-af44-995ae4ab8e72,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-cd433e5c-7378-4b0e-bf31-f1e0793e229d,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-d7fc14fc-5879-4419-af44-995ae4ab8e72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38287,DS-c0b86f7a-b4c1-4d2c-aab5-a9bd09227f12,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-4ba708d7-04ca-4051-9d2a-fcdddc69975b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38287,DS-c0b86f7a-b4c1-4d2c-aab5-a9bd09227f12,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-4ba708d7-04ca-4051-9d2a-fcdddc69975b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38287,DS-c0b86f7a-b4c1-4d2c-aab5-a9bd09227f12,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-4ba708d7-04ca-4051-9d2a-fcdddc69975b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38287,DS-c0b86f7a-b4c1-4d2c-aab5-a9bd09227f12,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-4ba708d7-04ca-4051-9d2a-fcdddc69975b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-6a58f18f-8644-4aa2-a8f6-5ed3365e2d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-7b456f1e-cdd0-46c6-95da-9fd82e40aae7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-6a58f18f-8644-4aa2-a8f6-5ed3365e2d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-7b456f1e-cdd0-46c6-95da-9fd82e40aae7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-6a58f18f-8644-4aa2-a8f6-5ed3365e2d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-7b456f1e-cdd0-46c6-95da-9fd82e40aae7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-6a58f18f-8644-4aa2-a8f6-5ed3365e2d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-7b456f1e-cdd0-46c6-95da-9fd82e40aae7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-4ac2bcd6-606b-48f2-aa3f-20d50dffbf94,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-11466e8e-6716-4b46-80fc-7a7276eb6ee7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-4ac2bcd6-606b-48f2-aa3f-20d50dffbf94,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-11466e8e-6716-4b46-80fc-7a7276eb6ee7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-4ac2bcd6-606b-48f2-aa3f-20d50dffbf94,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-11466e8e-6716-4b46-80fc-7a7276eb6ee7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42701,DS-4ac2bcd6-606b-48f2-aa3f-20d50dffbf94,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-11466e8e-6716-4b46-80fc-7a7276eb6ee7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-50661305-e27d-4c7a-b398-3d0eedd6fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-249aa761-9c4c-476a-abdc-6d726b36c83b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-50661305-e27d-4c7a-b398-3d0eedd6fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-249aa761-9c4c-476a-abdc-6d726b36c83b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-50661305-e27d-4c7a-b398-3d0eedd6fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-249aa761-9c4c-476a-abdc-6d726b36c83b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-50661305-e27d-4c7a-b398-3d0eedd6fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-249aa761-9c4c-476a-abdc-6d726b36c83b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46587,DS-06a0cea1-97e2-4a7a-b54d-14ee6244f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-7c6243c4-e744-456e-b141-cb7d4921ed84,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43949,DS-7c6243c4-e744-456e-b141-cb7d4921ed84,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-06a0cea1-97e2-4a7a-b54d-14ee6244f9b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46587,DS-06a0cea1-97e2-4a7a-b54d-14ee6244f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-7c6243c4-e744-456e-b141-cb7d4921ed84,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43949,DS-7c6243c4-e744-456e-b141-cb7d4921ed84,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-06a0cea1-97e2-4a7a-b54d-14ee6244f9b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-1f2f8700-a278-4c41-997d-fbce0437900a,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-518eaf67-000f-40ac-8362-c05fc08fcb8e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-1f2f8700-a278-4c41-997d-fbce0437900a,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-518eaf67-000f-40ac-8362-c05fc08fcb8e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-1f2f8700-a278-4c41-997d-fbce0437900a,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-518eaf67-000f-40ac-8362-c05fc08fcb8e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-1f2f8700-a278-4c41-997d-fbce0437900a,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-518eaf67-000f-40ac-8362-c05fc08fcb8e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-8f20ba3c-be1f-4dd3-8372-7181996774a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-082f19e5-7065-4951-a3f9-9dab87e546db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-8f20ba3c-be1f-4dd3-8372-7181996774a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-082f19e5-7065-4951-a3f9-9dab87e546db,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-8f20ba3c-be1f-4dd3-8372-7181996774a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-082f19e5-7065-4951-a3f9-9dab87e546db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-8f20ba3c-be1f-4dd3-8372-7181996774a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-082f19e5-7065-4951-a3f9-9dab87e546db,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-659bcd09-1089-4784-8938-70e8c6aab032,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-a267eb21-3588-4db1-82bb-72f3349d12fb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-659bcd09-1089-4784-8938-70e8c6aab032,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-a267eb21-3588-4db1-82bb-72f3349d12fb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-659bcd09-1089-4784-8938-70e8c6aab032,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-a267eb21-3588-4db1-82bb-72f3349d12fb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-659bcd09-1089-4784-8938-70e8c6aab032,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-a267eb21-3588-4db1-82bb-72f3349d12fb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-3374797c-bfa3-4add-aabd-40b98dabd0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-98b0e84c-0c1f-4d0b-9e5a-d0eaa459e8c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-3374797c-bfa3-4add-aabd-40b98dabd0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-98b0e84c-0c1f-4d0b-9e5a-d0eaa459e8c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-3374797c-bfa3-4add-aabd-40b98dabd0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-98b0e84c-0c1f-4d0b-9e5a-d0eaa459e8c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-3374797c-bfa3-4add-aabd-40b98dabd0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-98b0e84c-0c1f-4d0b-9e5a-d0eaa459e8c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46738,DS-2bf3ee0f-a1af-418e-8984-01daa2fa5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-30aa58aa-6577-4401-a56a-29bbdf37f6c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-30aa58aa-6577-4401-a56a-29bbdf37f6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-2bf3ee0f-a1af-418e-8984-01daa2fa5aa5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46738,DS-2bf3ee0f-a1af-418e-8984-01daa2fa5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-30aa58aa-6577-4401-a56a-29bbdf37f6c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-30aa58aa-6577-4401-a56a-29bbdf37f6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-2bf3ee0f-a1af-418e-8984-01daa2fa5aa5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-7cbd28b9-f21e-4da6-979b-04920aff6d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-3ff59d4c-d5f1-4dcf-94fd-e1a5b0dcaf58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-7cbd28b9-f21e-4da6-979b-04920aff6d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-3ff59d4c-d5f1-4dcf-94fd-e1a5b0dcaf58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-7cbd28b9-f21e-4da6-979b-04920aff6d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-3ff59d4c-d5f1-4dcf-94fd-e1a5b0dcaf58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-7cbd28b9-f21e-4da6-979b-04920aff6d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-3ff59d4c-d5f1-4dcf-94fd-e1a5b0dcaf58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33148,DS-072cf21f-4e25-48e3-822c-2235f3db10d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-86bd3d60-3c3d-4e4f-a635-75ee71f04cf9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-86bd3d60-3c3d-4e4f-a635-75ee71f04cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-072cf21f-4e25-48e3-822c-2235f3db10d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33148,DS-072cf21f-4e25-48e3-822c-2235f3db10d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-86bd3d60-3c3d-4e4f-a635-75ee71f04cf9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-86bd3d60-3c3d-4e4f-a635-75ee71f04cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-072cf21f-4e25-48e3-822c-2235f3db10d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43944,DS-9de0f511-c79e-4ffa-b37d-3320427c3837,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-dbe0aad5-dae6-4758-87d1-14b4b60fe133,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-dbe0aad5-dae6-4758-87d1-14b4b60fe133,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-9de0f511-c79e-4ffa-b37d-3320427c3837,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43944,DS-9de0f511-c79e-4ffa-b37d-3320427c3837,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-dbe0aad5-dae6-4758-87d1-14b4b60fe133,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-dbe0aad5-dae6-4758-87d1-14b4b60fe133,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-9de0f511-c79e-4ffa-b37d-3320427c3837,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-1b2f5357-f578-4655-a869-f668ae0847f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-4aab3ab4-825a-4819-8bc3-b08fdb518b83,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-1b2f5357-f578-4655-a869-f668ae0847f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-4aab3ab4-825a-4819-8bc3-b08fdb518b83,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-1b2f5357-f578-4655-a869-f668ae0847f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-4aab3ab4-825a-4819-8bc3-b08fdb518b83,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-1b2f5357-f578-4655-a869-f668ae0847f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-4aab3ab4-825a-4819-8bc3-b08fdb518b83,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-ae3488cc-eb43-4749-9c67-43ee92418b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-f0f62e5c-9570-47e2-9384-592345304841,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-f0f62e5c-9570-47e2-9384-592345304841,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-ae3488cc-eb43-4749-9c67-43ee92418b0c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-ae3488cc-eb43-4749-9c67-43ee92418b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-f0f62e5c-9570-47e2-9384-592345304841,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-f0f62e5c-9570-47e2-9384-592345304841,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-ae3488cc-eb43-4749-9c67-43ee92418b0c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-5aa5f9bc-11f1-477e-be3c-77c9cc92d893,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-b60f6220-fd57-4cc0-a4f9-9d1983eb63e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35248,DS-b60f6220-fd57-4cc0-a4f9-9d1983eb63e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-5aa5f9bc-11f1-477e-be3c-77c9cc92d893,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-5aa5f9bc-11f1-477e-be3c-77c9cc92d893,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-b60f6220-fd57-4cc0-a4f9-9d1983eb63e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35248,DS-b60f6220-fd57-4cc0-a4f9-9d1983eb63e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-5aa5f9bc-11f1-477e-be3c-77c9cc92d893,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-15b3c9a0-b09a-49c2-8f66-1f6a366df4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-85350b99-cdfd-4462-bb8a-187ffbd1a9f4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-15b3c9a0-b09a-49c2-8f66-1f6a366df4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-85350b99-cdfd-4462-bb8a-187ffbd1a9f4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-15b3c9a0-b09a-49c2-8f66-1f6a366df4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-85350b99-cdfd-4462-bb8a-187ffbd1a9f4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39279,DS-15b3c9a0-b09a-49c2-8f66-1f6a366df4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-85350b99-cdfd-4462-bb8a-187ffbd1a9f4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37978,DS-96d31004-d0f4-46a3-81f8-4e126a81c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-3532ab1f-b965-48bc-b7dc-df87a80d7665,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43878,DS-3532ab1f-b965-48bc-b7dc-df87a80d7665,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-96d31004-d0f4-46a3-81f8-4e126a81c85f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37978,DS-96d31004-d0f4-46a3-81f8-4e126a81c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-3532ab1f-b965-48bc-b7dc-df87a80d7665,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43878,DS-3532ab1f-b965-48bc-b7dc-df87a80d7665,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-96d31004-d0f4-46a3-81f8-4e126a81c85f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-12eb4ec6-0bc5-4060-b46d-ee1526fd4a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-12588f7a-f265-454a-bf54-52ddeb3a3b5d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-12eb4ec6-0bc5-4060-b46d-ee1526fd4a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-12588f7a-f265-454a-bf54-52ddeb3a3b5d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-12eb4ec6-0bc5-4060-b46d-ee1526fd4a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-12588f7a-f265-454a-bf54-52ddeb3a3b5d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-12eb4ec6-0bc5-4060-b46d-ee1526fd4a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-12588f7a-f265-454a-bf54-52ddeb3a3b5d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41899,DS-9996658f-fdbf-4e60-9b3b-eb54b23eff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-9190f268-0e03-4672-a477-8167f5e8b6b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-9190f268-0e03-4672-a477-8167f5e8b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-9996658f-fdbf-4e60-9b3b-eb54b23eff3f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41899,DS-9996658f-fdbf-4e60-9b3b-eb54b23eff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-9190f268-0e03-4672-a477-8167f5e8b6b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-9190f268-0e03-4672-a477-8167f5e8b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-9996658f-fdbf-4e60-9b3b-eb54b23eff3f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-e5ffd603-1505-4c8e-85cf-4bb68952be87,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-b193c2c9-ee37-4194-8b2d-6983a46a7515,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39952,DS-b193c2c9-ee37-4194-8b2d-6983a46a7515,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-e5ffd603-1505-4c8e-85cf-4bb68952be87,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-e5ffd603-1505-4c8e-85cf-4bb68952be87,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-b193c2c9-ee37-4194-8b2d-6983a46a7515,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39952,DS-b193c2c9-ee37-4194-8b2d-6983a46a7515,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-e5ffd603-1505-4c8e-85cf-4bb68952be87,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42898,DS-61280526-db2c-4337-910f-3a70652eae30,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-026cbb46-751e-4143-95e3-b7c6df6d2590,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34926,DS-026cbb46-751e-4143-95e3-b7c6df6d2590,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-61280526-db2c-4337-910f-3a70652eae30,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42898,DS-61280526-db2c-4337-910f-3a70652eae30,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-026cbb46-751e-4143-95e3-b7c6df6d2590,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34926,DS-026cbb46-751e-4143-95e3-b7c6df6d2590,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-61280526-db2c-4337-910f-3a70652eae30,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-5243dc17-d264-4761-a7b1-5d07b37c518d,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-9fa8589d-abe0-467e-bb3f-81381eaca0ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-5243dc17-d264-4761-a7b1-5d07b37c518d,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-9fa8589d-abe0-467e-bb3f-81381eaca0ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-5243dc17-d264-4761-a7b1-5d07b37c518d,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-9fa8589d-abe0-467e-bb3f-81381eaca0ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-5243dc17-d264-4761-a7b1-5d07b37c518d,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-9fa8589d-abe0-467e-bb3f-81381eaca0ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37215,DS-1e5c9bb8-c060-44e9-af6d-5fa90c3414d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-2c273ec2-2e1d-4efe-831e-12587f783577,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33522,DS-2c273ec2-2e1d-4efe-831e-12587f783577,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-1e5c9bb8-c060-44e9-af6d-5fa90c3414d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37215,DS-1e5c9bb8-c060-44e9-af6d-5fa90c3414d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-2c273ec2-2e1d-4efe-831e-12587f783577,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33522,DS-2c273ec2-2e1d-4efe-831e-12587f783577,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-1e5c9bb8-c060-44e9-af6d-5fa90c3414d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-cc9a4549-6811-4bfa-8cd4-f8b74f7160d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-b28917a0-052d-4d4a-8ae1-4bab597dcfc1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-cc9a4549-6811-4bfa-8cd4-f8b74f7160d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-b28917a0-052d-4d4a-8ae1-4bab597dcfc1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-cc9a4549-6811-4bfa-8cd4-f8b74f7160d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-b28917a0-052d-4d4a-8ae1-4bab597dcfc1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-cc9a4549-6811-4bfa-8cd4-f8b74f7160d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-b28917a0-052d-4d4a-8ae1-4bab597dcfc1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-e17957c4-5343-457f-a8ca-29e370ed63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-f09d0153-82a1-47ca-9ccc-a1c2cb0bc951,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-e17957c4-5343-457f-a8ca-29e370ed63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-f09d0153-82a1-47ca-9ccc-a1c2cb0bc951,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-e17957c4-5343-457f-a8ca-29e370ed63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-f09d0153-82a1-47ca-9ccc-a1c2cb0bc951,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-e17957c4-5343-457f-a8ca-29e370ed63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-f09d0153-82a1-47ca-9ccc-a1c2cb0bc951,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-6978933b-4ad7-42b8-a41e-54aa772830b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-a3793b18-8ac9-48df-bd17-c6f1c3f0af9e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-6978933b-4ad7-42b8-a41e-54aa772830b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-a3793b18-8ac9-48df-bd17-c6f1c3f0af9e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-6978933b-4ad7-42b8-a41e-54aa772830b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-a3793b18-8ac9-48df-bd17-c6f1c3f0af9e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-6978933b-4ad7-42b8-a41e-54aa772830b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-a3793b18-8ac9-48df-bd17-c6f1c3f0af9e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-ce7271cb-c1cd-4ba6-8320-ec280306f713,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-851b71aa-c27b-4bec-8429-9d8221eefa3a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-851b71aa-c27b-4bec-8429-9d8221eefa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-ce7271cb-c1cd-4ba6-8320-ec280306f713,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-ce7271cb-c1cd-4ba6-8320-ec280306f713,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-851b71aa-c27b-4bec-8429-9d8221eefa3a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-851b71aa-c27b-4bec-8429-9d8221eefa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-ce7271cb-c1cd-4ba6-8320-ec280306f713,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-400e5e01-2adf-43c1-9933-81b89e23c346,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-20f00610-8173-4750-a2db-a22ab9583294,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-400e5e01-2adf-43c1-9933-81b89e23c346,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-20f00610-8173-4750-a2db-a22ab9583294,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-400e5e01-2adf-43c1-9933-81b89e23c346,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-20f00610-8173-4750-a2db-a22ab9583294,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-400e5e01-2adf-43c1-9933-81b89e23c346,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-20f00610-8173-4750-a2db-a22ab9583294,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-04c9ec16-4853-4d3e-aa8d-28f53c3634a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-72bf8a38-e786-4288-8146-95737b44728e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-04c9ec16-4853-4d3e-aa8d-28f53c3634a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-72bf8a38-e786-4288-8146-95737b44728e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-04c9ec16-4853-4d3e-aa8d-28f53c3634a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-72bf8a38-e786-4288-8146-95737b44728e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-04c9ec16-4853-4d3e-aa8d-28f53c3634a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-72bf8a38-e786-4288-8146-95737b44728e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesSnapChecksumWithTrunkAndAppend
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-389486b6-20aa-4211-b602-80573ea82db9,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-f8c2577a-6e67-485f-9fe7-9ab1c2a3a8cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43734,DS-f8c2577a-6e67-485f-9fe7-9ab1c2a3a8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-389486b6-20aa-4211-b602-80573ea82db9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-389486b6-20aa-4211-b602-80573ea82db9,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-f8c2577a-6e67-485f-9fe7-9ab1c2a3a8cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43734,DS-f8c2577a-6e67-485f-9fe7-9ab1c2a3a8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-389486b6-20aa-4211-b602-80573ea82db9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 46 out of 50
v1v1v2v2 failed with probability 2 out of 50
result: might be true error
Total execution time in seconds : 3529
