reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609894510-172.17.0.19-1595681869050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40300,DS-cf582789-dc36-4566-a789-05954706b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-468d7f84-3168-41cd-9602-c2180d810e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-10cb1248-c0aa-43e4-aef0-3fc5ac3c19ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-5a8e0a3c-ba78-4685-bfbc-743868395349,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-dc56199a-ebf8-478c-9e77-52d6fe54dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-51867d74-55c0-432f-ac6a-537c0977e553,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-715b7f10-6bd4-4bfe-ae9d-94dca055f0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-b1875d05-d671-4569-b3b5-46b16e3d4a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609894510-172.17.0.19-1595681869050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40300,DS-cf582789-dc36-4566-a789-05954706b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-468d7f84-3168-41cd-9602-c2180d810e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-10cb1248-c0aa-43e4-aef0-3fc5ac3c19ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-5a8e0a3c-ba78-4685-bfbc-743868395349,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-dc56199a-ebf8-478c-9e77-52d6fe54dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-51867d74-55c0-432f-ac6a-537c0977e553,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-715b7f10-6bd4-4bfe-ae9d-94dca055f0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-b1875d05-d671-4569-b3b5-46b16e3d4a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046024739-172.17.0.19-1595681908413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33083,DS-910f3376-a500-4be5-9aad-af506387d334,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-ba5a3a27-573c-46aa-a6c2-662962baf2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-1b679aae-8d3e-4b87-bbbb-a182e56f6f47,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-0a1031a6-5bec-4198-aa59-c66010217189,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-529bb077-0d40-4bde-8e76-213ac5bb1e75,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-646ba9b9-adeb-4651-adc0-500c1fec9e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-aa1ba0bb-1ef8-4529-8978-559c870484c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-bbad251d-ed47-44c9-93d7-92c108784d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046024739-172.17.0.19-1595681908413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33083,DS-910f3376-a500-4be5-9aad-af506387d334,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-ba5a3a27-573c-46aa-a6c2-662962baf2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-1b679aae-8d3e-4b87-bbbb-a182e56f6f47,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-0a1031a6-5bec-4198-aa59-c66010217189,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-529bb077-0d40-4bde-8e76-213ac5bb1e75,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-646ba9b9-adeb-4651-adc0-500c1fec9e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-aa1ba0bb-1ef8-4529-8978-559c870484c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-bbad251d-ed47-44c9-93d7-92c108784d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881883341-172.17.0.19-1595682126133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44335,DS-cd3d0fb6-0970-4e13-82b0-3f1e420f9769,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-dc2b788d-958c-44b8-8e70-150fb9c8ef0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-10b3462b-aa89-40c5-b316-e4aaff414dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-5a08950b-add0-4d3e-b44b-600bf6eedb59,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-4fe8e891-f843-4e69-b936-76f9f59e78c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-461894c1-8ff5-4588-8f0d-40a11856b897,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-a6ef348c-6ff1-4072-92ed-48aa98a2fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-554cc8da-d104-4dce-93c1-6e39235d4ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881883341-172.17.0.19-1595682126133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44335,DS-cd3d0fb6-0970-4e13-82b0-3f1e420f9769,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-dc2b788d-958c-44b8-8e70-150fb9c8ef0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-10b3462b-aa89-40c5-b316-e4aaff414dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-5a08950b-add0-4d3e-b44b-600bf6eedb59,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-4fe8e891-f843-4e69-b936-76f9f59e78c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-461894c1-8ff5-4588-8f0d-40a11856b897,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-a6ef348c-6ff1-4072-92ed-48aa98a2fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-554cc8da-d104-4dce-93c1-6e39235d4ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901163092-172.17.0.19-1595682350227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43633,DS-8ef4a789-e2bb-470b-a256-4e94e8a9f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-81adf83c-5b02-4eb6-a416-63cee2f74958,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-af2467d1-5c7f-4733-ac71-6fbd6150f2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-bf654fd8-b008-43c9-a11e-60f0eb516e94,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-b64b0323-a33b-4536-bbe8-1f95de84c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-3fccad77-a277-47a6-b28e-717c218eada7,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-f1576114-759c-4fb6-95f2-ff7b8fcd2d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-a3526395-6e37-45c0-b537-953bd927ee2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901163092-172.17.0.19-1595682350227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43633,DS-8ef4a789-e2bb-470b-a256-4e94e8a9f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-81adf83c-5b02-4eb6-a416-63cee2f74958,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-af2467d1-5c7f-4733-ac71-6fbd6150f2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-bf654fd8-b008-43c9-a11e-60f0eb516e94,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-b64b0323-a33b-4536-bbe8-1f95de84c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-3fccad77-a277-47a6-b28e-717c218eada7,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-f1576114-759c-4fb6-95f2-ff7b8fcd2d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-a3526395-6e37-45c0-b537-953bd927ee2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531256711-172.17.0.19-1595682809157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37741,DS-d96c2974-d532-4e89-8c21-98bbff2195a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-2ff739fc-3a49-4cd7-860a-5f25122da661,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-91bb5ea2-0f63-4605-9bbb-99a558c54d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-e6570906-9a91-4776-b1ac-6a958c6cd334,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-46368f2b-65e8-4f1c-83d6-73faaa809334,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-00609fb8-defa-40ac-a761-9882d6046bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-f32ab7f0-a2e8-4ef4-8b00-9e383b2256a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-50a70b7d-007b-4bf4-96cf-f8bde76104f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531256711-172.17.0.19-1595682809157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37741,DS-d96c2974-d532-4e89-8c21-98bbff2195a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-2ff739fc-3a49-4cd7-860a-5f25122da661,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-91bb5ea2-0f63-4605-9bbb-99a558c54d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-e6570906-9a91-4776-b1ac-6a958c6cd334,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-46368f2b-65e8-4f1c-83d6-73faaa809334,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-00609fb8-defa-40ac-a761-9882d6046bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-f32ab7f0-a2e8-4ef4-8b00-9e383b2256a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-50a70b7d-007b-4bf4-96cf-f8bde76104f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486500052-172.17.0.19-1595682910795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-1dc348f1-dbd1-4342-bb12-57f5afe321e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-dc906c83-c754-4d25-8dee-38716199e2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-1cc55d1e-b322-4739-bb17-cf1d95967bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-c115e57e-bd9a-461c-ba52-ca5ade6614ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-934a969e-863a-4097-8d2b-87a955b49cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-6a2012e2-0266-4ddc-943f-6fd7341966a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-9e3e6fb0-85b3-4fd7-84e5-532b7f4433d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-0eddbd59-cb7b-4e67-b006-e6c2f882f592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486500052-172.17.0.19-1595682910795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-1dc348f1-dbd1-4342-bb12-57f5afe321e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-dc906c83-c754-4d25-8dee-38716199e2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-1cc55d1e-b322-4739-bb17-cf1d95967bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-c115e57e-bd9a-461c-ba52-ca5ade6614ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-934a969e-863a-4097-8d2b-87a955b49cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-6a2012e2-0266-4ddc-943f-6fd7341966a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-9e3e6fb0-85b3-4fd7-84e5-532b7f4433d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-0eddbd59-cb7b-4e67-b006-e6c2f882f592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120169515-172.17.0.19-1595682946636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-7b6c6747-4f5b-41dc-bf51-cca65216ecbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-1fd2af5f-a86d-426b-842e-115d5e834282,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-3cb94e35-73e0-420a-bcc2-f6cb24c55fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-77938b7b-a027-4282-851a-536158f2ff99,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-1ee3e3a5-3301-4f34-9669-c23c6e70c8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-3215233e-98e4-4895-adaa-db759bd4e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-60119964-6091-44e2-97ec-a9558886687f,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-deb85526-89c6-43a4-8186-0e1578d49251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120169515-172.17.0.19-1595682946636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-7b6c6747-4f5b-41dc-bf51-cca65216ecbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-1fd2af5f-a86d-426b-842e-115d5e834282,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-3cb94e35-73e0-420a-bcc2-f6cb24c55fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-77938b7b-a027-4282-851a-536158f2ff99,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-1ee3e3a5-3301-4f34-9669-c23c6e70c8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-3215233e-98e4-4895-adaa-db759bd4e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-60119964-6091-44e2-97ec-a9558886687f,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-deb85526-89c6-43a4-8186-0e1578d49251,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078442466-172.17.0.19-1595683262464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43967,DS-22066d58-cd18-4e8e-bcb8-4a298629aa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-3caa0585-60c2-453c-885a-a9d406f55255,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-2e2044b2-9dc5-4a6d-8a7f-cb913f1a1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-57b3f12a-1d47-4b67-a1ba-6620ec409470,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-ab158e0e-7c5d-43ea-9068-d813fba2ffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-7efdec2a-6eef-4e63-8b1d-4fe2e8d1bc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-f972c000-6b2c-4336-9ee2-41a6e4148185,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-4719af5b-b802-4233-a74c-91c78077f75f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078442466-172.17.0.19-1595683262464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43967,DS-22066d58-cd18-4e8e-bcb8-4a298629aa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-3caa0585-60c2-453c-885a-a9d406f55255,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-2e2044b2-9dc5-4a6d-8a7f-cb913f1a1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-57b3f12a-1d47-4b67-a1ba-6620ec409470,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-ab158e0e-7c5d-43ea-9068-d813fba2ffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-7efdec2a-6eef-4e63-8b1d-4fe2e8d1bc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-f972c000-6b2c-4336-9ee2-41a6e4148185,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-4719af5b-b802-4233-a74c-91c78077f75f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793574651-172.17.0.19-1595683908708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-71c0089d-9cd3-473f-853f-80825a3b819f,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-3dbb9d71-71c0-4294-83b2-b7224ac67870,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-94bcb5a9-c2d5-4513-bee4-2bee6f26ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-e72b979f-13f8-4f2b-8eac-5b9840e2a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-d97a6e01-29b9-4875-9420-f0bdbfe4c650,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-69b552fc-092a-40b6-a699-2fbeec514065,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-c4f54347-1fee-4142-ad31-a7c9d72ba588,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-5e74d83b-6f86-41ca-8235-e05051146348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793574651-172.17.0.19-1595683908708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-71c0089d-9cd3-473f-853f-80825a3b819f,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-3dbb9d71-71c0-4294-83b2-b7224ac67870,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-94bcb5a9-c2d5-4513-bee4-2bee6f26ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-e72b979f-13f8-4f2b-8eac-5b9840e2a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-d97a6e01-29b9-4875-9420-f0bdbfe4c650,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-69b552fc-092a-40b6-a699-2fbeec514065,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-c4f54347-1fee-4142-ad31-a7c9d72ba588,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-5e74d83b-6f86-41ca-8235-e05051146348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442444679-172.17.0.19-1595683943480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35485,DS-c4b72e23-a378-4fd6-81d5-42f4ff6b0de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-2c8ed4d6-db1c-48d0-8fc9-026ea941b7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-bfa849f3-cb19-4ea9-879e-3a2093368fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-32fbc9bf-77db-42dd-8f0a-8911bce88738,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-bec23a82-1ea3-40c3-86d4-6ad1fe91a814,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-ef72c6a1-4167-4e96-b16d-267892e77838,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-e651dd86-7ef0-4eea-85af-19ad1310156f,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-176b99ad-d4fa-408c-b2ff-8a2127e0cab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442444679-172.17.0.19-1595683943480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35485,DS-c4b72e23-a378-4fd6-81d5-42f4ff6b0de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-2c8ed4d6-db1c-48d0-8fc9-026ea941b7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-bfa849f3-cb19-4ea9-879e-3a2093368fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-32fbc9bf-77db-42dd-8f0a-8911bce88738,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-bec23a82-1ea3-40c3-86d4-6ad1fe91a814,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-ef72c6a1-4167-4e96-b16d-267892e77838,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-e651dd86-7ef0-4eea-85af-19ad1310156f,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-176b99ad-d4fa-408c-b2ff-8a2127e0cab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826575679-172.17.0.19-1595684282904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40283,DS-062068c7-2c72-4ee8-a532-aed419762b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-ea7eca32-1ec8-4774-bba9-09ae00891192,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-b59f6aaf-910f-49a6-856e-40c6e3024699,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-e619d214-b949-405d-813f-2038157dae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-0c4c7b9f-d4f4-4c77-a142-069fadfba830,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-83191f56-0921-4283-838f-ce2e04d0fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-2786b73f-b51f-4986-8736-2a887f7609fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-d308da88-1c6b-4ad3-9b74-cf024de31142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826575679-172.17.0.19-1595684282904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40283,DS-062068c7-2c72-4ee8-a532-aed419762b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-ea7eca32-1ec8-4774-bba9-09ae00891192,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-b59f6aaf-910f-49a6-856e-40c6e3024699,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-e619d214-b949-405d-813f-2038157dae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-0c4c7b9f-d4f4-4c77-a142-069fadfba830,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-83191f56-0921-4283-838f-ce2e04d0fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-2786b73f-b51f-4986-8736-2a887f7609fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-d308da88-1c6b-4ad3-9b74-cf024de31142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369141498-172.17.0.19-1595684506148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-f370acf0-2563-4131-8a7c-91f140bbadac,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-804daba9-9165-4dba-a213-51840ad033e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-787c0ac5-bda8-4d4f-b6c5-e485cce6f5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-7151d82d-d1b8-4f1c-b681-8970eeb6085d,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-499f36f2-c079-4d95-992f-223639ae8551,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-53ba4fd4-2d9b-4b16-b41c-1db1abf1fa15,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-dcf296d4-12a4-4050-af7f-d1f5a14c5bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-08e6046c-f191-442c-8a20-b5a89703aa3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369141498-172.17.0.19-1595684506148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-f370acf0-2563-4131-8a7c-91f140bbadac,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-804daba9-9165-4dba-a213-51840ad033e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-787c0ac5-bda8-4d4f-b6c5-e485cce6f5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-7151d82d-d1b8-4f1c-b681-8970eeb6085d,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-499f36f2-c079-4d95-992f-223639ae8551,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-53ba4fd4-2d9b-4b16-b41c-1db1abf1fa15,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-dcf296d4-12a4-4050-af7f-d1f5a14c5bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-08e6046c-f191-442c-8a20-b5a89703aa3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11296612-172.17.0.19-1595684546050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43144,DS-81456048-dc18-4438-85a0-33026b8a20fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-4f2e0520-646d-4a30-9d3a-f617f26579bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-c36027a7-80e9-4fdd-887f-5bbf12da269f,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-e06d5d7e-019c-4e53-9b0f-3bfb200e60d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-51186332-731a-4731-953a-c39860d70809,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-958f537e-6c59-4929-80b0-c54fb1c70e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-c462fb79-041d-47f0-bbf0-27896c564a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-8f9017bb-7711-48fb-9872-cd5a43e0ba1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11296612-172.17.0.19-1595684546050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43144,DS-81456048-dc18-4438-85a0-33026b8a20fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-4f2e0520-646d-4a30-9d3a-f617f26579bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-c36027a7-80e9-4fdd-887f-5bbf12da269f,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-e06d5d7e-019c-4e53-9b0f-3bfb200e60d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-51186332-731a-4731-953a-c39860d70809,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-958f537e-6c59-4929-80b0-c54fb1c70e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-c462fb79-041d-47f0-bbf0-27896c564a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-8f9017bb-7711-48fb-9872-cd5a43e0ba1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245819269-172.17.0.19-1595685175639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46274,DS-e1b49ddc-db0e-44f5-bbe0-6bbf5611c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-06e87079-2dd8-4e97-8dc2-f83ae054abe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-2fabd4ba-b8d7-4e03-8557-8c98d8c442b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-f0e9c326-7e33-4a56-a3f3-567da2f89d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-1ff4caa7-aec3-4453-9276-74d71353610e,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-97d0af5f-8fdd-4cd8-ae5b-09f6d8f50459,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-bcfb73c6-2c05-4520-bc4f-149203663c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-80b017dc-4765-49a6-9b18-969cf70075c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245819269-172.17.0.19-1595685175639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46274,DS-e1b49ddc-db0e-44f5-bbe0-6bbf5611c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-06e87079-2dd8-4e97-8dc2-f83ae054abe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-2fabd4ba-b8d7-4e03-8557-8c98d8c442b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-f0e9c326-7e33-4a56-a3f3-567da2f89d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-1ff4caa7-aec3-4453-9276-74d71353610e,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-97d0af5f-8fdd-4cd8-ae5b-09f6d8f50459,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-bcfb73c6-2c05-4520-bc4f-149203663c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-80b017dc-4765-49a6-9b18-969cf70075c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293251884-172.17.0.19-1595685955086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-06e6d71d-ebc0-412d-b574-e4a5cc7271da,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-36497a4c-2416-4ce1-a249-af47702fd654,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-8f762169-e358-45e8-a2d7-451a831ec8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-b0d3ec3d-9330-4890-a3af-bb22e426086d,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-44a1d5a5-3d0e-478f-8049-61e47b7fb2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-1c5e09f9-3489-4855-a11e-d8e8ef0b6ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-2b1bb2c4-af46-4401-9655-22140e6f8ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-c707cd53-6513-413d-a271-a4c8f3376322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293251884-172.17.0.19-1595685955086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-06e6d71d-ebc0-412d-b574-e4a5cc7271da,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-36497a4c-2416-4ce1-a249-af47702fd654,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-8f762169-e358-45e8-a2d7-451a831ec8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-b0d3ec3d-9330-4890-a3af-bb22e426086d,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-44a1d5a5-3d0e-478f-8049-61e47b7fb2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-1c5e09f9-3489-4855-a11e-d8e8ef0b6ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-2b1bb2c4-af46-4401-9655-22140e6f8ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-c707cd53-6513-413d-a271-a4c8f3376322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80058636-172.17.0.19-1595686213398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46017,DS-045a5f10-c0ee-4078-8cef-eb64cb845ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-a4f79ff8-a195-40f9-b05e-3a133ce00442,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-19b05314-8bd3-4251-8b69-3c329dac61eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-78327fcc-82cc-4b0d-b343-de3e7f4ce54f,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-c98681b0-bf0a-49d4-8048-a31e005d6d49,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-da8645d3-457a-4fec-b2f3-3c5ac15d36a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-8132d831-2cd1-4580-b4b3-d88581ee1bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-2216c77d-3e11-4d9e-8a53-70ae8d9b9324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80058636-172.17.0.19-1595686213398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46017,DS-045a5f10-c0ee-4078-8cef-eb64cb845ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-a4f79ff8-a195-40f9-b05e-3a133ce00442,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-19b05314-8bd3-4251-8b69-3c329dac61eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-78327fcc-82cc-4b0d-b343-de3e7f4ce54f,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-c98681b0-bf0a-49d4-8048-a31e005d6d49,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-da8645d3-457a-4fec-b2f3-3c5ac15d36a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-8132d831-2cd1-4580-b4b3-d88581ee1bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-2216c77d-3e11-4d9e-8a53-70ae8d9b9324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109446006-172.17.0.19-1595686251464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-a9dc3692-ada7-402b-8566-e6d613301cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-14221cdf-f1da-4538-800d-ab5e3d1efcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-5a011300-dc80-4ce6-bf83-a6ac8377a4df,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-9c1bb336-8f49-4457-8320-621b45e154d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-185cf4a9-cfab-4312-bc09-754c66faa2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-31999180-75ce-4d28-b5ec-5fde44479066,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-50fb8fac-1818-4aeb-b687-3184d3926ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-7e2d7c4c-f95f-4933-9b6c-7bce8bfc8b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109446006-172.17.0.19-1595686251464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-a9dc3692-ada7-402b-8566-e6d613301cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-14221cdf-f1da-4538-800d-ab5e3d1efcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-5a011300-dc80-4ce6-bf83-a6ac8377a4df,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-9c1bb336-8f49-4457-8320-621b45e154d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-185cf4a9-cfab-4312-bc09-754c66faa2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-31999180-75ce-4d28-b5ec-5fde44479066,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-50fb8fac-1818-4aeb-b687-3184d3926ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-7e2d7c4c-f95f-4933-9b6c-7bce8bfc8b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892520284-172.17.0.19-1595686286235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-75d8abdc-8e68-40f2-9f74-7dd3cc5590cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-0c331269-f3c4-46b2-8266-da418151eb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-d466fd93-0d84-4ee2-bc7c-bd9d398cd022,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-e2b9f992-d694-4395-9d59-4973dcf9d35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-e0851a80-7f08-4271-ae96-fccba733e4af,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-9e40bd62-0fe9-45ab-8d53-7291973092c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-3bdc8434-bc9e-4894-94d6-4878211636a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-7029eba3-6f28-44cd-b2a7-4ac339d5bf04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892520284-172.17.0.19-1595686286235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-75d8abdc-8e68-40f2-9f74-7dd3cc5590cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-0c331269-f3c4-46b2-8266-da418151eb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-d466fd93-0d84-4ee2-bc7c-bd9d398cd022,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-e2b9f992-d694-4395-9d59-4973dcf9d35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-e0851a80-7f08-4271-ae96-fccba733e4af,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-9e40bd62-0fe9-45ab-8d53-7291973092c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-3bdc8434-bc9e-4894-94d6-4878211636a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-7029eba3-6f28-44cd-b2a7-4ac339d5bf04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154490807-172.17.0.19-1595686354516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44609,DS-d17dc8b5-4b4d-46b9-bad3-2c319d83c24d,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-4167aba2-e3cd-4a7b-8fa1-fa1a09877713,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-377f0c06-4673-4276-a9e1-9173fc8fd700,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-cc25f0c8-7827-4c70-8cc3-2d2f60537793,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-fa811037-0bdf-440b-a723-7203222e39c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-07cfb9fd-476d-4af2-bf91-b10ea401ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-a22f3442-8ef0-42d5-aace-3d2f3496dfca,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-69dbc55e-fbb9-4ec1-9640-e20719582347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154490807-172.17.0.19-1595686354516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44609,DS-d17dc8b5-4b4d-46b9-bad3-2c319d83c24d,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-4167aba2-e3cd-4a7b-8fa1-fa1a09877713,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-377f0c06-4673-4276-a9e1-9173fc8fd700,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-cc25f0c8-7827-4c70-8cc3-2d2f60537793,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-fa811037-0bdf-440b-a723-7203222e39c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-07cfb9fd-476d-4af2-bf91-b10ea401ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-a22f3442-8ef0-42d5-aace-3d2f3496dfca,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-69dbc55e-fbb9-4ec1-9640-e20719582347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976212327-172.17.0.19-1595686681906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36287,DS-748e9536-df13-4bdf-8b6a-cf85fd6d9e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-c5b4bf00-72f5-4e45-bf72-eab0696cb075,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-4088c687-9076-40a9-a51e-8363dfabe2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-58f01df3-f311-41fd-8fa7-ec0cc430a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-69b8869b-733b-415b-8903-c99d57e3ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-c927a742-a41f-4866-9842-1ccfb904564a,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-1d0dd873-9296-4959-b4d7-3b9cff506b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-a9adce97-21e7-4d29-97c0-3bc33815ced9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976212327-172.17.0.19-1595686681906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36287,DS-748e9536-df13-4bdf-8b6a-cf85fd6d9e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-c5b4bf00-72f5-4e45-bf72-eab0696cb075,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-4088c687-9076-40a9-a51e-8363dfabe2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-58f01df3-f311-41fd-8fa7-ec0cc430a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-69b8869b-733b-415b-8903-c99d57e3ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-c927a742-a41f-4866-9842-1ccfb904564a,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-1d0dd873-9296-4959-b4d7-3b9cff506b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-a9adce97-21e7-4d29-97c0-3bc33815ced9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641220418-172.17.0.19-1595687053230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36907,DS-a1cb9bc4-74b1-4de2-ae54-8e9c1b1c01f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-8b67c644-7329-4395-b1bc-5481a4132189,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-ce7a4c76-732c-4b52-98a3-8d13da3b9680,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-157c45ed-d5dc-46c1-ba21-1ac18bf84733,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-7217d1bf-42e5-4267-b246-c394dbd27795,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-df5ff443-bd34-4a44-85bc-b8f5f9d5c6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-e7888f3f-e11c-4ce3-a52b-c4eb1bfa03e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-2e9d7c56-97ca-4040-b315-b0b5b8e97023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641220418-172.17.0.19-1595687053230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36907,DS-a1cb9bc4-74b1-4de2-ae54-8e9c1b1c01f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-8b67c644-7329-4395-b1bc-5481a4132189,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-ce7a4c76-732c-4b52-98a3-8d13da3b9680,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-157c45ed-d5dc-46c1-ba21-1ac18bf84733,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-7217d1bf-42e5-4267-b246-c394dbd27795,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-df5ff443-bd34-4a44-85bc-b8f5f9d5c6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-e7888f3f-e11c-4ce3-a52b-c4eb1bfa03e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-2e9d7c56-97ca-4040-b315-b0b5b8e97023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110326747-172.17.0.19-1595687237469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-b1629ebd-635a-4c84-a143-565f9aefb737,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-b589bf0d-ee96-468f-b20b-0bbf6b189b83,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-b5b185af-c358-4ae1-986d-56acbc35348b,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-2b67d366-f465-429f-8ffa-d422acbbf012,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-99be3eb7-6d22-49d0-9fa3-822436624c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-77700865-a4b8-4bcc-82ed-666a2badd40f,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-331dec6d-a804-4ff2-9090-effd6aca3386,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-46872e87-2ddd-449e-b768-a9b426ecb7f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110326747-172.17.0.19-1595687237469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-b1629ebd-635a-4c84-a143-565f9aefb737,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-b589bf0d-ee96-468f-b20b-0bbf6b189b83,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-b5b185af-c358-4ae1-986d-56acbc35348b,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-2b67d366-f465-429f-8ffa-d422acbbf012,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-99be3eb7-6d22-49d0-9fa3-822436624c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-77700865-a4b8-4bcc-82ed-666a2badd40f,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-331dec6d-a804-4ff2-9090-effd6aca3386,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-46872e87-2ddd-449e-b768-a9b426ecb7f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5478
