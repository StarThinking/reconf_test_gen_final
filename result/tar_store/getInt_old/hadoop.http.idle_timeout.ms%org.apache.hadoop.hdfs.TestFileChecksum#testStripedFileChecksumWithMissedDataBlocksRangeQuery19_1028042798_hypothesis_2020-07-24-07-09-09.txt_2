reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056589364-172.17.0.17-1595575132263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35332,DS-07ea289d-9776-49d5-8dc4-36557a5d4026,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-0fe233dc-9081-44ec-acda-fc5bc345ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-7f5a3abb-89eb-483d-8bfe-905446f027aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-f324334b-64e2-4171-afda-2380ee84684d,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-e7c6725e-850a-431a-9387-56ac280cd8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-778632e5-5437-4459-91a6-37c49e895513,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-53849baa-f0db-443b-b42b-62071f336c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-9c611b66-c580-4851-b25e-4c9a6c814d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056589364-172.17.0.17-1595575132263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35332,DS-07ea289d-9776-49d5-8dc4-36557a5d4026,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-0fe233dc-9081-44ec-acda-fc5bc345ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-7f5a3abb-89eb-483d-8bfe-905446f027aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-f324334b-64e2-4171-afda-2380ee84684d,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-e7c6725e-850a-431a-9387-56ac280cd8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-778632e5-5437-4459-91a6-37c49e895513,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-53849baa-f0db-443b-b42b-62071f336c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-9c611b66-c580-4851-b25e-4c9a6c814d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634949017-172.17.0.17-1595575173306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-83f9f889-9c8e-44bd-8177-693d2b4562e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-87595ab5-8af4-41eb-a0cd-83c8c5d55f99,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-d99fbe52-d5ed-4f56-9ed5-6dd6c5832a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-6d555e3b-8b6b-4527-bd81-b780d37cdd28,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-dc466f52-d318-406c-bbc6-f22bc3070f48,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-2b01f37d-83d1-40ef-a3f6-77bb0d313d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-92db2fe3-5125-4107-8768-12543ceb2602,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-d3ee68c5-65dc-43bf-81c1-0bd54373c490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634949017-172.17.0.17-1595575173306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-83f9f889-9c8e-44bd-8177-693d2b4562e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-87595ab5-8af4-41eb-a0cd-83c8c5d55f99,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-d99fbe52-d5ed-4f56-9ed5-6dd6c5832a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-6d555e3b-8b6b-4527-bd81-b780d37cdd28,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-dc466f52-d318-406c-bbc6-f22bc3070f48,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-2b01f37d-83d1-40ef-a3f6-77bb0d313d62,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-92db2fe3-5125-4107-8768-12543ceb2602,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-d3ee68c5-65dc-43bf-81c1-0bd54373c490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104317770-172.17.0.17-1595575725662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-7cbd778f-02f5-4f03-b586-74f9585a8126,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-33bd2b7d-5ef1-45c8-b5a2-cd8611725ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-361c7b7b-9206-4862-a897-7001c0a00676,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-8d8906ed-a5f4-4ea1-aba0-578005261a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-42e9c41b-d6f0-4a78-8696-a8a8a13e4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-21dad303-ac9d-4746-bf92-4cc4765fd046,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-6865d588-e808-44b9-8168-0e9288c90812,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-725ab3b7-055e-4316-a416-65e3f09c9f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104317770-172.17.0.17-1595575725662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-7cbd778f-02f5-4f03-b586-74f9585a8126,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-33bd2b7d-5ef1-45c8-b5a2-cd8611725ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-361c7b7b-9206-4862-a897-7001c0a00676,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-8d8906ed-a5f4-4ea1-aba0-578005261a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-42e9c41b-d6f0-4a78-8696-a8a8a13e4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-21dad303-ac9d-4746-bf92-4cc4765fd046,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-6865d588-e808-44b9-8168-0e9288c90812,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-725ab3b7-055e-4316-a416-65e3f09c9f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604304871-172.17.0.17-1595575758393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32986,DS-5a1ef17f-ea1e-448b-9732-1290450b63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-46f1b176-118b-4d8c-a334-850df27a3fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-c7512a54-cc60-4c4d-a4d5-4c1ec4158835,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-493020f5-b807-4098-9e1c-955c04628a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-1497f180-2bb5-4272-9704-2a5b180ba82e,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-649c0e66-5923-41df-ba37-3098aebad9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-72fd1799-1d51-4145-bb1e-826d0e48e352,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-aec7d9ba-e6e4-4bad-b1ac-304698103bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604304871-172.17.0.17-1595575758393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32986,DS-5a1ef17f-ea1e-448b-9732-1290450b63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-46f1b176-118b-4d8c-a334-850df27a3fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-c7512a54-cc60-4c4d-a4d5-4c1ec4158835,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-493020f5-b807-4098-9e1c-955c04628a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-1497f180-2bb5-4272-9704-2a5b180ba82e,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-649c0e66-5923-41df-ba37-3098aebad9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-72fd1799-1d51-4145-bb1e-826d0e48e352,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-aec7d9ba-e6e4-4bad-b1ac-304698103bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321892816-172.17.0.17-1595576646206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42455,DS-4487a44e-3af9-4e8c-bd07-de0e71f2ebf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-60fa4332-1ab7-40e7-be53-427b5b68ea18,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-8ed38da1-7af3-435b-964c-1e4ff1d55606,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-0631aa54-f492-46bc-82a7-86982cbd4f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-892dffeb-3c09-4480-ac8a-f19d45524d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-05ec6802-bb66-4be8-ba97-78c6347f1eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-a22184a5-2f76-44ab-b585-c930abe14b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-a6df9053-8b7b-4042-a940-7b2c8f6893cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321892816-172.17.0.17-1595576646206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42455,DS-4487a44e-3af9-4e8c-bd07-de0e71f2ebf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-60fa4332-1ab7-40e7-be53-427b5b68ea18,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-8ed38da1-7af3-435b-964c-1e4ff1d55606,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-0631aa54-f492-46bc-82a7-86982cbd4f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-892dffeb-3c09-4480-ac8a-f19d45524d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-05ec6802-bb66-4be8-ba97-78c6347f1eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-a22184a5-2f76-44ab-b585-c930abe14b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-a6df9053-8b7b-4042-a940-7b2c8f6893cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644420179-172.17.0.17-1595577492936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-706221ed-0fea-411f-9558-bffe1ef86f04,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-2573022e-9911-4ef2-b2cb-d895bdfc1e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-c3835d58-b432-4e07-ab8d-29893af9f953,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-1a480166-2d13-48d4-a5bf-7fc3e1964612,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-8053e07e-62d7-4b3e-b9d0-4956bb9a8a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-78782a53-d03c-4bab-a60b-4d6796da0b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-9692c283-6ee6-4007-b62c-4a913c4cd1de,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-a555f14b-3d00-4abe-8ac9-8982f378c865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644420179-172.17.0.17-1595577492936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42278,DS-706221ed-0fea-411f-9558-bffe1ef86f04,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-2573022e-9911-4ef2-b2cb-d895bdfc1e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-c3835d58-b432-4e07-ab8d-29893af9f953,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-1a480166-2d13-48d4-a5bf-7fc3e1964612,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-8053e07e-62d7-4b3e-b9d0-4956bb9a8a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-78782a53-d03c-4bab-a60b-4d6796da0b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-9692c283-6ee6-4007-b62c-4a913c4cd1de,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-a555f14b-3d00-4abe-8ac9-8982f378c865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564867827-172.17.0.17-1595577678873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37048,DS-71af93d5-28de-4e24-82e3-9921e1a19cda,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-f5d6b9d6-5c25-4b2e-9f10-5d8dea0e294c,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-4c2ab988-f7b6-4946-b00b-f255b84c0a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-50010a07-84c5-4256-8fb8-65c25da185f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-98966001-000a-4867-ad32-accbd8b52d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-7eaa11d5-34a0-4050-8069-794581775b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-9e0051b8-04fa-4cb1-bbb1-c02a18b1e77a,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-a54ef3a7-320b-421c-a4c0-091a48c59b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564867827-172.17.0.17-1595577678873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37048,DS-71af93d5-28de-4e24-82e3-9921e1a19cda,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-f5d6b9d6-5c25-4b2e-9f10-5d8dea0e294c,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-4c2ab988-f7b6-4946-b00b-f255b84c0a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-50010a07-84c5-4256-8fb8-65c25da185f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-98966001-000a-4867-ad32-accbd8b52d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-7eaa11d5-34a0-4050-8069-794581775b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-9e0051b8-04fa-4cb1-bbb1-c02a18b1e77a,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-a54ef3a7-320b-421c-a4c0-091a48c59b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858885098-172.17.0.17-1595578408896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-ed66626d-87b8-4131-92b7-ea3555e21fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-4805a7c2-f15e-440a-a0b5-ed612cb2a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-7835e009-4a14-45ee-85d9-933d8c1c779a,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-4065c1a1-1fa4-40ca-b950-296a86535a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-837c0760-72be-4eb5-91f8-04a72a19236a,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-ec2bb69e-7588-4205-af86-922c0a196c48,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-16131177-d222-4702-9846-ed74bea8e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-54089ae7-4606-4491-afc8-4bc37eea3731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858885098-172.17.0.17-1595578408896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-ed66626d-87b8-4131-92b7-ea3555e21fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-4805a7c2-f15e-440a-a0b5-ed612cb2a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-7835e009-4a14-45ee-85d9-933d8c1c779a,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-4065c1a1-1fa4-40ca-b950-296a86535a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-837c0760-72be-4eb5-91f8-04a72a19236a,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-ec2bb69e-7588-4205-af86-922c0a196c48,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-16131177-d222-4702-9846-ed74bea8e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-54089ae7-4606-4491-afc8-4bc37eea3731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661573602-172.17.0.17-1595578481752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-d943e038-16ad-43c5-9b45-16693c06de30,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-ca56819c-0e88-4ecd-8e4a-4af2d87a522e,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-e85c153f-c856-4903-ae6e-f38048e204e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-536cd0b3-709c-488f-95fd-ead180c2f325,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-cddedd3b-b5e3-49ed-a062-7878f2a8cfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-4a5360a5-f659-42b2-bcf8-d49f4faac0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-77e5d2ec-7355-47dd-a238-bb73119f41ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-715ab223-b971-4cde-9f42-34b561e78961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661573602-172.17.0.17-1595578481752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-d943e038-16ad-43c5-9b45-16693c06de30,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-ca56819c-0e88-4ecd-8e4a-4af2d87a522e,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-e85c153f-c856-4903-ae6e-f38048e204e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-536cd0b3-709c-488f-95fd-ead180c2f325,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-cddedd3b-b5e3-49ed-a062-7878f2a8cfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-4a5360a5-f659-42b2-bcf8-d49f4faac0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-77e5d2ec-7355-47dd-a238-bb73119f41ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-715ab223-b971-4cde-9f42-34b561e78961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306664479-172.17.0.17-1595578842241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40205,DS-afb9d948-a2de-4f1e-bb0d-6906dff17ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-ab908e39-5bb9-41ff-ade3-b29925ee0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-cbff24bc-6ce3-415e-b1b7-10f322770547,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-719962fc-7f61-497d-80d7-ceec5c1b0258,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-376461db-198b-4406-95f7-fc56a222f398,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-61f9f9b9-a131-4fd6-949e-e489c2685675,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-e6937fb5-dffb-4543-91a8-99ef5a090edc,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-276af77c-edb2-4cb3-a8dc-e4993adf8536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306664479-172.17.0.17-1595578842241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40205,DS-afb9d948-a2de-4f1e-bb0d-6906dff17ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-ab908e39-5bb9-41ff-ade3-b29925ee0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-cbff24bc-6ce3-415e-b1b7-10f322770547,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-719962fc-7f61-497d-80d7-ceec5c1b0258,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-376461db-198b-4406-95f7-fc56a222f398,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-61f9f9b9-a131-4fd6-949e-e489c2685675,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-e6937fb5-dffb-4543-91a8-99ef5a090edc,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-276af77c-edb2-4cb3-a8dc-e4993adf8536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723736443-172.17.0.17-1595579224055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37001,DS-14fea7ac-5e09-427f-8c24-16162b9826e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-e1fa7015-e955-4078-bfc8-51f80c07a32b,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-0c295391-fba1-480f-8472-17fc5ea5b159,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-ab32ec28-0227-4954-929c-2f3fb9340c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-a3157f4c-ee22-4417-b533-d9fad8277342,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-c146f50f-573d-4c4b-890e-0b59db1067ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-8e7ac4d4-3925-401c-9042-8fd66e9c2d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-3ee58e97-cb92-44e3-9a77-d1a97970bdde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723736443-172.17.0.17-1595579224055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37001,DS-14fea7ac-5e09-427f-8c24-16162b9826e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-e1fa7015-e955-4078-bfc8-51f80c07a32b,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-0c295391-fba1-480f-8472-17fc5ea5b159,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-ab32ec28-0227-4954-929c-2f3fb9340c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-a3157f4c-ee22-4417-b533-d9fad8277342,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-c146f50f-573d-4c4b-890e-0b59db1067ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-8e7ac4d4-3925-401c-9042-8fd66e9c2d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-3ee58e97-cb92-44e3-9a77-d1a97970bdde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666871260-172.17.0.17-1595579809295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-ac6b9788-bddb-4a3d-953e-ff5e80f50a44,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-4a7cd991-207a-44ec-b2f6-2e9f4c862edb,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-a3cdac16-e282-4e2b-b7f4-d106c4320712,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-488991b9-126a-4e67-8798-c9bd4d7a8f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-8141734d-73ff-47cd-84bd-502c87ec5421,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-7f35d194-f736-4b29-98ea-eff1bb9b262a,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-a9f823b7-9e27-4a37-bf08-d8ba714cd3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-0382d5a7-9992-4dd9-9e3d-966be3b99c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666871260-172.17.0.17-1595579809295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-ac6b9788-bddb-4a3d-953e-ff5e80f50a44,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-4a7cd991-207a-44ec-b2f6-2e9f4c862edb,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-a3cdac16-e282-4e2b-b7f4-d106c4320712,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-488991b9-126a-4e67-8798-c9bd4d7a8f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-8141734d-73ff-47cd-84bd-502c87ec5421,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-7f35d194-f736-4b29-98ea-eff1bb9b262a,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-a9f823b7-9e27-4a37-bf08-d8ba714cd3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-0382d5a7-9992-4dd9-9e3d-966be3b99c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5443
