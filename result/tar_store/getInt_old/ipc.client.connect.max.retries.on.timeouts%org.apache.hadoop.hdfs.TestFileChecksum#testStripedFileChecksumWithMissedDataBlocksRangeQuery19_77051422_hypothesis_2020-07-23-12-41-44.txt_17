reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658067225-172.17.0.9-1595508359506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-5b6ed906-2f1a-4d46-a5f6-474e508d8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-ba6f6e4b-fb6e-4b24-99cd-cb931de4d1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-5b1ba855-4634-4c11-928b-526a700cd7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-eea87621-1f0b-4bd0-9cca-1aa8e54587ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-f8fb0ce4-9c95-4a2d-b461-3ce92bbafc27,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-2e5d451c-9183-499a-9296-86a365eb8a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-43428c67-94ac-4b93-b880-36a211201cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-75add3c8-1bf0-415f-8268-e4dd525cda19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658067225-172.17.0.9-1595508359506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-5b6ed906-2f1a-4d46-a5f6-474e508d8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-ba6f6e4b-fb6e-4b24-99cd-cb931de4d1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-5b1ba855-4634-4c11-928b-526a700cd7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-eea87621-1f0b-4bd0-9cca-1aa8e54587ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-f8fb0ce4-9c95-4a2d-b461-3ce92bbafc27,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-2e5d451c-9183-499a-9296-86a365eb8a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-43428c67-94ac-4b93-b880-36a211201cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-75add3c8-1bf0-415f-8268-e4dd525cda19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761581476-172.17.0.9-1595509272530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-ebf22720-a979-4520-9693-1ffdfedcb10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-0e2911d9-8392-4194-9f07-6db656c659d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-a5d4592e-89a2-4b3b-b65f-e21ccc94b7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-910ffd25-a132-4b45-a9b2-499c8b57b90f,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-de8a4618-cec6-45c3-8d79-1f90400ac2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-99314a65-e0cf-45dc-b54b-366d24c9768b,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-1ee00ce5-2228-4bfe-85fc-c501086793fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-aa027372-f222-4c4a-8f24-4969ee878c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761581476-172.17.0.9-1595509272530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-ebf22720-a979-4520-9693-1ffdfedcb10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-0e2911d9-8392-4194-9f07-6db656c659d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-a5d4592e-89a2-4b3b-b65f-e21ccc94b7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-910ffd25-a132-4b45-a9b2-499c8b57b90f,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-de8a4618-cec6-45c3-8d79-1f90400ac2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-99314a65-e0cf-45dc-b54b-366d24c9768b,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-1ee00ce5-2228-4bfe-85fc-c501086793fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-aa027372-f222-4c4a-8f24-4969ee878c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964241898-172.17.0.9-1595510230981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42036,DS-353699c8-bfe9-4343-943d-2e8519be1c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-5ca76c6e-ab15-4be4-949b-820aa45e2d70,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-9642a925-5ab9-44b6-8c1d-f7fd56c4b082,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-668f698f-b028-41d7-9a34-2b08a489cc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-c76a712d-9874-4e27-a160-623df61ff3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-c33f2511-f660-4e3a-b1ce-cfd44e41c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-ad561bcd-423e-4846-925c-808ddb75d03e,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-6c839884-4538-4e27-8d7c-49e84229c90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964241898-172.17.0.9-1595510230981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42036,DS-353699c8-bfe9-4343-943d-2e8519be1c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-5ca76c6e-ab15-4be4-949b-820aa45e2d70,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-9642a925-5ab9-44b6-8c1d-f7fd56c4b082,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-668f698f-b028-41d7-9a34-2b08a489cc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-c76a712d-9874-4e27-a160-623df61ff3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-c33f2511-f660-4e3a-b1ce-cfd44e41c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-ad561bcd-423e-4846-925c-808ddb75d03e,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-6c839884-4538-4e27-8d7c-49e84229c90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860198793-172.17.0.9-1595510359115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44981,DS-2b04052b-2cae-490b-8f54-3e7341ff5ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-ef1a762e-d9f7-46d4-80b9-8dcbaf0d9674,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-7bff64be-1e95-496d-b3cf-dc5ae8f59914,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-4f1c6b9d-8474-4673-9d00-946cabd0d8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-5a12c5d6-e801-426e-a4f0-804a84014b81,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-7412ef25-5383-4f05-b13a-27dd507b17a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-c93f678d-89dd-4fa4-b327-1c386165cd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-16c7438b-faa5-491b-82ac-b8e6660bdbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860198793-172.17.0.9-1595510359115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44981,DS-2b04052b-2cae-490b-8f54-3e7341ff5ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-ef1a762e-d9f7-46d4-80b9-8dcbaf0d9674,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-7bff64be-1e95-496d-b3cf-dc5ae8f59914,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-4f1c6b9d-8474-4673-9d00-946cabd0d8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-5a12c5d6-e801-426e-a4f0-804a84014b81,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-7412ef25-5383-4f05-b13a-27dd507b17a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-c93f678d-89dd-4fa4-b327-1c386165cd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-16c7438b-faa5-491b-82ac-b8e6660bdbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012970854-172.17.0.9-1595511296051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-c43ad35a-7c02-4efa-b09d-ec59f6cdec76,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-8c61413f-d61a-4faa-9811-7b15c824d007,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-1b708998-e35a-4a21-8355-277f773adeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-80a425e7-50ac-4394-aa30-bed6d5297f36,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-7d8e424f-49e3-413b-aaf6-2e8e6746f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-46d98563-64de-4b6c-a33f-c39fc9a6e0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-55b36c83-bebb-4afc-bf76-d6e204808369,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-9d98f819-f2c5-47d4-8e05-cfd58daf5852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012970854-172.17.0.9-1595511296051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-c43ad35a-7c02-4efa-b09d-ec59f6cdec76,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-8c61413f-d61a-4faa-9811-7b15c824d007,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-1b708998-e35a-4a21-8355-277f773adeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-80a425e7-50ac-4394-aa30-bed6d5297f36,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-7d8e424f-49e3-413b-aaf6-2e8e6746f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-46d98563-64de-4b6c-a33f-c39fc9a6e0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-55b36c83-bebb-4afc-bf76-d6e204808369,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-9d98f819-f2c5-47d4-8e05-cfd58daf5852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216814136-172.17.0.9-1595511336793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41789,DS-c8584cc5-33c8-4a2d-b364-3e33ad0f50a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-ea40ddd6-b63d-4343-b702-df1d0335ec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-3d798e81-ffc1-4abf-8c48-47bae4d30563,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-bff11663-fbd1-4b9f-95c3-1518ccdedf35,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-f74c5061-1e8f-4f52-8429-b0c4d59a7dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-4030b3c4-41a8-4647-8a36-448bd15475d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-5e39a9cc-2030-4a4a-b5bb-0755f3f4c065,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-16865ff7-2ad3-4d9e-bd6f-d48d9578d87e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216814136-172.17.0.9-1595511336793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41789,DS-c8584cc5-33c8-4a2d-b364-3e33ad0f50a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-ea40ddd6-b63d-4343-b702-df1d0335ec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-3d798e81-ffc1-4abf-8c48-47bae4d30563,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-bff11663-fbd1-4b9f-95c3-1518ccdedf35,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-f74c5061-1e8f-4f52-8429-b0c4d59a7dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-4030b3c4-41a8-4647-8a36-448bd15475d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-5e39a9cc-2030-4a4a-b5bb-0755f3f4c065,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-16865ff7-2ad3-4d9e-bd6f-d48d9578d87e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97031144-172.17.0.9-1595511469916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-6e558bbd-b131-4dd5-bcb9-d07faec86f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-82280b7d-7cf6-4c68-b65c-73b089714324,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-2023c1dc-9fbb-4d02-b1fe-1a49cb1a3415,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-a27c7cfe-d11d-48b7-af95-2659e897123b,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-e71e87f9-c488-4ba2-a94e-e1c10c1fa0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-4c38e72f-c723-4471-9aa3-22b978371061,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-c7c2819f-8ccf-4da9-b9d4-de1e64ab96af,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-53f6a88a-f178-4e83-999c-5a5f9f5b0a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97031144-172.17.0.9-1595511469916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-6e558bbd-b131-4dd5-bcb9-d07faec86f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-82280b7d-7cf6-4c68-b65c-73b089714324,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-2023c1dc-9fbb-4d02-b1fe-1a49cb1a3415,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-a27c7cfe-d11d-48b7-af95-2659e897123b,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-e71e87f9-c488-4ba2-a94e-e1c10c1fa0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-4c38e72f-c723-4471-9aa3-22b978371061,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-c7c2819f-8ccf-4da9-b9d4-de1e64ab96af,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-53f6a88a-f178-4e83-999c-5a5f9f5b0a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134450181-172.17.0.9-1595512526750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-69a1465c-4324-4270-9c50-9560d0f429b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-bdad27a7-6988-4bbf-9426-802203b37359,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-dc6139c0-9594-4c5d-9821-20cb7e71521b,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-eb70ba1c-0de3-487d-b18c-e7e0741d6e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-eed7f579-bc81-4239-8e6b-9bbde1089e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-c64f30e3-023f-4afc-91c8-59572da0fab8,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-80018577-2232-4347-aaba-7256b514175e,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-cc3d82d0-c37a-4045-b033-d11620356b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134450181-172.17.0.9-1595512526750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-69a1465c-4324-4270-9c50-9560d0f429b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-bdad27a7-6988-4bbf-9426-802203b37359,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-dc6139c0-9594-4c5d-9821-20cb7e71521b,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-eb70ba1c-0de3-487d-b18c-e7e0741d6e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-eed7f579-bc81-4239-8e6b-9bbde1089e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-c64f30e3-023f-4afc-91c8-59572da0fab8,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-80018577-2232-4347-aaba-7256b514175e,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-cc3d82d0-c37a-4045-b033-d11620356b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045101358-172.17.0.9-1595512701029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34644,DS-8625d51b-8b62-4f39-8407-13756d0ceb69,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-f167ce6f-321e-4933-98ee-5e23ac9e8fff,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-b7cb8da5-0e28-447a-905a-e1e8d5d74b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-81cce18e-e3ae-42a2-b962-4fa38996422e,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-0e9e972f-f47f-430f-9306-83e3caa5b575,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-b562cb4e-a57f-43c6-88c6-aca909095a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-18dc639e-a684-40de-929a-3cb024b06478,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-30e30a76-90a6-4b68-9f98-69e1250eaad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045101358-172.17.0.9-1595512701029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34644,DS-8625d51b-8b62-4f39-8407-13756d0ceb69,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-f167ce6f-321e-4933-98ee-5e23ac9e8fff,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-b7cb8da5-0e28-447a-905a-e1e8d5d74b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-81cce18e-e3ae-42a2-b962-4fa38996422e,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-0e9e972f-f47f-430f-9306-83e3caa5b575,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-b562cb4e-a57f-43c6-88c6-aca909095a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-18dc639e-a684-40de-929a-3cb024b06478,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-30e30a76-90a6-4b68-9f98-69e1250eaad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979898800-172.17.0.9-1595513543627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40744,DS-1daaa982-30aa-4170-ae5e-4e915519de9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-4ab45e56-a620-4bb2-b67d-47a359992524,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-62f2eb50-d0ad-43ab-817d-dba6d4deb56f,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-61552565-ff35-48ad-8fcd-76fee5134a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-790b3249-7873-4c06-a7ca-0db2b199108e,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-173b560b-e3de-4729-8ce3-550ba1b621f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-8cc6301d-d37c-490c-a8f4-18db6aa4de4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-1acb0fd4-09e2-42c5-ba92-0c263e67eb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979898800-172.17.0.9-1595513543627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40744,DS-1daaa982-30aa-4170-ae5e-4e915519de9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-4ab45e56-a620-4bb2-b67d-47a359992524,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-62f2eb50-d0ad-43ab-817d-dba6d4deb56f,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-61552565-ff35-48ad-8fcd-76fee5134a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-790b3249-7873-4c06-a7ca-0db2b199108e,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-173b560b-e3de-4729-8ce3-550ba1b621f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-8cc6301d-d37c-490c-a8f4-18db6aa4de4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-1acb0fd4-09e2-42c5-ba92-0c263e67eb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460110741-172.17.0.9-1595513588558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-bb55b0b4-b553-43d1-b337-417a098101fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-3a3c7757-327f-413e-910e-aad78dde0aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-0c1a976d-b835-486a-b01f-781096fe1720,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-22db75b8-34ae-4fc1-84d4-8f0ad95569b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-9f58473e-6196-47ad-ba8c-4cac4de406d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-d08a7220-b5b0-4ed7-b1f8-5b1c298e5688,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-8b0c5947-3814-490d-a0dc-6539d254088b,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-b485f111-e7ca-4b34-b39c-67956500f147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460110741-172.17.0.9-1595513588558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-bb55b0b4-b553-43d1-b337-417a098101fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-3a3c7757-327f-413e-910e-aad78dde0aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-0c1a976d-b835-486a-b01f-781096fe1720,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-22db75b8-34ae-4fc1-84d4-8f0ad95569b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-9f58473e-6196-47ad-ba8c-4cac4de406d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-d08a7220-b5b0-4ed7-b1f8-5b1c298e5688,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-8b0c5947-3814-490d-a0dc-6539d254088b,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-b485f111-e7ca-4b34-b39c-67956500f147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46954698-172.17.0.9-1595513629269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-967321e1-3bd0-4381-8fd0-534d1ec921d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-42f44402-9a34-41c8-b0cc-b2b3b0ee6ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-c06bc432-1fda-4e12-aa6a-55d1ca15d10d,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-355616c4-e58b-42ec-b65d-2de16c9908bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-377fe63a-5067-4066-968e-5d5114856ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-6271cf40-b626-4f1f-b3a2-3dee7f8ba244,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-629a58be-7202-4118-ac0d-a04a4ee81d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-a006b35f-e48c-46b5-81ce-dc02e054f023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46954698-172.17.0.9-1595513629269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-967321e1-3bd0-4381-8fd0-534d1ec921d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-42f44402-9a34-41c8-b0cc-b2b3b0ee6ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-c06bc432-1fda-4e12-aa6a-55d1ca15d10d,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-355616c4-e58b-42ec-b65d-2de16c9908bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-377fe63a-5067-4066-968e-5d5114856ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-6271cf40-b626-4f1f-b3a2-3dee7f8ba244,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-629a58be-7202-4118-ac0d-a04a4ee81d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-a006b35f-e48c-46b5-81ce-dc02e054f023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033196453-172.17.0.9-1595513721934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-2b37ac52-e617-4426-bf9e-597fe0179e47,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-df07ccf7-a6a4-4325-a0c6-dfa61fa9dfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-a5a4714f-1a7a-4f7f-a212-e1ca7fc4b404,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-ce5d7775-bdcb-4f52-a7de-7a1298aabb65,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-c6259545-cb50-45c5-95e7-617b32cda39a,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-2456729a-9580-4c25-80f7-66b4a276244b,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-aa7c173b-11b9-40fb-902d-1a35ee409223,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-63b1012f-a01e-4a57-b11f-8f7af660e9ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033196453-172.17.0.9-1595513721934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-2b37ac52-e617-4426-bf9e-597fe0179e47,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-df07ccf7-a6a4-4325-a0c6-dfa61fa9dfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-a5a4714f-1a7a-4f7f-a212-e1ca7fc4b404,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-ce5d7775-bdcb-4f52-a7de-7a1298aabb65,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-c6259545-cb50-45c5-95e7-617b32cda39a,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-2456729a-9580-4c25-80f7-66b4a276244b,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-aa7c173b-11b9-40fb-902d-1a35ee409223,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-63b1012f-a01e-4a57-b11f-8f7af660e9ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102373983-172.17.0.9-1595514269347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45216,DS-e898ee97-f325-4a2d-ab89-462ac263a25d,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-daf52217-9944-449b-bd24-b1ff79f5dfac,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-6e24e32e-567d-4e09-9821-a3ff4ff78ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-2fe0374e-5a02-4073-a38e-63aba8dce1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-1a79aa88-4989-446c-a582-20f733a8d139,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-1aa29905-befb-40cb-8504-80c4c1aee107,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-f35d83a2-366a-4eb2-a65d-8b3a431c0871,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-9f5df0be-b085-4396-aa6d-2808fb77364f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102373983-172.17.0.9-1595514269347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45216,DS-e898ee97-f325-4a2d-ab89-462ac263a25d,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-daf52217-9944-449b-bd24-b1ff79f5dfac,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-6e24e32e-567d-4e09-9821-a3ff4ff78ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-2fe0374e-5a02-4073-a38e-63aba8dce1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-1a79aa88-4989-446c-a582-20f733a8d139,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-1aa29905-befb-40cb-8504-80c4c1aee107,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-f35d83a2-366a-4eb2-a65d-8b3a431c0871,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-9f5df0be-b085-4396-aa6d-2808fb77364f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722161433-172.17.0.9-1595514572542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35162,DS-6cfd57fd-4abb-410f-b146-6a49b5fa89dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-2b7eda48-4c7a-40a1-bf0a-f1660d290f40,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-02199077-0d77-45ec-863e-336b2bbfa484,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-eef272f8-3aac-4ef9-b2d3-fa01dd2dce12,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-8813f974-9445-415b-ab8d-a74947058098,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-bd54c891-4e81-4b06-a11f-880936c98f53,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-8d598ba3-080a-4c9c-a251-f884e83db20d,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-d2f90484-ef23-43bb-acfb-9e9601129620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722161433-172.17.0.9-1595514572542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35162,DS-6cfd57fd-4abb-410f-b146-6a49b5fa89dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-2b7eda48-4c7a-40a1-bf0a-f1660d290f40,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-02199077-0d77-45ec-863e-336b2bbfa484,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-eef272f8-3aac-4ef9-b2d3-fa01dd2dce12,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-8813f974-9445-415b-ab8d-a74947058098,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-bd54c891-4e81-4b06-a11f-880936c98f53,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-8d598ba3-080a-4c9c-a251-f884e83db20d,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-d2f90484-ef23-43bb-acfb-9e9601129620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6632
