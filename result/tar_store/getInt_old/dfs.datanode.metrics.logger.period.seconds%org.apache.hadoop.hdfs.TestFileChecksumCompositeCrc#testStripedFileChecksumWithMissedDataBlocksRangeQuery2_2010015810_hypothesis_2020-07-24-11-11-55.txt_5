reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266286814-172.17.0.19-1595589273885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36613,DS-1bde2483-0d95-427f-b2d6-ad81889cc6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-14c78666-0a8c-4959-ba37-b842c1bee7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-dd7d1ac1-178d-4518-a777-ce34f12bbc49,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-aace5d5d-5a97-4fec-99b8-553b0ca633e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-4bc95cdf-5e11-4161-9a64-ea830fa2579a,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-1f7df946-c090-4919-aaed-53dec7cbb4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-964cf95d-f30e-40c8-ad8a-5faedfe2f19b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-b01262ed-7739-443f-bef1-7201aa22b40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266286814-172.17.0.19-1595589273885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36613,DS-1bde2483-0d95-427f-b2d6-ad81889cc6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-14c78666-0a8c-4959-ba37-b842c1bee7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-dd7d1ac1-178d-4518-a777-ce34f12bbc49,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-aace5d5d-5a97-4fec-99b8-553b0ca633e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-4bc95cdf-5e11-4161-9a64-ea830fa2579a,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-1f7df946-c090-4919-aaed-53dec7cbb4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-964cf95d-f30e-40c8-ad8a-5faedfe2f19b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-b01262ed-7739-443f-bef1-7201aa22b40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386101542-172.17.0.19-1595589351807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33116,DS-bfdcd380-240a-484f-a504-4c86d1dc63ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-d7e8bb12-e541-45f3-a4c7-d4ac43544ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-677f0a53-10f6-4b8c-8d6a-c9cba7b703de,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-fd56bd4a-5004-433e-a705-0d766efb3089,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-689b1d93-634d-431d-8409-41eef7d5e804,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-d684a180-12cc-40d8-ac24-184180ded08f,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-b988af53-4c1e-441a-a44c-bb453c7685d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-9af87227-71d5-401a-879a-02da68604ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386101542-172.17.0.19-1595589351807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33116,DS-bfdcd380-240a-484f-a504-4c86d1dc63ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-d7e8bb12-e541-45f3-a4c7-d4ac43544ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-677f0a53-10f6-4b8c-8d6a-c9cba7b703de,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-fd56bd4a-5004-433e-a705-0d766efb3089,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-689b1d93-634d-431d-8409-41eef7d5e804,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-d684a180-12cc-40d8-ac24-184180ded08f,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-b988af53-4c1e-441a-a44c-bb453c7685d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-9af87227-71d5-401a-879a-02da68604ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616161759-172.17.0.19-1595589386097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41825,DS-48c91e49-532f-4610-b526-27d0be63c104,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-96ce6dbf-505d-4134-9324-d180e295a70b,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-c49dd5b0-1b50-474d-991c-9be3a92dde73,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-92bba491-486c-49f0-9d87-b3570d2faaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-85d34cfd-03b1-4161-9a9d-7b3963c879d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-842510ea-bbda-45bc-8632-c34f0d7f852a,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-6ae90583-c825-4d66-bf69-9c68e83702ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-126e1887-11f3-4ceb-ad37-d5336a3217d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616161759-172.17.0.19-1595589386097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41825,DS-48c91e49-532f-4610-b526-27d0be63c104,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-96ce6dbf-505d-4134-9324-d180e295a70b,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-c49dd5b0-1b50-474d-991c-9be3a92dde73,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-92bba491-486c-49f0-9d87-b3570d2faaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-85d34cfd-03b1-4161-9a9d-7b3963c879d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-842510ea-bbda-45bc-8632-c34f0d7f852a,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-6ae90583-c825-4d66-bf69-9c68e83702ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-126e1887-11f3-4ceb-ad37-d5336a3217d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507188321-172.17.0.19-1595590212546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-aac76e18-eefb-47c6-9acb-270d0b67c3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-3bc374c5-71d5-4319-9ca1-f0942ab8ca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-c62e6d83-d7a3-4a29-8cc1-89a921a6d735,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-d92cf684-7170-4c3b-8540-007112414d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-4ed195d2-f281-405c-91a2-a706cafd2e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-4363df2f-c795-459d-b8dd-1ee02abc1022,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-2ca0f900-48dc-4173-8b32-d81272ac048e,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-c9b876c8-c865-4df8-ba8b-f5a86dbca2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507188321-172.17.0.19-1595590212546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-aac76e18-eefb-47c6-9acb-270d0b67c3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-3bc374c5-71d5-4319-9ca1-f0942ab8ca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-c62e6d83-d7a3-4a29-8cc1-89a921a6d735,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-d92cf684-7170-4c3b-8540-007112414d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-4ed195d2-f281-405c-91a2-a706cafd2e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-4363df2f-c795-459d-b8dd-1ee02abc1022,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-2ca0f900-48dc-4173-8b32-d81272ac048e,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-c9b876c8-c865-4df8-ba8b-f5a86dbca2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211936281-172.17.0.19-1595590702588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45194,DS-45c3e206-3321-4165-a6a1-7fd396ebd8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b6aac771-b243-40db-be8e-d6caa9f0135b,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-c5317736-7784-406c-a288-5d1f0c4592c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-59389409-470d-46a2-8c78-1daa2d4a526f,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-a04ca0af-a6a8-4498-abd1-a61ab0de60ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-6d0bc735-edd8-494b-a3c8-f3edd2ec290d,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-f4bb47ee-2ea8-4a4f-88b8-1cdcacdfeed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-c6ab9e64-2f64-4927-8139-a7438ae290d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211936281-172.17.0.19-1595590702588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45194,DS-45c3e206-3321-4165-a6a1-7fd396ebd8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b6aac771-b243-40db-be8e-d6caa9f0135b,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-c5317736-7784-406c-a288-5d1f0c4592c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-59389409-470d-46a2-8c78-1daa2d4a526f,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-a04ca0af-a6a8-4498-abd1-a61ab0de60ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-6d0bc735-edd8-494b-a3c8-f3edd2ec290d,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-f4bb47ee-2ea8-4a4f-88b8-1cdcacdfeed6,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-c6ab9e64-2f64-4927-8139-a7438ae290d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438521779-172.17.0.19-1595590778748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35600,DS-9b92c21d-55b9-41a7-ac3a-c81735dfb883,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-eb39507f-ddb0-4a4c-a064-8238cbd99b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-ec175c71-26ee-40ac-9293-cae6b0b754b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-c159769d-623c-4ccf-831a-d7b35eca08ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-2d9eeb54-d73e-4a02-8d83-f0e596e73f60,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f5d3441d-83d3-42a1-b31a-e3985bc999a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-bce32e7f-11af-4c67-940e-4bf0617b2dba,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-716dce22-77be-4ac0-a015-d86c2bf068b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438521779-172.17.0.19-1595590778748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35600,DS-9b92c21d-55b9-41a7-ac3a-c81735dfb883,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-eb39507f-ddb0-4a4c-a064-8238cbd99b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-ec175c71-26ee-40ac-9293-cae6b0b754b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-c159769d-623c-4ccf-831a-d7b35eca08ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-2d9eeb54-d73e-4a02-8d83-f0e596e73f60,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f5d3441d-83d3-42a1-b31a-e3985bc999a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-bce32e7f-11af-4c67-940e-4bf0617b2dba,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-716dce22-77be-4ac0-a015-d86c2bf068b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760592012-172.17.0.19-1595590817033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35720,DS-475ec83f-2f27-476d-97dd-8560a0fe9b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-ee9a8c5a-12f4-47b7-969a-c555e6ed4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-7abfc4a5-3e9b-4dab-8da0-4cb309f97db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-152fd7a2-b581-4aca-8909-a3839106f743,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-c7108ab3-d121-433d-a83c-ad4836ae23b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-c315af52-0bf9-452f-84c8-bb96cce74c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-92975c3b-a09d-48f8-bd91-af23595ca504,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-7c981a75-75a4-419b-9784-e264be84681b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760592012-172.17.0.19-1595590817033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35720,DS-475ec83f-2f27-476d-97dd-8560a0fe9b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-ee9a8c5a-12f4-47b7-969a-c555e6ed4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-7abfc4a5-3e9b-4dab-8da0-4cb309f97db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-152fd7a2-b581-4aca-8909-a3839106f743,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-c7108ab3-d121-433d-a83c-ad4836ae23b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-c315af52-0bf9-452f-84c8-bb96cce74c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-92975c3b-a09d-48f8-bd91-af23595ca504,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-7c981a75-75a4-419b-9784-e264be84681b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459011140-172.17.0.19-1595591436960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38364,DS-ca78a353-9979-4299-a5f4-986b4eabcbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-357db9a3-ae7c-49c6-b5b4-713d25d98d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-801f7bbf-ff12-4785-9322-ca07007dcf77,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-fe70dafc-62f7-4cf8-988e-51fce027ea30,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-e45067cf-feee-4b7d-8d3e-44eef26d2efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-9980ad49-3331-400e-99cd-4cd2ba91ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-7286afc7-29bb-4db0-afe5-7e0e6751a373,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-27c22a04-cd25-41ec-bd1d-1b84d5decb13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459011140-172.17.0.19-1595591436960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38364,DS-ca78a353-9979-4299-a5f4-986b4eabcbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-357db9a3-ae7c-49c6-b5b4-713d25d98d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-801f7bbf-ff12-4785-9322-ca07007dcf77,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-fe70dafc-62f7-4cf8-988e-51fce027ea30,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-e45067cf-feee-4b7d-8d3e-44eef26d2efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-9980ad49-3331-400e-99cd-4cd2ba91ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-7286afc7-29bb-4db0-afe5-7e0e6751a373,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-27c22a04-cd25-41ec-bd1d-1b84d5decb13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093166914-172.17.0.19-1595591470083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36040,DS-0949386d-9375-4e9c-b05a-00babb64bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-3302bf4b-861d-443c-a5d6-5caadeebfe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-9998a666-35d0-40e6-b4d4-5dfe210ae558,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-77c887d2-0f01-4268-af67-5eced9159158,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-f57669f6-258c-4ab8-a4fa-32a4bc8fc10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-4f2cfbbe-89c4-4b6b-afd1-a2dcba878ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-85f9d4b9-a373-4a3c-94e1-bbdf04cb6a90,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-fdbd3226-41d7-4862-8812-d9cdeef1ed00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093166914-172.17.0.19-1595591470083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36040,DS-0949386d-9375-4e9c-b05a-00babb64bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-3302bf4b-861d-443c-a5d6-5caadeebfe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-9998a666-35d0-40e6-b4d4-5dfe210ae558,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-77c887d2-0f01-4268-af67-5eced9159158,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-f57669f6-258c-4ab8-a4fa-32a4bc8fc10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-4f2cfbbe-89c4-4b6b-afd1-a2dcba878ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-85f9d4b9-a373-4a3c-94e1-bbdf04cb6a90,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-fdbd3226-41d7-4862-8812-d9cdeef1ed00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281874741-172.17.0.19-1595591622816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39185,DS-d19bf815-c4b1-443f-b74a-c9e6e89380ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-eb61889f-d9ef-479b-acba-63f5b30216d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-25d5bae1-44a0-4d56-8a5a-08064825facf,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-c27c52bd-25ce-4446-9972-1157445753ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-96c2816e-0e09-4c2d-ac5a-beffe91baa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-00b2c4b2-3fe9-4f49-acfa-4da954edd86e,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-bc0b6691-4509-4dae-8487-548e705aa925,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-62dab904-f4a1-44fc-977c-83329dd1a27f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281874741-172.17.0.19-1595591622816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39185,DS-d19bf815-c4b1-443f-b74a-c9e6e89380ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-eb61889f-d9ef-479b-acba-63f5b30216d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-25d5bae1-44a0-4d56-8a5a-08064825facf,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-c27c52bd-25ce-4446-9972-1157445753ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-96c2816e-0e09-4c2d-ac5a-beffe91baa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-00b2c4b2-3fe9-4f49-acfa-4da954edd86e,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-bc0b6691-4509-4dae-8487-548e705aa925,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-62dab904-f4a1-44fc-977c-83329dd1a27f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190244544-172.17.0.19-1595591779824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-18565fbb-af26-4a40-bb76-4c0249b0bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b76acadf-6d74-41a4-b1f9-b12ce0836ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-5eea251e-578c-4ca3-ad6f-c0aaca868642,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-d10dcc8c-42c2-490f-b0e3-479938f226e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-94fa1bfe-161c-4e9f-b50f-bbb1b25c0a80,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-56e34e93-d761-420e-9d9c-39f3eebe40a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-bc56c83e-9972-4fe2-b41b-69ff2b69e3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-729e236a-c5e5-4cb5-b322-7d4f5693e0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190244544-172.17.0.19-1595591779824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-18565fbb-af26-4a40-bb76-4c0249b0bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b76acadf-6d74-41a4-b1f9-b12ce0836ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-5eea251e-578c-4ca3-ad6f-c0aaca868642,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-d10dcc8c-42c2-490f-b0e3-479938f226e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-94fa1bfe-161c-4e9f-b50f-bbb1b25c0a80,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-56e34e93-d761-420e-9d9c-39f3eebe40a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-bc56c83e-9972-4fe2-b41b-69ff2b69e3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-729e236a-c5e5-4cb5-b322-7d4f5693e0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291978321-172.17.0.19-1595591931060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-5661d689-bd09-4d63-8919-30a8ecc2d640,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-45304421-fd1a-4bf6-90ca-6d5197202f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-3b07928b-5ab8-4a8d-9434-5a266d0ce9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-bfa40d34-cbe4-4db3-be4e-e7ecccc5dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-0f121687-8d20-4a88-ab85-fbc54d2a8645,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-f35d2326-3a9f-432c-98d5-01d9eed39476,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-7309db2a-3a7a-4346-a444-9b7273f324bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-eb96943a-b8f7-4d80-a048-ad6d63ea1b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291978321-172.17.0.19-1595591931060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-5661d689-bd09-4d63-8919-30a8ecc2d640,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-45304421-fd1a-4bf6-90ca-6d5197202f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-3b07928b-5ab8-4a8d-9434-5a266d0ce9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-bfa40d34-cbe4-4db3-be4e-e7ecccc5dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-0f121687-8d20-4a88-ab85-fbc54d2a8645,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-f35d2326-3a9f-432c-98d5-01d9eed39476,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-7309db2a-3a7a-4346-a444-9b7273f324bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-eb96943a-b8f7-4d80-a048-ad6d63ea1b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722474218-172.17.0.19-1595591969804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-142652cf-2af5-4cb0-8886-f278aa5f4284,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-c5c4b438-d5c5-4fcd-83f6-77460de2a816,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-6b91d82e-dc41-43cb-88db-9392960ce5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-7abbc01c-df6f-42d0-85ec-8e4e31002d59,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-fe32417b-523b-465e-9ea6-f3c88898c388,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-82aefa6e-b504-4b3a-b4aa-8d50a88fb4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-456a1bad-7194-4cbe-8acb-164b02edef60,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-2a6a5b0e-2eb8-4c0b-aca8-83a4988412e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722474218-172.17.0.19-1595591969804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-142652cf-2af5-4cb0-8886-f278aa5f4284,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-c5c4b438-d5c5-4fcd-83f6-77460de2a816,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-6b91d82e-dc41-43cb-88db-9392960ce5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-7abbc01c-df6f-42d0-85ec-8e4e31002d59,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-fe32417b-523b-465e-9ea6-f3c88898c388,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-82aefa6e-b504-4b3a-b4aa-8d50a88fb4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-456a1bad-7194-4cbe-8acb-164b02edef60,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-2a6a5b0e-2eb8-4c0b-aca8-83a4988412e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319374708-172.17.0.19-1595592304758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-61c2c9f1-ebef-4c13-9b6c-309e1ab882ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-1cec7376-a422-47b7-bd1c-a7e34e2c32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-49a6065a-1608-4bc8-9e8e-a6bf8bcece48,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-c5792fb5-0afc-41b4-bc68-c517cbc6f5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-32809c94-1013-4392-96ae-1273acbbfda5,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-9cb38a47-3323-438a-9e20-b06a8a027730,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-7a49b877-785f-4532-8970-6538d0e03033,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-48ad996d-87e6-48ce-9af0-e272b9f4b9fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319374708-172.17.0.19-1595592304758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41648,DS-61c2c9f1-ebef-4c13-9b6c-309e1ab882ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-1cec7376-a422-47b7-bd1c-a7e34e2c32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-49a6065a-1608-4bc8-9e8e-a6bf8bcece48,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-c5792fb5-0afc-41b4-bc68-c517cbc6f5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-32809c94-1013-4392-96ae-1273acbbfda5,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-9cb38a47-3323-438a-9e20-b06a8a027730,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-7a49b877-785f-4532-8970-6538d0e03033,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-48ad996d-87e6-48ce-9af0-e272b9f4b9fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434042321-172.17.0.19-1595592491077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46220,DS-7c9a333d-14f4-418e-8205-6bea5707a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-f6faae60-cc97-4fa6-a790-2ab379b6eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-a97e3099-bb88-4754-80b0-994c2fb763a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-d43886d4-6035-43d8-bddc-2b970cb0bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-44a2aa68-4e0b-4603-858c-20ecd72514e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-3d42546d-f873-4c3c-a344-f6951afc4832,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-b2672d35-89f8-4c6d-b193-7953728efd81,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-57a17196-7dd3-4fc5-bbb3-d1d695025c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434042321-172.17.0.19-1595592491077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46220,DS-7c9a333d-14f4-418e-8205-6bea5707a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-f6faae60-cc97-4fa6-a790-2ab379b6eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-a97e3099-bb88-4754-80b0-994c2fb763a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-d43886d4-6035-43d8-bddc-2b970cb0bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-44a2aa68-4e0b-4603-858c-20ecd72514e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-3d42546d-f873-4c3c-a344-f6951afc4832,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-b2672d35-89f8-4c6d-b193-7953728efd81,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-57a17196-7dd3-4fc5-bbb3-d1d695025c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036684856-172.17.0.19-1595592623744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-07bfddb1-8016-4688-b19c-c8bd3f75cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-368401d5-cf8a-46ed-a652-1636d9727816,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-7c096092-bb2a-49f9-a782-90ec2cda8312,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-b3d01f0d-c918-4924-9421-13e1bb0c8fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-44d5d045-600d-4129-ae61-78986322e749,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-a82e3f43-dc15-4825-a2a9-37019ec21965,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-864b5792-b884-4f92-b571-fc48baed9679,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-9a1492cb-7d2f-4ded-8850-4de3074a3253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036684856-172.17.0.19-1595592623744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-07bfddb1-8016-4688-b19c-c8bd3f75cc67,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-368401d5-cf8a-46ed-a652-1636d9727816,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-7c096092-bb2a-49f9-a782-90ec2cda8312,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-b3d01f0d-c918-4924-9421-13e1bb0c8fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-44d5d045-600d-4129-ae61-78986322e749,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-a82e3f43-dc15-4825-a2a9-37019ec21965,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-864b5792-b884-4f92-b571-fc48baed9679,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-9a1492cb-7d2f-4ded-8850-4de3074a3253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 1200
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851022659-172.17.0.19-1595592959387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-ab758bcb-fe44-4a88-b2b2-1aa707553d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-d2d73129-2bbc-4fbd-b116-428097777256,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-e301c89f-47aa-4aa5-825a-0454cc8d7b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-5206d1cf-7b3a-4e8c-87db-766afae0ba54,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-d6556754-c405-47d7-8c21-62f5411fa447,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-8adb905f-dbc1-46d5-ae64-02224d7d9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-596c3570-8838-4c63-8868-18abe0477f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-80940ae1-abad-4091-ba12-ba526a0e826f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851022659-172.17.0.19-1595592959387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-ab758bcb-fe44-4a88-b2b2-1aa707553d75,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-d2d73129-2bbc-4fbd-b116-428097777256,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-e301c89f-47aa-4aa5-825a-0454cc8d7b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-5206d1cf-7b3a-4e8c-87db-766afae0ba54,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-d6556754-c405-47d7-8c21-62f5411fa447,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-8adb905f-dbc1-46d5-ae64-02224d7d9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-596c3570-8838-4c63-8868-18abe0477f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-80940ae1-abad-4091-ba12-ba526a0e826f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5501
