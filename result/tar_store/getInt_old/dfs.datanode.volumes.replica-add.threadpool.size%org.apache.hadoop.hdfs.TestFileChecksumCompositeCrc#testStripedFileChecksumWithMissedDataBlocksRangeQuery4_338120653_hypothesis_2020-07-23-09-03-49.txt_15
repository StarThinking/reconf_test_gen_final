reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49508905-172.17.0.21-1595495314575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46868,DS-d3e92d2a-cdbb-423e-a8dc-f597b515225f,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-31222d55-3b88-44b0-b81e-02c8fe651c44,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-98275e78-a5eb-4d50-9159-a2dd57fb70d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-e54c9526-aa4b-41bc-9e04-901d72040c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-71560613-8783-4ce2-a505-bc62050fbe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-beee70fe-13fc-44ef-99ca-3f851f653463,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-794dbe66-b7ec-44ff-8dae-20a650c79f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-9b5ba644-c87f-4cb6-9794-e219a985f78b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49508905-172.17.0.21-1595495314575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46868,DS-d3e92d2a-cdbb-423e-a8dc-f597b515225f,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-31222d55-3b88-44b0-b81e-02c8fe651c44,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-98275e78-a5eb-4d50-9159-a2dd57fb70d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-e54c9526-aa4b-41bc-9e04-901d72040c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-71560613-8783-4ce2-a505-bc62050fbe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-beee70fe-13fc-44ef-99ca-3f851f653463,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-794dbe66-b7ec-44ff-8dae-20a650c79f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-9b5ba644-c87f-4cb6-9794-e219a985f78b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010683819-172.17.0.21-1595495350999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-a43ec7d7-0543-4586-a487-88d50239ba0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-da698b59-ebcc-4a3f-b3a7-aa59e98f9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-10d7c9cc-68f1-4289-898e-fbf101bc9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-c5911938-fbaa-4aa5-8998-b036689f6522,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-3b452b2d-0677-42a9-9042-fa75ddeb29c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-35683d1a-3387-4450-b8cd-12aab9530d05,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-0959b563-4ac0-49d2-8e64-f59bd6fe6eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-f6ffe852-787c-43e2-b016-f94a434251f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010683819-172.17.0.21-1595495350999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-a43ec7d7-0543-4586-a487-88d50239ba0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-da698b59-ebcc-4a3f-b3a7-aa59e98f9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-10d7c9cc-68f1-4289-898e-fbf101bc9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-c5911938-fbaa-4aa5-8998-b036689f6522,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-3b452b2d-0677-42a9-9042-fa75ddeb29c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-35683d1a-3387-4450-b8cd-12aab9530d05,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-0959b563-4ac0-49d2-8e64-f59bd6fe6eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-f6ffe852-787c-43e2-b016-f94a434251f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546945856-172.17.0.21-1595495829867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-18373f7e-f673-4f23-b6e3-211655cea010,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-0dc035c8-6167-402d-bb30-574d54c583be,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-9d8b8bba-16b0-426c-810a-c5803d1553e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-a8468cf1-55ed-4c57-9958-b49946813196,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-ca0d382a-9a59-4f4e-a456-80bb857a89a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-c7b51bc3-d610-420e-8d31-99c6e245ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-2c23053c-485b-458a-9a65-0e7de787d6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-159b7c93-4162-4570-a673-4c8d3c26f38a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546945856-172.17.0.21-1595495829867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-18373f7e-f673-4f23-b6e3-211655cea010,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-0dc035c8-6167-402d-bb30-574d54c583be,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-9d8b8bba-16b0-426c-810a-c5803d1553e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-a8468cf1-55ed-4c57-9958-b49946813196,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-ca0d382a-9a59-4f4e-a456-80bb857a89a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-c7b51bc3-d610-420e-8d31-99c6e245ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-2c23053c-485b-458a-9a65-0e7de787d6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-159b7c93-4162-4570-a673-4c8d3c26f38a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730339459-172.17.0.21-1595496543571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42337,DS-cb81e8ff-be4b-4f39-8daf-ccada2a86eec,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-a4a46bb3-dc0b-469a-aeec-a7a038cf2a24,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-3dce76f0-4ff0-454d-85c9-6e48eaa753c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-684e24c0-11d1-431f-9651-8270c35c2f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-ad29caae-41d7-48e7-95b0-443ee43315d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-872cc3b2-8ce3-46a1-a70c-6365052ea2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-3a05d3dc-30a7-4627-99af-6baac2b677f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-d44c3bfe-7edf-473f-9f05-0bd409039d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730339459-172.17.0.21-1595496543571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42337,DS-cb81e8ff-be4b-4f39-8daf-ccada2a86eec,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-a4a46bb3-dc0b-469a-aeec-a7a038cf2a24,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-3dce76f0-4ff0-454d-85c9-6e48eaa753c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-684e24c0-11d1-431f-9651-8270c35c2f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-ad29caae-41d7-48e7-95b0-443ee43315d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-872cc3b2-8ce3-46a1-a70c-6365052ea2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-3a05d3dc-30a7-4627-99af-6baac2b677f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-d44c3bfe-7edf-473f-9f05-0bd409039d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054460351-172.17.0.21-1595496615537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35203,DS-b3f3e446-668e-4e28-87e9-066691c6336b,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-ad90847a-19a1-4422-b379-2dacb82ef4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-199cf5dd-0240-4247-94ef-4314989b8ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-65596e70-efb4-4ed4-8098-65fedfd4d518,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-b5fe3520-550a-4aec-bf51-4541fd56d15b,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-2824f2e5-82a8-4c4a-9d32-4398e3dab049,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-e6f85c60-8d36-4d83-ac8e-5cd91ab9703a,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-98fcc81b-d68d-420f-bbe8-4af36c0a749b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054460351-172.17.0.21-1595496615537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35203,DS-b3f3e446-668e-4e28-87e9-066691c6336b,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-ad90847a-19a1-4422-b379-2dacb82ef4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-199cf5dd-0240-4247-94ef-4314989b8ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-65596e70-efb4-4ed4-8098-65fedfd4d518,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-b5fe3520-550a-4aec-bf51-4541fd56d15b,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-2824f2e5-82a8-4c4a-9d32-4398e3dab049,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-e6f85c60-8d36-4d83-ac8e-5cd91ab9703a,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-98fcc81b-d68d-420f-bbe8-4af36c0a749b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209325990-172.17.0.21-1595496655706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37547,DS-583b8ab7-836b-47de-9808-71e2bbfd331e,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-ef537fe4-961a-4895-b1ae-ad17e137d70d,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-cb89ba47-abd1-43b4-835c-72bdcd614497,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-cbdafb73-6dc2-4948-9d7f-088994628d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-a8d169b6-acd8-4958-921c-daf38d2d64fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-a16f258a-b3c7-42a0-aa78-e560f06ef883,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-6dbc9ef7-c342-4545-a130-79200112a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-aedbaf27-f8fc-4486-97cb-c5f9842eeb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209325990-172.17.0.21-1595496655706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37547,DS-583b8ab7-836b-47de-9808-71e2bbfd331e,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-ef537fe4-961a-4895-b1ae-ad17e137d70d,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-cb89ba47-abd1-43b4-835c-72bdcd614497,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-cbdafb73-6dc2-4948-9d7f-088994628d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-a8d169b6-acd8-4958-921c-daf38d2d64fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-a16f258a-b3c7-42a0-aa78-e560f06ef883,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-6dbc9ef7-c342-4545-a130-79200112a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-aedbaf27-f8fc-4486-97cb-c5f9842eeb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637839655-172.17.0.21-1595496692055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-fe0244d5-2b5a-448b-85f5-f6c72402c778,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-3f696b06-40d6-4699-a870-7f633cee727b,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-d0ec3e11-0366-4b3d-bc9d-5cde86c85de9,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-bdab5466-3226-4e8b-b452-5341e6816f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-ea959bf3-ed88-4744-883f-d4dfd979fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-e8848800-93b1-4b68-9ee1-143d1900aab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-1300be57-a26f-4d68-ac2a-2d957418a567,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-43f95b47-def7-4f6d-bea3-8c22151a4c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637839655-172.17.0.21-1595496692055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-fe0244d5-2b5a-448b-85f5-f6c72402c778,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-3f696b06-40d6-4699-a870-7f633cee727b,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-d0ec3e11-0366-4b3d-bc9d-5cde86c85de9,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-bdab5466-3226-4e8b-b452-5341e6816f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-ea959bf3-ed88-4744-883f-d4dfd979fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-e8848800-93b1-4b68-9ee1-143d1900aab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-1300be57-a26f-4d68-ac2a-2d957418a567,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-43f95b47-def7-4f6d-bea3-8c22151a4c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088068867-172.17.0.21-1595497012964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35065,DS-1d93c23a-94cd-4fd2-812a-616b5d682bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-99bfa05e-990a-4920-aa17-eff253edd972,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-e1365b85-3e71-4f1c-b772-9ce382e9d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-b2c32575-eb2e-4906-927c-4b1c5f433224,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-b5f104cf-6d3e-43bf-89ce-f00db0cfe3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2210a395-27ab-4a4f-9b13-d0138ff23ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-da00792c-a192-4cc4-b69d-3a813b9dddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-f092c748-caf4-4b31-a2fa-86a5af31bdc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088068867-172.17.0.21-1595497012964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35065,DS-1d93c23a-94cd-4fd2-812a-616b5d682bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-99bfa05e-990a-4920-aa17-eff253edd972,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-e1365b85-3e71-4f1c-b772-9ce382e9d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-b2c32575-eb2e-4906-927c-4b1c5f433224,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-b5f104cf-6d3e-43bf-89ce-f00db0cfe3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2210a395-27ab-4a4f-9b13-d0138ff23ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-da00792c-a192-4cc4-b69d-3a813b9dddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-f092c748-caf4-4b31-a2fa-86a5af31bdc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731493174-172.17.0.21-1595497455526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35985,DS-93c4e801-ec77-4234-8e2c-651d5e09c4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-bb7c4002-061f-4ddc-a836-db816ac05b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-104a8dff-67df-49b0-b82a-10e2544278ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-7b24d026-abef-4929-936d-52bb15f3ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-d0b92bf9-8410-49be-bdb2-52243d47449f,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-b7c4d8b0-028e-47d8-9513-435051d090ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-8e9e51e4-3d27-409d-aea0-5f3b9f65842c,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-5af6fd83-ebe6-44ab-9a5b-a2e30fd9a6fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731493174-172.17.0.21-1595497455526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35985,DS-93c4e801-ec77-4234-8e2c-651d5e09c4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-bb7c4002-061f-4ddc-a836-db816ac05b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-104a8dff-67df-49b0-b82a-10e2544278ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-7b24d026-abef-4929-936d-52bb15f3ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-d0b92bf9-8410-49be-bdb2-52243d47449f,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-b7c4d8b0-028e-47d8-9513-435051d090ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-8e9e51e4-3d27-409d-aea0-5f3b9f65842c,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-5af6fd83-ebe6-44ab-9a5b-a2e30fd9a6fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771551743-172.17.0.21-1595497559760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-b1a038c1-c229-430e-8810-fccfed2be6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-1014ae41-fb12-4901-b9b8-cdddc5e4b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-10e7ff7e-1627-4cda-a5eb-5583e0c7750d,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-ad60410a-aff8-4f97-b4dd-20b62125bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-5fd792cb-e0a2-471b-ad4b-5ac59f91d9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-840c2232-fea7-4756-a866-2dd045b0c691,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-5beaa45d-ff7f-4072-b0a7-a844b73007a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-456662a4-db05-49b0-ae3e-b5180edaeb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771551743-172.17.0.21-1595497559760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-b1a038c1-c229-430e-8810-fccfed2be6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-1014ae41-fb12-4901-b9b8-cdddc5e4b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-10e7ff7e-1627-4cda-a5eb-5583e0c7750d,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-ad60410a-aff8-4f97-b4dd-20b62125bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-5fd792cb-e0a2-471b-ad4b-5ac59f91d9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-840c2232-fea7-4756-a866-2dd045b0c691,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-5beaa45d-ff7f-4072-b0a7-a844b73007a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-456662a4-db05-49b0-ae3e-b5180edaeb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402295154-172.17.0.21-1595497827807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35842,DS-2c3fd549-0d25-4664-abc6-5ac9e226d2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-00fa3cbb-5a03-4d59-8ff0-85e9983af6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-5c31dcae-49ed-466b-ab34-826efc5f677c,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-2f174fbb-509d-4ee5-9143-d227a34c1e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-9cf21cf8-c426-4b75-9b69-514383af63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-ff529bd7-eeb7-4850-9a46-ecccb816b64e,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-e423142f-6772-4f22-b2d4-c6f3c041da17,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-16c7f26b-1d11-4f15-8acd-94809e654111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402295154-172.17.0.21-1595497827807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35842,DS-2c3fd549-0d25-4664-abc6-5ac9e226d2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-00fa3cbb-5a03-4d59-8ff0-85e9983af6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-5c31dcae-49ed-466b-ab34-826efc5f677c,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-2f174fbb-509d-4ee5-9143-d227a34c1e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-9cf21cf8-c426-4b75-9b69-514383af63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-ff529bd7-eeb7-4850-9a46-ecccb816b64e,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-e423142f-6772-4f22-b2d4-c6f3c041da17,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-16c7f26b-1d11-4f15-8acd-94809e654111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559858676-172.17.0.21-1595498558220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41989,DS-11df5b07-abc3-4ec6-bbf5-a606d1dd7a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-e15ea5a0-d814-42b1-b030-14594cb2c895,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-d275ae9d-504d-42dc-bcfa-ed494357a759,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-5938a801-2d3a-42ba-9973-327c10a29cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-ffb227eb-7a4c-49d1-b610-522ce9c1ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-873a58b9-4070-4d67-abb3-790a407f5525,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-ef6d1cf9-dac1-471c-b23e-a3a849ac2df6,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-49d6d7a9-3348-4c05-a933-afc211b2ee1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559858676-172.17.0.21-1595498558220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41989,DS-11df5b07-abc3-4ec6-bbf5-a606d1dd7a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-e15ea5a0-d814-42b1-b030-14594cb2c895,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-d275ae9d-504d-42dc-bcfa-ed494357a759,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-5938a801-2d3a-42ba-9973-327c10a29cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-ffb227eb-7a4c-49d1-b610-522ce9c1ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-873a58b9-4070-4d67-abb3-790a407f5525,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-ef6d1cf9-dac1-471c-b23e-a3a849ac2df6,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-49d6d7a9-3348-4c05-a933-afc211b2ee1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226072332-172.17.0.21-1595498697581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44835,DS-cfe80f6a-7992-4252-9dd2-6e6a462b6950,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-8fec249c-1075-4b7b-b04f-2dd8978dcdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-c3cb5540-8ed0-4e1c-9784-9e6e9f482531,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-a220fa7c-b636-4581-8887-beedee0d18a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-6b2eaff9-f367-4e4d-97aa-3001df0f5649,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-49238722-40ee-4c77-916c-e07b9de6e85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-458aceec-1f83-4e81-a67e-fbbf0b35a0df,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-b2fff92c-f091-4ce2-84d0-38abf722ccda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226072332-172.17.0.21-1595498697581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44835,DS-cfe80f6a-7992-4252-9dd2-6e6a462b6950,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-8fec249c-1075-4b7b-b04f-2dd8978dcdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-c3cb5540-8ed0-4e1c-9784-9e6e9f482531,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-a220fa7c-b636-4581-8887-beedee0d18a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-6b2eaff9-f367-4e4d-97aa-3001df0f5649,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-49238722-40ee-4c77-916c-e07b9de6e85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-458aceec-1f83-4e81-a67e-fbbf0b35a0df,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-b2fff92c-f091-4ce2-84d0-38abf722ccda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631058052-172.17.0.21-1595498844495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-2d7a6cc6-f3b2-4a07-968b-2ed92b37777a,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-55fcc973-4f7d-42af-867b-db3f9be12f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-18237221-3553-462d-b555-b0c0afd35b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-6713b357-49e2-4812-a134-24ba7c8152d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-573e3dcb-f510-43a1-971f-e76653f578f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-2d99f32f-54da-475a-967f-db2f73eab0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-938d10f6-263a-42c5-a464-cc8386a923ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-a1388891-44bd-4cac-bb35-e95e27241cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631058052-172.17.0.21-1595498844495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-2d7a6cc6-f3b2-4a07-968b-2ed92b37777a,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-55fcc973-4f7d-42af-867b-db3f9be12f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-18237221-3553-462d-b555-b0c0afd35b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-6713b357-49e2-4812-a134-24ba7c8152d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-573e3dcb-f510-43a1-971f-e76653f578f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-2d99f32f-54da-475a-967f-db2f73eab0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-938d10f6-263a-42c5-a464-cc8386a923ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-a1388891-44bd-4cac-bb35-e95e27241cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511554175-172.17.0.21-1595498964280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38280,DS-08ba47db-123b-4ccb-8376-78dbc15ec006,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-adf813d3-215e-48f2-8053-97ec5ff8c499,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-f6961b05-e61d-44ba-b25a-f4dcdef0df71,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-53554c99-d474-49e4-ba5f-2642242c5469,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-4f7d309b-dcc5-4ab5-87fe-e39b343cd747,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-29f2991a-8bdb-44da-b031-4572d8ec0d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-cc94c603-a928-4b49-b118-58c1650788ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-72534708-39ed-4336-9c80-b760d3c4b11d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511554175-172.17.0.21-1595498964280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38280,DS-08ba47db-123b-4ccb-8376-78dbc15ec006,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-adf813d3-215e-48f2-8053-97ec5ff8c499,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-f6961b05-e61d-44ba-b25a-f4dcdef0df71,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-53554c99-d474-49e4-ba5f-2642242c5469,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-4f7d309b-dcc5-4ab5-87fe-e39b343cd747,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-29f2991a-8bdb-44da-b031-4572d8ec0d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-cc94c603-a928-4b49-b118-58c1650788ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-72534708-39ed-4336-9c80-b760d3c4b11d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392157254-172.17.0.21-1595499572026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41384,DS-9e24c01e-df9d-4d13-8f7d-afde189474bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-a29c7292-ae5d-4aaa-91ea-50db7ec47c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-7275c472-b4f2-4801-8f61-a6c15b041a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-a7cb4f3b-d2c7-4f04-a74d-1bd70cffdf49,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-8f28cac2-a566-48dd-9a5e-be654d6e4389,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-1b3f31a7-2c17-42a2-a42f-0127b5cd80e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-a7789587-afa9-4eaa-b02d-0ae0f25acf20,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-ca6b839b-6207-42c1-bdc0-992eb49694c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392157254-172.17.0.21-1595499572026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41384,DS-9e24c01e-df9d-4d13-8f7d-afde189474bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-a29c7292-ae5d-4aaa-91ea-50db7ec47c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-7275c472-b4f2-4801-8f61-a6c15b041a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-a7cb4f3b-d2c7-4f04-a74d-1bd70cffdf49,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-8f28cac2-a566-48dd-9a5e-be654d6e4389,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-1b3f31a7-2c17-42a2-a42f-0127b5cd80e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-a7789587-afa9-4eaa-b02d-0ae0f25acf20,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-ca6b839b-6207-42c1-bdc0-992eb49694c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035227822-172.17.0.21-1595500177043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-bd785bb1-999c-4b16-bbb6-70824d9fe417,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-139a8a72-e50e-47be-8c9e-22c7d1e95066,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-24e54f9b-ac9b-463d-8ee9-2e1f5860bf45,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-8bc3254a-919e-473b-b608-e244cabc9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-4169fd23-07f6-461b-b611-1e99d59c9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-756bacae-2206-402f-af47-6f00cb4f9468,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-a9a46cd3-b591-40aa-adc3-cf703cdd9c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-31e3e11c-c64d-4b6f-80c3-a7c2d44f517e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035227822-172.17.0.21-1595500177043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-bd785bb1-999c-4b16-bbb6-70824d9fe417,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-139a8a72-e50e-47be-8c9e-22c7d1e95066,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-24e54f9b-ac9b-463d-8ee9-2e1f5860bf45,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-8bc3254a-919e-473b-b608-e244cabc9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-4169fd23-07f6-461b-b611-1e99d59c9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-756bacae-2206-402f-af47-6f00cb4f9468,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-a9a46cd3-b591-40aa-adc3-cf703cdd9c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-31e3e11c-c64d-4b6f-80c3-a7c2d44f517e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 2000
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753001631-172.17.0.21-1595500327900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-c688693e-a2d5-4c8f-becb-77cb8895a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-a9dce51e-3140-414e-ba96-f7d58769f179,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-5ab68f2a-6235-456a-9528-cdf9aea1a012,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-5fe8c289-c6fb-4624-88cb-08f37e4502d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-f8507901-4982-4d53-97b5-97200f0bf1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-c32d5f72-806a-48d1-bc0f-b59f9fe288bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-a75a34c5-7f28-4ca8-b820-96b0eaa6e260,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-49753ec4-bd9c-42b7-aab1-dd07040e3f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753001631-172.17.0.21-1595500327900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-c688693e-a2d5-4c8f-becb-77cb8895a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-a9dce51e-3140-414e-ba96-f7d58769f179,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-5ab68f2a-6235-456a-9528-cdf9aea1a012,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-5fe8c289-c6fb-4624-88cb-08f37e4502d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-f8507901-4982-4d53-97b5-97200f0bf1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-c32d5f72-806a-48d1-bc0f-b59f9fe288bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-a75a34c5-7f28-4ca8-b820-96b0eaa6e260,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-49753ec4-bd9c-42b7-aab1-dd07040e3f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5588
