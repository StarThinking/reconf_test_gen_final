reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326493374-172.17.0.20-1595542656801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-b5c41c2b-13a1-4697-a93e-d4a002de20bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-34aae0be-96b5-4974-a23d-316479cccc32,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-591d584e-b88c-4ea2-8820-44755038bbee,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-2d480519-bd9c-4631-a281-b9e0918b78aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-2ab432ed-1825-45ae-bdbc-e8e9e069c891,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-e271655d-0ef8-4092-bec3-f3f1d3d128e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-d7fccc63-f1a0-49f2-b89a-f47be78f0cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-c80e9e13-a0f0-4a24-90fd-ee74d62930a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326493374-172.17.0.20-1595542656801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-b5c41c2b-13a1-4697-a93e-d4a002de20bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-34aae0be-96b5-4974-a23d-316479cccc32,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-591d584e-b88c-4ea2-8820-44755038bbee,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-2d480519-bd9c-4631-a281-b9e0918b78aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-2ab432ed-1825-45ae-bdbc-e8e9e069c891,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-e271655d-0ef8-4092-bec3-f3f1d3d128e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-d7fccc63-f1a0-49f2-b89a-f47be78f0cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-c80e9e13-a0f0-4a24-90fd-ee74d62930a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724372638-172.17.0.20-1595542705148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-2c2b461f-05b3-4d8f-a457-0cdaf0ad84ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-2222ac0e-bbe5-42be-ae86-1515905a308a,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-fbfe9c4e-0166-4daf-b06a-f08941bee552,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-6f2d9e90-1d4e-4dd0-a0fa-f92432b85a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-a7df7c27-5b80-4e21-9019-7fa0cefeefb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-6df1cc4e-5476-4e59-91d8-3b99a89dbf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-df6161a3-1852-4f73-abdd-c8508c978983,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-f541e4a2-0fdf-47ed-bc05-64a007ada632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724372638-172.17.0.20-1595542705148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-2c2b461f-05b3-4d8f-a457-0cdaf0ad84ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-2222ac0e-bbe5-42be-ae86-1515905a308a,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-fbfe9c4e-0166-4daf-b06a-f08941bee552,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-6f2d9e90-1d4e-4dd0-a0fa-f92432b85a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-a7df7c27-5b80-4e21-9019-7fa0cefeefb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-6df1cc4e-5476-4e59-91d8-3b99a89dbf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-df6161a3-1852-4f73-abdd-c8508c978983,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-f541e4a2-0fdf-47ed-bc05-64a007ada632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344453823-172.17.0.20-1595543014334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-3555f400-9905-470a-a3aa-5ef7894ee290,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-a579d82c-a5a9-42f2-ad34-9eb043aaebeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-6f014fd7-50b4-4436-9bbe-2519e257d7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-c86b1b90-4839-42ce-a16f-f117929743bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-e76718b4-9945-4ba6-b29e-fda05545300c,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-f6279c44-75b7-4c47-b4a9-3eee1c32fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-65c850e8-a4d6-4d8a-8edf-766f49dab74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-27ada9fa-c15c-439c-b95d-ccc8dee1ebea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344453823-172.17.0.20-1595543014334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-3555f400-9905-470a-a3aa-5ef7894ee290,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-a579d82c-a5a9-42f2-ad34-9eb043aaebeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-6f014fd7-50b4-4436-9bbe-2519e257d7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-c86b1b90-4839-42ce-a16f-f117929743bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-e76718b4-9945-4ba6-b29e-fda05545300c,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-f6279c44-75b7-4c47-b4a9-3eee1c32fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-65c850e8-a4d6-4d8a-8edf-766f49dab74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-27ada9fa-c15c-439c-b95d-ccc8dee1ebea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432342119-172.17.0.20-1595543228191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41230,DS-59c4dae1-ab78-4a2a-aa27-562ce5646d00,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-be79e22a-37a7-4e48-9369-a7cdc36961c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-25f3cf80-c156-4adf-a485-d94b05257222,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-b53b8eae-91e4-4c2b-be1d-fc01786f9e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-62fcf205-ce0f-4598-b48f-3a1bf6b14884,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-3cfe90f1-0483-4357-86c2-a9203cc82460,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-97af847f-dcf6-4cae-a103-49c0fcc7d410,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-124bfb7a-d324-4a0c-a442-2483cd6679a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432342119-172.17.0.20-1595543228191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41230,DS-59c4dae1-ab78-4a2a-aa27-562ce5646d00,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-be79e22a-37a7-4e48-9369-a7cdc36961c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-25f3cf80-c156-4adf-a485-d94b05257222,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-b53b8eae-91e4-4c2b-be1d-fc01786f9e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-62fcf205-ce0f-4598-b48f-3a1bf6b14884,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-3cfe90f1-0483-4357-86c2-a9203cc82460,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-97af847f-dcf6-4cae-a103-49c0fcc7d410,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-124bfb7a-d324-4a0c-a442-2483cd6679a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937093435-172.17.0.20-1595544928705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-6b464252-d139-40d8-8117-29adf1b93855,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-a8a3cecc-94ba-48b8-9d88-9e197f12d3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-f3cafe73-2521-46ac-9411-51b3597cb190,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-1725ce85-5060-44f1-a645-861c28e3bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-6d6c5bf0-933b-4a2f-9ad0-f699c39e87ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-14972ddf-6495-4431-8674-f8a38f45632d,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-df503c6f-f71e-4305-8500-9480d87717c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-158140e2-c255-4fef-833d-73daa5fb9af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937093435-172.17.0.20-1595544928705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-6b464252-d139-40d8-8117-29adf1b93855,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-a8a3cecc-94ba-48b8-9d88-9e197f12d3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-f3cafe73-2521-46ac-9411-51b3597cb190,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-1725ce85-5060-44f1-a645-861c28e3bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-6d6c5bf0-933b-4a2f-9ad0-f699c39e87ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-14972ddf-6495-4431-8674-f8a38f45632d,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-df503c6f-f71e-4305-8500-9480d87717c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-158140e2-c255-4fef-833d-73daa5fb9af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162359175-172.17.0.20-1595545472895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43649,DS-e728f813-3741-4ec8-b0d7-40760e0b0359,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-2b74ec08-08ad-495a-99c1-fe29a2a54ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-976ae72a-ecd2-4153-b3b6-aa5342a22562,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-85a278f4-7cfd-44c4-8a0c-e9f908001760,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-26ab0703-f8bd-46ef-ad37-b9819893ca82,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-cbfed7e1-9528-431e-8d83-b139502b44e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-ab0420e6-04e7-4683-8397-1aa3c4250b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-07b1380d-40eb-45a7-875c-d73e09a6c1f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162359175-172.17.0.20-1595545472895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43649,DS-e728f813-3741-4ec8-b0d7-40760e0b0359,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-2b74ec08-08ad-495a-99c1-fe29a2a54ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-976ae72a-ecd2-4153-b3b6-aa5342a22562,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-85a278f4-7cfd-44c4-8a0c-e9f908001760,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-26ab0703-f8bd-46ef-ad37-b9819893ca82,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-cbfed7e1-9528-431e-8d83-b139502b44e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-ab0420e6-04e7-4683-8397-1aa3c4250b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-07b1380d-40eb-45a7-875c-d73e09a6c1f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140741100-172.17.0.20-1595545706133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-a49bc56c-21ba-42a1-b1b8-65333f88805c,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-43921614-2a98-4cf4-8057-c87586c4d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-64969eac-f1e3-4a08-97ef-6824427e8768,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-a1bf4ccd-a664-4a4d-a6ea-1099687449af,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-323c21ad-c2e9-44a0-a4c7-9faa4ed93a92,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-a87de327-ffbc-4a12-beb9-b2b4d178667a,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-b878a71f-b37d-4483-83db-12432a09a822,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-f7171d17-bb35-4f62-990a-d65dec12a83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140741100-172.17.0.20-1595545706133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-a49bc56c-21ba-42a1-b1b8-65333f88805c,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-43921614-2a98-4cf4-8057-c87586c4d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-64969eac-f1e3-4a08-97ef-6824427e8768,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-a1bf4ccd-a664-4a4d-a6ea-1099687449af,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-323c21ad-c2e9-44a0-a4c7-9faa4ed93a92,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-a87de327-ffbc-4a12-beb9-b2b4d178667a,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-b878a71f-b37d-4483-83db-12432a09a822,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-f7171d17-bb35-4f62-990a-d65dec12a83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078168871-172.17.0.20-1595545847537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36467,DS-789a43a1-3169-448c-952f-502e808b7e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-862152bf-5346-4a81-8491-48bd6f555b79,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-73596461-62d9-4abc-83dc-e5f26e4d73a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-a7880834-760d-4eca-9d9a-03dccf5ed604,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-cc1ff860-e965-45fe-8c24-7ec644cffa24,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-d4bdaea6-9378-4ab3-b872-c66c195d88db,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-1a65012a-8589-4e20-9b62-0847806a26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-0ffb159a-0840-4b52-a675-67449d451108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078168871-172.17.0.20-1595545847537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36467,DS-789a43a1-3169-448c-952f-502e808b7e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-862152bf-5346-4a81-8491-48bd6f555b79,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-73596461-62d9-4abc-83dc-e5f26e4d73a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-a7880834-760d-4eca-9d9a-03dccf5ed604,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-cc1ff860-e965-45fe-8c24-7ec644cffa24,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-d4bdaea6-9378-4ab3-b872-c66c195d88db,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-1a65012a-8589-4e20-9b62-0847806a26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-0ffb159a-0840-4b52-a675-67449d451108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474201246-172.17.0.20-1595546182498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-22616ff1-c01c-4ad0-a51c-7d7905a285dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-aa22b0d4-2374-467d-a92b-142fd6af6720,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-b6ad66d1-9dae-4fa1-be97-1bf3f6b416dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-f9de5be6-886f-44c0-8331-b56af9790372,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-d43e4bdb-0660-489c-95ff-33df9974903b,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-40d36b2e-f01d-4efb-8c44-ea1e70b05227,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-0eb7fb76-5f9e-441d-87d9-b2e610741171,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-f539a41f-22c9-4966-b8c1-1a28b5ec7d9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474201246-172.17.0.20-1595546182498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-22616ff1-c01c-4ad0-a51c-7d7905a285dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-aa22b0d4-2374-467d-a92b-142fd6af6720,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-b6ad66d1-9dae-4fa1-be97-1bf3f6b416dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-f9de5be6-886f-44c0-8331-b56af9790372,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-d43e4bdb-0660-489c-95ff-33df9974903b,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-40d36b2e-f01d-4efb-8c44-ea1e70b05227,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-0eb7fb76-5f9e-441d-87d9-b2e610741171,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-f539a41f-22c9-4966-b8c1-1a28b5ec7d9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420312787-172.17.0.20-1595546379729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38914,DS-a4264b07-f14b-4939-a54b-2bd1d70df223,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-6f15fab7-1874-438a-95ee-a42cf117ea01,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-6b403f03-0919-433f-9d56-d82e803e4e42,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-3aa24e4b-56f3-4269-bafc-9085a5af5e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-0bbe56bf-08c8-4b78-b176-d5aac3739497,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-50714cab-b4f9-4a91-9569-95ad942003d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-56600a93-3162-4fc0-b168-a8b0f1f0a0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-3dd5bd12-f467-4d34-9e19-7c3b6c6b8955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420312787-172.17.0.20-1595546379729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38914,DS-a4264b07-f14b-4939-a54b-2bd1d70df223,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-6f15fab7-1874-438a-95ee-a42cf117ea01,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-6b403f03-0919-433f-9d56-d82e803e4e42,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-3aa24e4b-56f3-4269-bafc-9085a5af5e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-0bbe56bf-08c8-4b78-b176-d5aac3739497,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-50714cab-b4f9-4a91-9569-95ad942003d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-56600a93-3162-4fc0-b168-a8b0f1f0a0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-3dd5bd12-f467-4d34-9e19-7c3b6c6b8955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821782454-172.17.0.20-1595546738754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-34e9b08c-44e2-4166-bf23-429151c9fa08,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-42f45f98-12a9-48e7-a4ea-ab869d8d416a,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-924ce9de-7d40-4665-9c93-f0f0368939b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-7690b66e-6d16-48d3-bc86-cedf01eb8297,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-3d5cf7e6-2961-4743-ab10-b3218876465b,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-03580c8d-c380-4295-9b92-1d2d82dcffe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-1d185db8-b444-42ce-863d-56d8e620cd54,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-4749034e-88fb-4025-b1a4-5d905e77c91e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821782454-172.17.0.20-1595546738754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-34e9b08c-44e2-4166-bf23-429151c9fa08,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-42f45f98-12a9-48e7-a4ea-ab869d8d416a,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-924ce9de-7d40-4665-9c93-f0f0368939b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-7690b66e-6d16-48d3-bc86-cedf01eb8297,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-3d5cf7e6-2961-4743-ab10-b3218876465b,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-03580c8d-c380-4295-9b92-1d2d82dcffe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-1d185db8-b444-42ce-863d-56d8e620cd54,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-4749034e-88fb-4025-b1a4-5d905e77c91e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124975659-172.17.0.20-1595546982777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35450,DS-a3fc15a4-f232-4e26-9257-5ab0a4417ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-351090a9-598d-4a55-80cf-17e9f534b913,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-6758a64b-3729-43e6-83ef-1c15009ede4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-824a33f8-9be8-4f46-b0b4-68094a8689b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-441e5a6d-26e3-42d3-8342-17969c0bcbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-07fad56a-a584-4508-91cb-22bae32cc628,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-e60c8ba1-0d1d-4a21-80dd-5c0a9b9f2639,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-f414b218-2935-4d25-ad8f-1e01f25d26ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124975659-172.17.0.20-1595546982777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35450,DS-a3fc15a4-f232-4e26-9257-5ab0a4417ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-351090a9-598d-4a55-80cf-17e9f534b913,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-6758a64b-3729-43e6-83ef-1c15009ede4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-824a33f8-9be8-4f46-b0b4-68094a8689b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-441e5a6d-26e3-42d3-8342-17969c0bcbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-07fad56a-a584-4508-91cb-22bae32cc628,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-e60c8ba1-0d1d-4a21-80dd-5c0a9b9f2639,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-f414b218-2935-4d25-ad8f-1e01f25d26ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109242778-172.17.0.20-1595547154083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-82dbbf24-7510-4c2d-ad29-677146a04062,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-9138bb27-85ce-404e-8ebe-4569c7bc7c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-6982ceae-5831-44b6-abb7-ca3a8ebb9b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-0b54a02e-4075-48c7-82b1-6928f68402ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-407a905d-4042-4a7c-8060-95e9c5481ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-20a9474a-2380-4a53-bff6-93395d01bef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-e2d600bf-5e23-4ae9-a57c-ab5997bf20ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-ce81aa1d-27a3-48d7-ae6e-55a3b1916d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109242778-172.17.0.20-1595547154083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-82dbbf24-7510-4c2d-ad29-677146a04062,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-9138bb27-85ce-404e-8ebe-4569c7bc7c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-6982ceae-5831-44b6-abb7-ca3a8ebb9b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-0b54a02e-4075-48c7-82b1-6928f68402ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-407a905d-4042-4a7c-8060-95e9c5481ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-20a9474a-2380-4a53-bff6-93395d01bef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-e2d600bf-5e23-4ae9-a57c-ab5997bf20ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-ce81aa1d-27a3-48d7-ae6e-55a3b1916d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136563228-172.17.0.20-1595547271577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40569,DS-f3644471-a949-4376-869a-7e4f932d89ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-e544dfa5-2b3c-4642-bac1-923bc4adde98,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-c73e06da-6cc7-40f9-9757-a7c952723a90,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-fc2012d7-4baf-48bb-aa22-b0e3a1fae377,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-543009d8-a1ec-403e-a53f-6c817a048be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-ddc57b0c-c329-4ec4-ba81-118ec598e529,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-b8889416-693b-4ca1-91c0-c5b2f1f08431,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-2f80edfc-0ac1-4c75-bcee-04e2e712e853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136563228-172.17.0.20-1595547271577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40569,DS-f3644471-a949-4376-869a-7e4f932d89ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-e544dfa5-2b3c-4642-bac1-923bc4adde98,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-c73e06da-6cc7-40f9-9757-a7c952723a90,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-fc2012d7-4baf-48bb-aa22-b0e3a1fae377,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-543009d8-a1ec-403e-a53f-6c817a048be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-ddc57b0c-c329-4ec4-ba81-118ec598e529,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-b8889416-693b-4ca1-91c0-c5b2f1f08431,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-2f80edfc-0ac1-4c75-bcee-04e2e712e853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853157536-172.17.0.20-1595547347021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-5d3b2e53-ddd4-4962-aa24-f56c15726109,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-620e7992-5dbd-4f55-82bf-6514433202a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-b12161be-fe6a-4c05-8fe5-0c773304d3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-a484bc5a-8003-476a-883c-d38c24cce647,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-ae835884-3dec-469f-8293-ef91ac40bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-a2974b77-72fa-4cba-b53f-57d4af672eae,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-81020c09-0aaa-40d0-845c-4da2b3b62d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-645762b4-d916-44f7-9dab-de1ade01f5b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853157536-172.17.0.20-1595547347021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-5d3b2e53-ddd4-4962-aa24-f56c15726109,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-620e7992-5dbd-4f55-82bf-6514433202a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-b12161be-fe6a-4c05-8fe5-0c773304d3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-a484bc5a-8003-476a-883c-d38c24cce647,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-ae835884-3dec-469f-8293-ef91ac40bb25,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-a2974b77-72fa-4cba-b53f-57d4af672eae,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-81020c09-0aaa-40d0-845c-4da2b3b62d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-645762b4-d916-44f7-9dab-de1ade01f5b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992194645-172.17.0.20-1595547947927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-eaaf3ba7-cdcb-4ad9-95ee-f92410054e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-8fc78007-64e4-44d7-80a4-fbecc93b6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-f434786a-a207-4614-bd93-ebc2c6a9ce12,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-f05e3d0a-e01c-48b3-ad68-547815b82b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-983cf423-701b-4f82-8df5-8cd5bf257791,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-413cf55c-ac39-4693-aee7-cef1cb963ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-ce7dc3b3-5b8c-4552-93f0-5af7fee9682a,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-2c87c399-6373-4c1b-8e82-5096f249347b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992194645-172.17.0.20-1595547947927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-eaaf3ba7-cdcb-4ad9-95ee-f92410054e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-8fc78007-64e4-44d7-80a4-fbecc93b6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-f434786a-a207-4614-bd93-ebc2c6a9ce12,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-f05e3d0a-e01c-48b3-ad68-547815b82b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-983cf423-701b-4f82-8df5-8cd5bf257791,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-413cf55c-ac39-4693-aee7-cef1cb963ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-ce7dc3b3-5b8c-4552-93f0-5af7fee9682a,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-2c87c399-6373-4c1b-8e82-5096f249347b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6614
