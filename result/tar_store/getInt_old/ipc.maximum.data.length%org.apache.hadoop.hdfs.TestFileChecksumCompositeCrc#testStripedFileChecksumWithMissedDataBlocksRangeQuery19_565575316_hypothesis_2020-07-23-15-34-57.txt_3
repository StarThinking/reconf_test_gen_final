reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798663001-172.17.0.12-1595518686353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-59d5f84f-384f-4ee3-b7be-12b9138e123c,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-5675db2b-9dae-4f6f-a8ae-55fb0c6042db,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-f5279294-64f7-46f7-bd08-4267c3164d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-1d72c219-a3f2-4d07-874c-aabec20327c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-7aba50d5-ed08-4015-b94d-c99a51eb7bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-324c60eb-40e9-440e-be1a-9efd3a605d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-c4b4ef34-7c11-4e8f-81ac-746fff7feb02,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-1c214ce5-6b9f-49a6-b8fb-01649bd51fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798663001-172.17.0.12-1595518686353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-59d5f84f-384f-4ee3-b7be-12b9138e123c,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-5675db2b-9dae-4f6f-a8ae-55fb0c6042db,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-f5279294-64f7-46f7-bd08-4267c3164d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-1d72c219-a3f2-4d07-874c-aabec20327c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-7aba50d5-ed08-4015-b94d-c99a51eb7bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-324c60eb-40e9-440e-be1a-9efd3a605d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-c4b4ef34-7c11-4e8f-81ac-746fff7feb02,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-1c214ce5-6b9f-49a6-b8fb-01649bd51fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085538925-172.17.0.12-1595519161952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-395693cd-11bd-4d54-98e3-9b4c702cbb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-7fbbcddc-548b-4039-9673-4a2aef4bfd30,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-196bfadc-8f8c-4429-9187-2f1fd9d63cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-9566f98e-f2ea-4632-99a9-6e0e1038b489,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-b692078a-34d0-48cc-a1d8-b3509247cfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-f88c7167-5f7e-4367-81a5-936abdbc7c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-71104675-3f8c-4117-9c68-294805ba7da0,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-61b53dfe-385e-45af-a091-615c435e1b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085538925-172.17.0.12-1595519161952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-395693cd-11bd-4d54-98e3-9b4c702cbb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-7fbbcddc-548b-4039-9673-4a2aef4bfd30,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-196bfadc-8f8c-4429-9187-2f1fd9d63cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-9566f98e-f2ea-4632-99a9-6e0e1038b489,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-b692078a-34d0-48cc-a1d8-b3509247cfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-f88c7167-5f7e-4367-81a5-936abdbc7c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-71104675-3f8c-4117-9c68-294805ba7da0,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-61b53dfe-385e-45af-a091-615c435e1b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301342260-172.17.0.12-1595519635921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-de6f6b82-5307-446f-a372-442dac3e3041,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-83f224da-034b-4298-b71e-4157dd2f4d43,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-8782d5d2-2533-458d-92b3-22cd369bf83a,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-eadc6634-e7fd-4bc6-b42d-9769b5dde962,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-e3d1d154-8263-4fd0-94dc-a3f0713225ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-8bc66a21-f6ea-4bf4-8177-4ebefea89315,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-ffeda852-3d5e-434b-a2d2-150ef0659552,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-4453e457-159f-4901-a3c1-5e1cf442fb8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301342260-172.17.0.12-1595519635921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33098,DS-de6f6b82-5307-446f-a372-442dac3e3041,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-83f224da-034b-4298-b71e-4157dd2f4d43,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-8782d5d2-2533-458d-92b3-22cd369bf83a,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-eadc6634-e7fd-4bc6-b42d-9769b5dde962,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-e3d1d154-8263-4fd0-94dc-a3f0713225ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-8bc66a21-f6ea-4bf4-8177-4ebefea89315,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-ffeda852-3d5e-434b-a2d2-150ef0659552,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-4453e457-159f-4901-a3c1-5e1cf442fb8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107978044-172.17.0.12-1595519672316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-4c54bd3b-e72b-4a5a-9e4c-04dc4277c479,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-1b877032-ca12-4486-9e21-3a950a6804a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-2c592cea-3211-4737-88e2-616ef7db727f,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-9094ac06-9f3b-42ee-8545-65dae46b0e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-9fb2ff28-ce02-46de-8f27-d321581c4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-00389f92-132f-4d54-a62c-e578cf916ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-8f2ee333-e95a-424a-a529-58cb65cb5d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-d688a487-f5cc-4673-aa83-99d7fa8cecda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107978044-172.17.0.12-1595519672316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-4c54bd3b-e72b-4a5a-9e4c-04dc4277c479,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-1b877032-ca12-4486-9e21-3a950a6804a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-2c592cea-3211-4737-88e2-616ef7db727f,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-9094ac06-9f3b-42ee-8545-65dae46b0e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-9fb2ff28-ce02-46de-8f27-d321581c4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-00389f92-132f-4d54-a62c-e578cf916ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-8f2ee333-e95a-424a-a529-58cb65cb5d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-d688a487-f5cc-4673-aa83-99d7fa8cecda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125162844-172.17.0.12-1595519899383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-f126a0df-20d1-4ced-b2ab-55d17aac33f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-113ab0c5-3900-427d-94ce-675e854b0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-3257f085-5a1c-4a54-addf-f4f65d938c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-80ebe545-a787-4800-856f-85c2b1db71e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-17213f06-9932-4407-ae5f-e4c71dc247a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-77586236-fad9-405b-9b5a-9eddec7686a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-0f10a8af-e3e3-4278-a541-e2d449216b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-255d8539-424b-4a09-a8eb-2aa1f53ae806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125162844-172.17.0.12-1595519899383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-f126a0df-20d1-4ced-b2ab-55d17aac33f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-113ab0c5-3900-427d-94ce-675e854b0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-3257f085-5a1c-4a54-addf-f4f65d938c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-80ebe545-a787-4800-856f-85c2b1db71e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-17213f06-9932-4407-ae5f-e4c71dc247a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-77586236-fad9-405b-9b5a-9eddec7686a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-0f10a8af-e3e3-4278-a541-e2d449216b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-255d8539-424b-4a09-a8eb-2aa1f53ae806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30497874-172.17.0.12-1595520093243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35361,DS-b06d715e-c559-4286-afa7-07b0e26c3682,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-291f62bd-e8ef-48d6-9e11-833f24ce15c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-0a9e972f-b288-4489-988d-44396e8ccaab,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-1c40efa2-ec0d-4cd1-8873-a43654de38f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-f96a9134-0db6-48b5-9d84-91e7d462a900,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-69f4649c-a3de-4a09-84d5-bb9f1cf2abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-c797151a-8618-4bcb-9721-5f7919338779,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-a417f122-daea-41c7-9807-7f9463434091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30497874-172.17.0.12-1595520093243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35361,DS-b06d715e-c559-4286-afa7-07b0e26c3682,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-291f62bd-e8ef-48d6-9e11-833f24ce15c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-0a9e972f-b288-4489-988d-44396e8ccaab,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-1c40efa2-ec0d-4cd1-8873-a43654de38f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-f96a9134-0db6-48b5-9d84-91e7d462a900,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-69f4649c-a3de-4a09-84d5-bb9f1cf2abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-c797151a-8618-4bcb-9721-5f7919338779,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-a417f122-daea-41c7-9807-7f9463434091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853541086-172.17.0.12-1595520170695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-2d45c114-facb-46aa-bf80-f677b5306d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-ef12d174-c561-4dc0-8573-ab4bb3e13c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-c06f8524-9c07-4339-888f-abfc26afdd67,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-c793cd68-8ecb-4f4d-8807-70a182898fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-d72b6a14-e9b8-44ba-9831-7175fa34ab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-877e26bc-ef63-45ff-a19c-a6920c33d205,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-6ab8b544-74a1-451c-b7c5-79ee8bbdb208,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-795abb20-295d-406d-a736-cbc60c8a146b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853541086-172.17.0.12-1595520170695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-2d45c114-facb-46aa-bf80-f677b5306d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-ef12d174-c561-4dc0-8573-ab4bb3e13c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-c06f8524-9c07-4339-888f-abfc26afdd67,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-c793cd68-8ecb-4f4d-8807-70a182898fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-d72b6a14-e9b8-44ba-9831-7175fa34ab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-877e26bc-ef63-45ff-a19c-a6920c33d205,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-6ab8b544-74a1-451c-b7c5-79ee8bbdb208,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-795abb20-295d-406d-a736-cbc60c8a146b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910359156-172.17.0.12-1595520512509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-e0bd14bc-4780-4351-bb0e-ef5e7a7adf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-8f86ecce-c42f-432c-bc14-f14fbc8b0ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-9d66d40d-5be8-4d21-8fb9-781e064d5e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-df73189d-6ac1-4e73-a8c0-286f57626e08,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-d12e312c-aa39-4683-92d3-af378e3028b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-59e1cdd3-51f3-442e-8604-4f595468f4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-3935cebd-0f5f-40b4-b8e2-1626f12e84ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-67987f88-a255-49fe-8b25-dce41314dc03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910359156-172.17.0.12-1595520512509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-e0bd14bc-4780-4351-bb0e-ef5e7a7adf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-8f86ecce-c42f-432c-bc14-f14fbc8b0ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-9d66d40d-5be8-4d21-8fb9-781e064d5e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-df73189d-6ac1-4e73-a8c0-286f57626e08,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-d12e312c-aa39-4683-92d3-af378e3028b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-59e1cdd3-51f3-442e-8604-4f595468f4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-3935cebd-0f5f-40b4-b8e2-1626f12e84ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-67987f88-a255-49fe-8b25-dce41314dc03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018029506-172.17.0.12-1595520680357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-dd79c819-01e8-449a-8c6d-db999c364d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-7d186129-5331-4e9a-bb14-767ca9bc619f,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-701d1518-820a-426d-8652-b47593d90bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-4ae2d5b2-a48c-4aba-8e72-eb9676e9cb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-a1d07101-eb0b-4fe4-a0de-1953953b82f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-3407f7db-ab45-4757-ba6c-5deef16c8bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-3282e137-e2b4-4e38-af0c-637c17ffee08,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-394d34be-fb61-4411-9c19-1b8713726eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018029506-172.17.0.12-1595520680357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-dd79c819-01e8-449a-8c6d-db999c364d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-7d186129-5331-4e9a-bb14-767ca9bc619f,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-701d1518-820a-426d-8652-b47593d90bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-4ae2d5b2-a48c-4aba-8e72-eb9676e9cb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-a1d07101-eb0b-4fe4-a0de-1953953b82f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-3407f7db-ab45-4757-ba6c-5deef16c8bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-3282e137-e2b4-4e38-af0c-637c17ffee08,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-394d34be-fb61-4411-9c19-1b8713726eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447055869-172.17.0.12-1595521009917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43352,DS-c76db737-a8f6-43de-a10a-9473c442a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-791bef8f-b729-4cc4-8c50-16c0f70dd575,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-d4c41163-e199-40a8-9a08-c447f4870d01,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-24e625b5-bebb-49b6-a5fb-3702ec516d94,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-87ceb028-dcc8-4dc6-b15b-c6a6a3c8413e,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-4d39d45e-a115-489a-b43d-6bc4361996b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-72d0ef03-8217-461b-a80e-149116ac80bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-4e6efc8c-6227-4340-9b10-30711a3289f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447055869-172.17.0.12-1595521009917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43352,DS-c76db737-a8f6-43de-a10a-9473c442a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-791bef8f-b729-4cc4-8c50-16c0f70dd575,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-d4c41163-e199-40a8-9a08-c447f4870d01,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-24e625b5-bebb-49b6-a5fb-3702ec516d94,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-87ceb028-dcc8-4dc6-b15b-c6a6a3c8413e,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-4d39d45e-a115-489a-b43d-6bc4361996b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-72d0ef03-8217-461b-a80e-149116ac80bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-4e6efc8c-6227-4340-9b10-30711a3289f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575186429-172.17.0.12-1595521114657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45253,DS-6274969c-d552-4c34-acdf-3dd33d02c09f,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-7198ce93-4f5c-4e3a-8422-db1da2857fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-cd9aa7d9-7663-46ef-b243-904b73c501ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-c64fbd93-66c6-449d-bb07-2f37160dfbea,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-08a99d6c-a9a9-4375-a953-1ab0320c9acd,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-c15472eb-105d-4979-a5c8-590dfe3e9cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-f6348cf7-92ba-402d-8f50-c2f4a7740eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-1c56eb14-7d4b-4820-b0f4-719ac57b5bbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575186429-172.17.0.12-1595521114657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45253,DS-6274969c-d552-4c34-acdf-3dd33d02c09f,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-7198ce93-4f5c-4e3a-8422-db1da2857fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-cd9aa7d9-7663-46ef-b243-904b73c501ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-c64fbd93-66c6-449d-bb07-2f37160dfbea,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-08a99d6c-a9a9-4375-a953-1ab0320c9acd,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-c15472eb-105d-4979-a5c8-590dfe3e9cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-f6348cf7-92ba-402d-8f50-c2f4a7740eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-1c56eb14-7d4b-4820-b0f4-719ac57b5bbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863197617-172.17.0.12-1595521213562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37836,DS-06e82d26-a649-4a72-99b9-aa4e1d805c30,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-130c9e39-6e65-4324-9ff3-a42145c2ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-2344ff1b-c6b2-4666-9eaa-da7b8c1f5bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-be023b04-f996-46f2-b2f2-ff2a198ae8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-370472b4-52ee-425f-a5a5-f9e3439f41f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-5a3561a5-3a47-4586-bab0-9332539b7031,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-0312d0d2-a26b-4356-b404-f3ef5a979f86,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-9138ee38-49e7-4226-9fd2-eda3055c3054,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863197617-172.17.0.12-1595521213562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37836,DS-06e82d26-a649-4a72-99b9-aa4e1d805c30,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-130c9e39-6e65-4324-9ff3-a42145c2ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-2344ff1b-c6b2-4666-9eaa-da7b8c1f5bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-be023b04-f996-46f2-b2f2-ff2a198ae8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-370472b4-52ee-425f-a5a5-f9e3439f41f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-5a3561a5-3a47-4586-bab0-9332539b7031,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-0312d0d2-a26b-4356-b404-f3ef5a979f86,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-9138ee38-49e7-4226-9fd2-eda3055c3054,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783570037-172.17.0.12-1595521456259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41121,DS-9f97929e-602c-4709-ba1c-7b85e3a4a3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-35161102-8691-4d09-92fc-26c605112f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-8581c7c3-3a3f-4c29-a2cf-f7b24e2b32bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-4acbdacb-c79c-4631-ac01-48b2b9a10d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-b8987d22-6532-4ab0-9748-e2f9b4924ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-43fb19ed-ca35-43c8-906e-f33ba18d7ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-cda469ce-cafd-418a-a262-12b84d3f2d52,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-5d33a633-8aa5-42ac-abc9-4feaff4349f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783570037-172.17.0.12-1595521456259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41121,DS-9f97929e-602c-4709-ba1c-7b85e3a4a3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-35161102-8691-4d09-92fc-26c605112f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-8581c7c3-3a3f-4c29-a2cf-f7b24e2b32bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-4acbdacb-c79c-4631-ac01-48b2b9a10d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-b8987d22-6532-4ab0-9748-e2f9b4924ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-43fb19ed-ca35-43c8-906e-f33ba18d7ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-cda469ce-cafd-418a-a262-12b84d3f2d52,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-5d33a633-8aa5-42ac-abc9-4feaff4349f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780111729-172.17.0.12-1595521495811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-a2100f46-fd5c-4f49-809a-813e0c43f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-a7d4f3e9-fe93-4d45-8b03-f4b18557fe13,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-7353a721-3a48-461c-8455-94a51c2ee70b,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-7b33f535-b006-49f6-aa31-e0eeabf1027c,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-b15b95bd-a000-49ef-b264-a0413116c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-58389bb2-5242-40a8-9e68-898ac5008ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-fd2a2562-afd6-48a1-a0f2-dcefd3bc31ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-0a5724bc-9282-4912-ae59-a3db5ab282d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780111729-172.17.0.12-1595521495811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-a2100f46-fd5c-4f49-809a-813e0c43f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-a7d4f3e9-fe93-4d45-8b03-f4b18557fe13,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-7353a721-3a48-461c-8455-94a51c2ee70b,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-7b33f535-b006-49f6-aa31-e0eeabf1027c,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-b15b95bd-a000-49ef-b264-a0413116c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-58389bb2-5242-40a8-9e68-898ac5008ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-fd2a2562-afd6-48a1-a0f2-dcefd3bc31ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-0a5724bc-9282-4912-ae59-a3db5ab282d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721430365-172.17.0.12-1595521638483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-27455c27-7d4f-4a1d-ad83-02529ea04d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-32e31522-f4a1-42ad-8f9b-be2e5395825c,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-9195a263-b0bb-4b7a-8ba1-55bb2086de4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-c2d8dedf-cc4f-4331-88e0-30e8465df8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-667c6da3-8681-4095-b12e-0bf0950d9e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-22bc261f-ce7d-4eb1-a098-423155d9670b,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-e4a1ab67-4bf1-4894-9c74-82462390304d,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-43e958dc-d775-492d-bf60-526d966c225d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721430365-172.17.0.12-1595521638483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-27455c27-7d4f-4a1d-ad83-02529ea04d59,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-32e31522-f4a1-42ad-8f9b-be2e5395825c,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-9195a263-b0bb-4b7a-8ba1-55bb2086de4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-c2d8dedf-cc4f-4331-88e0-30e8465df8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-667c6da3-8681-4095-b12e-0bf0950d9e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-22bc261f-ce7d-4eb1-a098-423155d9670b,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-e4a1ab67-4bf1-4894-9c74-82462390304d,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-43e958dc-d775-492d-bf60-526d966c225d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56149682-172.17.0.12-1595522381817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44674,DS-ba2f10fd-418d-4a4f-a20d-2761e61acc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-2887f775-1c72-49f6-bb0d-7489b6ea3f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-48c933e0-f93d-4f6b-a4de-21f252e94470,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-64c3ae65-9a44-438f-b78e-53cedc06cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-6b43d650-8f72-4a08-86ca-a07d73b7dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-e590b070-8df9-47c8-bdee-6309216e7c13,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-b79a970d-5577-440d-a924-1096614578c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-3418009d-d4de-4ec3-8a46-e4f7557b92a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56149682-172.17.0.12-1595522381817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44674,DS-ba2f10fd-418d-4a4f-a20d-2761e61acc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-2887f775-1c72-49f6-bb0d-7489b6ea3f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-48c933e0-f93d-4f6b-a4de-21f252e94470,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-64c3ae65-9a44-438f-b78e-53cedc06cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-6b43d650-8f72-4a08-86ca-a07d73b7dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-e590b070-8df9-47c8-bdee-6309216e7c13,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-b79a970d-5577-440d-a924-1096614578c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-3418009d-d4de-4ec3-8a46-e4f7557b92a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740549339-172.17.0.12-1595522834397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-e6a70d4d-80c5-4d62-80dc-b21f380e1f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-059fc499-fb21-49c7-ba25-e84e753a269a,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-a227f207-a7e2-4b8b-95ae-7f3e609f4063,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-e7b4eded-1041-4dbc-a64d-79122b98a392,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-f60ed82c-f150-462a-b121-c3bd3a305856,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-7d8ad75b-00a5-4fdf-ab76-cb548bea8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-196fc1cd-eaeb-440f-a849-0d4f96806a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-7df6bf11-5d07-45e7-97e4-2d1b28846598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740549339-172.17.0.12-1595522834397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-e6a70d4d-80c5-4d62-80dc-b21f380e1f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-059fc499-fb21-49c7-ba25-e84e753a269a,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-a227f207-a7e2-4b8b-95ae-7f3e609f4063,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-e7b4eded-1041-4dbc-a64d-79122b98a392,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-f60ed82c-f150-462a-b121-c3bd3a305856,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-7d8ad75b-00a5-4fdf-ab76-cb548bea8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-196fc1cd-eaeb-440f-a849-0d4f96806a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-7df6bf11-5d07-45e7-97e4-2d1b28846598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400954931-172.17.0.12-1595523219917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-2033c702-25a6-4d4d-b980-dbf44fbf6114,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-066d8ee5-d018-43b0-8ebe-42127428b648,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-ab53e7e4-c0a8-4626-8900-684b47f3ffed,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-f4e0b6a5-ccb8-4e1f-a4db-5c1c1269254d,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-67c39a24-e872-43b9-81d8-905b2a7b180d,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-360ad701-82db-47f1-bad4-74a9e1514b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-873bdceb-d907-40b5-a88d-daf39db52061,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-42fe21b5-e935-40a6-aef1-c9907ac11d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400954931-172.17.0.12-1595523219917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-2033c702-25a6-4d4d-b980-dbf44fbf6114,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-066d8ee5-d018-43b0-8ebe-42127428b648,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-ab53e7e4-c0a8-4626-8900-684b47f3ffed,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-f4e0b6a5-ccb8-4e1f-a4db-5c1c1269254d,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-67c39a24-e872-43b9-81d8-905b2a7b180d,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-360ad701-82db-47f1-bad4-74a9e1514b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-873bdceb-d907-40b5-a88d-daf39db52061,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-42fe21b5-e935-40a6-aef1-c9907ac11d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511371706-172.17.0.12-1595523580180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42069,DS-71da769e-81b6-4910-9a58-ffcb7f9d25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-11a3c0f5-5a38-4abd-ac23-c84d36e8f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-a1ff0cb0-ae8c-4348-9514-648688a93e77,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-1444c5c6-bd75-49aa-b3f9-19c590f1b578,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-164a3b04-3334-43a5-bc26-843e92f93a29,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-a3f6f961-c819-4889-b646-f7aa468b2b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-06fd65ba-89a3-4a2e-8d6c-2fd26c9827dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-52a76a43-97ed-48b0-a7c4-648bf050743a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511371706-172.17.0.12-1595523580180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42069,DS-71da769e-81b6-4910-9a58-ffcb7f9d25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-11a3c0f5-5a38-4abd-ac23-c84d36e8f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-a1ff0cb0-ae8c-4348-9514-648688a93e77,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-1444c5c6-bd75-49aa-b3f9-19c590f1b578,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-164a3b04-3334-43a5-bc26-843e92f93a29,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-a3f6f961-c819-4889-b646-f7aa468b2b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-06fd65ba-89a3-4a2e-8d6c-2fd26c9827dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-52a76a43-97ed-48b0-a7c4-648bf050743a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556635461-172.17.0.12-1595523795589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44956,DS-331f6440-72ca-43c5-8e9c-2bcaa7c7ca60,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-280a7de6-63ee-426e-b679-3bbb34e4919c,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-4cef9022-4525-4f65-ab55-319dcb2ff33a,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-f3028e4d-3b12-4317-873a-6b00c056714d,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-5f258585-566c-41e7-8386-4d4e3c647150,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-93d0920e-6a69-4b49-b52b-65462e395d50,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-4f74b468-a43f-4126-8d75-895392b025d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-9969c3b8-9141-4929-9a6d-abde57c50201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556635461-172.17.0.12-1595523795589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44956,DS-331f6440-72ca-43c5-8e9c-2bcaa7c7ca60,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-280a7de6-63ee-426e-b679-3bbb34e4919c,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-4cef9022-4525-4f65-ab55-319dcb2ff33a,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-f3028e4d-3b12-4317-873a-6b00c056714d,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-5f258585-566c-41e7-8386-4d4e3c647150,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-93d0920e-6a69-4b49-b52b-65462e395d50,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-4f74b468-a43f-4126-8d75-895392b025d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-9969c3b8-9141-4929-9a6d-abde57c50201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5358
