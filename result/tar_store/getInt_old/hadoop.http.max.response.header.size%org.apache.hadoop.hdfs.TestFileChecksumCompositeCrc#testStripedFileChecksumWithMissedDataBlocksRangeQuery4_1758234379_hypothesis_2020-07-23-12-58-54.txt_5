reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998729522-172.17.0.16-1595509297299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37470,DS-deed1365-572e-4acd-ae2d-fe0e444b619c,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-94049c55-ae51-40aa-a027-14beefeeadd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-9ca49b90-7b2d-46c6-aa67-c08dd65ada62,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-75a05c7f-2b94-47d5-a072-19917aba6658,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-1974ac70-095a-418a-8354-a353bf55f28b,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-cb3915f6-13db-4109-b9d6-12a637521c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-379c11e6-39d7-49a5-a973-2f28b23fc544,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-385e82e9-901b-429e-910a-69a551c59dc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998729522-172.17.0.16-1595509297299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37470,DS-deed1365-572e-4acd-ae2d-fe0e444b619c,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-94049c55-ae51-40aa-a027-14beefeeadd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-9ca49b90-7b2d-46c6-aa67-c08dd65ada62,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-75a05c7f-2b94-47d5-a072-19917aba6658,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-1974ac70-095a-418a-8354-a353bf55f28b,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-cb3915f6-13db-4109-b9d6-12a637521c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-379c11e6-39d7-49a5-a973-2f28b23fc544,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-385e82e9-901b-429e-910a-69a551c59dc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160003576-172.17.0.16-1595509618753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43479,DS-fb40a936-245d-4689-8e1b-52354c8af858,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-b878ecc1-d8cd-47e4-9e0e-dae964259334,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-710e76bd-3abf-4692-8e59-278651e028c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-676bcaac-5071-49d5-8595-35d0e78a0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-e5b31c8e-fd9f-49df-9d09-3c356f20bf67,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-e5efdd89-85b6-44b4-89dc-36f03748f610,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-13b2b9ff-a0eb-40a0-a848-f0a919d5980e,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-287c5bb8-0a5c-43a8-9dfb-a52cfae9d081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160003576-172.17.0.16-1595509618753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43479,DS-fb40a936-245d-4689-8e1b-52354c8af858,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-b878ecc1-d8cd-47e4-9e0e-dae964259334,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-710e76bd-3abf-4692-8e59-278651e028c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-676bcaac-5071-49d5-8595-35d0e78a0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-e5b31c8e-fd9f-49df-9d09-3c356f20bf67,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-e5efdd89-85b6-44b4-89dc-36f03748f610,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-13b2b9ff-a0eb-40a0-a848-f0a919d5980e,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-287c5bb8-0a5c-43a8-9dfb-a52cfae9d081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402058644-172.17.0.16-1595509667064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37314,DS-5c5d527c-9362-45fc-ae41-f2ce6d3a8aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-7f526455-a9da-42d5-b76a-e5eece01793d,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-41c830e4-16c8-4173-9984-4f0ecb66e031,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-ca333e11-5f4e-454d-b33d-bca608fd0972,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-3f5f332e-49ab-4ea2-8be1-b94fc2c66766,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-5e331da2-5b1a-4ea0-8fce-2697e98ed8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-4e4c69ff-aae3-4ca0-9ac6-fbe720c4a560,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-f32a701c-774f-4387-8da2-cacca26d12c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402058644-172.17.0.16-1595509667064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37314,DS-5c5d527c-9362-45fc-ae41-f2ce6d3a8aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-7f526455-a9da-42d5-b76a-e5eece01793d,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-41c830e4-16c8-4173-9984-4f0ecb66e031,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-ca333e11-5f4e-454d-b33d-bca608fd0972,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-3f5f332e-49ab-4ea2-8be1-b94fc2c66766,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-5e331da2-5b1a-4ea0-8fce-2697e98ed8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-4e4c69ff-aae3-4ca0-9ac6-fbe720c4a560,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-f32a701c-774f-4387-8da2-cacca26d12c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108194802-172.17.0.16-1595510767023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41166,DS-a995b58e-9419-4e1b-80a4-1441b67d5ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-ef9f6ded-f7e3-4174-9d27-fe809df4ca97,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-93fd0269-7dfe-4dfd-ae8c-556cad9437d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-6742f98b-74bb-49bc-b57f-6b98208fab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-e6b2fa22-62fe-41de-aef3-6baa9d11b711,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-63b54b04-473e-47f1-b7c8-4a889eee9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-a81399a1-0b08-4c7a-a71e-4d7c348beb40,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-27e2c815-df1a-477e-a1ca-f69b40b4aaea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108194802-172.17.0.16-1595510767023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41166,DS-a995b58e-9419-4e1b-80a4-1441b67d5ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-ef9f6ded-f7e3-4174-9d27-fe809df4ca97,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-93fd0269-7dfe-4dfd-ae8c-556cad9437d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-6742f98b-74bb-49bc-b57f-6b98208fab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-e6b2fa22-62fe-41de-aef3-6baa9d11b711,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-63b54b04-473e-47f1-b7c8-4a889eee9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-a81399a1-0b08-4c7a-a71e-4d7c348beb40,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-27e2c815-df1a-477e-a1ca-f69b40b4aaea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367940914-172.17.0.16-1595510807538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-83fbad3e-f891-4803-9c3e-79a778ba55fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-c564f521-efa3-4632-a0a0-7526318539db,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-826dc210-ac97-4256-aad7-178e5ea069d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-b938dc32-cdea-4766-bd07-d9ee6e432194,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-aba796b9-6f47-4a53-bd41-37a99d1b953e,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-88888380-3901-4986-b59e-b0b072d26b75,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-40f6eb42-4717-49bf-9389-b5a6a1683776,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-936aa0ce-24b3-4aa0-8478-21d6e4066d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367940914-172.17.0.16-1595510807538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-83fbad3e-f891-4803-9c3e-79a778ba55fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-c564f521-efa3-4632-a0a0-7526318539db,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-826dc210-ac97-4256-aad7-178e5ea069d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-b938dc32-cdea-4766-bd07-d9ee6e432194,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-aba796b9-6f47-4a53-bd41-37a99d1b953e,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-88888380-3901-4986-b59e-b0b072d26b75,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-40f6eb42-4717-49bf-9389-b5a6a1683776,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-936aa0ce-24b3-4aa0-8478-21d6e4066d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564340029-172.17.0.16-1595510964277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-41ad97fc-4bb9-4678-9061-07c595f70677,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-4b02ddb9-7c13-4aaf-aa05-c6f365c9fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-11d42794-2af8-471a-88b5-1c9cf9a89098,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-0c1e07b2-f61a-4689-bee0-a8f4c141ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-42fc2e8d-f64a-4f73-aea2-dcad9e01695d,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-831cf39a-4018-492d-8cc3-dd4572f1cb01,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-177489fe-a14c-4b1e-ad22-0336258eff73,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-3f58d70c-a656-47bb-b55b-0e0b007bdfba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564340029-172.17.0.16-1595510964277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-41ad97fc-4bb9-4678-9061-07c595f70677,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-4b02ddb9-7c13-4aaf-aa05-c6f365c9fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-11d42794-2af8-471a-88b5-1c9cf9a89098,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-0c1e07b2-f61a-4689-bee0-a8f4c141ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-42fc2e8d-f64a-4f73-aea2-dcad9e01695d,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-831cf39a-4018-492d-8cc3-dd4572f1cb01,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-177489fe-a14c-4b1e-ad22-0336258eff73,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-3f58d70c-a656-47bb-b55b-0e0b007bdfba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046945744-172.17.0.16-1595511554773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46694,DS-a6762647-e8c0-4f71-a54a-b2d4057ae4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-22e05689-1b9b-4f60-a3dd-4d063c00c4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-bbbd94d5-103b-44d0-9f97-2950c81ba6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-a60f3ccb-6d29-4e86-809b-be6014df0519,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-0cb2a38e-2bf4-4301-888e-349c9661a3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-2947a507-2f85-4404-a65c-3d0b690e36b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-78ed15a7-b95f-4f19-961c-26a2433cbcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-e78d4753-2c8d-4512-915b-7564a93ba87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046945744-172.17.0.16-1595511554773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46694,DS-a6762647-e8c0-4f71-a54a-b2d4057ae4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-22e05689-1b9b-4f60-a3dd-4d063c00c4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-bbbd94d5-103b-44d0-9f97-2950c81ba6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-a60f3ccb-6d29-4e86-809b-be6014df0519,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-0cb2a38e-2bf4-4301-888e-349c9661a3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-2947a507-2f85-4404-a65c-3d0b690e36b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-78ed15a7-b95f-4f19-961c-26a2433cbcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-e78d4753-2c8d-4512-915b-7564a93ba87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587712038-172.17.0.16-1595512091311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46299,DS-bfdf3c75-2211-44e4-850c-cf5f8b2842cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-337a3175-2262-4457-83c9-237cbc2108fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-93521601-9448-491f-95e8-1f7047674d60,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-d538e4de-37e1-4deb-a26e-b84be12a9229,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-a557ce81-2725-451e-adcb-8d9d28411b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-0e4683bd-ee2a-4c55-8b4a-6db6dc3f0f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a236eb40-375d-40e0-be0d-04ad5397139c,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-70aa889d-4b3a-4cf8-842a-24bed06ac531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587712038-172.17.0.16-1595512091311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46299,DS-bfdf3c75-2211-44e4-850c-cf5f8b2842cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-337a3175-2262-4457-83c9-237cbc2108fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-93521601-9448-491f-95e8-1f7047674d60,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-d538e4de-37e1-4deb-a26e-b84be12a9229,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-a557ce81-2725-451e-adcb-8d9d28411b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-0e4683bd-ee2a-4c55-8b4a-6db6dc3f0f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a236eb40-375d-40e0-be0d-04ad5397139c,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-70aa889d-4b3a-4cf8-842a-24bed06ac531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129099845-172.17.0.16-1595512239761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40352,DS-cd6990ef-6e9a-4ba6-b514-a65482d6f736,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-c58780d5-0528-4396-9c5b-a810cb2c1122,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-a33e4778-0d39-4e62-97dc-9ae9c600910e,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-cf28a456-71f8-434c-9480-15b287c1c687,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-0631ded8-d666-4431-94d1-cb3a1f1f3889,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-8083f77d-19b9-47a9-9eb8-3b4afeb486d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-09d4cfe8-5207-43f7-a29c-13e2938a899b,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-cce8d302-dbe2-4057-bec5-c387b4dce191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129099845-172.17.0.16-1595512239761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40352,DS-cd6990ef-6e9a-4ba6-b514-a65482d6f736,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-c58780d5-0528-4396-9c5b-a810cb2c1122,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-a33e4778-0d39-4e62-97dc-9ae9c600910e,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-cf28a456-71f8-434c-9480-15b287c1c687,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-0631ded8-d666-4431-94d1-cb3a1f1f3889,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-8083f77d-19b9-47a9-9eb8-3b4afeb486d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-09d4cfe8-5207-43f7-a29c-13e2938a899b,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-cce8d302-dbe2-4057-bec5-c387b4dce191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138822453-172.17.0.16-1595513086548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-7b43c318-d147-40bd-bd67-9e7c26269636,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-f97a8bca-9d27-413f-9633-7f481872af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-d7b2fb56-840f-4ab8-9eb5-41c375a9878b,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-34ee857e-26cf-43dc-aff7-50ea72d1e3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-814832d9-3bcd-452f-b699-120d2ca7b5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-700c395c-3b65-4c82-824d-7091a7bc20e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-0e4032be-6ab5-4aaf-9d36-f5960b76b8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-31c7544c-a4e3-4525-a3d4-ba46a09b023c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138822453-172.17.0.16-1595513086548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-7b43c318-d147-40bd-bd67-9e7c26269636,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-f97a8bca-9d27-413f-9633-7f481872af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-d7b2fb56-840f-4ab8-9eb5-41c375a9878b,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-34ee857e-26cf-43dc-aff7-50ea72d1e3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-814832d9-3bcd-452f-b699-120d2ca7b5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-700c395c-3b65-4c82-824d-7091a7bc20e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-0e4032be-6ab5-4aaf-9d36-f5960b76b8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-31c7544c-a4e3-4525-a3d4-ba46a09b023c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725737025-172.17.0.16-1595513209097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46351,DS-82b976ec-e0f8-4889-85d8-409a60d99a80,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-0afee484-736e-4a01-8e18-36858c45a1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-48bdb619-3e40-4b51-bd76-803b410e36c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-494a11d0-19eb-43f1-9db8-d721a9d8c052,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-0b930370-2d28-4391-9ae7-f8924638e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-17cdaf39-7a54-4e49-b5e4-f3abd156f138,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-24e4e93f-e4f5-4fdc-a51e-7e2073b9c614,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-b3bfb55b-81ab-4efb-a3f4-88c1756c6322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725737025-172.17.0.16-1595513209097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46351,DS-82b976ec-e0f8-4889-85d8-409a60d99a80,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-0afee484-736e-4a01-8e18-36858c45a1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-48bdb619-3e40-4b51-bd76-803b410e36c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-494a11d0-19eb-43f1-9db8-d721a9d8c052,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-0b930370-2d28-4391-9ae7-f8924638e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-17cdaf39-7a54-4e49-b5e4-f3abd156f138,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-24e4e93f-e4f5-4fdc-a51e-7e2073b9c614,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-b3bfb55b-81ab-4efb-a3f4-88c1756c6322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852470026-172.17.0.16-1595513316043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-61595bb2-8bd9-4aff-a7d2-a03ae5590a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-24cb7ab0-1fc7-4588-a68e-868bd832b3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-f098c4b6-2b41-4b8e-9501-c1225dcb9b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-64e0f8a5-4b73-4cb6-9bf0-826570c05b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-01aa64c6-819d-4891-8c3a-f0b7c9fa0889,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-3b05c478-11c9-4432-b3b5-279f24bb64c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-3c2fec70-6ad5-41c1-8716-6cc65d265835,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-f8b495ce-1108-4a08-ad4c-ea2d9189f568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852470026-172.17.0.16-1595513316043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-61595bb2-8bd9-4aff-a7d2-a03ae5590a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-24cb7ab0-1fc7-4588-a68e-868bd832b3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-f098c4b6-2b41-4b8e-9501-c1225dcb9b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-64e0f8a5-4b73-4cb6-9bf0-826570c05b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-01aa64c6-819d-4891-8c3a-f0b7c9fa0889,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-3b05c478-11c9-4432-b3b5-279f24bb64c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-3c2fec70-6ad5-41c1-8716-6cc65d265835,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-f8b495ce-1108-4a08-ad4c-ea2d9189f568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73666204-172.17.0.16-1595513361279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34080,DS-b785bd8c-85b1-4f20-8a81-eb7bc5c8d225,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-355dc6f9-096a-4b5a-b21e-eea63987cf23,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-ab95db8f-483c-48fd-9492-4bf94295a66e,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-7639cdcb-187d-4a91-8031-b3cf3e98ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-0009c770-c7e4-4784-ac29-6d044b0cabc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-ed667aa5-a452-483f-84a5-9f32b92703ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-90d6fc73-f819-4259-a46e-67beef02e445,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-5f2c44fb-1751-4e6d-a938-2a3b4cd89abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73666204-172.17.0.16-1595513361279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34080,DS-b785bd8c-85b1-4f20-8a81-eb7bc5c8d225,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-355dc6f9-096a-4b5a-b21e-eea63987cf23,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-ab95db8f-483c-48fd-9492-4bf94295a66e,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-7639cdcb-187d-4a91-8031-b3cf3e98ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-0009c770-c7e4-4784-ac29-6d044b0cabc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-ed667aa5-a452-483f-84a5-9f32b92703ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-90d6fc73-f819-4259-a46e-67beef02e445,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-5f2c44fb-1751-4e6d-a938-2a3b4cd89abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721695060-172.17.0.16-1595513389215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-6e95afcc-7700-47aa-9588-e2f66765a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-2b4d4d97-fc0f-4101-ae13-f285a319d3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-4ec0bdb6-a65f-4f5b-9a56-84f72b029ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-feb54290-a864-45c4-ae0d-14933d7ae3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-0fd2412a-eb60-4189-865e-6ecc50fbffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-ca0a2e76-34f2-46e7-a076-dc08ee1510d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-62201410-485c-437f-92fb-52724afad074,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-fb25a16a-1c1c-4344-805e-149b0e6c80cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721695060-172.17.0.16-1595513389215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-6e95afcc-7700-47aa-9588-e2f66765a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-2b4d4d97-fc0f-4101-ae13-f285a319d3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-4ec0bdb6-a65f-4f5b-9a56-84f72b029ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-feb54290-a864-45c4-ae0d-14933d7ae3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-0fd2412a-eb60-4189-865e-6ecc50fbffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-ca0a2e76-34f2-46e7-a076-dc08ee1510d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-62201410-485c-437f-92fb-52724afad074,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-fb25a16a-1c1c-4344-805e-149b0e6c80cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056197852-172.17.0.16-1595513556539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39675,DS-a24d0468-7695-4e71-9550-4ad508281793,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-722fb60b-f249-441d-b78d-4e5a3ac8c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-e1f8f437-2960-4325-a891-1d5f0b786a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-65db2aa2-527d-4603-a4ea-f2c1d315596e,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-7e38464e-41ff-43e2-a465-04bb3d3bbd83,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-8c40df65-2d70-4330-9919-05d295aac9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-1bca0967-2194-4e15-97f7-f70b1d8561ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-2a990b0e-7b6b-4534-97fa-7902867d4473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056197852-172.17.0.16-1595513556539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39675,DS-a24d0468-7695-4e71-9550-4ad508281793,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-722fb60b-f249-441d-b78d-4e5a3ac8c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-e1f8f437-2960-4325-a891-1d5f0b786a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-65db2aa2-527d-4603-a4ea-f2c1d315596e,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-7e38464e-41ff-43e2-a465-04bb3d3bbd83,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-8c40df65-2d70-4330-9919-05d295aac9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-1bca0967-2194-4e15-97f7-f70b1d8561ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-2a990b0e-7b6b-4534-97fa-7902867d4473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551721150-172.17.0.16-1595513813611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-e9817fc9-dd27-499d-abc9-adb8847ca0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-dea051d0-0973-4643-ba8a-14b90e3920d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-4bee30b0-f994-40b7-99ce-e8e153967698,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-0f4addf8-c30b-43f7-b411-d25425dcbe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-4cff8e4e-2d71-426a-b16b-ecd64c1a6367,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-0a1bcb89-696e-451a-9cd8-bbac812346d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-8e047376-793f-4882-8b60-3cc719d08875,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-c5867443-fd17-4145-b2bb-12a8cb413d0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551721150-172.17.0.16-1595513813611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-e9817fc9-dd27-499d-abc9-adb8847ca0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-dea051d0-0973-4643-ba8a-14b90e3920d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-4bee30b0-f994-40b7-99ce-e8e153967698,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-0f4addf8-c30b-43f7-b411-d25425dcbe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-4cff8e4e-2d71-426a-b16b-ecd64c1a6367,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-0a1bcb89-696e-451a-9cd8-bbac812346d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-8e047376-793f-4882-8b60-3cc719d08875,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-c5867443-fd17-4145-b2bb-12a8cb413d0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457876736-172.17.0.16-1595514224586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33919,DS-4d7ea3c5-abbb-48a8-9e66-057ddca59522,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-cfa2c48a-0623-423b-a078-410ba0e5efe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-bd8a81be-fc9f-42c5-b79c-6058b09ead7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-974af562-de06-4509-a826-eb12c47909be,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-cf1f67d9-1839-4f97-9436-06a94029fe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-1e737eb5-74e3-44bb-9d75-3cccac836d30,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-67a6c02c-fc31-48e6-9f74-894d9ab43ade,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-02bff4fe-f4de-4509-bf2b-56d09a829ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457876736-172.17.0.16-1595514224586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33919,DS-4d7ea3c5-abbb-48a8-9e66-057ddca59522,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-cfa2c48a-0623-423b-a078-410ba0e5efe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-bd8a81be-fc9f-42c5-b79c-6058b09ead7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-974af562-de06-4509-a826-eb12c47909be,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-cf1f67d9-1839-4f97-9436-06a94029fe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-1e737eb5-74e3-44bb-9d75-3cccac836d30,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-67a6c02c-fc31-48e6-9f74-894d9ab43ade,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-02bff4fe-f4de-4509-bf2b-56d09a829ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63946097-172.17.0.16-1595514676851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-5f8018e6-48a7-4224-93fa-7b6c56a5516c,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-554cdb0c-f90d-4b6f-b85d-c4a81ee0f759,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-85c4df23-80f4-4843-b1b8-b39353583dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-812ead7a-6e11-437f-9d31-81622e8659d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-7f4f5a48-e118-41bf-bfb8-f8d42bb3fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-6e7d52cd-c230-42da-82de-f99d7b5e749b,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-40af267a-f79c-4e21-8379-c27f2406c511,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-ec9fa6c9-9328-4523-bf97-f90af98d0761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63946097-172.17.0.16-1595514676851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-5f8018e6-48a7-4224-93fa-7b6c56a5516c,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-554cdb0c-f90d-4b6f-b85d-c4a81ee0f759,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-85c4df23-80f4-4843-b1b8-b39353583dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-812ead7a-6e11-437f-9d31-81622e8659d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-7f4f5a48-e118-41bf-bfb8-f8d42bb3fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-6e7d52cd-c230-42da-82de-f99d7b5e749b,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-40af267a-f79c-4e21-8379-c27f2406c511,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-ec9fa6c9-9328-4523-bf97-f90af98d0761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5759
