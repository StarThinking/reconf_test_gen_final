reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301531682-172.17.0.8-1595688219805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32822,DS-f3d0df1a-1c2b-447b-9f5f-526e2ab8b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-9d36830c-d451-4c1f-a192-86b1c9db8b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-8b4a9897-fa1e-4b9d-8233-2628587b16a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-04b74eb6-842a-457e-b798-35b4d14ee371,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-a7c9eca5-d097-40bd-8043-10a05738323c,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-98cb57bc-05bd-486f-bb42-a851993deaca,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-f9824a66-5e16-4be3-bc38-298caeb5ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-ff3e4732-c000-4ce9-b834-76eec564afed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301531682-172.17.0.8-1595688219805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32822,DS-f3d0df1a-1c2b-447b-9f5f-526e2ab8b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-9d36830c-d451-4c1f-a192-86b1c9db8b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-8b4a9897-fa1e-4b9d-8233-2628587b16a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-04b74eb6-842a-457e-b798-35b4d14ee371,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-a7c9eca5-d097-40bd-8043-10a05738323c,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-98cb57bc-05bd-486f-bb42-a851993deaca,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-f9824a66-5e16-4be3-bc38-298caeb5ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-ff3e4732-c000-4ce9-b834-76eec564afed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996337661-172.17.0.8-1595688417745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-5fdea36d-134b-4ab3-a55c-704d45316290,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-c4ec1c0b-9336-4ec4-b632-0b1cb959b6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-b7e5925e-881b-465c-abd0-f817782c1113,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-72e48792-c6d1-444f-95d9-2c14214aff43,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-3b4dcf49-9bc8-4ed2-b631-dda9f9c73850,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-b8b8297e-4f4c-4e3a-a4fe-bc697db56a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-7954bb59-69a5-4a67-b170-5edcb8d6df0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-ead1a768-888a-4f4b-a0c1-d196ecef6768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996337661-172.17.0.8-1595688417745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-5fdea36d-134b-4ab3-a55c-704d45316290,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-c4ec1c0b-9336-4ec4-b632-0b1cb959b6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-b7e5925e-881b-465c-abd0-f817782c1113,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-72e48792-c6d1-444f-95d9-2c14214aff43,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-3b4dcf49-9bc8-4ed2-b631-dda9f9c73850,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-b8b8297e-4f4c-4e3a-a4fe-bc697db56a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-7954bb59-69a5-4a67-b170-5edcb8d6df0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-ead1a768-888a-4f4b-a0c1-d196ecef6768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880819865-172.17.0.8-1595688454145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35004,DS-59f56db6-887a-4b4c-9522-42e17558221e,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-ae96e216-37bd-4b6b-97d8-0b9ff354a6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-43844304-4151-4960-ac71-4a9a7503b623,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-f1eb700a-d4b9-4658-9ad6-b5f9bfdda2df,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-a2e850f2-aff2-43a1-b700-ddfb81b27d22,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-525973fa-aab9-46ab-95a5-0ffc1ba0ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-dd926e17-7f2b-4e38-b1d5-873f6820f961,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-9b1256dc-4e68-4ec8-b0d6-b9069452eeb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880819865-172.17.0.8-1595688454145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35004,DS-59f56db6-887a-4b4c-9522-42e17558221e,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-ae96e216-37bd-4b6b-97d8-0b9ff354a6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-43844304-4151-4960-ac71-4a9a7503b623,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-f1eb700a-d4b9-4658-9ad6-b5f9bfdda2df,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-a2e850f2-aff2-43a1-b700-ddfb81b27d22,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-525973fa-aab9-46ab-95a5-0ffc1ba0ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-dd926e17-7f2b-4e38-b1d5-873f6820f961,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-9b1256dc-4e68-4ec8-b0d6-b9069452eeb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500691227-172.17.0.8-1595688517754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-dfd802e7-4f52-4d1e-a1d6-51a231d06b10,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-cf4268ce-14de-463e-b2fa-d748037e8775,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-e83362bb-c23f-43c2-9b1d-9fc2e0b2c005,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-2e55904b-91c1-47cb-85e4-0c6ecd6f6b36,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-f1475ee1-57ca-4de9-985b-9620a858fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-b03fdbae-84c1-43c2-b33f-49b64341c58b,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-3bbc5f4d-8a38-421a-a6f4-8ded051cbca2,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-293e9c36-1018-4afc-b6fe-ddd73e0ca3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500691227-172.17.0.8-1595688517754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-dfd802e7-4f52-4d1e-a1d6-51a231d06b10,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-cf4268ce-14de-463e-b2fa-d748037e8775,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-e83362bb-c23f-43c2-9b1d-9fc2e0b2c005,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-2e55904b-91c1-47cb-85e4-0c6ecd6f6b36,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-f1475ee1-57ca-4de9-985b-9620a858fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-b03fdbae-84c1-43c2-b33f-49b64341c58b,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-3bbc5f4d-8a38-421a-a6f4-8ded051cbca2,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-293e9c36-1018-4afc-b6fe-ddd73e0ca3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038531597-172.17.0.8-1595688952806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-85705777-da77-4bcf-8c92-dddcd31831c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-433e0a61-806b-41cb-aa74-c4cc12e3e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-4e316658-0e6e-4019-ba15-2d48a751ee19,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-778f84ed-fa4d-472c-894b-f399ae0f6cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-504831b1-31ba-4b0a-b1f3-b27a84a1b737,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-92c256dd-a778-4f23-a4eb-8ecb55877cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-da4ec377-6692-417c-a194-894eba184c69,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-bb9aca78-b233-48ae-8407-a03e4d763c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038531597-172.17.0.8-1595688952806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-85705777-da77-4bcf-8c92-dddcd31831c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-433e0a61-806b-41cb-aa74-c4cc12e3e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-4e316658-0e6e-4019-ba15-2d48a751ee19,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-778f84ed-fa4d-472c-894b-f399ae0f6cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-504831b1-31ba-4b0a-b1f3-b27a84a1b737,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-92c256dd-a778-4f23-a4eb-8ecb55877cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-da4ec377-6692-417c-a194-894eba184c69,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-bb9aca78-b233-48ae-8407-a03e4d763c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387186197-172.17.0.8-1595689054311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-68fbc802-c209-4355-9df1-25d8c8892d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-d8faa290-6b0b-4694-8d1e-b060d0502668,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-f51d3b36-fab7-4b55-9d28-080885c57607,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-71b621a2-7335-476f-8747-c9464334a00a,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-0d9a01f0-8736-4e9c-8f3b-9799857e2ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-6eff1954-58a8-4d95-a324-c5cc911d6f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-05b98711-555e-4b26-9cbc-3560bb29ba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-99b46fe4-9049-44de-bd2a-bc3433083aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387186197-172.17.0.8-1595689054311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-68fbc802-c209-4355-9df1-25d8c8892d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-d8faa290-6b0b-4694-8d1e-b060d0502668,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-f51d3b36-fab7-4b55-9d28-080885c57607,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-71b621a2-7335-476f-8747-c9464334a00a,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-0d9a01f0-8736-4e9c-8f3b-9799857e2ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-6eff1954-58a8-4d95-a324-c5cc911d6f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-05b98711-555e-4b26-9cbc-3560bb29ba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-99b46fe4-9049-44de-bd2a-bc3433083aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327799528-172.17.0.8-1595689848410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33308,DS-9814c4e2-444b-478e-805e-2d905285dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-220b012d-bd1a-498f-821b-ab1db358e739,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-930cf011-d892-40d9-befc-75c81c13654d,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-ff938842-9fe6-4d4d-aeea-fdc4a723dff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-9863082f-beb2-4854-a597-03f59b3f8d24,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-f43f6bce-6835-413f-9c26-f7e8a35e0273,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-b6609ac7-2675-463c-ae3a-0dc9020a53b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-094ec690-2a67-404b-90f4-7aed08fa7b9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327799528-172.17.0.8-1595689848410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33308,DS-9814c4e2-444b-478e-805e-2d905285dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-220b012d-bd1a-498f-821b-ab1db358e739,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-930cf011-d892-40d9-befc-75c81c13654d,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-ff938842-9fe6-4d4d-aeea-fdc4a723dff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-9863082f-beb2-4854-a597-03f59b3f8d24,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-f43f6bce-6835-413f-9c26-f7e8a35e0273,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-b6609ac7-2675-463c-ae3a-0dc9020a53b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-094ec690-2a67-404b-90f4-7aed08fa7b9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273554959-172.17.0.8-1595689978385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35685,DS-07b7e528-ac4a-4c23-b5f9-82c7baaca107,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-e5be37d5-28b2-4d54-8839-d4f0395277f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-5222e925-b9a4-4c2e-9d31-1a9cd0c6ca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-2ae769c9-5bff-459d-9ef2-b344467998f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-a1b94316-9b09-465b-bb50-587f4b444583,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-b0e074ba-4931-4ff6-a2b4-63ad364bae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-c9136ea3-eb8c-42af-ad33-e8f1eea366f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-492121c2-8333-4b5b-8a3b-5192506e753a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273554959-172.17.0.8-1595689978385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35685,DS-07b7e528-ac4a-4c23-b5f9-82c7baaca107,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-e5be37d5-28b2-4d54-8839-d4f0395277f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-5222e925-b9a4-4c2e-9d31-1a9cd0c6ca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-2ae769c9-5bff-459d-9ef2-b344467998f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-a1b94316-9b09-465b-bb50-587f4b444583,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-b0e074ba-4931-4ff6-a2b4-63ad364bae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-c9136ea3-eb8c-42af-ad33-e8f1eea366f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-492121c2-8333-4b5b-8a3b-5192506e753a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598518733-172.17.0.8-1595690680886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-d8ec4a6d-3402-4811-bfbb-13d2b6af16df,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-7f6117ee-86ca-465e-9ef3-69288fce6194,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-821e42ef-113f-4162-abd3-6f73866c7d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-2c0c0d4c-79de-4a63-a0b2-23edd332baec,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-d2187a8e-e8af-47b0-a896-88ed5f75fc78,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-727a7d93-5248-4bc1-8253-b57ac3827b61,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-9e5ea8ab-cf10-4e25-8f76-02cc8a2945c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-d50bae4d-d8c8-4c06-a339-bb2d7a678930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598518733-172.17.0.8-1595690680886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-d8ec4a6d-3402-4811-bfbb-13d2b6af16df,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-7f6117ee-86ca-465e-9ef3-69288fce6194,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-821e42ef-113f-4162-abd3-6f73866c7d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-2c0c0d4c-79de-4a63-a0b2-23edd332baec,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-d2187a8e-e8af-47b0-a896-88ed5f75fc78,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-727a7d93-5248-4bc1-8253-b57ac3827b61,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-9e5ea8ab-cf10-4e25-8f76-02cc8a2945c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-d50bae4d-d8c8-4c06-a339-bb2d7a678930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130588742-172.17.0.8-1595690820170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34515,DS-1c98c01a-1b67-4fd5-8fa0-94ea3c3d85ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-590eb5c6-b333-457e-b242-57689579bc26,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-bf7d4a80-3d6b-42b9-aef1-f4b884ccf6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-bdd03705-c9ab-41e0-84ec-37bc1b162c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-0d93e8f6-f6be-4616-a701-f8ccbd019dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-4d8aba79-2b49-4ed3-8ad3-bd64c4d39871,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-d8d0a928-5950-495c-ab56-213c07b7af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-655ec302-3f2d-4cf1-9f5c-63411b7ac2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130588742-172.17.0.8-1595690820170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34515,DS-1c98c01a-1b67-4fd5-8fa0-94ea3c3d85ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-590eb5c6-b333-457e-b242-57689579bc26,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-bf7d4a80-3d6b-42b9-aef1-f4b884ccf6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-bdd03705-c9ab-41e0-84ec-37bc1b162c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-0d93e8f6-f6be-4616-a701-f8ccbd019dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-4d8aba79-2b49-4ed3-8ad3-bd64c4d39871,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-d8d0a928-5950-495c-ab56-213c07b7af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-655ec302-3f2d-4cf1-9f5c-63411b7ac2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967982337-172.17.0.8-1595691122464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44539,DS-0df9e9b9-8a5c-497e-a768-d829bf171224,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-e4e674a1-2451-4585-814d-6472440642fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-72729414-699e-4c6c-ab88-fdf4fe2f383f,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-851e2978-7d7a-4ff3-8646-2aab13795a95,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-252e012b-233b-44da-b6f5-cde7eaa624e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-655d4837-9aa7-4d34-8509-d8e1258558a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-217043b2-ebc3-480b-ba92-139912484842,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-c8cd194d-85ef-498b-888e-80f7b2f54e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967982337-172.17.0.8-1595691122464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44539,DS-0df9e9b9-8a5c-497e-a768-d829bf171224,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-e4e674a1-2451-4585-814d-6472440642fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-72729414-699e-4c6c-ab88-fdf4fe2f383f,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-851e2978-7d7a-4ff3-8646-2aab13795a95,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-252e012b-233b-44da-b6f5-cde7eaa624e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-655d4837-9aa7-4d34-8509-d8e1258558a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-217043b2-ebc3-480b-ba92-139912484842,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-c8cd194d-85ef-498b-888e-80f7b2f54e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784723916-172.17.0.8-1595691435580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34201,DS-7f3e2105-a9f0-4433-af2f-6fd0ae346f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-4db51a82-7968-4372-b321-611a74f18d59,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-eb689bbf-b6cf-438a-98e1-99dec2a63854,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-27e77b14-f1ae-4e5e-aa5f-c76f6b910d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-9966ab23-bd96-49de-b0e9-fec16504d478,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-fda46045-321c-4720-9def-ad0be2e3a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-51a7ec6f-9461-4ca6-a5e3-8d5cd1765fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-f07bd5df-6e9d-40b6-a01c-687066cbcd30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784723916-172.17.0.8-1595691435580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34201,DS-7f3e2105-a9f0-4433-af2f-6fd0ae346f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-4db51a82-7968-4372-b321-611a74f18d59,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-eb689bbf-b6cf-438a-98e1-99dec2a63854,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-27e77b14-f1ae-4e5e-aa5f-c76f6b910d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-9966ab23-bd96-49de-b0e9-fec16504d478,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-fda46045-321c-4720-9def-ad0be2e3a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-51a7ec6f-9461-4ca6-a5e3-8d5cd1765fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-f07bd5df-6e9d-40b6-a01c-687066cbcd30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114912016-172.17.0.8-1595691577439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-f1549b71-e384-412e-ae1b-ff558a5737a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-b4d2faa9-61dd-4082-a611-e6d696519988,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-c097a547-7665-4193-b04d-6a6125862cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-57291c11-b002-4aa9-bec3-2c55ff9cbe52,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-bced856d-129a-434c-bd36-b3b0f449f9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-88930afb-3ff6-4d19-893e-ef7422a90141,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-2c049400-1876-48af-93ce-a4e42725ed76,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-20d28841-12cb-4925-9970-45fc12405328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114912016-172.17.0.8-1595691577439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-f1549b71-e384-412e-ae1b-ff558a5737a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-b4d2faa9-61dd-4082-a611-e6d696519988,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-c097a547-7665-4193-b04d-6a6125862cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-57291c11-b002-4aa9-bec3-2c55ff9cbe52,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-bced856d-129a-434c-bd36-b3b0f449f9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-88930afb-3ff6-4d19-893e-ef7422a90141,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-2c049400-1876-48af-93ce-a4e42725ed76,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-20d28841-12cb-4925-9970-45fc12405328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687452053-172.17.0.8-1595691688246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38775,DS-24dd0e8e-6602-4b0c-adea-082332522d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6fc382ac-894d-493f-80d7-9450f2002460,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-34e5f6c4-c658-43a5-88b4-76e07d83f30b,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-7e31e996-61ca-44be-8f28-851a6b6bbd12,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-0dedebe4-1cca-4ce0-beb3-2cdbd8a34126,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-b713c947-1eda-4a24-a1a3-dda32c723fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-9ba7f1e7-48cf-491e-9dc9-fefdd880e113,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-e84f8676-5045-4eac-9758-56a1da75ec32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687452053-172.17.0.8-1595691688246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38775,DS-24dd0e8e-6602-4b0c-adea-082332522d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6fc382ac-894d-493f-80d7-9450f2002460,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-34e5f6c4-c658-43a5-88b4-76e07d83f30b,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-7e31e996-61ca-44be-8f28-851a6b6bbd12,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-0dedebe4-1cca-4ce0-beb3-2cdbd8a34126,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-b713c947-1eda-4a24-a1a3-dda32c723fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-9ba7f1e7-48cf-491e-9dc9-fefdd880e113,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-e84f8676-5045-4eac-9758-56a1da75ec32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194846406-172.17.0.8-1595691730096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43104,DS-402e4363-eb8d-4ee4-844a-43d271e650e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-8a56b661-7d83-439a-a6c3-dbccbc70eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-8dec3222-f827-4551-9a0f-6d4a69d74a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-af59156a-bdd4-4185-b52f-ed7cbc65ac27,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-319f2ca6-9e67-4354-9e3c-0f0a70726652,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-ccbd9301-de2c-4edb-9f4d-333bc5dcbf78,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-87c4aaf7-17a3-49ea-9c06-4d6be59a8013,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-dca4f217-940f-4bbe-a0d2-79b5cf8701e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194846406-172.17.0.8-1595691730096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43104,DS-402e4363-eb8d-4ee4-844a-43d271e650e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-8a56b661-7d83-439a-a6c3-dbccbc70eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-8dec3222-f827-4551-9a0f-6d4a69d74a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-af59156a-bdd4-4185-b52f-ed7cbc65ac27,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-319f2ca6-9e67-4354-9e3c-0f0a70726652,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-ccbd9301-de2c-4edb-9f4d-333bc5dcbf78,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-87c4aaf7-17a3-49ea-9c06-4d6be59a8013,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-dca4f217-940f-4bbe-a0d2-79b5cf8701e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323841798-172.17.0.8-1595691964240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33320,DS-f53f7ee6-ce77-443a-8cca-bb9df8db78f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-bbce9a1a-e7ca-45b2-9cf4-802a4e3fe854,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-7a71d7e9-ba72-4a96-949c-6e2f176afe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-0ca98d30-46d4-4136-8f55-ef5dc0083b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-7f0de0c9-d92a-4dd7-9e4a-bc92f3e5cc58,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-284e94fc-63f9-4af1-ad99-df67eb7aac56,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-9b3e6257-ae06-49c2-bf4f-02b3c7152902,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-b1a622b9-9917-4fb5-91e3-0c36d089a048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323841798-172.17.0.8-1595691964240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33320,DS-f53f7ee6-ce77-443a-8cca-bb9df8db78f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-bbce9a1a-e7ca-45b2-9cf4-802a4e3fe854,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-7a71d7e9-ba72-4a96-949c-6e2f176afe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-0ca98d30-46d4-4136-8f55-ef5dc0083b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-7f0de0c9-d92a-4dd7-9e4a-bc92f3e5cc58,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-284e94fc-63f9-4af1-ad99-df67eb7aac56,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-9b3e6257-ae06-49c2-bf4f-02b3c7152902,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-b1a622b9-9917-4fb5-91e3-0c36d089a048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623617091-172.17.0.8-1595692071857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46635,DS-25e04c26-0c1d-4f6f-a5ee-8fd007e56308,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-a14fc362-1c24-4172-a53f-bfeb60790bac,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-b49e6353-be1f-4139-b2d5-265c24dab811,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-55c98122-2c2d-4697-bcaa-829d1d1e0eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-973c4332-4f37-466a-96ce-796d5853fe64,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-d78495e0-f4e8-45fd-88d5-8cc787834ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-41b766e8-3457-4405-b39c-516b49cdd58e,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-e7ed58e6-a575-46e8-96ab-12f3ef8b0568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623617091-172.17.0.8-1595692071857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46635,DS-25e04c26-0c1d-4f6f-a5ee-8fd007e56308,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-a14fc362-1c24-4172-a53f-bfeb60790bac,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-b49e6353-be1f-4139-b2d5-265c24dab811,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-55c98122-2c2d-4697-bcaa-829d1d1e0eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-973c4332-4f37-466a-96ce-796d5853fe64,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-d78495e0-f4e8-45fd-88d5-8cc787834ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-41b766e8-3457-4405-b39c-516b49cdd58e,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-e7ed58e6-a575-46e8-96ab-12f3ef8b0568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969458078-172.17.0.8-1595692794815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37636,DS-4ba96d86-b793-407b-85a7-47609949b284,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-26694088-51be-49b4-988d-b8f0ee68ed31,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-fda356ae-cb91-4a09-8d70-4bc5ab1ce6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-8445c7ce-3a5c-4714-b12b-04d7d0506e04,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-17e49875-bd67-4eb6-803e-13b4820b40c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-103560e3-f84b-4b23-b887-3d2ff5fe51c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-acd3e4bb-6bf0-4040-997e-c1483de568f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-feef5b9f-fb8f-4d18-9c06-122dd2ebd409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969458078-172.17.0.8-1595692794815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37636,DS-4ba96d86-b793-407b-85a7-47609949b284,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-26694088-51be-49b4-988d-b8f0ee68ed31,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-fda356ae-cb91-4a09-8d70-4bc5ab1ce6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-8445c7ce-3a5c-4714-b12b-04d7d0506e04,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-17e49875-bd67-4eb6-803e-13b4820b40c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-103560e3-f84b-4b23-b887-3d2ff5fe51c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-acd3e4bb-6bf0-4040-997e-c1483de568f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-feef5b9f-fb8f-4d18-9c06-122dd2ebd409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047161814-172.17.0.8-1595692889821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43607,DS-cf1866ba-c268-45b9-801c-3d93c98da2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-e2a4b14b-b862-4e28-be4c-276aa9e6bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-0bd817f1-d3cc-40ef-89a4-6eef1eab0890,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-f742e5c2-69ec-4074-8f02-936491408b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-ccb286f4-cd79-4a00-b218-398189217752,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-9ceab666-a82b-4a9a-b2fe-8260f7d670f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-df881e43-432d-4f56-a9a6-69bbd132e8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-584d0d9b-fcc4-4bcf-a5ee-3db33e9b0a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047161814-172.17.0.8-1595692889821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43607,DS-cf1866ba-c268-45b9-801c-3d93c98da2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-e2a4b14b-b862-4e28-be4c-276aa9e6bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-0bd817f1-d3cc-40ef-89a4-6eef1eab0890,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-f742e5c2-69ec-4074-8f02-936491408b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-ccb286f4-cd79-4a00-b218-398189217752,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-9ceab666-a82b-4a9a-b2fe-8260f7d670f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-df881e43-432d-4f56-a9a6-69bbd132e8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-584d0d9b-fcc4-4bcf-a5ee-3db33e9b0a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80913050-172.17.0.8-1595693021712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-df76063b-9f5c-4c11-81df-041f529a8ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-80bf49ce-9f11-4337-b677-bd13d416323b,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-41c3b472-ff97-491c-91d6-a336db20e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-c63cc141-9491-48e2-85aa-ebf510f84553,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-e83fc41a-33aa-47b8-815a-7efd99b2c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-0b4b0ab9-9222-4c78-8e8c-cfca8454a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-002ba716-2d53-45da-b612-a0f83957afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-5cef38de-374f-4b71-9db0-c2e518c5e131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80913050-172.17.0.8-1595693021712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-df76063b-9f5c-4c11-81df-041f529a8ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-80bf49ce-9f11-4337-b677-bd13d416323b,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-41c3b472-ff97-491c-91d6-a336db20e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-c63cc141-9491-48e2-85aa-ebf510f84553,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-e83fc41a-33aa-47b8-815a-7efd99b2c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-0b4b0ab9-9222-4c78-8e8c-cfca8454a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-002ba716-2d53-45da-b612-a0f83957afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-5cef38de-374f-4b71-9db0-c2e518c5e131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5104
